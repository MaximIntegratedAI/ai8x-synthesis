2023-04-16 22:42:43,351 - Log file for this run: /home/seldauyanik/Workspace/ai8x-training/logs/2023.04.16-224243/2023.04.16-224243.log
2023-04-16 22:42:45,919 - Optimizer Type: <class 'torch.optim.adam.Adam'>
2023-04-16 22:42:45,919 - Optimizer Args: {'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 1e-06, 'amsgrad': False}
2023-04-16 22:42:45,948 - Dataset sizes:
	training=16551
	validation=4952
	test=4952
2023-04-16 22:42:45,948 - Reading compression schedule from: policies/schedule-pascalvoc.yaml
2023-04-16 22:42:45,952 - 

2023-04-16 22:42:45,952 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-16 22:42:57,173 - Epoch: [0][   50/  518]    Overall Loss 8.237191    Objective Loss 8.237191                                        LR 0.001000    Time 0.224378    
2023-04-16 22:43:07,288 - Epoch: [0][  100/  518]    Overall Loss 7.115329    Objective Loss 7.115329                                        LR 0.001000    Time 0.213325    
2023-04-16 22:43:17,265 - Epoch: [0][  150/  518]    Overall Loss 6.693707    Objective Loss 6.693707                                        LR 0.001000    Time 0.208719    
2023-04-16 22:43:27,318 - Epoch: [0][  200/  518]    Overall Loss 6.473962    Objective Loss 6.473962                                        LR 0.001000    Time 0.206796    
2023-04-16 22:43:37,358 - Epoch: [0][  250/  518]    Overall Loss 6.329215    Objective Loss 6.329215                                        LR 0.001000    Time 0.205587    
2023-04-16 22:43:47,472 - Epoch: [0][  300/  518]    Overall Loss 6.226711    Objective Loss 6.226711                                        LR 0.001000    Time 0.205033    
2023-04-16 22:43:57,577 - Epoch: [0][  350/  518]    Overall Loss 6.149803    Objective Loss 6.149803                                        LR 0.001000    Time 0.204608    
2023-04-16 22:44:07,567 - Epoch: [0][  400/  518]    Overall Loss 6.089528    Objective Loss 6.089528                                        LR 0.001000    Time 0.204005    
2023-04-16 22:44:17,616 - Epoch: [0][  450/  518]    Overall Loss 6.032137    Objective Loss 6.032137                                        LR 0.001000    Time 0.203665    
2023-04-16 22:44:27,651 - Epoch: [0][  500/  518]    Overall Loss 5.983904    Objective Loss 5.983904                                        LR 0.001000    Time 0.203365    
2023-04-16 22:44:31,135 - Epoch: [0][  518/  518]    Overall Loss 5.969994    Objective Loss 5.969994                                        LR 0.001000    Time 0.203023    
2023-04-16 22:44:31,212 - --- validate (epoch=0)-----------
2023-04-16 22:44:31,212 - 4952 samples (32 per mini-batch)
2023-04-16 22:44:31,645 - indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/IndexingUtils.h:30.)

2023-04-16 22:44:31,646 - indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/IndexingUtils.h:30.)

2023-04-16 22:45:36,143 - Epoch: [0][   50/  155]    Loss 5.599827    mAP 0.014746    
2023-04-16 22:46:39,627 - Epoch: [0][  100/  155]    Loss 5.639605    mAP 0.013765    
2023-04-16 22:47:43,302 - Epoch: [0][  150/  155]    Loss 5.632133    mAP 0.013772    
2023-04-16 22:47:49,161 - Epoch: [0][  155/  155]    Loss 5.629184    mAP 0.013548    
2023-04-16 22:47:49,241 - ==> mAP: 0.01355    Loss: 5.629

2023-04-16 22:47:49,244 - ==> Best [mAP: 0.013548   vloss: 5.629184   Sparsity:0.00   Params: 2177088 on epoch: 0]
2023-04-16 22:47:49,244 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-16 22:47:49,283 - 

2023-04-16 22:47:49,283 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-16 22:48:00,222 - Epoch: [1][   50/  518]    Overall Loss 5.441087    Objective Loss 5.441087                                        LR 0.001000    Time 0.218726    
2023-04-16 22:48:10,456 - Epoch: [1][  100/  518]    Overall Loss 5.430060    Objective Loss 5.430060                                        LR 0.001000    Time 0.211686    
2023-04-16 22:48:20,620 - Epoch: [1][  150/  518]    Overall Loss 5.445517    Objective Loss 5.445517                                        LR 0.001000    Time 0.208872    
2023-04-16 22:48:31,095 - Epoch: [1][  200/  518]    Overall Loss 5.451118    Objective Loss 5.451118                                        LR 0.001000    Time 0.209023    
2023-04-16 22:48:41,341 - Epoch: [1][  250/  518]    Overall Loss 5.434522    Objective Loss 5.434522                                        LR 0.001000    Time 0.208195    
2023-04-16 22:48:51,593 - Epoch: [1][  300/  518]    Overall Loss 5.411199    Objective Loss 5.411199                                        LR 0.001000    Time 0.207663    
2023-04-16 22:49:01,735 - Epoch: [1][  350/  518]    Overall Loss 5.399736    Objective Loss 5.399736                                        LR 0.001000    Time 0.206971    
2023-04-16 22:49:11,938 - Epoch: [1][  400/  518]    Overall Loss 5.379289    Objective Loss 5.379289                                        LR 0.001000    Time 0.206602    
2023-04-16 22:49:22,033 - Epoch: [1][  450/  518]    Overall Loss 5.363777    Objective Loss 5.363777                                        LR 0.001000    Time 0.206077    
2023-04-16 22:49:32,222 - Epoch: [1][  500/  518]    Overall Loss 5.348303    Objective Loss 5.348303                                        LR 0.001000    Time 0.205844    
2023-04-16 22:49:35,727 - Epoch: [1][  518/  518]    Overall Loss 5.345273    Objective Loss 5.345273                                        LR 0.001000    Time 0.205457    
2023-04-16 22:49:35,810 - --- validate (epoch=1)-----------
2023-04-16 22:49:35,810 - 4952 samples (32 per mini-batch)
2023-04-16 22:51:03,424 - Epoch: [1][   50/  155]    Loss 5.441351    mAP 0.039561    
2023-04-16 22:52:31,212 - Epoch: [1][  100/  155]    Loss 5.427170    mAP 0.039614    
2023-04-16 22:53:58,860 - Epoch: [1][  150/  155]    Loss 5.411219    mAP 0.039513    
2023-04-16 22:54:07,497 - Epoch: [1][  155/  155]    Loss 5.412885    mAP 0.040342    
2023-04-16 22:54:07,577 - ==> mAP: 0.04034    Loss: 5.413

2023-04-16 22:54:07,581 - ==> Best [mAP: 0.040342   vloss: 5.412885   Sparsity:0.00   Params: 2177088 on epoch: 1]
2023-04-16 22:54:07,581 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-16 22:54:07,634 - 

2023-04-16 22:54:07,634 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-16 22:54:18,465 - Epoch: [2][   50/  518]    Overall Loss 5.187617    Objective Loss 5.187617                                        LR 0.001000    Time 0.216563    
2023-04-16 22:54:28,699 - Epoch: [2][  100/  518]    Overall Loss 5.178783    Objective Loss 5.178783                                        LR 0.001000    Time 0.210606    
2023-04-16 22:54:38,845 - Epoch: [2][  150/  518]    Overall Loss 5.136059    Objective Loss 5.136059                                        LR 0.001000    Time 0.208034    
2023-04-16 22:54:48,924 - Epoch: [2][  200/  518]    Overall Loss 5.133342    Objective Loss 5.133342                                        LR 0.001000    Time 0.206411    
2023-04-16 22:54:58,952 - Epoch: [2][  250/  518]    Overall Loss 5.134025    Objective Loss 5.134025                                        LR 0.001000    Time 0.205238    
2023-04-16 22:55:09,108 - Epoch: [2][  300/  518]    Overall Loss 5.113637    Objective Loss 5.113637                                        LR 0.001000    Time 0.204879    
2023-04-16 22:55:19,280 - Epoch: [2][  350/  518]    Overall Loss 5.097106    Objective Loss 5.097106                                        LR 0.001000    Time 0.204670    
2023-04-16 22:55:29,785 - Epoch: [2][  400/  518]    Overall Loss 5.089794    Objective Loss 5.089794                                        LR 0.001000    Time 0.205344    
2023-04-16 22:55:40,175 - Epoch: [2][  450/  518]    Overall Loss 5.077323    Objective Loss 5.077323                                        LR 0.001000    Time 0.205613    
2023-04-16 22:55:50,306 - Epoch: [2][  500/  518]    Overall Loss 5.068526    Objective Loss 5.068526                                        LR 0.001000    Time 0.205311    
2023-04-16 22:55:53,840 - Epoch: [2][  518/  518]    Overall Loss 5.066222    Objective Loss 5.066222                                        LR 0.001000    Time 0.204999    
2023-04-16 22:55:53,921 - --- validate (epoch=2)-----------
2023-04-16 22:55:53,921 - 4952 samples (32 per mini-batch)
2023-04-16 22:57:23,565 - Epoch: [2][   50/  155]    Loss 5.398074    mAP 0.040189    
2023-04-16 22:58:52,887 - Epoch: [2][  100/  155]    Loss 5.363900    mAP 0.040710    
2023-04-16 23:00:21,048 - Epoch: [2][  150/  155]    Loss 5.369977    mAP 0.039912    
2023-04-16 23:00:29,303 - Epoch: [2][  155/  155]    Loss 5.371558    mAP 0.039666    
2023-04-16 23:00:29,380 - ==> mAP: 0.03967    Loss: 5.372

2023-04-16 23:00:29,384 - ==> Best [mAP: 0.040342   vloss: 5.412885   Sparsity:0.00   Params: 2177088 on epoch: 1]
2023-04-16 23:00:29,384 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-16 23:00:29,421 - 

2023-04-16 23:00:29,421 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-16 23:00:40,155 - Epoch: [3][   50/  518]    Overall Loss 4.998041    Objective Loss 4.998041                                        LR 0.001000    Time 0.214615    
2023-04-16 23:00:50,353 - Epoch: [3][  100/  518]    Overall Loss 4.998555    Objective Loss 4.998555                                        LR 0.001000    Time 0.209269    
2023-04-16 23:01:00,455 - Epoch: [3][  150/  518]    Overall Loss 4.958633    Objective Loss 4.958633                                        LR 0.001000    Time 0.206849    
2023-04-16 23:01:10,511 - Epoch: [3][  200/  518]    Overall Loss 4.936174    Objective Loss 4.936174                                        LR 0.001000    Time 0.205412    
2023-04-16 23:01:20,600 - Epoch: [3][  250/  518]    Overall Loss 4.908194    Objective Loss 4.908194                                        LR 0.001000    Time 0.204677    
2023-04-16 23:01:30,747 - Epoch: [3][  300/  518]    Overall Loss 4.912178    Objective Loss 4.912178                                        LR 0.001000    Time 0.204385    
2023-04-16 23:01:40,858 - Epoch: [3][  350/  518]    Overall Loss 4.903115    Objective Loss 4.903115                                        LR 0.001000    Time 0.204069    
2023-04-16 23:01:50,929 - Epoch: [3][  400/  518]    Overall Loss 4.899069    Objective Loss 4.899069                                        LR 0.001000    Time 0.203734    
2023-04-16 23:02:01,091 - Epoch: [3][  450/  518]    Overall Loss 4.888830    Objective Loss 4.888830                                        LR 0.001000    Time 0.203675    
2023-04-16 23:02:11,093 - Epoch: [3][  500/  518]    Overall Loss 4.884668    Objective Loss 4.884668                                        LR 0.001000    Time 0.203310    
2023-04-16 23:02:14,601 - Epoch: [3][  518/  518]    Overall Loss 4.882371    Objective Loss 4.882371                                        LR 0.001000    Time 0.203017    
2023-04-16 23:02:14,681 - --- validate (epoch=3)-----------
2023-04-16 23:02:14,682 - 4952 samples (32 per mini-batch)
2023-04-16 23:03:35,488 - Epoch: [3][   50/  155]    Loss 4.968530    mAP 0.121055    
2023-04-16 23:04:56,648 - Epoch: [3][  100/  155]    Loss 4.946941    mAP 0.121692    
2023-04-16 23:06:17,395 - Epoch: [3][  150/  155]    Loss 4.936594    mAP 0.120674    
2023-04-16 23:06:24,828 - Epoch: [3][  155/  155]    Loss 4.941592    mAP 0.119993    
2023-04-16 23:06:24,906 - ==> mAP: 0.11999    Loss: 4.942

2023-04-16 23:06:24,910 - ==> Best [mAP: 0.119993   vloss: 4.941592   Sparsity:0.00   Params: 2177088 on epoch: 3]
2023-04-16 23:06:24,910 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-16 23:06:24,962 - 

2023-04-16 23:06:24,963 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-16 23:06:35,807 - Epoch: [4][   50/  518]    Overall Loss 4.801500    Objective Loss 4.801500                                        LR 0.001000    Time 0.216823    
2023-04-16 23:06:45,877 - Epoch: [4][  100/  518]    Overall Loss 4.807311    Objective Loss 4.807311                                        LR 0.001000    Time 0.209098    
2023-04-16 23:06:56,029 - Epoch: [4][  150/  518]    Overall Loss 4.787132    Objective Loss 4.787132                                        LR 0.001000    Time 0.207072    
2023-04-16 23:07:06,064 - Epoch: [4][  200/  518]    Overall Loss 4.766682    Objective Loss 4.766682                                        LR 0.001000    Time 0.205469    
2023-04-16 23:07:16,180 - Epoch: [4][  250/  518]    Overall Loss 4.762650    Objective Loss 4.762650                                        LR 0.001000    Time 0.204834    
2023-04-16 23:07:26,274 - Epoch: [4][  300/  518]    Overall Loss 4.754578    Objective Loss 4.754578                                        LR 0.001000    Time 0.204336    
2023-04-16 23:07:36,341 - Epoch: [4][  350/  518]    Overall Loss 4.747921    Objective Loss 4.747921                                        LR 0.001000    Time 0.203904    
2023-04-16 23:07:46,434 - Epoch: [4][  400/  518]    Overall Loss 4.745812    Objective Loss 4.745812                                        LR 0.001000    Time 0.203645    
2023-04-16 23:07:56,516 - Epoch: [4][  450/  518]    Overall Loss 4.736337    Objective Loss 4.736337                                        LR 0.001000    Time 0.203417    
2023-04-16 23:08:06,662 - Epoch: [4][  500/  518]    Overall Loss 4.734571    Objective Loss 4.734571                                        LR 0.001000    Time 0.203366    
2023-04-16 23:08:10,174 - Epoch: [4][  518/  518]    Overall Loss 4.733552    Objective Loss 4.733552                                        LR 0.001000    Time 0.203077    
2023-04-16 23:08:10,253 - --- validate (epoch=4)-----------
2023-04-16 23:08:10,253 - 4952 samples (32 per mini-batch)
2023-04-16 23:09:32,349 - Epoch: [4][   50/  155]    Loss 5.281632    mAP 0.086739    
2023-04-16 23:10:54,352 - Epoch: [4][  100/  155]    Loss 5.270475    mAP 0.086936    
2023-04-16 23:12:16,646 - Epoch: [4][  150/  155]    Loss 5.282158    mAP 0.086675    
2023-04-16 23:12:24,554 - Epoch: [4][  155/  155]    Loss 5.284674    mAP 0.086555    
2023-04-16 23:12:24,633 - ==> mAP: 0.08656    Loss: 5.285

2023-04-16 23:12:24,637 - ==> Best [mAP: 0.119993   vloss: 4.941592   Sparsity:0.00   Params: 2177088 on epoch: 3]
2023-04-16 23:12:24,638 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-16 23:12:24,675 - 

2023-04-16 23:12:24,675 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-16 23:12:35,658 - Epoch: [5][   50/  518]    Overall Loss 4.709315    Objective Loss 4.709315                                        LR 0.001000    Time 0.219614    
2023-04-16 23:12:45,805 - Epoch: [5][  100/  518]    Overall Loss 4.673423    Objective Loss 4.673423                                        LR 0.001000    Time 0.211259    
2023-04-16 23:12:55,851 - Epoch: [5][  150/  518]    Overall Loss 4.658844    Objective Loss 4.658844                                        LR 0.001000    Time 0.207801    
2023-04-16 23:13:06,022 - Epoch: [5][  200/  518]    Overall Loss 4.662020    Objective Loss 4.662020                                        LR 0.001000    Time 0.206699    
2023-04-16 23:13:16,077 - Epoch: [5][  250/  518]    Overall Loss 4.657608    Objective Loss 4.657608                                        LR 0.001000    Time 0.205572    
2023-04-16 23:13:26,173 - Epoch: [5][  300/  518]    Overall Loss 4.652825    Objective Loss 4.652825                                        LR 0.001000    Time 0.204959    
2023-04-16 23:13:36,305 - Epoch: [5][  350/  518]    Overall Loss 4.647009    Objective Loss 4.647009                                        LR 0.001000    Time 0.204624    
2023-04-16 23:13:46,477 - Epoch: [5][  400/  518]    Overall Loss 4.639428    Objective Loss 4.639428                                        LR 0.001000    Time 0.204472    
2023-04-16 23:13:56,788 - Epoch: [5][  450/  518]    Overall Loss 4.631677    Objective Loss 4.631677                                        LR 0.001000    Time 0.204663    
2023-04-16 23:14:07,231 - Epoch: [5][  500/  518]    Overall Loss 4.630312    Objective Loss 4.630312                                        LR 0.001000    Time 0.205078    
2023-04-16 23:14:10,973 - Epoch: [5][  518/  518]    Overall Loss 4.633758    Objective Loss 4.633758                                        LR 0.001000    Time 0.205174    
2023-04-16 23:14:11,054 - --- validate (epoch=5)-----------
2023-04-16 23:14:11,054 - 4952 samples (32 per mini-batch)
2023-04-16 23:15:40,642 - Epoch: [5][   50/  155]    Loss 4.864622    mAP 0.132262    
2023-04-16 23:17:27,425 - Epoch: [5][  100/  155]    Loss 4.863718    mAP 0.133702    
2023-04-16 23:19:14,917 - Epoch: [5][  150/  155]    Loss 4.871879    mAP 0.135155    
2023-04-16 23:19:25,026 - Epoch: [5][  155/  155]    Loss 4.872213    mAP 0.135733    
2023-04-16 23:19:25,123 - ==> mAP: 0.13573    Loss: 4.872

2023-04-16 23:19:25,127 - ==> Best [mAP: 0.135733   vloss: 4.872213   Sparsity:0.00   Params: 2177088 on epoch: 5]
2023-04-16 23:19:25,127 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-16 23:19:25,217 - 

2023-04-16 23:19:25,218 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-16 23:19:39,721 - Epoch: [6][   50/  518]    Overall Loss 4.627974    Objective Loss 4.627974                                        LR 0.001000    Time 0.289968    
2023-04-16 23:19:53,204 - Epoch: [6][  100/  518]    Overall Loss 4.585209    Objective Loss 4.585209                                        LR 0.001000    Time 0.279772    
2023-04-16 23:20:06,672 - Epoch: [6][  150/  518]    Overall Loss 4.560047    Objective Loss 4.560047                                        LR 0.001000    Time 0.276289    
2023-04-16 23:20:20,447 - Epoch: [6][  200/  518]    Overall Loss 4.558052    Objective Loss 4.558052                                        LR 0.001000    Time 0.276075    
2023-04-16 23:20:34,010 - Epoch: [6][  250/  518]    Overall Loss 4.553258    Objective Loss 4.553258                                        LR 0.001000    Time 0.275102    
2023-04-16 23:20:47,476 - Epoch: [6][  300/  518]    Overall Loss 4.545489    Objective Loss 4.545489                                        LR 0.001000    Time 0.274133    
2023-04-16 23:21:00,964 - Epoch: [6][  350/  518]    Overall Loss 4.548104    Objective Loss 4.548104                                        LR 0.001000    Time 0.273500    
2023-04-16 23:21:14,672 - Epoch: [6][  400/  518]    Overall Loss 4.545371    Objective Loss 4.545371                                        LR 0.001000    Time 0.273575    
2023-04-16 23:21:28,340 - Epoch: [6][  450/  518]    Overall Loss 4.530071    Objective Loss 4.530071                                        LR 0.001000    Time 0.273545    
2023-04-16 23:21:41,936 - Epoch: [6][  500/  518]    Overall Loss 4.525442    Objective Loss 4.525442                                        LR 0.001000    Time 0.273376    
2023-04-16 23:21:46,651 - Epoch: [6][  518/  518]    Overall Loss 4.527685    Objective Loss 4.527685                                        LR 0.001000    Time 0.272977    
2023-04-16 23:21:46,763 - --- validate (epoch=6)-----------
2023-04-16 23:21:46,763 - 4952 samples (32 per mini-batch)
2023-04-16 23:23:26,449 - Epoch: [6][   50/  155]    Loss 4.678777    mAP 0.181964    
2023-04-16 23:24:46,273 - Epoch: [6][  100/  155]    Loss 4.692131    mAP 0.182436    
2023-04-16 23:26:05,490 - Epoch: [6][  150/  155]    Loss 4.710834    mAP 0.180973    
2023-04-16 23:26:12,920 - Epoch: [6][  155/  155]    Loss 4.713729    mAP 0.181230    
2023-04-16 23:26:12,999 - ==> mAP: 0.18123    Loss: 4.714

2023-04-16 23:26:13,003 - ==> Best [mAP: 0.181230   vloss: 4.713729   Sparsity:0.00   Params: 2177088 on epoch: 6]
2023-04-16 23:26:13,003 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-16 23:26:13,055 - 

2023-04-16 23:26:13,055 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-16 23:26:23,848 - Epoch: [7][   50/  518]    Overall Loss 4.487099    Objective Loss 4.487099                                        LR 0.001000    Time 0.215807    
2023-04-16 23:26:33,989 - Epoch: [7][  100/  518]    Overall Loss 4.477225    Objective Loss 4.477225                                        LR 0.001000    Time 0.209291    
2023-04-16 23:26:44,604 - Epoch: [7][  150/  518]    Overall Loss 4.473513    Objective Loss 4.473513                                        LR 0.001000    Time 0.210284    
2023-04-16 23:26:54,782 - Epoch: [7][  200/  518]    Overall Loss 4.453216    Objective Loss 4.453216                                        LR 0.001000    Time 0.208596    
2023-04-16 23:27:04,901 - Epoch: [7][  250/  518]    Overall Loss 4.451999    Objective Loss 4.451999                                        LR 0.001000    Time 0.207346    
2023-04-16 23:27:14,986 - Epoch: [7][  300/  518]    Overall Loss 4.444699    Objective Loss 4.444699                                        LR 0.001000    Time 0.206400    
2023-04-16 23:27:25,104 - Epoch: [7][  350/  518]    Overall Loss 4.441089    Objective Loss 4.441089                                        LR 0.001000    Time 0.205819    
2023-04-16 23:27:35,240 - Epoch: [7][  400/  518]    Overall Loss 4.439208    Objective Loss 4.439208                                        LR 0.001000    Time 0.205428    
2023-04-16 23:27:45,343 - Epoch: [7][  450/  518]    Overall Loss 4.440157    Objective Loss 4.440157                                        LR 0.001000    Time 0.205050    
2023-04-16 23:27:55,390 - Epoch: [7][  500/  518]    Overall Loss 4.443462    Objective Loss 4.443462                                        LR 0.001000    Time 0.204636    
2023-04-16 23:27:58,909 - Epoch: [7][  518/  518]    Overall Loss 4.442818    Objective Loss 4.442818                                        LR 0.001000    Time 0.204317    
2023-04-16 23:27:58,990 - --- validate (epoch=7)-----------
2023-04-16 23:27:58,991 - 4952 samples (32 per mini-batch)
2023-04-16 23:29:25,799 - Epoch: [7][   50/  155]    Loss 4.653636    mAP 0.169790    
2023-04-16 23:30:51,844 - Epoch: [7][  100/  155]    Loss 4.648209    mAP 0.171523    
2023-04-16 23:32:19,406 - Epoch: [7][  150/  155]    Loss 4.667730    mAP 0.173163    
2023-04-16 23:32:27,835 - Epoch: [7][  155/  155]    Loss 4.669215    mAP 0.172227    
2023-04-16 23:32:27,915 - ==> mAP: 0.17223    Loss: 4.669

2023-04-16 23:32:27,919 - ==> Best [mAP: 0.181230   vloss: 4.713729   Sparsity:0.00   Params: 2177088 on epoch: 6]
2023-04-16 23:32:27,919 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-16 23:32:27,955 - 

2023-04-16 23:32:27,955 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-16 23:32:38,927 - Epoch: [8][   50/  518]    Overall Loss 4.359698    Objective Loss 4.359698                                        LR 0.001000    Time 0.219388    
2023-04-16 23:32:48,950 - Epoch: [8][  100/  518]    Overall Loss 4.369515    Objective Loss 4.369515                                        LR 0.001000    Time 0.209906    
2023-04-16 23:32:59,041 - Epoch: [8][  150/  518]    Overall Loss 4.380999    Objective Loss 4.380999                                        LR 0.001000    Time 0.207197    
2023-04-16 23:33:09,126 - Epoch: [8][  200/  518]    Overall Loss 4.401233    Objective Loss 4.401233                                        LR 0.001000    Time 0.205818    
2023-04-16 23:33:19,150 - Epoch: [8][  250/  518]    Overall Loss 4.374095    Objective Loss 4.374095                                        LR 0.001000    Time 0.204745    
2023-04-16 23:33:29,404 - Epoch: [8][  300/  518]    Overall Loss 4.373994    Objective Loss 4.373994                                        LR 0.001000    Time 0.204796    
2023-04-16 23:33:39,478 - Epoch: [8][  350/  518]    Overall Loss 4.375810    Objective Loss 4.375810                                        LR 0.001000    Time 0.204318    
2023-04-16 23:33:49,554 - Epoch: [8][  400/  518]    Overall Loss 4.369137    Objective Loss 4.369137                                        LR 0.001000    Time 0.203964    
2023-04-16 23:33:59,601 - Epoch: [8][  450/  518]    Overall Loss 4.366292    Objective Loss 4.366292                                        LR 0.001000    Time 0.203624    
2023-04-16 23:34:09,696 - Epoch: [8][  500/  518]    Overall Loss 4.369276    Objective Loss 4.369276                                        LR 0.001000    Time 0.203449    
2023-04-16 23:34:13,232 - Epoch: [8][  518/  518]    Overall Loss 4.366034    Objective Loss 4.366034                                        LR 0.001000    Time 0.203205    
2023-04-16 23:34:13,312 - --- validate (epoch=8)-----------
2023-04-16 23:34:13,313 - 4952 samples (32 per mini-batch)
2023-04-16 23:35:19,719 - Epoch: [8][   50/  155]    Loss 4.476247    mAP 0.221571    
2023-04-16 23:36:24,796 - Epoch: [8][  100/  155]    Loss 4.510340    mAP 0.220489    
2023-04-16 23:37:31,023 - Epoch: [8][  150/  155]    Loss 4.507911    mAP 0.217039    
2023-04-16 23:37:37,420 - Epoch: [8][  155/  155]    Loss 4.506198    mAP 0.215620    
2023-04-16 23:37:37,498 - ==> mAP: 0.21562    Loss: 4.506

2023-04-16 23:37:37,502 - ==> Best [mAP: 0.215620   vloss: 4.506198   Sparsity:0.00   Params: 2177088 on epoch: 8]
2023-04-16 23:37:37,502 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-16 23:37:37,551 - 

2023-04-16 23:37:37,551 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-16 23:37:48,508 - Epoch: [9][   50/  518]    Overall Loss 4.362676    Objective Loss 4.362676                                        LR 0.001000    Time 0.219079    
2023-04-16 23:37:58,627 - Epoch: [9][  100/  518]    Overall Loss 4.330047    Objective Loss 4.330047                                        LR 0.001000    Time 0.210711    
2023-04-16 23:38:08,696 - Epoch: [9][  150/  518]    Overall Loss 4.300735    Objective Loss 4.300735                                        LR 0.001000    Time 0.207591    
2023-04-16 23:38:18,807 - Epoch: [9][  200/  518]    Overall Loss 4.310927    Objective Loss 4.310927                                        LR 0.001000    Time 0.206239    
2023-04-16 23:38:28,874 - Epoch: [9][  250/  518]    Overall Loss 4.301496    Objective Loss 4.301496                                        LR 0.001000    Time 0.205255    
2023-04-16 23:38:39,028 - Epoch: [9][  300/  518]    Overall Loss 4.301951    Objective Loss 4.301951                                        LR 0.001000    Time 0.204888    
2023-04-16 23:38:49,098 - Epoch: [9][  350/  518]    Overall Loss 4.300520    Objective Loss 4.300520                                        LR 0.001000    Time 0.204385    
2023-04-16 23:38:59,167 - Epoch: [9][  400/  518]    Overall Loss 4.301627    Objective Loss 4.301627                                        LR 0.001000    Time 0.204005    
2023-04-16 23:39:09,224 - Epoch: [9][  450/  518]    Overall Loss 4.294804    Objective Loss 4.294804                                        LR 0.001000    Time 0.203685    
2023-04-16 23:39:19,339 - Epoch: [9][  500/  518]    Overall Loss 4.292201    Objective Loss 4.292201                                        LR 0.001000    Time 0.203543    
2023-04-16 23:39:22,831 - Epoch: [9][  518/  518]    Overall Loss 4.292681    Objective Loss 4.292681                                        LR 0.001000    Time 0.203210    
2023-04-16 23:39:22,913 - --- validate (epoch=9)-----------
2023-04-16 23:39:22,913 - 4952 samples (32 per mini-batch)
2023-04-16 23:40:52,153 - Epoch: [9][   50/  155]    Loss 4.679311    mAP 0.180841    
2023-04-16 23:42:21,396 - Epoch: [9][  100/  155]    Loss 4.661003    mAP 0.181188    
2023-04-16 23:43:50,154 - Epoch: [9][  150/  155]    Loss 4.665054    mAP 0.182786    
2023-04-16 23:43:58,579 - Epoch: [9][  155/  155]    Loss 4.662121    mAP 0.182506    
2023-04-16 23:43:58,660 - ==> mAP: 0.18251    Loss: 4.662

2023-04-16 23:43:58,664 - ==> Best [mAP: 0.215620   vloss: 4.506198   Sparsity:0.00   Params: 2177088 on epoch: 8]
2023-04-16 23:43:58,664 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-16 23:43:58,700 - 

2023-04-16 23:43:58,700 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-16 23:44:09,561 - Epoch: [10][   50/  518]    Overall Loss 4.260335    Objective Loss 4.260335                                        LR 0.001000    Time 0.217173    
2023-04-16 23:44:19,632 - Epoch: [10][  100/  518]    Overall Loss 4.210977    Objective Loss 4.210977                                        LR 0.001000    Time 0.209274    
2023-04-16 23:44:29,740 - Epoch: [10][  150/  518]    Overall Loss 4.224777    Objective Loss 4.224777                                        LR 0.001000    Time 0.206893    
2023-04-16 23:44:39,810 - Epoch: [10][  200/  518]    Overall Loss 4.241149    Objective Loss 4.241149                                        LR 0.001000    Time 0.205516    
2023-04-16 23:44:49,863 - Epoch: [10][  250/  518]    Overall Loss 4.237181    Objective Loss 4.237181                                        LR 0.001000    Time 0.204617    
2023-04-16 23:45:00,047 - Epoch: [10][  300/  518]    Overall Loss 4.243693    Objective Loss 4.243693                                        LR 0.001000    Time 0.204455    
2023-04-16 23:45:10,176 - Epoch: [10][  350/  518]    Overall Loss 4.236777    Objective Loss 4.236777                                        LR 0.001000    Time 0.204184    
2023-04-16 23:45:20,274 - Epoch: [10][  400/  518]    Overall Loss 4.239956    Objective Loss 4.239956                                        LR 0.001000    Time 0.203900    
2023-04-16 23:45:30,383 - Epoch: [10][  450/  518]    Overall Loss 4.238241    Objective Loss 4.238241                                        LR 0.001000    Time 0.203707    
2023-04-16 23:45:40,547 - Epoch: [10][  500/  518]    Overall Loss 4.231877    Objective Loss 4.231877                                        LR 0.001000    Time 0.203662    
2023-04-16 23:45:44,057 - Epoch: [10][  518/  518]    Overall Loss 4.229070    Objective Loss 4.229070                                        LR 0.001000    Time 0.203358    
2023-04-16 23:45:44,137 - --- validate (epoch=10)-----------
2023-04-16 23:45:44,137 - 4952 samples (32 per mini-batch)
2023-04-16 23:46:41,656 - Epoch: [10][   50/  155]    Loss 4.394418    mAP 0.241454    
2023-04-16 23:47:38,963 - Epoch: [10][  100/  155]    Loss 4.391034    mAP 0.237938    
2023-04-16 23:48:36,404 - Epoch: [10][  150/  155]    Loss 4.389785    mAP 0.237651    
2023-04-16 23:48:41,851 - Epoch: [10][  155/  155]    Loss 4.391538    mAP 0.239388    
2023-04-16 23:48:41,931 - ==> mAP: 0.23939    Loss: 4.392

2023-04-16 23:48:41,935 - ==> Best [mAP: 0.239388   vloss: 4.391538   Sparsity:0.00   Params: 2177088 on epoch: 10]
2023-04-16 23:48:41,935 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-16 23:48:41,982 - 

2023-04-16 23:48:41,982 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-16 23:48:52,750 - Epoch: [11][   50/  518]    Overall Loss 4.177017    Objective Loss 4.177017                                        LR 0.001000    Time 0.215303    
2023-04-16 23:49:02,845 - Epoch: [11][  100/  518]    Overall Loss 4.153222    Objective Loss 4.153222                                        LR 0.001000    Time 0.208579    
2023-04-16 23:49:13,001 - Epoch: [11][  150/  518]    Overall Loss 4.174151    Objective Loss 4.174151                                        LR 0.001000    Time 0.206755    
2023-04-16 23:49:23,164 - Epoch: [11][  200/  518]    Overall Loss 4.185431    Objective Loss 4.185431                                        LR 0.001000    Time 0.205872    
2023-04-16 23:49:33,226 - Epoch: [11][  250/  518]    Overall Loss 4.178135    Objective Loss 4.178135                                        LR 0.001000    Time 0.204939    
2023-04-16 23:49:43,408 - Epoch: [11][  300/  518]    Overall Loss 4.188836    Objective Loss 4.188836                                        LR 0.001000    Time 0.204717    
2023-04-16 23:49:53,517 - Epoch: [11][  350/  518]    Overall Loss 4.191437    Objective Loss 4.191437                                        LR 0.001000    Time 0.204352    
2023-04-16 23:50:03,600 - Epoch: [11][  400/  518]    Overall Loss 4.186068    Objective Loss 4.186068                                        LR 0.001000    Time 0.204010    
2023-04-16 23:50:13,675 - Epoch: [11][  450/  518]    Overall Loss 4.185809    Objective Loss 4.185809                                        LR 0.001000    Time 0.203728    
2023-04-16 23:50:23,757 - Epoch: [11][  500/  518]    Overall Loss 4.173000    Objective Loss 4.173000                                        LR 0.001000    Time 0.203516    
2023-04-16 23:50:27,267 - Epoch: [11][  518/  518]    Overall Loss 4.173387    Objective Loss 4.173387                                        LR 0.001000    Time 0.203219    
2023-04-16 23:50:27,345 - --- validate (epoch=11)-----------
2023-04-16 23:50:27,346 - 4952 samples (32 per mini-batch)
2023-04-16 23:51:35,777 - Epoch: [11][   50/  155]    Loss 4.432818    mAP 0.255001    
2023-04-16 23:52:44,548 - Epoch: [11][  100/  155]    Loss 4.408360    mAP 0.263572    
2023-04-16 23:53:51,882 - Epoch: [11][  150/  155]    Loss 4.418241    mAP 0.260675    
2023-04-16 23:53:58,008 - Epoch: [11][  155/  155]    Loss 4.415262    mAP 0.261397    
2023-04-16 23:53:58,086 - ==> mAP: 0.26140    Loss: 4.415

2023-04-16 23:53:58,090 - ==> Best [mAP: 0.261397   vloss: 4.415262   Sparsity:0.00   Params: 2177088 on epoch: 11]
2023-04-16 23:53:58,090 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-16 23:53:58,139 - 

2023-04-16 23:53:58,139 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-16 23:54:09,071 - Epoch: [12][   50/  518]    Overall Loss 4.194182    Objective Loss 4.194182                                        LR 0.001000    Time 0.218576    
2023-04-16 23:54:19,175 - Epoch: [12][  100/  518]    Overall Loss 4.158288    Objective Loss 4.158288                                        LR 0.001000    Time 0.210312    
2023-04-16 23:54:29,285 - Epoch: [12][  150/  518]    Overall Loss 4.154930    Objective Loss 4.154930                                        LR 0.001000    Time 0.207603    
2023-04-16 23:54:39,401 - Epoch: [12][  200/  518]    Overall Loss 4.154468    Objective Loss 4.154468                                        LR 0.001000    Time 0.206272    
2023-04-16 23:54:49,525 - Epoch: [12][  250/  518]    Overall Loss 4.160560    Objective Loss 4.160560                                        LR 0.001000    Time 0.205508    
2023-04-16 23:54:59,675 - Epoch: [12][  300/  518]    Overall Loss 4.148730    Objective Loss 4.148730                                        LR 0.001000    Time 0.205084    
2023-04-16 23:55:09,724 - Epoch: [12][  350/  518]    Overall Loss 4.143430    Objective Loss 4.143430                                        LR 0.001000    Time 0.204495    
2023-04-16 23:55:19,795 - Epoch: [12][  400/  518]    Overall Loss 4.141912    Objective Loss 4.141912                                        LR 0.001000    Time 0.204106    
2023-04-16 23:55:29,851 - Epoch: [12][  450/  518]    Overall Loss 4.136117    Objective Loss 4.136117                                        LR 0.001000    Time 0.203771    
2023-04-16 23:55:39,889 - Epoch: [12][  500/  518]    Overall Loss 4.137954    Objective Loss 4.137954                                        LR 0.001000    Time 0.203467    
2023-04-16 23:55:43,420 - Epoch: [12][  518/  518]    Overall Loss 4.138768    Objective Loss 4.138768                                        LR 0.001000    Time 0.203212    
2023-04-16 23:55:43,500 - --- validate (epoch=12)-----------
2023-04-16 23:55:43,501 - 4952 samples (32 per mini-batch)
2023-04-16 23:57:13,364 - Epoch: [12][   50/  155]    Loss 4.952773    mAP 0.150333    
2023-04-16 23:58:41,861 - Epoch: [12][  100/  155]    Loss 4.965202    mAP 0.151433    
2023-04-17 00:00:09,070 - Epoch: [12][  150/  155]    Loss 4.960528    mAP 0.152695    
2023-04-17 00:00:17,456 - Epoch: [12][  155/  155]    Loss 4.962928    mAP 0.152611    
2023-04-17 00:00:17,535 - ==> mAP: 0.15261    Loss: 4.963

2023-04-17 00:00:17,539 - ==> Best [mAP: 0.261397   vloss: 4.415262   Sparsity:0.00   Params: 2177088 on epoch: 11]
2023-04-17 00:00:17,539 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 00:00:17,575 - 

2023-04-17 00:00:17,575 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 00:00:28,595 - Epoch: [13][   50/  518]    Overall Loss 4.067986    Objective Loss 4.067986                                        LR 0.001000    Time 0.220334    
2023-04-17 00:00:38,640 - Epoch: [13][  100/  518]    Overall Loss 4.054862    Objective Loss 4.054862                                        LR 0.001000    Time 0.210608    
2023-04-17 00:00:48,627 - Epoch: [13][  150/  518]    Overall Loss 4.059194    Objective Loss 4.059194                                        LR 0.001000    Time 0.206972    
2023-04-17 00:00:58,701 - Epoch: [13][  200/  518]    Overall Loss 4.045993    Objective Loss 4.045993                                        LR 0.001000    Time 0.205590    
2023-04-17 00:01:08,763 - Epoch: [13][  250/  518]    Overall Loss 4.050278    Objective Loss 4.050278                                        LR 0.001000    Time 0.204714    
2023-04-17 00:01:18,850 - Epoch: [13][  300/  518]    Overall Loss 4.052314    Objective Loss 4.052314                                        LR 0.001000    Time 0.204214    
2023-04-17 00:01:29,007 - Epoch: [13][  350/  518]    Overall Loss 4.053610    Objective Loss 4.053610                                        LR 0.001000    Time 0.204056    
2023-04-17 00:01:39,079 - Epoch: [13][  400/  518]    Overall Loss 4.050098    Objective Loss 4.050098                                        LR 0.001000    Time 0.203726    
2023-04-17 00:01:49,170 - Epoch: [13][  450/  518]    Overall Loss 4.055096    Objective Loss 4.055096                                        LR 0.001000    Time 0.203510    
2023-04-17 00:01:59,324 - Epoch: [13][  500/  518]    Overall Loss 4.058782    Objective Loss 4.058782                                        LR 0.001000    Time 0.203464    
2023-04-17 00:02:02,895 - Epoch: [13][  518/  518]    Overall Loss 4.054675    Objective Loss 4.054675                                        LR 0.001000    Time 0.203287    
2023-04-17 00:02:02,975 - --- validate (epoch=13)-----------
2023-04-17 00:02:02,976 - 4952 samples (32 per mini-batch)
2023-04-17 00:03:07,857 - Epoch: [13][   50/  155]    Loss 4.396775    mAP 0.276356    
2023-04-17 00:04:13,710 - Epoch: [13][  100/  155]    Loss 4.358057    mAP 0.269427    
2023-04-17 00:05:20,074 - Epoch: [13][  150/  155]    Loss 4.360708    mAP 0.266052    
2023-04-17 00:05:26,155 - Epoch: [13][  155/  155]    Loss 4.363663    mAP 0.266516    
2023-04-17 00:05:26,248 - ==> mAP: 0.26652    Loss: 4.364

2023-04-17 00:05:26,252 - ==> Best [mAP: 0.266516   vloss: 4.363663   Sparsity:0.00   Params: 2177088 on epoch: 13]
2023-04-17 00:05:26,252 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 00:05:26,303 - 

2023-04-17 00:05:26,304 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 00:05:37,172 - Epoch: [14][   50/  518]    Overall Loss 4.110358    Objective Loss 4.110358                                        LR 0.001000    Time 0.217308    
2023-04-17 00:05:47,296 - Epoch: [14][  100/  518]    Overall Loss 4.073949    Objective Loss 4.073949                                        LR 0.001000    Time 0.209884    
2023-04-17 00:05:57,460 - Epoch: [14][  150/  518]    Overall Loss 4.048365    Objective Loss 4.048365                                        LR 0.001000    Time 0.207666    
2023-04-17 00:06:07,524 - Epoch: [14][  200/  518]    Overall Loss 4.032386    Objective Loss 4.032386                                        LR 0.001000    Time 0.206066    
2023-04-17 00:06:17,664 - Epoch: [14][  250/  518]    Overall Loss 4.030539    Objective Loss 4.030539                                        LR 0.001000    Time 0.205406    
2023-04-17 00:06:27,757 - Epoch: [14][  300/  518]    Overall Loss 4.033236    Objective Loss 4.033236                                        LR 0.001000    Time 0.204810    
2023-04-17 00:06:37,904 - Epoch: [14][  350/  518]    Overall Loss 4.031259    Objective Loss 4.031259                                        LR 0.001000    Time 0.204538    
2023-04-17 00:06:48,005 - Epoch: [14][  400/  518]    Overall Loss 4.028566    Objective Loss 4.028566                                        LR 0.001000    Time 0.204220    
2023-04-17 00:06:58,113 - Epoch: [14][  450/  518]    Overall Loss 4.024258    Objective Loss 4.024258                                        LR 0.001000    Time 0.203986    
2023-04-17 00:07:08,100 - Epoch: [14][  500/  518]    Overall Loss 4.027012    Objective Loss 4.027012                                        LR 0.001000    Time 0.203559    
2023-04-17 00:07:11,645 - Epoch: [14][  518/  518]    Overall Loss 4.026418    Objective Loss 4.026418                                        LR 0.001000    Time 0.203328    
2023-04-17 00:07:11,724 - --- validate (epoch=14)-----------
2023-04-17 00:07:11,725 - 4952 samples (32 per mini-batch)
2023-04-17 00:08:34,849 - Epoch: [14][   50/  155]    Loss 4.683262    mAP 0.190506    
2023-04-17 00:09:56,805 - Epoch: [14][  100/  155]    Loss 4.665575    mAP 0.191086    
2023-04-17 00:11:19,255 - Epoch: [14][  150/  155]    Loss 4.661221    mAP 0.188492    
2023-04-17 00:11:27,239 - Epoch: [14][  155/  155]    Loss 4.657305    mAP 0.187208    
2023-04-17 00:11:27,318 - ==> mAP: 0.18721    Loss: 4.657

2023-04-17 00:11:27,322 - ==> Best [mAP: 0.266516   vloss: 4.363663   Sparsity:0.00   Params: 2177088 on epoch: 13]
2023-04-17 00:11:27,322 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 00:11:27,358 - 

2023-04-17 00:11:27,358 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 00:11:38,137 - Epoch: [15][   50/  518]    Overall Loss 4.035742    Objective Loss 4.035742                                        LR 0.001000    Time 0.215517    
2023-04-17 00:11:48,257 - Epoch: [15][  100/  518]    Overall Loss 4.031049    Objective Loss 4.031049                                        LR 0.001000    Time 0.208944    
2023-04-17 00:11:58,383 - Epoch: [15][  150/  518]    Overall Loss 4.002933    Objective Loss 4.002933                                        LR 0.001000    Time 0.206792    
2023-04-17 00:12:08,543 - Epoch: [15][  200/  518]    Overall Loss 4.005113    Objective Loss 4.005113                                        LR 0.001000    Time 0.205886    
2023-04-17 00:12:18,608 - Epoch: [15][  250/  518]    Overall Loss 4.005871    Objective Loss 4.005871                                        LR 0.001000    Time 0.204964    
2023-04-17 00:12:28,714 - Epoch: [15][  300/  518]    Overall Loss 4.013275    Objective Loss 4.013275                                        LR 0.001000    Time 0.204484    
2023-04-17 00:12:38,715 - Epoch: [15][  350/  518]    Overall Loss 4.001112    Objective Loss 4.001112                                        LR 0.001000    Time 0.203841    
2023-04-17 00:12:48,779 - Epoch: [15][  400/  518]    Overall Loss 3.993474    Objective Loss 3.993474                                        LR 0.001000    Time 0.203518    
2023-04-17 00:12:58,938 - Epoch: [15][  450/  518]    Overall Loss 3.988236    Objective Loss 3.988236                                        LR 0.001000    Time 0.203477    
2023-04-17 00:13:08,999 - Epoch: [15][  500/  518]    Overall Loss 3.987853    Objective Loss 3.987853                                        LR 0.001000    Time 0.203249    
2023-04-17 00:13:12,518 - Epoch: [15][  518/  518]    Overall Loss 3.989603    Objective Loss 3.989603                                        LR 0.001000    Time 0.202978    
2023-04-17 00:13:12,598 - --- validate (epoch=15)-----------
2023-04-17 00:13:12,598 - 4952 samples (32 per mini-batch)
2023-04-17 00:14:07,088 - Epoch: [15][   50/  155]    Loss 4.330919    mAP 0.264418    
2023-04-17 00:15:00,337 - Epoch: [15][  100/  155]    Loss 4.321103    mAP 0.279822    
2023-04-17 00:15:53,934 - Epoch: [15][  150/  155]    Loss 4.335270    mAP 0.273472    
2023-04-17 00:15:58,963 - Epoch: [15][  155/  155]    Loss 4.339937    mAP 0.273249    
2023-04-17 00:15:59,042 - ==> mAP: 0.27325    Loss: 4.340

2023-04-17 00:15:59,046 - ==> Best [mAP: 0.273249   vloss: 4.339937   Sparsity:0.00   Params: 2177088 on epoch: 15]
2023-04-17 00:15:59,046 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 00:15:59,095 - 

2023-04-17 00:15:59,095 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 00:16:09,940 - Epoch: [16][   50/  518]    Overall Loss 3.984503    Objective Loss 3.984503                                        LR 0.001000    Time 0.216857    
2023-04-17 00:16:20,045 - Epoch: [16][  100/  518]    Overall Loss 3.989815    Objective Loss 3.989815                                        LR 0.001000    Time 0.209461    
2023-04-17 00:16:30,146 - Epoch: [16][  150/  518]    Overall Loss 3.976141    Objective Loss 3.976141                                        LR 0.001000    Time 0.206970    
2023-04-17 00:16:40,252 - Epoch: [16][  200/  518]    Overall Loss 3.959334    Objective Loss 3.959334                                        LR 0.001000    Time 0.205751    
2023-04-17 00:16:50,331 - Epoch: [16][  250/  518]    Overall Loss 3.954645    Objective Loss 3.954645                                        LR 0.001000    Time 0.204909    
2023-04-17 00:17:00,381 - Epoch: [16][  300/  518]    Overall Loss 3.958308    Objective Loss 3.958308                                        LR 0.001000    Time 0.204252    
2023-04-17 00:17:10,496 - Epoch: [16][  350/  518]    Overall Loss 3.953640    Objective Loss 3.953640                                        LR 0.001000    Time 0.203970    
2023-04-17 00:17:20,615 - Epoch: [16][  400/  518]    Overall Loss 3.957719    Objective Loss 3.957719                                        LR 0.001000    Time 0.203768    
2023-04-17 00:17:30,695 - Epoch: [16][  450/  518]    Overall Loss 3.951930    Objective Loss 3.951930                                        LR 0.001000    Time 0.203522    
2023-04-17 00:17:40,786 - Epoch: [16][  500/  518]    Overall Loss 3.951126    Objective Loss 3.951126                                        LR 0.001000    Time 0.203348    
2023-04-17 00:17:44,280 - Epoch: [16][  518/  518]    Overall Loss 3.950238    Objective Loss 3.950238                                        LR 0.001000    Time 0.203028    
2023-04-17 00:17:44,362 - --- validate (epoch=16)-----------
2023-04-17 00:17:44,362 - 4952 samples (32 per mini-batch)
2023-04-17 00:18:52,131 - Epoch: [16][   50/  155]    Loss 4.283781    mAP 0.283427    
2023-04-17 00:19:59,937 - Epoch: [16][  100/  155]    Loss 4.287791    mAP 0.277134    
2023-04-17 00:21:08,726 - Epoch: [16][  150/  155]    Loss 4.307803    mAP 0.273674    
2023-04-17 00:21:15,044 - Epoch: [16][  155/  155]    Loss 4.310921    mAP 0.273264    
2023-04-17 00:21:15,126 - ==> mAP: 0.27326    Loss: 4.311

2023-04-17 00:21:15,130 - ==> Best [mAP: 0.273264   vloss: 4.310921   Sparsity:0.00   Params: 2177088 on epoch: 16]
2023-04-17 00:21:15,130 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 00:21:15,180 - 

2023-04-17 00:21:15,180 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 00:21:26,124 - Epoch: [17][   50/  518]    Overall Loss 3.956318    Objective Loss 3.956318                                        LR 0.001000    Time 0.218839    
2023-04-17 00:21:36,214 - Epoch: [17][  100/  518]    Overall Loss 3.935797    Objective Loss 3.935797                                        LR 0.001000    Time 0.210298    
2023-04-17 00:21:46,298 - Epoch: [17][  150/  518]    Overall Loss 3.895963    Objective Loss 3.895963                                        LR 0.001000    Time 0.207413    
2023-04-17 00:21:56,459 - Epoch: [17][  200/  518]    Overall Loss 3.909047    Objective Loss 3.909047                                        LR 0.001000    Time 0.206357    
2023-04-17 00:22:06,546 - Epoch: [17][  250/  518]    Overall Loss 3.907803    Objective Loss 3.907803                                        LR 0.001000    Time 0.205428    
2023-04-17 00:22:16,695 - Epoch: [17][  300/  518]    Overall Loss 3.919371    Objective Loss 3.919371                                        LR 0.001000    Time 0.205015    
2023-04-17 00:22:26,821 - Epoch: [17][  350/  518]    Overall Loss 3.917155    Objective Loss 3.917155                                        LR 0.001000    Time 0.204656    
2023-04-17 00:22:36,962 - Epoch: [17][  400/  518]    Overall Loss 3.916732    Objective Loss 3.916732                                        LR 0.001000    Time 0.204421    
2023-04-17 00:22:47,043 - Epoch: [17][  450/  518]    Overall Loss 3.919948    Objective Loss 3.919948                                        LR 0.001000    Time 0.204107    
2023-04-17 00:22:57,162 - Epoch: [17][  500/  518]    Overall Loss 3.915610    Objective Loss 3.915610                                        LR 0.001000    Time 0.203931    
2023-04-17 00:23:00,675 - Epoch: [17][  518/  518]    Overall Loss 3.917174    Objective Loss 3.917174                                        LR 0.001000    Time 0.203626    
2023-04-17 00:23:00,757 - --- validate (epoch=17)-----------
2023-04-17 00:23:00,757 - 4952 samples (32 per mini-batch)
2023-04-17 00:24:25,427 - Epoch: [17][   50/  155]    Loss 4.245616    mAP 0.281215    
2023-04-17 00:25:50,938 - Epoch: [17][  100/  155]    Loss 4.274071    mAP 0.285817    
2023-04-17 00:27:18,025 - Epoch: [17][  150/  155]    Loss 4.287697    mAP 0.274808    
2023-04-17 00:27:26,500 - Epoch: [17][  155/  155]    Loss 4.288421    mAP 0.272428    
2023-04-17 00:27:26,579 - ==> mAP: 0.27243    Loss: 4.288

2023-04-17 00:27:26,583 - ==> Best [mAP: 0.273264   vloss: 4.310921   Sparsity:0.00   Params: 2177088 on epoch: 16]
2023-04-17 00:27:26,583 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 00:27:26,619 - 

2023-04-17 00:27:26,619 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 00:27:37,514 - Epoch: [18][   50/  518]    Overall Loss 3.894655    Objective Loss 3.894655                                        LR 0.001000    Time 0.217844    
2023-04-17 00:27:47,631 - Epoch: [18][  100/  518]    Overall Loss 3.857487    Objective Loss 3.857487                                        LR 0.001000    Time 0.210075    
2023-04-17 00:27:57,731 - Epoch: [18][  150/  518]    Overall Loss 3.873435    Objective Loss 3.873435                                        LR 0.001000    Time 0.207371    
2023-04-17 00:28:07,848 - Epoch: [18][  200/  518]    Overall Loss 3.863943    Objective Loss 3.863943                                        LR 0.001000    Time 0.206105    
2023-04-17 00:28:17,837 - Epoch: [18][  250/  518]    Overall Loss 3.877878    Objective Loss 3.877878                                        LR 0.001000    Time 0.204838    
2023-04-17 00:28:27,903 - Epoch: [18][  300/  518]    Overall Loss 3.880893    Objective Loss 3.880893                                        LR 0.001000    Time 0.204243    
2023-04-17 00:28:38,037 - Epoch: [18][  350/  518]    Overall Loss 3.877335    Objective Loss 3.877335                                        LR 0.001000    Time 0.204016    
2023-04-17 00:28:48,159 - Epoch: [18][  400/  518]    Overall Loss 3.879447    Objective Loss 3.879447                                        LR 0.001000    Time 0.203817    
2023-04-17 00:28:58,211 - Epoch: [18][  450/  518]    Overall Loss 3.873182    Objective Loss 3.873182                                        LR 0.001000    Time 0.203504    
2023-04-17 00:29:08,192 - Epoch: [18][  500/  518]    Overall Loss 3.875758    Objective Loss 3.875758                                        LR 0.001000    Time 0.203112    
2023-04-17 00:29:11,700 - Epoch: [18][  518/  518]    Overall Loss 3.875002    Objective Loss 3.875002                                        LR 0.001000    Time 0.202825    
2023-04-17 00:29:11,780 - --- validate (epoch=18)-----------
2023-04-17 00:29:11,781 - 4952 samples (32 per mini-batch)
2023-04-17 00:30:23,455 - Epoch: [18][   50/  155]    Loss 3.995185    mAP 0.337243    
2023-04-17 00:31:34,032 - Epoch: [18][  100/  155]    Loss 3.996111    mAP 0.333795    
2023-04-17 00:32:45,114 - Epoch: [18][  150/  155]    Loss 3.995245    mAP 0.338260    
2023-04-17 00:32:51,866 - Epoch: [18][  155/  155]    Loss 3.994999    mAP 0.338769    
2023-04-17 00:32:51,941 - ==> mAP: 0.33877    Loss: 3.995

2023-04-17 00:32:51,944 - ==> Best [mAP: 0.338769   vloss: 3.994999   Sparsity:0.00   Params: 2177088 on epoch: 18]
2023-04-17 00:32:51,944 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 00:32:51,996 - 

2023-04-17 00:32:51,996 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 00:33:02,974 - Epoch: [19][   50/  518]    Overall Loss 3.881172    Objective Loss 3.881172                                        LR 0.001000    Time 0.219516    
2023-04-17 00:33:13,122 - Epoch: [19][  100/  518]    Overall Loss 3.874255    Objective Loss 3.874255                                        LR 0.001000    Time 0.211213    
2023-04-17 00:33:23,196 - Epoch: [19][  150/  518]    Overall Loss 3.881295    Objective Loss 3.881295                                        LR 0.001000    Time 0.207961    
2023-04-17 00:33:33,264 - Epoch: [19][  200/  518]    Overall Loss 3.870498    Objective Loss 3.870498                                        LR 0.001000    Time 0.206302    
2023-04-17 00:33:43,431 - Epoch: [19][  250/  518]    Overall Loss 3.861801    Objective Loss 3.861801                                        LR 0.001000    Time 0.205704    
2023-04-17 00:33:53,473 - Epoch: [19][  300/  518]    Overall Loss 3.852411    Objective Loss 3.852411                                        LR 0.001000    Time 0.204887    
2023-04-17 00:34:03,480 - Epoch: [19][  350/  518]    Overall Loss 3.843957    Objective Loss 3.843957                                        LR 0.001000    Time 0.204205    
2023-04-17 00:34:13,557 - Epoch: [19][  400/  518]    Overall Loss 3.841922    Objective Loss 3.841922                                        LR 0.001000    Time 0.203867    
2023-04-17 00:34:23,770 - Epoch: [19][  450/  518]    Overall Loss 3.845017    Objective Loss 3.845017                                        LR 0.001000    Time 0.203909    
2023-04-17 00:34:33,927 - Epoch: [19][  500/  518]    Overall Loss 3.844666    Objective Loss 3.844666                                        LR 0.001000    Time 0.203829    
2023-04-17 00:34:37,414 - Epoch: [19][  518/  518]    Overall Loss 3.840900    Objective Loss 3.840900                                        LR 0.001000    Time 0.203477    
2023-04-17 00:34:37,493 - --- validate (epoch=19)-----------
2023-04-17 00:34:37,493 - 4952 samples (32 per mini-batch)
2023-04-17 00:35:55,529 - Epoch: [19][   50/  155]    Loss 4.145374    mAP 0.308151    
2023-04-17 00:37:09,867 - Epoch: [19][  100/  155]    Loss 4.125088    mAP 0.312924    
2023-04-17 00:38:26,405 - Epoch: [19][  150/  155]    Loss 4.130423    mAP 0.307661    
2023-04-17 00:38:33,637 - Epoch: [19][  155/  155]    Loss 4.126016    mAP 0.308824    
2023-04-17 00:38:33,715 - ==> mAP: 0.30882    Loss: 4.126

2023-04-17 00:38:33,719 - ==> Best [mAP: 0.338769   vloss: 3.994999   Sparsity:0.00   Params: 2177088 on epoch: 18]
2023-04-17 00:38:33,719 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 00:38:33,755 - 

2023-04-17 00:38:33,755 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 00:38:44,671 - Epoch: [20][   50/  518]    Overall Loss 3.823129    Objective Loss 3.823129                                        LR 0.001000    Time 0.218259    
2023-04-17 00:38:54,814 - Epoch: [20][  100/  518]    Overall Loss 3.830991    Objective Loss 3.830991                                        LR 0.001000    Time 0.210553    
2023-04-17 00:39:04,875 - Epoch: [20][  150/  518]    Overall Loss 3.831255    Objective Loss 3.831255                                        LR 0.001000    Time 0.207427    
2023-04-17 00:39:15,000 - Epoch: [20][  200/  518]    Overall Loss 3.825846    Objective Loss 3.825846                                        LR 0.001000    Time 0.206187    
2023-04-17 00:39:25,056 - Epoch: [20][  250/  518]    Overall Loss 3.838963    Objective Loss 3.838963                                        LR 0.001000    Time 0.205169    
2023-04-17 00:39:35,108 - Epoch: [20][  300/  518]    Overall Loss 3.834456    Objective Loss 3.834456                                        LR 0.001000    Time 0.204475    
2023-04-17 00:39:45,157 - Epoch: [20][  350/  518]    Overall Loss 3.830562    Objective Loss 3.830562                                        LR 0.001000    Time 0.203972    
2023-04-17 00:39:55,259 - Epoch: [20][  400/  518]    Overall Loss 3.836438    Objective Loss 3.836438                                        LR 0.001000    Time 0.203727    
2023-04-17 00:40:05,311 - Epoch: [20][  450/  518]    Overall Loss 3.835573    Objective Loss 3.835573                                        LR 0.001000    Time 0.203425    
2023-04-17 00:40:15,363 - Epoch: [20][  500/  518]    Overall Loss 3.832192    Objective Loss 3.832192                                        LR 0.001000    Time 0.203183    
2023-04-17 00:40:18,911 - Epoch: [20][  518/  518]    Overall Loss 3.832152    Objective Loss 3.832152                                        LR 0.001000    Time 0.202971    
2023-04-17 00:40:18,993 - --- validate (epoch=20)-----------
2023-04-17 00:40:18,993 - 4952 samples (32 per mini-batch)
2023-04-17 00:41:23,380 - Epoch: [20][   50/  155]    Loss 4.081340    mAP 0.303888    
2023-04-17 00:42:26,913 - Epoch: [20][  100/  155]    Loss 4.069035    mAP 0.312343    
2023-04-17 00:43:31,095 - Epoch: [20][  150/  155]    Loss 4.068701    mAP 0.312058    
2023-04-17 00:43:37,094 - Epoch: [20][  155/  155]    Loss 4.070417    mAP 0.312607    
2023-04-17 00:43:37,174 - ==> mAP: 0.31261    Loss: 4.070

2023-04-17 00:43:37,177 - ==> Best [mAP: 0.338769   vloss: 3.994999   Sparsity:0.00   Params: 2177088 on epoch: 18]
2023-04-17 00:43:37,177 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 00:43:37,212 - 

2023-04-17 00:43:37,212 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 00:43:48,240 - Epoch: [21][   50/  518]    Overall Loss 3.809566    Objective Loss 3.809566                                        LR 0.001000    Time 0.220498    
2023-04-17 00:43:58,309 - Epoch: [21][  100/  518]    Overall Loss 3.791367    Objective Loss 3.791367                                        LR 0.001000    Time 0.210920    
2023-04-17 00:44:08,439 - Epoch: [21][  150/  518]    Overall Loss 3.789088    Objective Loss 3.789088                                        LR 0.001000    Time 0.208136    
2023-04-17 00:44:18,524 - Epoch: [21][  200/  518]    Overall Loss 3.797683    Objective Loss 3.797683                                        LR 0.001000    Time 0.206522    
2023-04-17 00:44:28,650 - Epoch: [21][  250/  518]    Overall Loss 3.794149    Objective Loss 3.794149                                        LR 0.001000    Time 0.205715    
2023-04-17 00:44:38,710 - Epoch: [21][  300/  518]    Overall Loss 3.802540    Objective Loss 3.802540                                        LR 0.001000    Time 0.204958    
2023-04-17 00:44:48,819 - Epoch: [21][  350/  518]    Overall Loss 3.806451    Objective Loss 3.806451                                        LR 0.001000    Time 0.204557    
2023-04-17 00:44:58,888 - Epoch: [21][  400/  518]    Overall Loss 3.799867    Objective Loss 3.799867                                        LR 0.001000    Time 0.204155    
2023-04-17 00:45:08,940 - Epoch: [21][  450/  518]    Overall Loss 3.794623    Objective Loss 3.794623                                        LR 0.001000    Time 0.203806    
2023-04-17 00:45:19,066 - Epoch: [21][  500/  518]    Overall Loss 3.794437    Objective Loss 3.794437                                        LR 0.001000    Time 0.203673    
2023-04-17 00:45:22,617 - Epoch: [21][  518/  518]    Overall Loss 3.796063    Objective Loss 3.796063                                        LR 0.001000    Time 0.203451    
2023-04-17 00:45:22,698 - --- validate (epoch=21)-----------
2023-04-17 00:45:22,698 - 4952 samples (32 per mini-batch)
2023-04-17 00:46:22,228 - Epoch: [21][   50/  155]    Loss 3.895969    mAP 0.372786    
2023-04-17 00:47:21,438 - Epoch: [21][  100/  155]    Loss 3.913835    mAP 0.364048    
2023-04-17 00:48:19,679 - Epoch: [21][  150/  155]    Loss 3.905356    mAP 0.362844    
2023-04-17 00:48:25,215 - Epoch: [21][  155/  155]    Loss 3.904115    mAP 0.362906    
2023-04-17 00:48:25,287 - ==> mAP: 0.36291    Loss: 3.904

2023-04-17 00:48:25,290 - ==> Best [mAP: 0.362906   vloss: 3.904115   Sparsity:0.00   Params: 2177088 on epoch: 21]
2023-04-17 00:48:25,291 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 00:48:25,337 - 

2023-04-17 00:48:25,337 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 00:48:36,310 - Epoch: [22][   50/  518]    Overall Loss 3.695840    Objective Loss 3.695840                                        LR 0.001000    Time 0.219397    
2023-04-17 00:48:46,415 - Epoch: [22][  100/  518]    Overall Loss 3.721552    Objective Loss 3.721552                                        LR 0.001000    Time 0.210734    
2023-04-17 00:48:56,578 - Epoch: [22][  150/  518]    Overall Loss 3.747544    Objective Loss 3.747544                                        LR 0.001000    Time 0.208235    
2023-04-17 00:49:06,666 - Epoch: [22][  200/  518]    Overall Loss 3.769349    Objective Loss 3.769349                                        LR 0.001000    Time 0.206605    
2023-04-17 00:49:16,763 - Epoch: [22][  250/  518]    Overall Loss 3.770120    Objective Loss 3.770120                                        LR 0.001000    Time 0.205669    
2023-04-17 00:49:26,830 - Epoch: [22][  300/  518]    Overall Loss 3.750630    Objective Loss 3.750630                                        LR 0.001000    Time 0.204942    
2023-04-17 00:49:37,009 - Epoch: [22][  350/  518]    Overall Loss 3.754812    Objective Loss 3.754812                                        LR 0.001000    Time 0.204742    
2023-04-17 00:49:47,077 - Epoch: [22][  400/  518]    Overall Loss 3.759899    Objective Loss 3.759899                                        LR 0.001000    Time 0.204316    
2023-04-17 00:49:57,177 - Epoch: [22][  450/  518]    Overall Loss 3.758521    Objective Loss 3.758521                                        LR 0.001000    Time 0.204054    
2023-04-17 00:50:07,336 - Epoch: [22][  500/  518]    Overall Loss 3.760003    Objective Loss 3.760003                                        LR 0.001000    Time 0.203965    
2023-04-17 00:50:10,828 - Epoch: [22][  518/  518]    Overall Loss 3.761186    Objective Loss 3.761186                                        LR 0.001000    Time 0.203617    
2023-04-17 00:50:10,909 - --- validate (epoch=22)-----------
2023-04-17 00:50:10,909 - 4952 samples (32 per mini-batch)
2023-04-17 00:51:02,593 - Epoch: [22][   50/  155]    Loss 4.528871    mAP 0.280224    
2023-04-17 00:51:54,330 - Epoch: [22][  100/  155]    Loss 4.513211    mAP 0.295439    
2023-04-17 00:52:45,975 - Epoch: [22][  150/  155]    Loss 4.501624    mAP 0.295752    
2023-04-17 00:52:50,635 - Epoch: [22][  155/  155]    Loss 4.503592    mAP 0.294738    
2023-04-17 00:52:50,714 - ==> mAP: 0.29474    Loss: 4.504

2023-04-17 00:52:50,717 - ==> Best [mAP: 0.362906   vloss: 3.904115   Sparsity:0.00   Params: 2177088 on epoch: 21]
2023-04-17 00:52:50,718 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 00:52:50,755 - 

2023-04-17 00:52:50,755 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 00:53:01,648 - Epoch: [23][   50/  518]    Overall Loss 3.820582    Objective Loss 3.820582                                        LR 0.001000    Time 0.217810    
2023-04-17 00:53:11,738 - Epoch: [23][  100/  518]    Overall Loss 3.766967    Objective Loss 3.766967                                        LR 0.001000    Time 0.209790    
2023-04-17 00:53:21,796 - Epoch: [23][  150/  518]    Overall Loss 3.778439    Objective Loss 3.778439                                        LR 0.001000    Time 0.206903    
2023-04-17 00:53:31,880 - Epoch: [23][  200/  518]    Overall Loss 3.765851    Objective Loss 3.765851                                        LR 0.001000    Time 0.205588    
2023-04-17 00:53:41,932 - Epoch: [23][  250/  518]    Overall Loss 3.760737    Objective Loss 3.760737                                        LR 0.001000    Time 0.204674    
2023-04-17 00:53:52,007 - Epoch: [23][  300/  518]    Overall Loss 3.757645    Objective Loss 3.757645                                        LR 0.001000    Time 0.204138    
2023-04-17 00:54:02,134 - Epoch: [23][  350/  518]    Overall Loss 3.756413    Objective Loss 3.756413                                        LR 0.001000    Time 0.203905    
2023-04-17 00:54:12,251 - Epoch: [23][  400/  518]    Overall Loss 3.753715    Objective Loss 3.753715                                        LR 0.001000    Time 0.203706    
2023-04-17 00:54:22,405 - Epoch: [23][  450/  518]    Overall Loss 3.750105    Objective Loss 3.750105                                        LR 0.001000    Time 0.203633    
2023-04-17 00:54:32,543 - Epoch: [23][  500/  518]    Overall Loss 3.753114    Objective Loss 3.753114                                        LR 0.001000    Time 0.203542    
2023-04-17 00:54:36,056 - Epoch: [23][  518/  518]    Overall Loss 3.749210    Objective Loss 3.749210                                        LR 0.001000    Time 0.203250    
2023-04-17 00:54:36,137 - --- validate (epoch=23)-----------
2023-04-17 00:54:36,137 - 4952 samples (32 per mini-batch)
2023-04-17 00:55:24,413 - Epoch: [23][   50/  155]    Loss 4.009038    mAP 0.336930    
2023-04-17 00:56:13,366 - Epoch: [23][  100/  155]    Loss 4.013901    mAP 0.349232    
2023-04-17 00:57:00,262 - Epoch: [23][  150/  155]    Loss 4.007582    mAP 0.345076    
2023-04-17 00:57:04,560 - Epoch: [23][  155/  155]    Loss 4.008187    mAP 0.345569    
2023-04-17 00:57:04,640 - ==> mAP: 0.34557    Loss: 4.008

2023-04-17 00:57:04,643 - ==> Best [mAP: 0.362906   vloss: 3.904115   Sparsity:0.00   Params: 2177088 on epoch: 21]
2023-04-17 00:57:04,644 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 00:57:04,680 - 

2023-04-17 00:57:04,680 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 00:57:15,667 - Epoch: [24][   50/  518]    Overall Loss 3.758564    Objective Loss 3.758564                                        LR 0.001000    Time 0.219684    
2023-04-17 00:57:25,791 - Epoch: [24][  100/  518]    Overall Loss 3.722347    Objective Loss 3.722347                                        LR 0.001000    Time 0.211064    
2023-04-17 00:57:35,896 - Epoch: [24][  150/  518]    Overall Loss 3.690798    Objective Loss 3.690798                                        LR 0.001000    Time 0.208069    
2023-04-17 00:57:45,983 - Epoch: [24][  200/  518]    Overall Loss 3.691377    Objective Loss 3.691377                                        LR 0.001000    Time 0.206477    
2023-04-17 00:57:56,138 - Epoch: [24][  250/  518]    Overall Loss 3.701436    Objective Loss 3.701436                                        LR 0.001000    Time 0.205794    
2023-04-17 00:58:06,202 - Epoch: [24][  300/  518]    Overall Loss 3.710806    Objective Loss 3.710806                                        LR 0.001000    Time 0.205038    
2023-04-17 00:58:16,399 - Epoch: [24][  350/  518]    Overall Loss 3.717341    Objective Loss 3.717341                                        LR 0.001000    Time 0.204877    
2023-04-17 00:58:26,482 - Epoch: [24][  400/  518]    Overall Loss 3.719254    Objective Loss 3.719254                                        LR 0.001000    Time 0.204471    
2023-04-17 00:58:36,534 - Epoch: [24][  450/  518]    Overall Loss 3.715559    Objective Loss 3.715559                                        LR 0.001000    Time 0.204086    
2023-04-17 00:58:46,621 - Epoch: [24][  500/  518]    Overall Loss 3.716824    Objective Loss 3.716824                                        LR 0.001000    Time 0.203848    
2023-04-17 00:58:50,146 - Epoch: [24][  518/  518]    Overall Loss 3.720252    Objective Loss 3.720252                                        LR 0.001000    Time 0.203569    
2023-04-17 00:58:50,224 - --- validate (epoch=24)-----------
2023-04-17 00:58:50,224 - 4952 samples (32 per mini-batch)
2023-04-17 00:59:41,786 - Epoch: [24][   50/  155]    Loss 4.307949    mAP 0.306209    
2023-04-17 01:00:32,942 - Epoch: [24][  100/  155]    Loss 4.277925    mAP 0.307158    
2023-04-17 01:01:22,439 - Epoch: [24][  150/  155]    Loss 4.279267    mAP 0.307846    
2023-04-17 01:01:27,303 - Epoch: [24][  155/  155]    Loss 4.275534    mAP 0.307222    
2023-04-17 01:01:27,380 - ==> mAP: 0.30722    Loss: 4.276

2023-04-17 01:01:27,384 - ==> Best [mAP: 0.362906   vloss: 3.904115   Sparsity:0.00   Params: 2177088 on epoch: 21]
2023-04-17 01:01:27,384 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 01:01:27,420 - 

2023-04-17 01:01:27,420 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 01:01:38,435 - Epoch: [25][   50/  518]    Overall Loss 3.679805    Objective Loss 3.679805                                        LR 0.001000    Time 0.220234    
2023-04-17 01:01:48,490 - Epoch: [25][  100/  518]    Overall Loss 3.701473    Objective Loss 3.701473                                        LR 0.001000    Time 0.210655    
2023-04-17 01:01:58,555 - Epoch: [25][  150/  518]    Overall Loss 3.701067    Objective Loss 3.701067                                        LR 0.001000    Time 0.207530    
2023-04-17 01:02:08,654 - Epoch: [25][  200/  518]    Overall Loss 3.693435    Objective Loss 3.693435                                        LR 0.001000    Time 0.206135    
2023-04-17 01:02:18,742 - Epoch: [25][  250/  518]    Overall Loss 3.694707    Objective Loss 3.694707                                        LR 0.001000    Time 0.205251    
2023-04-17 01:02:28,843 - Epoch: [25][  300/  518]    Overall Loss 3.702577    Objective Loss 3.702577                                        LR 0.001000    Time 0.204709    
2023-04-17 01:02:38,937 - Epoch: [25][  350/  518]    Overall Loss 3.698010    Objective Loss 3.698010                                        LR 0.001000    Time 0.204301    
2023-04-17 01:02:49,181 - Epoch: [25][  400/  518]    Overall Loss 3.699328    Objective Loss 3.699328                                        LR 0.001000    Time 0.204369    
2023-04-17 01:02:59,215 - Epoch: [25][  450/  518]    Overall Loss 3.693185    Objective Loss 3.693185                                        LR 0.001000    Time 0.203955    
2023-04-17 01:03:09,245 - Epoch: [25][  500/  518]    Overall Loss 3.690584    Objective Loss 3.690584                                        LR 0.001000    Time 0.203618    
2023-04-17 01:03:12,754 - Epoch: [25][  518/  518]    Overall Loss 3.689226    Objective Loss 3.689226                                        LR 0.001000    Time 0.203314    
2023-04-17 01:03:12,836 - --- validate (epoch=25)-----------
2023-04-17 01:03:12,836 - 4952 samples (32 per mini-batch)
2023-04-17 01:04:08,091 - Epoch: [25][   50/  155]    Loss 3.947484    mAP 0.351298    
2023-04-17 01:05:01,605 - Epoch: [25][  100/  155]    Loss 3.924481    mAP 0.353087    
2023-04-17 01:05:53,119 - Epoch: [25][  150/  155]    Loss 3.919279    mAP 0.352601    
2023-04-17 01:05:57,967 - Epoch: [25][  155/  155]    Loss 3.915207    mAP 0.352167    
2023-04-17 01:05:58,043 - ==> mAP: 0.35217    Loss: 3.915

2023-04-17 01:05:58,047 - ==> Best [mAP: 0.362906   vloss: 3.904115   Sparsity:0.00   Params: 2177088 on epoch: 21]
2023-04-17 01:05:58,047 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 01:05:58,083 - 

2023-04-17 01:05:58,083 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 01:06:08,896 - Epoch: [26][   50/  518]    Overall Loss 3.701971    Objective Loss 3.701971                                        LR 0.001000    Time 0.216218    
2023-04-17 01:06:18,973 - Epoch: [26][  100/  518]    Overall Loss 3.684072    Objective Loss 3.684072                                        LR 0.001000    Time 0.208856    
2023-04-17 01:06:29,089 - Epoch: [26][  150/  518]    Overall Loss 3.693715    Objective Loss 3.693715                                        LR 0.001000    Time 0.206665    
2023-04-17 01:06:39,141 - Epoch: [26][  200/  518]    Overall Loss 3.671796    Objective Loss 3.671796                                        LR 0.001000    Time 0.205255    
2023-04-17 01:06:49,241 - Epoch: [26][  250/  518]    Overall Loss 3.664486    Objective Loss 3.664486                                        LR 0.001000    Time 0.204596    
2023-04-17 01:06:59,317 - Epoch: [26][  300/  518]    Overall Loss 3.670272    Objective Loss 3.670272                                        LR 0.001000    Time 0.204080    
2023-04-17 01:07:09,423 - Epoch: [26][  350/  518]    Overall Loss 3.671121    Objective Loss 3.671121                                        LR 0.001000    Time 0.203794    
2023-04-17 01:07:19,487 - Epoch: [26][  400/  518]    Overall Loss 3.675638    Objective Loss 3.675638                                        LR 0.001000    Time 0.203476    
2023-04-17 01:07:29,500 - Epoch: [26][  450/  518]    Overall Loss 3.675734    Objective Loss 3.675734                                        LR 0.001000    Time 0.203115    
2023-04-17 01:07:39,580 - Epoch: [26][  500/  518]    Overall Loss 3.675266    Objective Loss 3.675266                                        LR 0.001000    Time 0.202960    
2023-04-17 01:07:43,095 - Epoch: [26][  518/  518]    Overall Loss 3.675644    Objective Loss 3.675644                                        LR 0.001000    Time 0.202692    
2023-04-17 01:07:43,176 - --- validate (epoch=26)-----------
2023-04-17 01:07:43,177 - 4952 samples (32 per mini-batch)
2023-04-17 01:08:44,231 - Epoch: [26][   50/  155]    Loss 3.871911    mAP 0.352395    
2023-04-17 01:09:43,925 - Epoch: [26][  100/  155]    Loss 3.853816    mAP 0.359963    
2023-04-17 01:10:44,448 - Epoch: [26][  150/  155]    Loss 3.848667    mAP 0.359634    
2023-04-17 01:10:50,349 - Epoch: [26][  155/  155]    Loss 3.850283    mAP 0.360232    
2023-04-17 01:10:50,437 - ==> mAP: 0.36023    Loss: 3.850

2023-04-17 01:10:50,441 - ==> Best [mAP: 0.362906   vloss: 3.904115   Sparsity:0.00   Params: 2177088 on epoch: 21]
2023-04-17 01:10:50,441 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 01:10:50,502 - 

2023-04-17 01:10:50,503 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 01:11:01,266 - Epoch: [27][   50/  518]    Overall Loss 3.667002    Objective Loss 3.667002                                        LR 0.001000    Time 0.215179    
2023-04-17 01:11:11,356 - Epoch: [27][  100/  518]    Overall Loss 3.666500    Objective Loss 3.666500                                        LR 0.001000    Time 0.208474    
2023-04-17 01:11:21,520 - Epoch: [27][  150/  518]    Overall Loss 3.659007    Objective Loss 3.659007                                        LR 0.001000    Time 0.206728    
2023-04-17 01:11:31,628 - Epoch: [27][  200/  518]    Overall Loss 3.656511    Objective Loss 3.656511                                        LR 0.001000    Time 0.205577    
2023-04-17 01:11:41,756 - Epoch: [27][  250/  518]    Overall Loss 3.660483    Objective Loss 3.660483                                        LR 0.001000    Time 0.204970    
2023-04-17 01:11:51,849 - Epoch: [27][  300/  518]    Overall Loss 3.661981    Objective Loss 3.661981                                        LR 0.001000    Time 0.204448    
2023-04-17 01:12:01,911 - Epoch: [27][  350/  518]    Overall Loss 3.652014    Objective Loss 3.652014                                        LR 0.001000    Time 0.203983    
2023-04-17 01:12:12,101 - Epoch: [27][  400/  518]    Overall Loss 3.650647    Objective Loss 3.650647                                        LR 0.001000    Time 0.203956    
2023-04-17 01:12:22,260 - Epoch: [27][  450/  518]    Overall Loss 3.653974    Objective Loss 3.653974                                        LR 0.001000    Time 0.203868    
2023-04-17 01:12:32,362 - Epoch: [27][  500/  518]    Overall Loss 3.653372    Objective Loss 3.653372                                        LR 0.001000    Time 0.203682    
2023-04-17 01:12:35,888 - Epoch: [27][  518/  518]    Overall Loss 3.652882    Objective Loss 3.652882                                        LR 0.001000    Time 0.203409    
2023-04-17 01:12:35,971 - --- validate (epoch=27)-----------
2023-04-17 01:12:35,971 - 4952 samples (32 per mini-batch)
2023-04-17 01:13:28,331 - Epoch: [27][   50/  155]    Loss 3.814050    mAP 0.361205    
2023-04-17 01:14:22,102 - Epoch: [27][  100/  155]    Loss 3.842994    mAP 0.361421    
2023-04-17 01:15:14,913 - Epoch: [27][  150/  155]    Loss 3.847936    mAP 0.361558    
2023-04-17 01:15:19,665 - Epoch: [27][  155/  155]    Loss 3.844316    mAP 0.363187    
2023-04-17 01:15:19,751 - ==> mAP: 0.36319    Loss: 3.844

2023-04-17 01:15:19,755 - ==> Best [mAP: 0.363187   vloss: 3.844316   Sparsity:0.00   Params: 2177088 on epoch: 27]
2023-04-17 01:15:19,755 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 01:15:19,806 - 

2023-04-17 01:15:19,806 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 01:15:30,572 - Epoch: [28][   50/  518]    Overall Loss 3.712203    Objective Loss 3.712203                                        LR 0.001000    Time 0.215263    
2023-04-17 01:15:40,645 - Epoch: [28][  100/  518]    Overall Loss 3.690363    Objective Loss 3.690363                                        LR 0.001000    Time 0.208346    
2023-04-17 01:15:50,747 - Epoch: [28][  150/  518]    Overall Loss 3.665044    Objective Loss 3.665044                                        LR 0.001000    Time 0.206237    
2023-04-17 01:16:00,982 - Epoch: [28][  200/  518]    Overall Loss 3.652866    Objective Loss 3.652866                                        LR 0.001000    Time 0.205841    
2023-04-17 01:16:11,058 - Epoch: [28][  250/  518]    Overall Loss 3.638911    Objective Loss 3.638911                                        LR 0.001000    Time 0.204973    
2023-04-17 01:16:21,061 - Epoch: [28][  300/  518]    Overall Loss 3.637071    Objective Loss 3.637071                                        LR 0.001000    Time 0.204149    
2023-04-17 01:16:31,109 - Epoch: [28][  350/  518]    Overall Loss 3.636828    Objective Loss 3.636828                                        LR 0.001000    Time 0.203688    
2023-04-17 01:16:41,275 - Epoch: [28][  400/  518]    Overall Loss 3.632191    Objective Loss 3.632191                                        LR 0.001000    Time 0.203639    
2023-04-17 01:16:51,308 - Epoch: [28][  450/  518]    Overall Loss 3.629963    Objective Loss 3.629963                                        LR 0.001000    Time 0.203306    
2023-04-17 01:17:01,414 - Epoch: [28][  500/  518]    Overall Loss 3.629250    Objective Loss 3.629250                                        LR 0.001000    Time 0.203184    
2023-04-17 01:17:04,929 - Epoch: [28][  518/  518]    Overall Loss 3.630351    Objective Loss 3.630351                                        LR 0.001000    Time 0.202907    
2023-04-17 01:17:05,008 - --- validate (epoch=28)-----------
2023-04-17 01:17:05,009 - 4952 samples (32 per mini-batch)
2023-04-17 01:18:14,335 - Epoch: [28][   50/  155]    Loss 3.887793    mAP 0.356596    
2023-04-17 01:19:24,817 - Epoch: [28][  100/  155]    Loss 3.898129    mAP 0.360152    
2023-04-17 01:20:35,165 - Epoch: [28][  150/  155]    Loss 3.866235    mAP 0.365674    
2023-04-17 01:20:41,812 - Epoch: [28][  155/  155]    Loss 3.863951    mAP 0.366504    
2023-04-17 01:20:41,888 - ==> mAP: 0.36650    Loss: 3.864

2023-04-17 01:20:41,892 - ==> Best [mAP: 0.366504   vloss: 3.863951   Sparsity:0.00   Params: 2177088 on epoch: 28]
2023-04-17 01:20:41,892 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 01:20:41,944 - 

2023-04-17 01:20:41,944 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 01:20:52,751 - Epoch: [29][   50/  518]    Overall Loss 3.665936    Objective Loss 3.665936                                        LR 0.001000    Time 0.216083    
2023-04-17 01:21:02,811 - Epoch: [29][  100/  518]    Overall Loss 3.633980    Objective Loss 3.633980                                        LR 0.001000    Time 0.208633    
2023-04-17 01:21:12,898 - Epoch: [29][  150/  518]    Overall Loss 3.630760    Objective Loss 3.630760                                        LR 0.001000    Time 0.206320    
2023-04-17 01:21:23,032 - Epoch: [29][  200/  518]    Overall Loss 3.609123    Objective Loss 3.609123                                        LR 0.001000    Time 0.205402    
2023-04-17 01:21:33,254 - Epoch: [29][  250/  518]    Overall Loss 3.626871    Objective Loss 3.626871                                        LR 0.001000    Time 0.205206    
2023-04-17 01:21:43,382 - Epoch: [29][  300/  518]    Overall Loss 3.615760    Objective Loss 3.615760                                        LR 0.001000    Time 0.204757    
2023-04-17 01:21:53,510 - Epoch: [29][  350/  518]    Overall Loss 3.620810    Objective Loss 3.620810                                        LR 0.001000    Time 0.204441    
2023-04-17 01:22:03,734 - Epoch: [29][  400/  518]    Overall Loss 3.622124    Objective Loss 3.622124                                        LR 0.001000    Time 0.204442    
2023-04-17 01:22:13,834 - Epoch: [29][  450/  518]    Overall Loss 3.619581    Objective Loss 3.619581                                        LR 0.001000    Time 0.204167    
2023-04-17 01:22:23,951 - Epoch: [29][  500/  518]    Overall Loss 3.615341    Objective Loss 3.615341                                        LR 0.001000    Time 0.203981    
2023-04-17 01:22:27,481 - Epoch: [29][  518/  518]    Overall Loss 3.615887    Objective Loss 3.615887                                        LR 0.001000    Time 0.203707    
2023-04-17 01:22:27,559 - --- validate (epoch=29)-----------
2023-04-17 01:22:27,559 - 4952 samples (32 per mini-batch)
2023-04-17 01:23:19,685 - Epoch: [29][   50/  155]    Loss 3.744844    mAP 0.410792    
2023-04-17 01:24:10,659 - Epoch: [29][  100/  155]    Loss 3.744517    mAP 0.404370    
2023-04-17 01:25:02,486 - Epoch: [29][  150/  155]    Loss 3.746022    mAP 0.391772    
2023-04-17 01:25:07,299 - Epoch: [29][  155/  155]    Loss 3.746455    mAP 0.389428    
2023-04-17 01:25:07,376 - ==> mAP: 0.38943    Loss: 3.746

2023-04-17 01:25:07,380 - ==> Best [mAP: 0.389428   vloss: 3.746455   Sparsity:0.00   Params: 2177088 on epoch: 29]
2023-04-17 01:25:07,380 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 01:25:07,431 - 

2023-04-17 01:25:07,431 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 01:25:18,271 - Epoch: [30][   50/  518]    Overall Loss 3.586300    Objective Loss 3.586300                                        LR 0.001000    Time 0.216737    
2023-04-17 01:25:28,356 - Epoch: [30][  100/  518]    Overall Loss 3.614478    Objective Loss 3.614478                                        LR 0.001000    Time 0.209200    
2023-04-17 01:25:38,470 - Epoch: [30][  150/  518]    Overall Loss 3.604260    Objective Loss 3.604260                                        LR 0.001000    Time 0.206887    
2023-04-17 01:25:48,567 - Epoch: [30][  200/  518]    Overall Loss 3.597605    Objective Loss 3.597605                                        LR 0.001000    Time 0.205640    
2023-04-17 01:25:58,696 - Epoch: [30][  250/  518]    Overall Loss 3.605489    Objective Loss 3.605489                                        LR 0.001000    Time 0.205021    
2023-04-17 01:26:08,756 - Epoch: [30][  300/  518]    Overall Loss 3.610535    Objective Loss 3.610535                                        LR 0.001000    Time 0.204379    
2023-04-17 01:26:18,866 - Epoch: [30][  350/  518]    Overall Loss 3.599045    Objective Loss 3.599045                                        LR 0.001000    Time 0.204056    
2023-04-17 01:26:28,984 - Epoch: [30][  400/  518]    Overall Loss 3.593237    Objective Loss 3.593237                                        LR 0.001000    Time 0.203840    
2023-04-17 01:26:39,151 - Epoch: [30][  450/  518]    Overall Loss 3.602303    Objective Loss 3.602303                                        LR 0.001000    Time 0.203781    
2023-04-17 01:26:49,257 - Epoch: [30][  500/  518]    Overall Loss 3.600727    Objective Loss 3.600727                                        LR 0.001000    Time 0.203613    
2023-04-17 01:26:52,721 - Epoch: [30][  518/  518]    Overall Loss 3.602775    Objective Loss 3.602775                                        LR 0.001000    Time 0.203223    
2023-04-17 01:26:52,799 - --- validate (epoch=30)-----------
2023-04-17 01:26:52,799 - 4952 samples (32 per mini-batch)
2023-04-17 01:27:50,163 - Epoch: [30][   50/  155]    Loss 4.033389    mAP 0.360312    
2023-04-17 01:28:46,308 - Epoch: [30][  100/  155]    Loss 3.974273    mAP 0.360260    
2023-04-17 01:29:44,440 - Epoch: [30][  150/  155]    Loss 3.978798    mAP 0.351668    
2023-04-17 01:29:49,631 - Epoch: [30][  155/  155]    Loss 3.977434    mAP 0.352413    
2023-04-17 01:29:49,717 - ==> mAP: 0.35241    Loss: 3.977

2023-04-17 01:29:49,721 - ==> Best [mAP: 0.389428   vloss: 3.746455   Sparsity:0.00   Params: 2177088 on epoch: 29]
2023-04-17 01:29:49,721 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 01:29:49,756 - 

2023-04-17 01:29:49,756 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 01:30:00,767 - Epoch: [31][   50/  518]    Overall Loss 3.581292    Objective Loss 3.581292                                        LR 0.001000    Time 0.220152    
2023-04-17 01:30:10,884 - Epoch: [31][  100/  518]    Overall Loss 3.583509    Objective Loss 3.583509                                        LR 0.001000    Time 0.211235    
2023-04-17 01:30:20,914 - Epoch: [31][  150/  518]    Overall Loss 3.573983    Objective Loss 3.573983                                        LR 0.001000    Time 0.207681    
2023-04-17 01:30:31,017 - Epoch: [31][  200/  518]    Overall Loss 3.577694    Objective Loss 3.577694                                        LR 0.001000    Time 0.206265    
2023-04-17 01:30:41,150 - Epoch: [31][  250/  518]    Overall Loss 3.588152    Objective Loss 3.588152                                        LR 0.001000    Time 0.205538    
2023-04-17 01:30:51,230 - Epoch: [31][  300/  518]    Overall Loss 3.582862    Objective Loss 3.582862                                        LR 0.001000    Time 0.204877    
2023-04-17 01:31:01,334 - Epoch: [31][  350/  518]    Overall Loss 3.586098    Objective Loss 3.586098                                        LR 0.001000    Time 0.204473    
2023-04-17 01:31:11,391 - Epoch: [31][  400/  518]    Overall Loss 3.594614    Objective Loss 3.594614                                        LR 0.001000    Time 0.204053    
2023-04-17 01:31:21,441 - Epoch: [31][  450/  518]    Overall Loss 3.597915    Objective Loss 3.597915                                        LR 0.001000    Time 0.203710    
2023-04-17 01:31:31,644 - Epoch: [31][  500/  518]    Overall Loss 3.591437    Objective Loss 3.591437                                        LR 0.001000    Time 0.203742    
2023-04-17 01:31:35,134 - Epoch: [31][  518/  518]    Overall Loss 3.593621    Objective Loss 3.593621                                        LR 0.001000    Time 0.203399    
2023-04-17 01:31:35,216 - --- validate (epoch=31)-----------
2023-04-17 01:31:35,216 - 4952 samples (32 per mini-batch)
2023-04-17 01:32:46,124 - Epoch: [31][   50/  155]    Loss 3.964944    mAP 0.367667    
2023-04-17 01:33:57,629 - Epoch: [31][  100/  155]    Loss 3.936713    mAP 0.370047    
2023-04-17 01:35:09,827 - Epoch: [31][  150/  155]    Loss 3.942379    mAP 0.359396    
2023-04-17 01:35:16,217 - Epoch: [31][  155/  155]    Loss 3.933286    mAP 0.361861    
2023-04-17 01:35:16,296 - ==> mAP: 0.36186    Loss: 3.933

2023-04-17 01:35:16,300 - ==> Best [mAP: 0.389428   vloss: 3.746455   Sparsity:0.00   Params: 2177088 on epoch: 29]
2023-04-17 01:35:16,300 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 01:35:16,336 - 

2023-04-17 01:35:16,336 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 01:35:27,295 - Epoch: [32][   50/  518]    Overall Loss 3.527231    Objective Loss 3.527231                                        LR 0.001000    Time 0.219123    
2023-04-17 01:35:37,381 - Epoch: [32][  100/  518]    Overall Loss 3.532097    Objective Loss 3.532097                                        LR 0.001000    Time 0.210410    
2023-04-17 01:35:47,462 - Epoch: [32][  150/  518]    Overall Loss 3.545331    Objective Loss 3.545331                                        LR 0.001000    Time 0.207466    
2023-04-17 01:35:57,640 - Epoch: [32][  200/  518]    Overall Loss 3.546878    Objective Loss 3.546878                                        LR 0.001000    Time 0.206483    
2023-04-17 01:36:07,696 - Epoch: [32][  250/  518]    Overall Loss 3.562336    Objective Loss 3.562336                                        LR 0.001000    Time 0.205405    
2023-04-17 01:36:17,850 - Epoch: [32][  300/  518]    Overall Loss 3.568200    Objective Loss 3.568200                                        LR 0.001000    Time 0.205013    
2023-04-17 01:36:27,941 - Epoch: [32][  350/  518]    Overall Loss 3.566187    Objective Loss 3.566187                                        LR 0.001000    Time 0.204552    
2023-04-17 01:36:37,972 - Epoch: [32][  400/  518]    Overall Loss 3.569355    Objective Loss 3.569355                                        LR 0.001000    Time 0.204057    
2023-04-17 01:36:48,088 - Epoch: [32][  450/  518]    Overall Loss 3.560425    Objective Loss 3.560425                                        LR 0.001000    Time 0.203861    
2023-04-17 01:36:58,164 - Epoch: [32][  500/  518]    Overall Loss 3.562017    Objective Loss 3.562017                                        LR 0.001000    Time 0.203623    
2023-04-17 01:37:01,642 - Epoch: [32][  518/  518]    Overall Loss 3.565019    Objective Loss 3.565019                                        LR 0.001000    Time 0.203261    
2023-04-17 01:37:01,721 - --- validate (epoch=32)-----------
2023-04-17 01:37:01,722 - 4952 samples (32 per mini-batch)
2023-04-17 01:38:05,878 - Epoch: [32][   50/  155]    Loss 3.972374    mAP 0.357996    
2023-04-17 01:39:08,970 - Epoch: [32][  100/  155]    Loss 3.969417    mAP 0.354197    
2023-04-17 01:40:12,588 - Epoch: [32][  150/  155]    Loss 3.990831    mAP 0.351915    
2023-04-17 01:40:18,802 - Epoch: [32][  155/  155]    Loss 3.988675    mAP 0.352442    
2023-04-17 01:40:18,880 - ==> mAP: 0.35244    Loss: 3.989

2023-04-17 01:40:18,885 - ==> Best [mAP: 0.389428   vloss: 3.746455   Sparsity:0.00   Params: 2177088 on epoch: 29]
2023-04-17 01:40:18,885 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 01:40:18,922 - 

2023-04-17 01:40:18,922 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 01:40:29,859 - Epoch: [33][   50/  518]    Overall Loss 3.716081    Objective Loss 3.716081                                        LR 0.001000    Time 0.218692    
2023-04-17 01:40:39,907 - Epoch: [33][  100/  518]    Overall Loss 3.651512    Objective Loss 3.651512                                        LR 0.001000    Time 0.209809    
2023-04-17 01:40:49,997 - Epoch: [33][  150/  518]    Overall Loss 3.632567    Objective Loss 3.632567                                        LR 0.001000    Time 0.207128    
2023-04-17 01:41:00,089 - Epoch: [33][  200/  518]    Overall Loss 3.607168    Objective Loss 3.607168                                        LR 0.001000    Time 0.205798    
2023-04-17 01:41:10,150 - Epoch: [33][  250/  518]    Overall Loss 3.599409    Objective Loss 3.599409                                        LR 0.001000    Time 0.204877    
2023-04-17 01:41:20,279 - Epoch: [33][  300/  518]    Overall Loss 3.593243    Objective Loss 3.593243                                        LR 0.001000    Time 0.204490    
2023-04-17 01:41:30,372 - Epoch: [33][  350/  518]    Overall Loss 3.597643    Objective Loss 3.597643                                        LR 0.001000    Time 0.204109    
2023-04-17 01:41:40,402 - Epoch: [33][  400/  518]    Overall Loss 3.602895    Objective Loss 3.602895                                        LR 0.001000    Time 0.203667    
2023-04-17 01:41:50,520 - Epoch: [33][  450/  518]    Overall Loss 3.601806    Objective Loss 3.601806                                        LR 0.001000    Time 0.203518    
2023-04-17 01:42:00,593 - Epoch: [33][  500/  518]    Overall Loss 3.595004    Objective Loss 3.595004                                        LR 0.001000    Time 0.203309    
2023-04-17 01:42:04,158 - Epoch: [33][  518/  518]    Overall Loss 3.596838    Objective Loss 3.596838                                        LR 0.001000    Time 0.203125    
2023-04-17 01:42:04,241 - --- validate (epoch=33)-----------
2023-04-17 01:42:04,242 - 4952 samples (32 per mini-batch)
2023-04-17 01:42:56,157 - Epoch: [33][   50/  155]    Loss 3.792664    mAP 0.387901    
2023-04-17 01:43:47,304 - Epoch: [33][  100/  155]    Loss 3.785504    mAP 0.374486    
2023-04-17 01:44:38,575 - Epoch: [33][  150/  155]    Loss 3.783776    mAP 0.377374    
2023-04-17 01:44:43,388 - Epoch: [33][  155/  155]    Loss 3.777766    mAP 0.375920    
2023-04-17 01:44:43,469 - ==> mAP: 0.37592    Loss: 3.778

2023-04-17 01:44:43,472 - ==> Best [mAP: 0.389428   vloss: 3.746455   Sparsity:0.00   Params: 2177088 on epoch: 29]
2023-04-17 01:44:43,472 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 01:44:43,510 - 

2023-04-17 01:44:43,510 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 01:44:54,357 - Epoch: [34][   50/  518]    Overall Loss 3.475605    Objective Loss 3.475605                                        LR 0.001000    Time 0.216881    
2023-04-17 01:45:04,412 - Epoch: [34][  100/  518]    Overall Loss 3.467722    Objective Loss 3.467722                                        LR 0.001000    Time 0.208974    
2023-04-17 01:45:14,561 - Epoch: [34][  150/  518]    Overall Loss 3.479838    Objective Loss 3.479838                                        LR 0.001000    Time 0.206964    
2023-04-17 01:45:24,673 - Epoch: [34][  200/  518]    Overall Loss 3.486525    Objective Loss 3.486525                                        LR 0.001000    Time 0.205774    
2023-04-17 01:45:34,815 - Epoch: [34][  250/  518]    Overall Loss 3.494694    Objective Loss 3.494694                                        LR 0.001000    Time 0.205181    
2023-04-17 01:45:44,935 - Epoch: [34][  300/  518]    Overall Loss 3.502438    Objective Loss 3.502438                                        LR 0.001000    Time 0.204713    
2023-04-17 01:45:55,043 - Epoch: [34][  350/  518]    Overall Loss 3.519254    Objective Loss 3.519254                                        LR 0.001000    Time 0.204345    
2023-04-17 01:46:05,073 - Epoch: [34][  400/  518]    Overall Loss 3.525379    Objective Loss 3.525379                                        LR 0.001000    Time 0.203871    
2023-04-17 01:46:15,170 - Epoch: [34][  450/  518]    Overall Loss 3.528019    Objective Loss 3.528019                                        LR 0.001000    Time 0.203654    
2023-04-17 01:46:25,202 - Epoch: [34][  500/  518]    Overall Loss 3.527940    Objective Loss 3.527940                                        LR 0.001000    Time 0.203350    
2023-04-17 01:46:28,697 - Epoch: [34][  518/  518]    Overall Loss 3.531104    Objective Loss 3.531104                                        LR 0.001000    Time 0.203030    
2023-04-17 01:46:28,777 - --- validate (epoch=34)-----------
2023-04-17 01:46:28,778 - 4952 samples (32 per mini-batch)
2023-04-17 01:47:17,645 - Epoch: [34][   50/  155]    Loss 3.832965    mAP 0.378284    
2023-04-17 01:48:07,775 - Epoch: [34][  100/  155]    Loss 3.833039    mAP 0.381253    
2023-04-17 01:48:57,724 - Epoch: [34][  150/  155]    Loss 3.798230    mAP 0.386539    
2023-04-17 01:49:02,226 - Epoch: [34][  155/  155]    Loss 3.802854    mAP 0.386744    
2023-04-17 01:49:02,298 - ==> mAP: 0.38674    Loss: 3.803

2023-04-17 01:49:02,302 - ==> Best [mAP: 0.389428   vloss: 3.746455   Sparsity:0.00   Params: 2177088 on epoch: 29]
2023-04-17 01:49:02,302 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 01:49:02,338 - 

2023-04-17 01:49:02,338 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 01:49:13,214 - Epoch: [35][   50/  518]    Overall Loss 3.556485    Objective Loss 3.556485                                        LR 0.001000    Time 0.217475    
2023-04-17 01:49:23,315 - Epoch: [35][  100/  518]    Overall Loss 3.537937    Objective Loss 3.537937                                        LR 0.001000    Time 0.209727    
2023-04-17 01:49:33,499 - Epoch: [35][  150/  518]    Overall Loss 3.541931    Objective Loss 3.541931                                        LR 0.001000    Time 0.207704    
2023-04-17 01:49:43,591 - Epoch: [35][  200/  518]    Overall Loss 3.526160    Objective Loss 3.526160                                        LR 0.001000    Time 0.206230    
2023-04-17 01:49:53,690 - Epoch: [35][  250/  518]    Overall Loss 3.528964    Objective Loss 3.528964                                        LR 0.001000    Time 0.205371    
2023-04-17 01:50:03,860 - Epoch: [35][  300/  518]    Overall Loss 3.523817    Objective Loss 3.523817                                        LR 0.001000    Time 0.205038    
2023-04-17 01:50:13,979 - Epoch: [35][  350/  518]    Overall Loss 3.524043    Objective Loss 3.524043                                        LR 0.001000    Time 0.204653    
2023-04-17 01:50:24,091 - Epoch: [35][  400/  518]    Overall Loss 3.526981    Objective Loss 3.526981                                        LR 0.001000    Time 0.204349    
2023-04-17 01:50:34,194 - Epoch: [35][  450/  518]    Overall Loss 3.518162    Objective Loss 3.518162                                        LR 0.001000    Time 0.204091    
2023-04-17 01:50:44,304 - Epoch: [35][  500/  518]    Overall Loss 3.521062    Objective Loss 3.521062                                        LR 0.001000    Time 0.203899    
2023-04-17 01:50:47,740 - Epoch: [35][  518/  518]    Overall Loss 3.526402    Objective Loss 3.526402                                        LR 0.001000    Time 0.203445    
2023-04-17 01:50:47,820 - --- validate (epoch=35)-----------
2023-04-17 01:50:47,821 - 4952 samples (32 per mini-batch)
2023-04-17 01:51:46,540 - Epoch: [35][   50/  155]    Loss 3.690344    mAP 0.388920    
2023-04-17 01:52:45,889 - Epoch: [35][  100/  155]    Loss 3.708017    mAP 0.391965    
2023-04-17 01:53:44,619 - Epoch: [35][  150/  155]    Loss 3.688843    mAP 0.399129    
2023-04-17 01:53:50,891 - Epoch: [35][  155/  155]    Loss 3.692914    mAP 0.397779    
2023-04-17 01:53:50,968 - ==> mAP: 0.39778    Loss: 3.693

2023-04-17 01:53:50,971 - ==> Best [mAP: 0.397779   vloss: 3.692914   Sparsity:0.00   Params: 2177088 on epoch: 35]
2023-04-17 01:53:50,971 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 01:53:51,020 - 

2023-04-17 01:53:51,020 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 01:54:02,035 - Epoch: [36][   50/  518]    Overall Loss 3.493156    Objective Loss 3.493156                                        LR 0.001000    Time 0.220244    
2023-04-17 01:54:12,078 - Epoch: [36][  100/  518]    Overall Loss 3.495520    Objective Loss 3.495520                                        LR 0.001000    Time 0.210537    
2023-04-17 01:54:22,120 - Epoch: [36][  150/  518]    Overall Loss 3.490998    Objective Loss 3.490998                                        LR 0.001000    Time 0.207294    
2023-04-17 01:54:32,194 - Epoch: [36][  200/  518]    Overall Loss 3.496659    Objective Loss 3.496659                                        LR 0.001000    Time 0.205830    
2023-04-17 01:54:42,367 - Epoch: [36][  250/  518]    Overall Loss 3.493016    Objective Loss 3.493016                                        LR 0.001000    Time 0.205352    
2023-04-17 01:54:52,538 - Epoch: [36][  300/  518]    Overall Loss 3.497130    Objective Loss 3.497130                                        LR 0.001000    Time 0.205025    
2023-04-17 01:55:02,658 - Epoch: [36][  350/  518]    Overall Loss 3.501263    Objective Loss 3.501263                                        LR 0.001000    Time 0.204644    
2023-04-17 01:55:12,713 - Epoch: [36][  400/  518]    Overall Loss 3.502686    Objective Loss 3.502686                                        LR 0.001000    Time 0.204197    
2023-04-17 01:55:22,829 - Epoch: [36][  450/  518]    Overall Loss 3.501523    Objective Loss 3.501523                                        LR 0.001000    Time 0.203987    
2023-04-17 01:55:32,898 - Epoch: [36][  500/  518]    Overall Loss 3.506807    Objective Loss 3.506807                                        LR 0.001000    Time 0.203723    
2023-04-17 01:55:36,384 - Epoch: [36][  518/  518]    Overall Loss 3.504443    Objective Loss 3.504443                                        LR 0.001000    Time 0.203372    
2023-04-17 01:55:36,465 - --- validate (epoch=36)-----------
2023-04-17 01:55:36,465 - 4952 samples (32 per mini-batch)
2023-04-17 01:56:15,111 - Epoch: [36][   50/  155]    Loss 3.915912    mAP 0.374561    
2023-04-17 01:56:53,674 - Epoch: [36][  100/  155]    Loss 3.917997    mAP 0.369665    
2023-04-17 01:57:32,326 - Epoch: [36][  150/  155]    Loss 3.930317    mAP 0.365819    
2023-04-17 01:57:36,193 - Epoch: [36][  155/  155]    Loss 3.931510    mAP 0.364529    
2023-04-17 01:57:36,271 - ==> mAP: 0.36453    Loss: 3.932

2023-04-17 01:57:36,275 - ==> Best [mAP: 0.397779   vloss: 3.692914   Sparsity:0.00   Params: 2177088 on epoch: 35]
2023-04-17 01:57:36,275 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 01:57:36,311 - 

2023-04-17 01:57:36,312 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 01:57:47,215 - Epoch: [37][   50/  518]    Overall Loss 3.483343    Objective Loss 3.483343                                        LR 0.001000    Time 0.218007    
2023-04-17 01:57:57,344 - Epoch: [37][  100/  518]    Overall Loss 3.472764    Objective Loss 3.472764                                        LR 0.001000    Time 0.210277    
2023-04-17 01:58:07,434 - Epoch: [37][  150/  518]    Overall Loss 3.465989    Objective Loss 3.465989                                        LR 0.001000    Time 0.207445    
2023-04-17 01:58:17,594 - Epoch: [37][  200/  518]    Overall Loss 3.461740    Objective Loss 3.461740                                        LR 0.001000    Time 0.206377    
2023-04-17 01:58:27,795 - Epoch: [37][  250/  518]    Overall Loss 3.470539    Objective Loss 3.470539                                        LR 0.001000    Time 0.205899    
2023-04-17 01:58:37,921 - Epoch: [37][  300/  518]    Overall Loss 3.476757    Objective Loss 3.476757                                        LR 0.001000    Time 0.205330    
2023-04-17 01:58:48,048 - Epoch: [37][  350/  518]    Overall Loss 3.476781    Objective Loss 3.476781                                        LR 0.001000    Time 0.204928    
2023-04-17 01:58:58,080 - Epoch: [37][  400/  518]    Overall Loss 3.484070    Objective Loss 3.484070                                        LR 0.001000    Time 0.204388    
2023-04-17 01:59:08,171 - Epoch: [37][  450/  518]    Overall Loss 3.485897    Objective Loss 3.485897                                        LR 0.001000    Time 0.204099    
2023-04-17 01:59:18,326 - Epoch: [37][  500/  518]    Overall Loss 3.483715    Objective Loss 3.483715                                        LR 0.001000    Time 0.203996    
2023-04-17 01:59:21,809 - Epoch: [37][  518/  518]    Overall Loss 3.485328    Objective Loss 3.485328                                        LR 0.001000    Time 0.203630    
2023-04-17 01:59:21,889 - --- validate (epoch=37)-----------
2023-04-17 01:59:21,889 - 4952 samples (32 per mini-batch)
2023-04-17 02:00:16,517 - Epoch: [37][   50/  155]    Loss 3.761208    mAP 0.412299    
2023-04-17 02:01:11,751 - Epoch: [37][  100/  155]    Loss 3.776413    mAP 0.401621    
2023-04-17 02:02:05,073 - Epoch: [37][  150/  155]    Loss 3.757745    mAP 0.398877    
2023-04-17 02:02:10,654 - Epoch: [37][  155/  155]    Loss 3.759681    mAP 0.399865    
2023-04-17 02:02:10,733 - ==> mAP: 0.39987    Loss: 3.760

2023-04-17 02:02:10,736 - ==> Best [mAP: 0.399865   vloss: 3.759681   Sparsity:0.00   Params: 2177088 on epoch: 37]
2023-04-17 02:02:10,736 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 02:02:10,784 - 

2023-04-17 02:02:10,784 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 02:02:21,621 - Epoch: [38][   50/  518]    Overall Loss 3.546454    Objective Loss 3.546454                                        LR 0.001000    Time 0.216683    
2023-04-17 02:02:31,631 - Epoch: [38][  100/  518]    Overall Loss 3.546338    Objective Loss 3.546338                                        LR 0.001000    Time 0.208416    
2023-04-17 02:02:41,707 - Epoch: [38][  150/  518]    Overall Loss 3.534696    Objective Loss 3.534696                                        LR 0.001000    Time 0.206107    
2023-04-17 02:02:51,764 - Epoch: [38][  200/  518]    Overall Loss 3.510388    Objective Loss 3.510388                                        LR 0.001000    Time 0.204858    
2023-04-17 02:03:01,849 - Epoch: [38][  250/  518]    Overall Loss 3.499017    Objective Loss 3.499017                                        LR 0.001000    Time 0.204221    
2023-04-17 02:03:11,861 - Epoch: [38][  300/  518]    Overall Loss 3.501323    Objective Loss 3.501323                                        LR 0.001000    Time 0.203551    
2023-04-17 02:03:21,909 - Epoch: [38][  350/  518]    Overall Loss 3.493956    Objective Loss 3.493956                                        LR 0.001000    Time 0.203178    
2023-04-17 02:03:31,964 - Epoch: [38][  400/  518]    Overall Loss 3.490674    Objective Loss 3.490674                                        LR 0.001000    Time 0.202914    
2023-04-17 02:03:41,991 - Epoch: [38][  450/  518]    Overall Loss 3.487501    Objective Loss 3.487501                                        LR 0.001000    Time 0.202647    
2023-04-17 02:03:52,042 - Epoch: [38][  500/  518]    Overall Loss 3.480170    Objective Loss 3.480170                                        LR 0.001000    Time 0.202482    
2023-04-17 02:03:55,522 - Epoch: [38][  518/  518]    Overall Loss 3.478987    Objective Loss 3.478987                                        LR 0.001000    Time 0.202163    
2023-04-17 02:03:55,603 - --- validate (epoch=38)-----------
2023-04-17 02:03:55,604 - 4952 samples (32 per mini-batch)
2023-04-17 02:04:55,667 - Epoch: [38][   50/  155]    Loss 3.792703    mAP 0.382397    
2023-04-17 02:05:56,039 - Epoch: [38][  100/  155]    Loss 3.819835    mAP 0.390346    
2023-04-17 02:06:57,019 - Epoch: [38][  150/  155]    Loss 3.809994    mAP 0.389650    
2023-04-17 02:07:03,170 - Epoch: [38][  155/  155]    Loss 3.809839    mAP 0.390903    
2023-04-17 02:07:03,246 - ==> mAP: 0.39090    Loss: 3.810

2023-04-17 02:07:03,250 - ==> Best [mAP: 0.399865   vloss: 3.759681   Sparsity:0.00   Params: 2177088 on epoch: 37]
2023-04-17 02:07:03,250 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 02:07:03,287 - 

2023-04-17 02:07:03,287 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 02:07:14,133 - Epoch: [39][   50/  518]    Overall Loss 3.524592    Objective Loss 3.524592                                        LR 0.001000    Time 0.216870    
2023-04-17 02:07:24,386 - Epoch: [39][  100/  518]    Overall Loss 3.471129    Objective Loss 3.471129                                        LR 0.001000    Time 0.210948    
2023-04-17 02:07:34,480 - Epoch: [39][  150/  518]    Overall Loss 3.467093    Objective Loss 3.467093                                        LR 0.001000    Time 0.207916    
2023-04-17 02:07:44,503 - Epoch: [39][  200/  518]    Overall Loss 3.459602    Objective Loss 3.459602                                        LR 0.001000    Time 0.206046    
2023-04-17 02:07:54,636 - Epoch: [39][  250/  518]    Overall Loss 3.453973    Objective Loss 3.453973                                        LR 0.001000    Time 0.205362    
2023-04-17 02:08:04,651 - Epoch: [39][  300/  518]    Overall Loss 3.450999    Objective Loss 3.450999                                        LR 0.001000    Time 0.204513    
2023-04-17 02:08:14,747 - Epoch: [39][  350/  518]    Overall Loss 3.453291    Objective Loss 3.453291                                        LR 0.001000    Time 0.204138    
2023-04-17 02:08:24,854 - Epoch: [39][  400/  518]    Overall Loss 3.459659    Objective Loss 3.459659                                        LR 0.001000    Time 0.203885    
2023-04-17 02:08:34,980 - Epoch: [39][  450/  518]    Overall Loss 3.460875    Objective Loss 3.460875                                        LR 0.001000    Time 0.203730    
2023-04-17 02:08:45,064 - Epoch: [39][  500/  518]    Overall Loss 3.467205    Objective Loss 3.467205                                        LR 0.001000    Time 0.203520    
2023-04-17 02:08:48,572 - Epoch: [39][  518/  518]    Overall Loss 3.468686    Objective Loss 3.468686                                        LR 0.001000    Time 0.203220    
2023-04-17 02:08:48,653 - --- validate (epoch=39)-----------
2023-04-17 02:08:48,653 - 4952 samples (32 per mini-batch)
2023-04-17 02:09:45,124 - Epoch: [39][   50/  155]    Loss 3.603869    mAP 0.413798    
2023-04-17 02:10:43,171 - Epoch: [39][  100/  155]    Loss 3.598896    mAP 0.409240    
2023-04-17 02:11:40,709 - Epoch: [39][  150/  155]    Loss 3.613694    mAP 0.409016    
2023-04-17 02:11:46,338 - Epoch: [39][  155/  155]    Loss 3.612725    mAP 0.409894    
2023-04-17 02:11:46,415 - ==> mAP: 0.40989    Loss: 3.613

2023-04-17 02:11:46,419 - ==> Best [mAP: 0.409894   vloss: 3.612725   Sparsity:0.00   Params: 2177088 on epoch: 39]
2023-04-17 02:11:46,419 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 02:11:46,468 - 

2023-04-17 02:11:46,468 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 02:11:57,555 - Epoch: [40][   50/  518]    Overall Loss 3.470661    Objective Loss 3.470661                                        LR 0.001000    Time 0.221676    
2023-04-17 02:12:07,639 - Epoch: [40][  100/  518]    Overall Loss 3.486776    Objective Loss 3.486776                                        LR 0.001000    Time 0.211663    
2023-04-17 02:12:17,742 - Epoch: [40][  150/  518]    Overall Loss 3.459643    Objective Loss 3.459643                                        LR 0.001000    Time 0.208456    
2023-04-17 02:12:27,792 - Epoch: [40][  200/  518]    Overall Loss 3.472873    Objective Loss 3.472873                                        LR 0.001000    Time 0.206585    
2023-04-17 02:12:37,976 - Epoch: [40][  250/  518]    Overall Loss 3.471127    Objective Loss 3.471127                                        LR 0.001000    Time 0.205997    
2023-04-17 02:12:48,074 - Epoch: [40][  300/  518]    Overall Loss 3.467747    Objective Loss 3.467747                                        LR 0.001000    Time 0.205319    
2023-04-17 02:12:58,255 - Epoch: [40][  350/  518]    Overall Loss 3.467586    Objective Loss 3.467586                                        LR 0.001000    Time 0.205071    
2023-04-17 02:13:08,309 - Epoch: [40][  400/  518]    Overall Loss 3.465479    Objective Loss 3.465479                                        LR 0.001000    Time 0.204570    
2023-04-17 02:13:18,405 - Epoch: [40][  450/  518]    Overall Loss 3.462340    Objective Loss 3.462340                                        LR 0.001000    Time 0.204271    
2023-04-17 02:13:28,597 - Epoch: [40][  500/  518]    Overall Loss 3.463698    Objective Loss 3.463698                                        LR 0.001000    Time 0.204225    
2023-04-17 02:13:32,126 - Epoch: [40][  518/  518]    Overall Loss 3.465794    Objective Loss 3.465794                                        LR 0.001000    Time 0.203940    
2023-04-17 02:13:32,206 - --- validate (epoch=40)-----------
2023-04-17 02:13:32,207 - 4952 samples (32 per mini-batch)
2023-04-17 02:14:19,257 - Epoch: [40][   50/  155]    Loss 3.816639    mAP 0.398261    
2023-04-17 02:15:06,518 - Epoch: [40][  100/  155]    Loss 3.765964    mAP 0.397653    
2023-04-17 02:15:53,990 - Epoch: [40][  150/  155]    Loss 3.760572    mAP 0.396420    
2023-04-17 02:15:58,298 - Epoch: [40][  155/  155]    Loss 3.764469    mAP 0.396415    
2023-04-17 02:15:58,373 - ==> mAP: 0.39641    Loss: 3.764

2023-04-17 02:15:58,377 - ==> Best [mAP: 0.409894   vloss: 3.612725   Sparsity:0.00   Params: 2177088 on epoch: 39]
2023-04-17 02:15:58,377 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 02:15:58,414 - 

2023-04-17 02:15:58,414 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 02:16:09,287 - Epoch: [41][   50/  518]    Overall Loss 3.410998    Objective Loss 3.410998                                        LR 0.001000    Time 0.217400    
2023-04-17 02:16:19,343 - Epoch: [41][  100/  518]    Overall Loss 3.427308    Objective Loss 3.427308                                        LR 0.001000    Time 0.209244    
2023-04-17 02:16:29,472 - Epoch: [41][  150/  518]    Overall Loss 3.426317    Objective Loss 3.426317                                        LR 0.001000    Time 0.207011    
2023-04-17 02:16:39,576 - Epoch: [41][  200/  518]    Overall Loss 3.429689    Objective Loss 3.429689                                        LR 0.001000    Time 0.205774    
2023-04-17 02:16:49,704 - Epoch: [41][  250/  518]    Overall Loss 3.424361    Objective Loss 3.424361                                        LR 0.001000    Time 0.205122    
2023-04-17 02:16:59,820 - Epoch: [41][  300/  518]    Overall Loss 3.420329    Objective Loss 3.420329                                        LR 0.001000    Time 0.204650    
2023-04-17 02:17:10,045 - Epoch: [41][  350/  518]    Overall Loss 3.431310    Objective Loss 3.431310                                        LR 0.001000    Time 0.204624    
2023-04-17 02:17:20,162 - Epoch: [41][  400/  518]    Overall Loss 3.440877    Objective Loss 3.440877                                        LR 0.001000    Time 0.204335    
2023-04-17 02:17:30,239 - Epoch: [41][  450/  518]    Overall Loss 3.442337    Objective Loss 3.442337                                        LR 0.001000    Time 0.204021    
2023-04-17 02:17:40,422 - Epoch: [41][  500/  518]    Overall Loss 3.445851    Objective Loss 3.445851                                        LR 0.001000    Time 0.203982    
2023-04-17 02:17:43,933 - Epoch: [41][  518/  518]    Overall Loss 3.448103    Objective Loss 3.448103                                        LR 0.001000    Time 0.203672    
2023-04-17 02:17:44,014 - --- validate (epoch=41)-----------
2023-04-17 02:17:44,014 - 4952 samples (32 per mini-batch)
2023-04-17 02:18:36,848 - Epoch: [41][   50/  155]    Loss 3.731291    mAP 0.399692    
2023-04-17 02:19:29,508 - Epoch: [41][  100/  155]    Loss 3.744188    mAP 0.397826    
2023-04-17 02:20:21,751 - Epoch: [41][  150/  155]    Loss 3.736256    mAP 0.398724    
2023-04-17 02:20:27,199 - Epoch: [41][  155/  155]    Loss 3.734817    mAP 0.397361    
2023-04-17 02:20:27,274 - ==> mAP: 0.39736    Loss: 3.735

2023-04-17 02:20:27,277 - ==> Best [mAP: 0.409894   vloss: 3.612725   Sparsity:0.00   Params: 2177088 on epoch: 39]
2023-04-17 02:20:27,277 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 02:20:27,313 - 

2023-04-17 02:20:27,314 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 02:20:38,158 - Epoch: [42][   50/  518]    Overall Loss 3.419853    Objective Loss 3.419853                                        LR 0.001000    Time 0.216829    
2023-04-17 02:20:48,228 - Epoch: [42][  100/  518]    Overall Loss 3.420090    Objective Loss 3.420090                                        LR 0.001000    Time 0.209098    
2023-04-17 02:20:58,299 - Epoch: [42][  150/  518]    Overall Loss 3.419185    Objective Loss 3.419185                                        LR 0.001000    Time 0.206527    
2023-04-17 02:21:08,424 - Epoch: [42][  200/  518]    Overall Loss 3.410371    Objective Loss 3.410371                                        LR 0.001000    Time 0.205516    
2023-04-17 02:21:18,408 - Epoch: [42][  250/  518]    Overall Loss 3.418133    Objective Loss 3.418133                                        LR 0.001000    Time 0.204343    
2023-04-17 02:21:28,483 - Epoch: [42][  300/  518]    Overall Loss 3.429622    Objective Loss 3.429622                                        LR 0.001000    Time 0.203861    
2023-04-17 02:21:38,605 - Epoch: [42][  350/  518]    Overall Loss 3.440753    Objective Loss 3.440753                                        LR 0.001000    Time 0.203655    
2023-04-17 02:21:48,677 - Epoch: [42][  400/  518]    Overall Loss 3.442411    Objective Loss 3.442411                                        LR 0.001000    Time 0.203375    
2023-04-17 02:21:58,874 - Epoch: [42][  450/  518]    Overall Loss 3.436976    Objective Loss 3.436976                                        LR 0.001000    Time 0.203433    
2023-04-17 02:22:08,921 - Epoch: [42][  500/  518]    Overall Loss 3.428424    Objective Loss 3.428424                                        LR 0.001000    Time 0.203182    
2023-04-17 02:22:12,406 - Epoch: [42][  518/  518]    Overall Loss 3.430129    Objective Loss 3.430129                                        LR 0.001000    Time 0.202848    
2023-04-17 02:22:12,487 - --- validate (epoch=42)-----------
2023-04-17 02:22:12,487 - 4952 samples (32 per mini-batch)
2023-04-17 02:22:57,661 - Epoch: [42][   50/  155]    Loss 3.683473    mAP 0.400188    
2023-04-17 02:23:42,260 - Epoch: [42][  100/  155]    Loss 3.707785    mAP 0.399151    
2023-04-17 02:24:27,315 - Epoch: [42][  150/  155]    Loss 3.702772    mAP 0.393081    
2023-04-17 02:24:31,474 - Epoch: [42][  155/  155]    Loss 3.705049    mAP 0.391796    
2023-04-17 02:24:31,545 - ==> mAP: 0.39180    Loss: 3.705

2023-04-17 02:24:31,549 - ==> Best [mAP: 0.409894   vloss: 3.612725   Sparsity:0.00   Params: 2177088 on epoch: 39]
2023-04-17 02:24:31,549 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 02:24:31,586 - 

2023-04-17 02:24:31,586 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 02:24:42,429 - Epoch: [43][   50/  518]    Overall Loss 3.429273    Objective Loss 3.429273                                        LR 0.001000    Time 0.216820    
2023-04-17 02:24:52,485 - Epoch: [43][  100/  518]    Overall Loss 3.419891    Objective Loss 3.419891                                        LR 0.001000    Time 0.208950    
2023-04-17 02:25:02,517 - Epoch: [43][  150/  518]    Overall Loss 3.414251    Objective Loss 3.414251                                        LR 0.001000    Time 0.206168    
2023-04-17 02:25:12,588 - Epoch: [43][  200/  518]    Overall Loss 3.422046    Objective Loss 3.422046                                        LR 0.001000    Time 0.204973    
2023-04-17 02:25:22,633 - Epoch: [43][  250/  518]    Overall Loss 3.414561    Objective Loss 3.414561                                        LR 0.001000    Time 0.204152    
2023-04-17 02:25:32,755 - Epoch: [43][  300/  518]    Overall Loss 3.412459    Objective Loss 3.412459                                        LR 0.001000    Time 0.203863    
2023-04-17 02:25:42,796 - Epoch: [43][  350/  518]    Overall Loss 3.420380    Objective Loss 3.420380                                        LR 0.001000    Time 0.203424    
2023-04-17 02:25:52,871 - Epoch: [43][  400/  518]    Overall Loss 3.418582    Objective Loss 3.418582                                        LR 0.001000    Time 0.203181    
2023-04-17 02:26:02,948 - Epoch: [43][  450/  518]    Overall Loss 3.422303    Objective Loss 3.422303                                        LR 0.001000    Time 0.202994    
2023-04-17 02:26:12,984 - Epoch: [43][  500/  518]    Overall Loss 3.417630    Objective Loss 3.417630                                        LR 0.001000    Time 0.202764    
2023-04-17 02:26:16,508 - Epoch: [43][  518/  518]    Overall Loss 3.420343    Objective Loss 3.420343                                        LR 0.001000    Time 0.202519    
2023-04-17 02:26:16,587 - --- validate (epoch=43)-----------
2023-04-17 02:26:16,587 - 4952 samples (32 per mini-batch)
2023-04-17 02:27:14,347 - Epoch: [43][   50/  155]    Loss 3.803909    mAP 0.396677    
2023-04-17 02:28:10,766 - Epoch: [43][  100/  155]    Loss 3.774206    mAP 0.395788    
2023-04-17 02:29:08,673 - Epoch: [43][  150/  155]    Loss 3.788854    mAP 0.394429    
2023-04-17 02:29:13,645 - Epoch: [43][  155/  155]    Loss 3.790941    mAP 0.393790    
2023-04-17 02:29:13,723 - ==> mAP: 0.39379    Loss: 3.791

2023-04-17 02:29:13,726 - ==> Best [mAP: 0.409894   vloss: 3.612725   Sparsity:0.00   Params: 2177088 on epoch: 39]
2023-04-17 02:29:13,727 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 02:29:13,763 - 

2023-04-17 02:29:13,763 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 02:29:24,648 - Epoch: [44][   50/  518]    Overall Loss 3.348050    Objective Loss 3.348050                                        LR 0.001000    Time 0.217647    
2023-04-17 02:29:34,760 - Epoch: [44][  100/  518]    Overall Loss 3.391938    Objective Loss 3.391938                                        LR 0.001000    Time 0.209925    
2023-04-17 02:29:44,874 - Epoch: [44][  150/  518]    Overall Loss 3.392417    Objective Loss 3.392417                                        LR 0.001000    Time 0.207366    
2023-04-17 02:29:54,986 - Epoch: [44][  200/  518]    Overall Loss 3.380906    Objective Loss 3.380906                                        LR 0.001000    Time 0.206080    
2023-04-17 02:30:05,016 - Epoch: [44][  250/  518]    Overall Loss 3.371098    Objective Loss 3.371098                                        LR 0.001000    Time 0.204978    
2023-04-17 02:30:15,131 - Epoch: [44][  300/  518]    Overall Loss 3.378334    Objective Loss 3.378334                                        LR 0.001000    Time 0.204526    
2023-04-17 02:30:25,232 - Epoch: [44][  350/  518]    Overall Loss 3.390128    Objective Loss 3.390128                                        LR 0.001000    Time 0.204162    
2023-04-17 02:30:35,297 - Epoch: [44][  400/  518]    Overall Loss 3.392982    Objective Loss 3.392982                                        LR 0.001000    Time 0.203802    
2023-04-17 02:30:45,448 - Epoch: [44][  450/  518]    Overall Loss 3.391064    Objective Loss 3.391064                                        LR 0.001000    Time 0.203710    
2023-04-17 02:30:55,505 - Epoch: [44][  500/  518]    Overall Loss 3.391481    Objective Loss 3.391481                                        LR 0.001000    Time 0.203450    
2023-04-17 02:30:59,024 - Epoch: [44][  518/  518]    Overall Loss 3.393668    Objective Loss 3.393668                                        LR 0.001000    Time 0.203174    
2023-04-17 02:30:59,105 - --- validate (epoch=44)-----------
2023-04-17 02:30:59,105 - 4952 samples (32 per mini-batch)
2023-04-17 02:31:47,353 - Epoch: [44][   50/  155]    Loss 3.660811    mAP 0.407209    
2023-04-17 02:32:34,635 - Epoch: [44][  100/  155]    Loss 3.625846    mAP 0.416629    
2023-04-17 02:33:20,646 - Epoch: [44][  150/  155]    Loss 3.620555    mAP 0.417169    
2023-04-17 02:33:24,798 - Epoch: [44][  155/  155]    Loss 3.624232    mAP 0.416294    
2023-04-17 02:33:24,879 - ==> mAP: 0.41629    Loss: 3.624

2023-04-17 02:33:24,883 - ==> Best [mAP: 0.416294   vloss: 3.624232   Sparsity:0.00   Params: 2177088 on epoch: 44]
2023-04-17 02:33:24,883 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 02:33:24,934 - 

2023-04-17 02:33:24,934 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 02:33:35,860 - Epoch: [45][   50/  518]    Overall Loss 3.385524    Objective Loss 3.385524                                        LR 0.001000    Time 0.218460    
2023-04-17 02:33:45,963 - Epoch: [45][  100/  518]    Overall Loss 3.375357    Objective Loss 3.375357                                        LR 0.001000    Time 0.210242    
2023-04-17 02:33:55,993 - Epoch: [45][  150/  518]    Overall Loss 3.389994    Objective Loss 3.389994                                        LR 0.001000    Time 0.207020    
2023-04-17 02:34:06,067 - Epoch: [45][  200/  518]    Overall Loss 3.395802    Objective Loss 3.395802                                        LR 0.001000    Time 0.205625    
2023-04-17 02:34:16,159 - Epoch: [45][  250/  518]    Overall Loss 3.403201    Objective Loss 3.403201                                        LR 0.001000    Time 0.204862    
2023-04-17 02:34:26,269 - Epoch: [45][  300/  518]    Overall Loss 3.401039    Objective Loss 3.401039                                        LR 0.001000    Time 0.204415    
2023-04-17 02:34:36,453 - Epoch: [45][  350/  518]    Overall Loss 3.406383    Objective Loss 3.406383                                        LR 0.001000    Time 0.204305    
2023-04-17 02:34:46,618 - Epoch: [45][  400/  518]    Overall Loss 3.404614    Objective Loss 3.404614                                        LR 0.001000    Time 0.204175    
2023-04-17 02:34:56,756 - Epoch: [45][  450/  518]    Overall Loss 3.399734    Objective Loss 3.399734                                        LR 0.001000    Time 0.204014    
2023-04-17 02:35:06,849 - Epoch: [45][  500/  518]    Overall Loss 3.394741    Objective Loss 3.394741                                        LR 0.001000    Time 0.203796    
2023-04-17 02:35:10,366 - Epoch: [45][  518/  518]    Overall Loss 3.388208    Objective Loss 3.388208                                        LR 0.001000    Time 0.203502    
2023-04-17 02:35:10,446 - --- validate (epoch=45)-----------
2023-04-17 02:35:10,446 - 4952 samples (32 per mini-batch)
2023-04-17 02:36:09,137 - Epoch: [45][   50/  155]    Loss 3.662873    mAP 0.418422    
2023-04-17 02:37:09,891 - Epoch: [45][  100/  155]    Loss 3.662656    mAP 0.412467    
2023-04-17 02:38:09,077 - Epoch: [45][  150/  155]    Loss 3.673738    mAP 0.412305    
2023-04-17 02:38:14,359 - Epoch: [45][  155/  155]    Loss 3.665748    mAP 0.413208    
2023-04-17 02:38:14,433 - ==> mAP: 0.41321    Loss: 3.666

2023-04-17 02:38:14,437 - ==> Best [mAP: 0.416294   vloss: 3.624232   Sparsity:0.00   Params: 2177088 on epoch: 44]
2023-04-17 02:38:14,437 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 02:38:14,473 - 

2023-04-17 02:38:14,473 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 02:38:25,481 - Epoch: [46][   50/  518]    Overall Loss 3.416368    Objective Loss 3.416368                                        LR 0.001000    Time 0.220095    
2023-04-17 02:38:35,584 - Epoch: [46][  100/  518]    Overall Loss 3.372302    Objective Loss 3.372302                                        LR 0.001000    Time 0.211063    
2023-04-17 02:38:45,591 - Epoch: [46][  150/  518]    Overall Loss 3.359363    Objective Loss 3.359363                                        LR 0.001000    Time 0.207408    
2023-04-17 02:38:55,687 - Epoch: [46][  200/  518]    Overall Loss 3.372557    Objective Loss 3.372557                                        LR 0.001000    Time 0.206028    
2023-04-17 02:39:05,777 - Epoch: [46][  250/  518]    Overall Loss 3.386126    Objective Loss 3.386126                                        LR 0.001000    Time 0.205176    
2023-04-17 02:39:15,835 - Epoch: [46][  300/  518]    Overall Loss 3.389630    Objective Loss 3.389630                                        LR 0.001000    Time 0.204502    
2023-04-17 02:39:25,907 - Epoch: [46][  350/  518]    Overall Loss 3.392554    Objective Loss 3.392554                                        LR 0.001000    Time 0.204060    
2023-04-17 02:39:35,911 - Epoch: [46][  400/  518]    Overall Loss 3.390686    Objective Loss 3.390686                                        LR 0.001000    Time 0.203560    
2023-04-17 02:39:46,018 - Epoch: [46][  450/  518]    Overall Loss 3.386967    Objective Loss 3.386967                                        LR 0.001000    Time 0.203398    
2023-04-17 02:39:56,100 - Epoch: [46][  500/  518]    Overall Loss 3.390030    Objective Loss 3.390030                                        LR 0.001000    Time 0.203219    
2023-04-17 02:39:59,612 - Epoch: [46][  518/  518]    Overall Loss 3.391505    Objective Loss 3.391505                                        LR 0.001000    Time 0.202937    
2023-04-17 02:39:59,694 - --- validate (epoch=46)-----------
2023-04-17 02:39:59,694 - 4952 samples (32 per mini-batch)
2023-04-17 02:40:46,582 - Epoch: [46][   50/  155]    Loss 3.924675    mAP 0.382308    
2023-04-17 02:41:32,822 - Epoch: [46][  100/  155]    Loss 3.857719    mAP 0.391991    
2023-04-17 02:42:19,458 - Epoch: [46][  150/  155]    Loss 3.836145    mAP 0.399326    
2023-04-17 02:42:24,382 - Epoch: [46][  155/  155]    Loss 3.836227    mAP 0.399909    
2023-04-17 02:42:24,472 - ==> mAP: 0.39991    Loss: 3.836

2023-04-17 02:42:24,476 - ==> Best [mAP: 0.416294   vloss: 3.624232   Sparsity:0.00   Params: 2177088 on epoch: 44]
2023-04-17 02:42:24,476 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 02:42:24,512 - 

2023-04-17 02:42:24,512 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 02:42:35,396 - Epoch: [47][   50/  518]    Overall Loss 3.374129    Objective Loss 3.374129                                        LR 0.001000    Time 0.217627    
2023-04-17 02:42:45,466 - Epoch: [47][  100/  518]    Overall Loss 3.373249    Objective Loss 3.373249                                        LR 0.001000    Time 0.209498    
2023-04-17 02:42:55,567 - Epoch: [47][  150/  518]    Overall Loss 3.380180    Objective Loss 3.380180                                        LR 0.001000    Time 0.206990    
2023-04-17 02:43:05,670 - Epoch: [47][  200/  518]    Overall Loss 3.381708    Objective Loss 3.381708                                        LR 0.001000    Time 0.205754    
2023-04-17 02:43:15,760 - Epoch: [47][  250/  518]    Overall Loss 3.378326    Objective Loss 3.378326                                        LR 0.001000    Time 0.204955    
2023-04-17 02:43:25,876 - Epoch: [47][  300/  518]    Overall Loss 3.373711    Objective Loss 3.373711                                        LR 0.001000    Time 0.204511    
2023-04-17 02:43:35,999 - Epoch: [47][  350/  518]    Overall Loss 3.367085    Objective Loss 3.367085                                        LR 0.001000    Time 0.204212    
2023-04-17 02:43:46,019 - Epoch: [47][  400/  518]    Overall Loss 3.368582    Objective Loss 3.368582                                        LR 0.001000    Time 0.203732    
2023-04-17 02:43:56,115 - Epoch: [47][  450/  518]    Overall Loss 3.364782    Objective Loss 3.364782                                        LR 0.001000    Time 0.203528    
2023-04-17 02:44:06,141 - Epoch: [47][  500/  518]    Overall Loss 3.370136    Objective Loss 3.370136                                        LR 0.001000    Time 0.203225    
2023-04-17 02:44:09,666 - Epoch: [47][  518/  518]    Overall Loss 3.366631    Objective Loss 3.366631                                        LR 0.001000    Time 0.202966    
2023-04-17 02:44:09,748 - --- validate (epoch=47)-----------
2023-04-17 02:44:09,749 - 4952 samples (32 per mini-batch)
2023-04-17 02:44:57,008 - Epoch: [47][   50/  155]    Loss 3.697853    mAP 0.410565    
2023-04-17 02:45:43,620 - Epoch: [47][  100/  155]    Loss 3.625589    mAP 0.422047    
2023-04-17 02:46:30,746 - Epoch: [47][  150/  155]    Loss 3.616057    mAP 0.422544    
2023-04-17 02:46:35,092 - Epoch: [47][  155/  155]    Loss 3.612478    mAP 0.423261    
2023-04-17 02:46:35,171 - ==> mAP: 0.42326    Loss: 3.612

2023-04-17 02:46:35,175 - ==> Best [mAP: 0.423261   vloss: 3.612478   Sparsity:0.00   Params: 2177088 on epoch: 47]
2023-04-17 02:46:35,175 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 02:46:35,225 - 

2023-04-17 02:46:35,225 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 02:46:46,151 - Epoch: [48][   50/  518]    Overall Loss 3.337179    Objective Loss 3.337179                                        LR 0.001000    Time 0.218461    
2023-04-17 02:46:56,200 - Epoch: [48][  100/  518]    Overall Loss 3.331981    Objective Loss 3.331981                                        LR 0.001000    Time 0.209705    
2023-04-17 02:47:06,357 - Epoch: [48][  150/  518]    Overall Loss 3.346566    Objective Loss 3.346566                                        LR 0.001000    Time 0.207502    
2023-04-17 02:47:16,498 - Epoch: [48][  200/  518]    Overall Loss 3.347922    Objective Loss 3.347922                                        LR 0.001000    Time 0.206327    
2023-04-17 02:47:26,605 - Epoch: [48][  250/  518]    Overall Loss 3.350742    Objective Loss 3.350742                                        LR 0.001000    Time 0.205483    
2023-04-17 02:47:36,741 - Epoch: [48][  300/  518]    Overall Loss 3.356956    Objective Loss 3.356956                                        LR 0.001000    Time 0.205018    
2023-04-17 02:47:46,852 - Epoch: [48][  350/  518]    Overall Loss 3.357661    Objective Loss 3.357661                                        LR 0.001000    Time 0.204614    
2023-04-17 02:47:57,007 - Epoch: [48][  400/  518]    Overall Loss 3.359178    Objective Loss 3.359178                                        LR 0.001000    Time 0.204419    
2023-04-17 02:48:07,034 - Epoch: [48][  450/  518]    Overall Loss 3.360287    Objective Loss 3.360287                                        LR 0.001000    Time 0.203986    
2023-04-17 02:48:17,138 - Epoch: [48][  500/  518]    Overall Loss 3.364849    Objective Loss 3.364849                                        LR 0.001000    Time 0.203793    
2023-04-17 02:48:20,636 - Epoch: [48][  518/  518]    Overall Loss 3.359244    Objective Loss 3.359244                                        LR 0.001000    Time 0.203461    
2023-04-17 02:48:20,716 - --- validate (epoch=48)-----------
2023-04-17 02:48:20,716 - 4952 samples (32 per mini-batch)
2023-04-17 02:49:14,838 - Epoch: [48][   50/  155]    Loss 3.603708    mAP 0.424169    
2023-04-17 02:50:07,066 - Epoch: [48][  100/  155]    Loss 3.597392    mAP 0.433845    
2023-04-17 02:51:00,672 - Epoch: [48][  150/  155]    Loss 3.609601    mAP 0.433432    
2023-04-17 02:51:05,558 - Epoch: [48][  155/  155]    Loss 3.607832    mAP 0.434168    
2023-04-17 02:51:05,637 - ==> mAP: 0.43417    Loss: 3.608

2023-04-17 02:51:05,641 - ==> Best [mAP: 0.434168   vloss: 3.607832   Sparsity:0.00   Params: 2177088 on epoch: 48]
2023-04-17 02:51:05,641 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 02:51:05,693 - 

2023-04-17 02:51:05,693 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 02:51:16,703 - Epoch: [49][   50/  518]    Overall Loss 3.316015    Objective Loss 3.316015                                        LR 0.001000    Time 0.220139    
2023-04-17 02:51:26,803 - Epoch: [49][  100/  518]    Overall Loss 3.336473    Objective Loss 3.336473                                        LR 0.001000    Time 0.211057    
2023-04-17 02:51:36,922 - Epoch: [49][  150/  518]    Overall Loss 3.343779    Objective Loss 3.343779                                        LR 0.001000    Time 0.208153    
2023-04-17 02:51:47,022 - Epoch: [49][  200/  518]    Overall Loss 3.344042    Objective Loss 3.344042                                        LR 0.001000    Time 0.206608    
2023-04-17 02:51:57,108 - Epoch: [49][  250/  518]    Overall Loss 3.340862    Objective Loss 3.340862                                        LR 0.001000    Time 0.205622    
2023-04-17 02:52:07,148 - Epoch: [49][  300/  518]    Overall Loss 3.339794    Objective Loss 3.339794                                        LR 0.001000    Time 0.204813    
2023-04-17 02:52:17,259 - Epoch: [49][  350/  518]    Overall Loss 3.336495    Objective Loss 3.336495                                        LR 0.001000    Time 0.204440    
2023-04-17 02:52:27,377 - Epoch: [49][  400/  518]    Overall Loss 3.341151    Objective Loss 3.341151                                        LR 0.001000    Time 0.204175    
2023-04-17 02:52:37,362 - Epoch: [49][  450/  518]    Overall Loss 3.339598    Objective Loss 3.339598                                        LR 0.001000    Time 0.203676    
2023-04-17 02:52:47,489 - Epoch: [49][  500/  518]    Overall Loss 3.335597    Objective Loss 3.335597                                        LR 0.001000    Time 0.203558    
2023-04-17 02:52:51,034 - Epoch: [49][  518/  518]    Overall Loss 3.333432    Objective Loss 3.333432                                        LR 0.001000    Time 0.203328    
2023-04-17 02:52:51,112 - --- validate (epoch=49)-----------
2023-04-17 02:52:51,112 - 4952 samples (32 per mini-batch)
2023-04-17 02:53:38,604 - Epoch: [49][   50/  155]    Loss 3.502501    mAP 0.425933    
2023-04-17 02:54:26,162 - Epoch: [49][  100/  155]    Loss 3.509994    mAP 0.432511    
2023-04-17 02:55:14,289 - Epoch: [49][  150/  155]    Loss 3.538018    mAP 0.427704    
2023-04-17 02:55:18,782 - Epoch: [49][  155/  155]    Loss 3.539096    mAP 0.426728    
2023-04-17 02:55:18,860 - ==> mAP: 0.42673    Loss: 3.539

2023-04-17 02:55:18,863 - ==> Best [mAP: 0.434168   vloss: 3.607832   Sparsity:0.00   Params: 2177088 on epoch: 48]
2023-04-17 02:55:18,863 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 02:55:18,900 - 

2023-04-17 02:55:18,900 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 02:55:29,732 - Epoch: [50][   50/  518]    Overall Loss 3.218051    Objective Loss 3.218051                                        LR 0.000250    Time 0.216580    
2023-04-17 02:55:39,815 - Epoch: [50][  100/  518]    Overall Loss 3.203565    Objective Loss 3.203565                                        LR 0.000250    Time 0.209105    
2023-04-17 02:55:49,937 - Epoch: [50][  150/  518]    Overall Loss 3.223215    Objective Loss 3.223215                                        LR 0.000250    Time 0.206869    
2023-04-17 02:56:00,082 - Epoch: [50][  200/  518]    Overall Loss 3.219547    Objective Loss 3.219547                                        LR 0.000250    Time 0.205869    
2023-04-17 02:56:10,186 - Epoch: [50][  250/  518]    Overall Loss 3.216247    Objective Loss 3.216247                                        LR 0.000250    Time 0.205104    
2023-04-17 02:56:20,302 - Epoch: [50][  300/  518]    Overall Loss 3.218715    Objective Loss 3.218715                                        LR 0.000250    Time 0.204638    
2023-04-17 02:56:30,441 - Epoch: [50][  350/  518]    Overall Loss 3.218597    Objective Loss 3.218597                                        LR 0.000250    Time 0.204368    
2023-04-17 02:56:40,579 - Epoch: [50][  400/  518]    Overall Loss 3.211926    Objective Loss 3.211926                                        LR 0.000250    Time 0.204161    
2023-04-17 02:56:50,720 - Epoch: [50][  450/  518]    Overall Loss 3.213032    Objective Loss 3.213032                                        LR 0.000250    Time 0.204009    
2023-04-17 02:57:00,815 - Epoch: [50][  500/  518]    Overall Loss 3.203361    Objective Loss 3.203361                                        LR 0.000250    Time 0.203795    
2023-04-17 02:57:04,350 - Epoch: [50][  518/  518]    Overall Loss 3.200077    Objective Loss 3.200077                                        LR 0.000250    Time 0.203537    
2023-04-17 02:57:04,431 - --- validate (epoch=50)-----------
2023-04-17 02:57:04,431 - 4952 samples (32 per mini-batch)
2023-04-17 02:57:55,208 - Epoch: [50][   50/  155]    Loss 3.375639    mAP 0.451134    
2023-04-17 02:58:46,064 - Epoch: [50][  100/  155]    Loss 3.343612    mAP 0.455259    
2023-04-17 02:59:39,034 - Epoch: [50][  150/  155]    Loss 3.342870    mAP 0.462959    
2023-04-17 02:59:43,640 - Epoch: [50][  155/  155]    Loss 3.342462    mAP 0.464638    
2023-04-17 02:59:43,717 - ==> mAP: 0.46464    Loss: 3.342

2023-04-17 02:59:43,721 - ==> Best [mAP: 0.464638   vloss: 3.342462   Sparsity:0.00   Params: 2177088 on epoch: 50]
2023-04-17 02:59:43,721 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 02:59:43,794 - 

2023-04-17 02:59:43,794 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 02:59:54,654 - Epoch: [51][   50/  518]    Overall Loss 3.214583    Objective Loss 3.214583                                        LR 0.000250    Time 0.217140    
2023-04-17 03:00:04,782 - Epoch: [51][  100/  518]    Overall Loss 3.168559    Objective Loss 3.168559                                        LR 0.000250    Time 0.209834    
2023-04-17 03:00:14,889 - Epoch: [51][  150/  518]    Overall Loss 3.191488    Objective Loss 3.191488                                        LR 0.000250    Time 0.207259    
2023-04-17 03:00:25,031 - Epoch: [51][  200/  518]    Overall Loss 3.176334    Objective Loss 3.176334                                        LR 0.000250    Time 0.206148    
2023-04-17 03:00:35,143 - Epoch: [51][  250/  518]    Overall Loss 3.176419    Objective Loss 3.176419                                        LR 0.000250    Time 0.205360    
2023-04-17 03:00:45,208 - Epoch: [51][  300/  518]    Overall Loss 3.184894    Objective Loss 3.184894                                        LR 0.000250    Time 0.204678    
2023-04-17 03:00:55,234 - Epoch: [51][  350/  518]    Overall Loss 3.176835    Objective Loss 3.176835                                        LR 0.000250    Time 0.204081    
2023-04-17 03:01:05,363 - Epoch: [51][  400/  518]    Overall Loss 3.175614    Objective Loss 3.175614                                        LR 0.000250    Time 0.203888    
2023-04-17 03:01:15,448 - Epoch: [51][  450/  518]    Overall Loss 3.170166    Objective Loss 3.170166                                        LR 0.000250    Time 0.203641    
2023-04-17 03:01:25,537 - Epoch: [51][  500/  518]    Overall Loss 3.167887    Objective Loss 3.167887                                        LR 0.000250    Time 0.203454    
2023-04-17 03:01:29,019 - Epoch: [51][  518/  518]    Overall Loss 3.163482    Objective Loss 3.163482                                        LR 0.000250    Time 0.203105    
2023-04-17 03:01:29,099 - --- validate (epoch=51)-----------
2023-04-17 03:01:29,100 - 4952 samples (32 per mini-batch)
2023-04-17 03:02:21,269 - Epoch: [51][   50/  155]    Loss 3.312570    mAP 0.453867    
2023-04-17 03:03:12,169 - Epoch: [51][  100/  155]    Loss 3.329417    mAP 0.461150    
2023-04-17 03:04:01,800 - Epoch: [51][  150/  155]    Loss 3.309745    mAP 0.467639    
2023-04-17 03:04:06,033 - Epoch: [51][  155/  155]    Loss 3.310584    mAP 0.466411    
2023-04-17 03:04:06,112 - ==> mAP: 0.46641    Loss: 3.311

2023-04-17 03:04:06,116 - ==> Best [mAP: 0.466411   vloss: 3.310584   Sparsity:0.00   Params: 2177088 on epoch: 51]
2023-04-17 03:04:06,116 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 03:04:06,168 - 

2023-04-17 03:04:06,168 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 03:04:17,033 - Epoch: [52][   50/  518]    Overall Loss 3.147738    Objective Loss 3.147738                                        LR 0.000250    Time 0.217246    
2023-04-17 03:04:27,124 - Epoch: [52][  100/  518]    Overall Loss 3.159853    Objective Loss 3.159853                                        LR 0.000250    Time 0.209513    
2023-04-17 03:04:37,229 - Epoch: [52][  150/  518]    Overall Loss 3.161534    Objective Loss 3.161534                                        LR 0.000250    Time 0.207033    
2023-04-17 03:04:47,353 - Epoch: [52][  200/  518]    Overall Loss 3.151609    Objective Loss 3.151609                                        LR 0.000250    Time 0.205889    
2023-04-17 03:04:57,546 - Epoch: [52][  250/  518]    Overall Loss 3.145630    Objective Loss 3.145630                                        LR 0.000250    Time 0.205476    
2023-04-17 03:05:07,604 - Epoch: [52][  300/  518]    Overall Loss 3.145251    Objective Loss 3.145251                                        LR 0.000250    Time 0.204750    
2023-04-17 03:05:17,775 - Epoch: [52][  350/  518]    Overall Loss 3.143002    Objective Loss 3.143002                                        LR 0.000250    Time 0.204557    
2023-04-17 03:05:27,905 - Epoch: [52][  400/  518]    Overall Loss 3.144827    Objective Loss 3.144827                                        LR 0.000250    Time 0.204309    
2023-04-17 03:05:37,996 - Epoch: [52][  450/  518]    Overall Loss 3.145102    Objective Loss 3.145102                                        LR 0.000250    Time 0.204029    
2023-04-17 03:05:48,137 - Epoch: [52][  500/  518]    Overall Loss 3.147899    Objective Loss 3.147899                                        LR 0.000250    Time 0.203904    
2023-04-17 03:05:51,696 - Epoch: [52][  518/  518]    Overall Loss 3.146765    Objective Loss 3.146765                                        LR 0.000250    Time 0.203689    
2023-04-17 03:05:51,776 - --- validate (epoch=52)-----------
2023-04-17 03:05:51,776 - 4952 samples (32 per mini-batch)
2023-04-17 03:06:44,793 - Epoch: [52][   50/  155]    Loss 3.274264    mAP 0.452031    
2023-04-17 03:07:35,678 - Epoch: [52][  100/  155]    Loss 3.309874    mAP 0.458140    
2023-04-17 03:08:27,683 - Epoch: [52][  150/  155]    Loss 3.302447    mAP 0.463722    
2023-04-17 03:08:33,150 - Epoch: [52][  155/  155]    Loss 3.306536    mAP 0.462938    
2023-04-17 03:08:33,229 - ==> mAP: 0.46294    Loss: 3.307

2023-04-17 03:08:33,233 - ==> Best [mAP: 0.466411   vloss: 3.310584   Sparsity:0.00   Params: 2177088 on epoch: 51]
2023-04-17 03:08:33,233 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 03:08:33,268 - 

2023-04-17 03:08:33,268 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 03:08:44,166 - Epoch: [53][   50/  518]    Overall Loss 3.151228    Objective Loss 3.151228                                        LR 0.000250    Time 0.217907    
2023-04-17 03:08:54,296 - Epoch: [53][  100/  518]    Overall Loss 3.139961    Objective Loss 3.139961                                        LR 0.000250    Time 0.210236    
2023-04-17 03:09:04,426 - Epoch: [53][  150/  518]    Overall Loss 3.137568    Objective Loss 3.137568                                        LR 0.000250    Time 0.207678    
2023-04-17 03:09:14,458 - Epoch: [53][  200/  518]    Overall Loss 3.137347    Objective Loss 3.137347                                        LR 0.000250    Time 0.205914    
2023-04-17 03:09:24,565 - Epoch: [53][  250/  518]    Overall Loss 3.137246    Objective Loss 3.137246                                        LR 0.000250    Time 0.205150    
2023-04-17 03:09:34,626 - Epoch: [53][  300/  518]    Overall Loss 3.140132    Objective Loss 3.140132                                        LR 0.000250    Time 0.204491    
2023-04-17 03:09:44,659 - Epoch: [53][  350/  518]    Overall Loss 3.141088    Objective Loss 3.141088                                        LR 0.000250    Time 0.203939    
2023-04-17 03:09:54,777 - Epoch: [53][  400/  518]    Overall Loss 3.137540    Objective Loss 3.137540                                        LR 0.000250    Time 0.203739    
2023-04-17 03:10:04,889 - Epoch: [53][  450/  518]    Overall Loss 3.141552    Objective Loss 3.141552                                        LR 0.000250    Time 0.203569    
2023-04-17 03:10:14,912 - Epoch: [53][  500/  518]    Overall Loss 3.139850    Objective Loss 3.139850                                        LR 0.000250    Time 0.203254    
2023-04-17 03:10:18,404 - Epoch: [53][  518/  518]    Overall Loss 3.139879    Objective Loss 3.139879                                        LR 0.000250    Time 0.202931    
2023-04-17 03:10:18,484 - --- validate (epoch=53)-----------
2023-04-17 03:10:18,484 - 4952 samples (32 per mini-batch)
2023-04-17 03:11:06,738 - Epoch: [53][   50/  155]    Loss 3.289910    mAP 0.459952    
2023-04-17 03:11:54,985 - Epoch: [53][  100/  155]    Loss 3.322895    mAP 0.463324    
2023-04-17 03:12:43,694 - Epoch: [53][  150/  155]    Loss 3.315985    mAP 0.461740    
2023-04-17 03:12:48,596 - Epoch: [53][  155/  155]    Loss 3.317242    mAP 0.459796    
2023-04-17 03:12:48,675 - ==> mAP: 0.45980    Loss: 3.317

2023-04-17 03:12:48,678 - ==> Best [mAP: 0.466411   vloss: 3.310584   Sparsity:0.00   Params: 2177088 on epoch: 51]
2023-04-17 03:12:48,678 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 03:12:48,715 - 

2023-04-17 03:12:48,715 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 03:12:59,608 - Epoch: [54][   50/  518]    Overall Loss 3.146529    Objective Loss 3.146529                                        LR 0.000250    Time 0.217820    
2023-04-17 03:13:09,679 - Epoch: [54][  100/  518]    Overall Loss 3.104051    Objective Loss 3.104051                                        LR 0.000250    Time 0.209600    
2023-04-17 03:13:19,775 - Epoch: [54][  150/  518]    Overall Loss 3.121506    Objective Loss 3.121506                                        LR 0.000250    Time 0.207030    
2023-04-17 03:13:29,871 - Epoch: [54][  200/  518]    Overall Loss 3.122415    Objective Loss 3.122415                                        LR 0.000250    Time 0.205746    
2023-04-17 03:13:39,961 - Epoch: [54][  250/  518]    Overall Loss 3.125539    Objective Loss 3.125539                                        LR 0.000250    Time 0.204948    
2023-04-17 03:13:50,029 - Epoch: [54][  300/  518]    Overall Loss 3.131247    Objective Loss 3.131247                                        LR 0.000250    Time 0.204345    
2023-04-17 03:14:00,113 - Epoch: [54][  350/  518]    Overall Loss 3.138441    Objective Loss 3.138441                                        LR 0.000250    Time 0.203961    
2023-04-17 03:14:10,283 - Epoch: [54][  400/  518]    Overall Loss 3.141518    Objective Loss 3.141518                                        LR 0.000250    Time 0.203886    
2023-04-17 03:14:20,365 - Epoch: [54][  450/  518]    Overall Loss 3.141083    Objective Loss 3.141083                                        LR 0.000250    Time 0.203633    
2023-04-17 03:14:30,384 - Epoch: [54][  500/  518]    Overall Loss 3.139252    Objective Loss 3.139252                                        LR 0.000250    Time 0.203304    
2023-04-17 03:14:33,902 - Epoch: [54][  518/  518]    Overall Loss 3.140032    Objective Loss 3.140032                                        LR 0.000250    Time 0.203030    
2023-04-17 03:14:33,984 - --- validate (epoch=54)-----------
2023-04-17 03:14:33,984 - 4952 samples (32 per mini-batch)
2023-04-17 03:15:23,873 - Epoch: [54][   50/  155]    Loss 3.329755    mAP 0.461876    
2023-04-17 03:16:13,920 - Epoch: [54][  100/  155]    Loss 3.302961    mAP 0.460889    
2023-04-17 03:17:03,075 - Epoch: [54][  150/  155]    Loss 3.290728    mAP 0.466295    
2023-04-17 03:17:07,596 - Epoch: [54][  155/  155]    Loss 3.291499    mAP 0.466590    
2023-04-17 03:17:07,676 - ==> mAP: 0.46659    Loss: 3.291

2023-04-17 03:17:07,679 - ==> Best [mAP: 0.466590   vloss: 3.291499   Sparsity:0.00   Params: 2177088 on epoch: 54]
2023-04-17 03:17:07,679 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 03:17:07,727 - 

2023-04-17 03:17:07,727 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 03:17:18,751 - Epoch: [55][   50/  518]    Overall Loss 3.071682    Objective Loss 3.071682                                        LR 0.000250    Time 0.220407    
2023-04-17 03:17:28,843 - Epoch: [55][  100/  518]    Overall Loss 3.112758    Objective Loss 3.112758                                        LR 0.000250    Time 0.211117    
2023-04-17 03:17:38,926 - Epoch: [55][  150/  518]    Overall Loss 3.111911    Objective Loss 3.111911                                        LR 0.000250    Time 0.207954    
2023-04-17 03:17:49,040 - Epoch: [55][  200/  518]    Overall Loss 3.112220    Objective Loss 3.112220                                        LR 0.000250    Time 0.206525    
2023-04-17 03:17:59,163 - Epoch: [55][  250/  518]    Overall Loss 3.125055    Objective Loss 3.125055                                        LR 0.000250    Time 0.205707    
2023-04-17 03:18:09,243 - Epoch: [55][  300/  518]    Overall Loss 3.126227    Objective Loss 3.126227                                        LR 0.000250    Time 0.205017    
2023-04-17 03:18:19,353 - Epoch: [55][  350/  518]    Overall Loss 3.120566    Objective Loss 3.120566                                        LR 0.000250    Time 0.204609    
2023-04-17 03:18:29,418 - Epoch: [55][  400/  518]    Overall Loss 3.125385    Objective Loss 3.125385                                        LR 0.000250    Time 0.204192    
2023-04-17 03:18:39,445 - Epoch: [55][  450/  518]    Overall Loss 3.120650    Objective Loss 3.120650                                        LR 0.000250    Time 0.203783    
2023-04-17 03:18:49,452 - Epoch: [55][  500/  518]    Overall Loss 3.125994    Objective Loss 3.125994                                        LR 0.000250    Time 0.203415    
2023-04-17 03:18:52,954 - Epoch: [55][  518/  518]    Overall Loss 3.128387    Objective Loss 3.128387                                        LR 0.000250    Time 0.203106    
2023-04-17 03:18:53,033 - --- validate (epoch=55)-----------
2023-04-17 03:18:53,033 - 4952 samples (32 per mini-batch)
2023-04-17 03:19:46,285 - Epoch: [55][   50/  155]    Loss 3.301114    mAP 0.485578    
2023-04-17 03:20:40,432 - Epoch: [55][  100/  155]    Loss 3.285377    mAP 0.479622    
2023-04-17 03:21:33,366 - Epoch: [55][  150/  155]    Loss 3.310679    mAP 0.472929    
2023-04-17 03:21:37,915 - Epoch: [55][  155/  155]    Loss 3.308453    mAP 0.471877    
2023-04-17 03:21:37,989 - ==> mAP: 0.47188    Loss: 3.308

2023-04-17 03:21:37,993 - ==> Best [mAP: 0.471877   vloss: 3.308453   Sparsity:0.00   Params: 2177088 on epoch: 55]
2023-04-17 03:21:37,994 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 03:21:38,045 - 

2023-04-17 03:21:38,045 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 03:21:48,924 - Epoch: [56][   50/  518]    Overall Loss 3.159341    Objective Loss 3.159341                                        LR 0.000250    Time 0.217523    
2023-04-17 03:21:58,943 - Epoch: [56][  100/  518]    Overall Loss 3.141078    Objective Loss 3.141078                                        LR 0.000250    Time 0.208935    
2023-04-17 03:22:09,146 - Epoch: [56][  150/  518]    Overall Loss 3.153477    Objective Loss 3.153477                                        LR 0.000250    Time 0.207297    
2023-04-17 03:22:19,184 - Epoch: [56][  200/  518]    Overall Loss 3.135020    Objective Loss 3.135020                                        LR 0.000250    Time 0.205657    
2023-04-17 03:22:29,365 - Epoch: [56][  250/  518]    Overall Loss 3.132993    Objective Loss 3.132993                                        LR 0.000250    Time 0.205245    
2023-04-17 03:22:39,451 - Epoch: [56][  300/  518]    Overall Loss 3.130020    Objective Loss 3.130020                                        LR 0.000250    Time 0.204651    
2023-04-17 03:22:49,475 - Epoch: [56][  350/  518]    Overall Loss 3.123805    Objective Loss 3.123805                                        LR 0.000250    Time 0.204052    
2023-04-17 03:22:59,597 - Epoch: [56][  400/  518]    Overall Loss 3.119288    Objective Loss 3.119288                                        LR 0.000250    Time 0.203847    
2023-04-17 03:23:09,662 - Epoch: [56][  450/  518]    Overall Loss 3.123867    Objective Loss 3.123867                                        LR 0.000250    Time 0.203560    
2023-04-17 03:23:19,727 - Epoch: [56][  500/  518]    Overall Loss 3.118030    Objective Loss 3.118030                                        LR 0.000250    Time 0.203331    
2023-04-17 03:23:23,232 - Epoch: [56][  518/  518]    Overall Loss 3.116688    Objective Loss 3.116688                                        LR 0.000250    Time 0.203031    
2023-04-17 03:23:23,312 - --- validate (epoch=56)-----------
2023-04-17 03:23:23,312 - 4952 samples (32 per mini-batch)
2023-04-17 03:24:15,765 - Epoch: [56][   50/  155]    Loss 3.282336    mAP 0.496797    
2023-04-17 03:25:04,290 - Epoch: [56][  100/  155]    Loss 3.303151    mAP 0.480674    
2023-04-17 03:25:55,874 - Epoch: [56][  150/  155]    Loss 3.304337    mAP 0.473453    
2023-04-17 03:26:00,866 - Epoch: [56][  155/  155]    Loss 3.303189    mAP 0.473623    
2023-04-17 03:26:00,944 - ==> mAP: 0.47362    Loss: 3.303

2023-04-17 03:26:00,948 - ==> Best [mAP: 0.473623   vloss: 3.303189   Sparsity:0.00   Params: 2177088 on epoch: 56]
2023-04-17 03:26:00,948 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 03:26:00,999 - 

2023-04-17 03:26:00,999 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 03:26:11,924 - Epoch: [57][   50/  518]    Overall Loss 3.120274    Objective Loss 3.120274                                        LR 0.000250    Time 0.218457    
2023-04-17 03:26:21,900 - Epoch: [57][  100/  518]    Overall Loss 3.118909    Objective Loss 3.118909                                        LR 0.000250    Time 0.208967    
2023-04-17 03:26:31,973 - Epoch: [57][  150/  518]    Overall Loss 3.112242    Objective Loss 3.112242                                        LR 0.000250    Time 0.206454    
2023-04-17 03:26:42,152 - Epoch: [57][  200/  518]    Overall Loss 3.100056    Objective Loss 3.100056                                        LR 0.000250    Time 0.205728    
2023-04-17 03:26:52,303 - Epoch: [57][  250/  518]    Overall Loss 3.101164    Objective Loss 3.101164                                        LR 0.000250    Time 0.205181    
2023-04-17 03:27:02,361 - Epoch: [57][  300/  518]    Overall Loss 3.094765    Objective Loss 3.094765                                        LR 0.000250    Time 0.204506    
2023-04-17 03:27:12,487 - Epoch: [57][  350/  518]    Overall Loss 3.099771    Objective Loss 3.099771                                        LR 0.000250    Time 0.204217    
2023-04-17 03:27:22,602 - Epoch: [57][  400/  518]    Overall Loss 3.105024    Objective Loss 3.105024                                        LR 0.000250    Time 0.203974    
2023-04-17 03:27:32,723 - Epoch: [57][  450/  518]    Overall Loss 3.107977    Objective Loss 3.107977                                        LR 0.000250    Time 0.203798    
2023-04-17 03:27:42,823 - Epoch: [57][  500/  518]    Overall Loss 3.113002    Objective Loss 3.113002                                        LR 0.000250    Time 0.203616    
2023-04-17 03:27:46,313 - Epoch: [57][  518/  518]    Overall Loss 3.115004    Objective Loss 3.115004                                        LR 0.000250    Time 0.203276    
2023-04-17 03:27:46,392 - --- validate (epoch=57)-----------
2023-04-17 03:27:46,392 - 4952 samples (32 per mini-batch)
2023-04-17 03:28:37,591 - Epoch: [57][   50/  155]    Loss 3.272115    mAP 0.471275    
2023-04-17 03:29:29,174 - Epoch: [57][  100/  155]    Loss 3.273835    mAP 0.480080    
2023-04-17 03:30:19,422 - Epoch: [57][  150/  155]    Loss 3.275709    mAP 0.480233    
2023-04-17 03:30:23,993 - Epoch: [57][  155/  155]    Loss 3.274841    mAP 0.481256    
2023-04-17 03:30:24,072 - ==> mAP: 0.48126    Loss: 3.275

2023-04-17 03:30:24,075 - ==> Best [mAP: 0.481256   vloss: 3.274841   Sparsity:0.00   Params: 2177088 on epoch: 57]
2023-04-17 03:30:24,075 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 03:30:24,126 - 

2023-04-17 03:30:24,126 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 03:30:35,183 - Epoch: [58][   50/  518]    Overall Loss 3.109831    Objective Loss 3.109831                                        LR 0.000250    Time 0.221073    
2023-04-17 03:30:45,281 - Epoch: [58][  100/  518]    Overall Loss 3.099611    Objective Loss 3.099611                                        LR 0.000250    Time 0.211501    
2023-04-17 03:30:55,360 - Epoch: [58][  150/  518]    Overall Loss 3.095002    Objective Loss 3.095002                                        LR 0.000250    Time 0.208187    
2023-04-17 03:31:05,373 - Epoch: [58][  200/  518]    Overall Loss 3.110941    Objective Loss 3.110941                                        LR 0.000250    Time 0.206196    
2023-04-17 03:31:15,376 - Epoch: [58][  250/  518]    Overall Loss 3.113901    Objective Loss 3.113901                                        LR 0.000250    Time 0.204963    
2023-04-17 03:31:25,443 - Epoch: [58][  300/  518]    Overall Loss 3.109096    Objective Loss 3.109096                                        LR 0.000250    Time 0.204353    
2023-04-17 03:31:35,510 - Epoch: [58][  350/  518]    Overall Loss 3.110553    Objective Loss 3.110553                                        LR 0.000250    Time 0.203919    
2023-04-17 03:31:45,736 - Epoch: [58][  400/  518]    Overall Loss 3.108788    Objective Loss 3.108788                                        LR 0.000250    Time 0.203989    
2023-04-17 03:31:55,783 - Epoch: [58][  450/  518]    Overall Loss 3.110242    Objective Loss 3.110242                                        LR 0.000250    Time 0.203649    
2023-04-17 03:32:05,956 - Epoch: [58][  500/  518]    Overall Loss 3.105699    Objective Loss 3.105699                                        LR 0.000250    Time 0.203626    
2023-04-17 03:32:09,462 - Epoch: [58][  518/  518]    Overall Loss 3.105536    Objective Loss 3.105536                                        LR 0.000250    Time 0.203318    
2023-04-17 03:32:09,542 - --- validate (epoch=58)-----------
2023-04-17 03:32:09,542 - 4952 samples (32 per mini-batch)
2023-04-17 03:32:55,444 - Epoch: [58][   50/  155]    Loss 3.258097    mAP 0.491512    
2023-04-17 03:33:40,497 - Epoch: [58][  100/  155]    Loss 3.277068    mAP 0.483232    
2023-04-17 03:34:25,995 - Epoch: [58][  150/  155]    Loss 3.278119    mAP 0.481882    
2023-04-17 03:34:30,935 - Epoch: [58][  155/  155]    Loss 3.278624    mAP 0.481423    
2023-04-17 03:34:31,023 - ==> mAP: 0.48142    Loss: 3.279

2023-04-17 03:34:31,027 - ==> Best [mAP: 0.481423   vloss: 3.278624   Sparsity:0.00   Params: 2177088 on epoch: 58]
2023-04-17 03:34:31,027 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 03:34:31,078 - 

2023-04-17 03:34:31,078 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 03:34:41,912 - Epoch: [59][   50/  518]    Overall Loss 3.132448    Objective Loss 3.132448                                        LR 0.000250    Time 0.216621    
2023-04-17 03:34:52,043 - Epoch: [59][  100/  518]    Overall Loss 3.117235    Objective Loss 3.117235                                        LR 0.000250    Time 0.209608    
2023-04-17 03:35:02,145 - Epoch: [59][  150/  518]    Overall Loss 3.100122    Objective Loss 3.100122                                        LR 0.000250    Time 0.207071    
2023-04-17 03:35:12,160 - Epoch: [59][  200/  518]    Overall Loss 3.084919    Objective Loss 3.084919                                        LR 0.000250    Time 0.205374    
2023-04-17 03:35:22,400 - Epoch: [59][  250/  518]    Overall Loss 3.083583    Objective Loss 3.083583                                        LR 0.000250    Time 0.205250    
2023-04-17 03:35:32,551 - Epoch: [59][  300/  518]    Overall Loss 3.077669    Objective Loss 3.077669                                        LR 0.000250    Time 0.204875    
2023-04-17 03:35:42,734 - Epoch: [59][  350/  518]    Overall Loss 3.084712    Objective Loss 3.084712                                        LR 0.000250    Time 0.204699    
2023-04-17 03:35:52,883 - Epoch: [59][  400/  518]    Overall Loss 3.086647    Objective Loss 3.086647                                        LR 0.000250    Time 0.204478    
2023-04-17 03:36:02,936 - Epoch: [59][  450/  518]    Overall Loss 3.085736    Objective Loss 3.085736                                        LR 0.000250    Time 0.204095    
2023-04-17 03:36:13,016 - Epoch: [59][  500/  518]    Overall Loss 3.092649    Objective Loss 3.092649                                        LR 0.000250    Time 0.203844    
2023-04-17 03:36:16,560 - Epoch: [59][  518/  518]    Overall Loss 3.089784    Objective Loss 3.089784                                        LR 0.000250    Time 0.203601    
2023-04-17 03:36:16,642 - --- validate (epoch=59)-----------
2023-04-17 03:36:16,642 - 4952 samples (32 per mini-batch)
2023-04-17 03:37:06,000 - Epoch: [59][   50/  155]    Loss 3.276720    mAP 0.467426    
2023-04-17 03:37:57,014 - Epoch: [59][  100/  155]    Loss 3.269851    mAP 0.473410    
2023-04-17 03:38:46,904 - Epoch: [59][  150/  155]    Loss 3.286193    mAP 0.469170    
2023-04-17 03:38:51,352 - Epoch: [59][  155/  155]    Loss 3.286961    mAP 0.470379    
2023-04-17 03:38:51,429 - ==> mAP: 0.47038    Loss: 3.287

2023-04-17 03:38:51,434 - ==> Best [mAP: 0.481423   vloss: 3.278624   Sparsity:0.00   Params: 2177088 on epoch: 58]
2023-04-17 03:38:51,434 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 03:38:51,470 - 

2023-04-17 03:38:51,471 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 03:39:02,240 - Epoch: [60][   50/  518]    Overall Loss 3.050889    Objective Loss 3.050889                                        LR 0.000250    Time 0.215342    
2023-04-17 03:39:12,304 - Epoch: [60][  100/  518]    Overall Loss 3.080555    Objective Loss 3.080555                                        LR 0.000250    Time 0.208291    
2023-04-17 03:39:22,384 - Epoch: [60][  150/  518]    Overall Loss 3.085426    Objective Loss 3.085426                                        LR 0.000250    Time 0.206053    
2023-04-17 03:39:32,569 - Epoch: [60][  200/  518]    Overall Loss 3.071013    Objective Loss 3.071013                                        LR 0.000250    Time 0.205453    
2023-04-17 03:39:42,639 - Epoch: [60][  250/  518]    Overall Loss 3.082789    Objective Loss 3.082789                                        LR 0.000250    Time 0.204640    
2023-04-17 03:39:52,741 - Epoch: [60][  300/  518]    Overall Loss 3.090067    Objective Loss 3.090067                                        LR 0.000250    Time 0.204199    
2023-04-17 03:40:02,908 - Epoch: [60][  350/  518]    Overall Loss 3.088863    Objective Loss 3.088863                                        LR 0.000250    Time 0.204074    
2023-04-17 03:40:13,033 - Epoch: [60][  400/  518]    Overall Loss 3.084548    Objective Loss 3.084548                                        LR 0.000250    Time 0.203873    
2023-04-17 03:40:23,147 - Epoch: [60][  450/  518]    Overall Loss 3.090404    Objective Loss 3.090404                                        LR 0.000250    Time 0.203691    
2023-04-17 03:40:33,229 - Epoch: [60][  500/  518]    Overall Loss 3.088337    Objective Loss 3.088337                                        LR 0.000250    Time 0.203483    
2023-04-17 03:40:36,769 - Epoch: [60][  518/  518]    Overall Loss 3.087379    Objective Loss 3.087379                                        LR 0.000250    Time 0.203245    
2023-04-17 03:40:36,850 - --- validate (epoch=60)-----------
2023-04-17 03:40:36,850 - 4952 samples (32 per mini-batch)
2023-04-17 03:41:29,891 - Epoch: [60][   50/  155]    Loss 3.275244    mAP 0.486295    
2023-04-17 03:42:21,764 - Epoch: [60][  100/  155]    Loss 3.287776    mAP 0.476769    
2023-04-17 03:43:13,395 - Epoch: [60][  150/  155]    Loss 3.284956    mAP 0.479243    
2023-04-17 03:43:18,356 - Epoch: [60][  155/  155]    Loss 3.283454    mAP 0.479216    
2023-04-17 03:43:18,433 - ==> mAP: 0.47922    Loss: 3.283

2023-04-17 03:43:18,437 - ==> Best [mAP: 0.481423   vloss: 3.278624   Sparsity:0.00   Params: 2177088 on epoch: 58]
2023-04-17 03:43:18,437 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 03:43:18,473 - 

2023-04-17 03:43:18,473 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 03:43:29,305 - Epoch: [61][   50/  518]    Overall Loss 3.073570    Objective Loss 3.073570                                        LR 0.000250    Time 0.216594    
2023-04-17 03:43:39,360 - Epoch: [61][  100/  518]    Overall Loss 3.069530    Objective Loss 3.069530                                        LR 0.000250    Time 0.208831    
2023-04-17 03:43:49,419 - Epoch: [61][  150/  518]    Overall Loss 3.093706    Objective Loss 3.093706                                        LR 0.000250    Time 0.206265    
2023-04-17 03:43:59,503 - Epoch: [61][  200/  518]    Overall Loss 3.084726    Objective Loss 3.084726                                        LR 0.000250    Time 0.205113    
2023-04-17 03:44:09,645 - Epoch: [61][  250/  518]    Overall Loss 3.080663    Objective Loss 3.080663                                        LR 0.000250    Time 0.204652    
2023-04-17 03:44:19,720 - Epoch: [61][  300/  518]    Overall Loss 3.075575    Objective Loss 3.075575                                        LR 0.000250    Time 0.204124    
2023-04-17 03:44:29,764 - Epoch: [61][  350/  518]    Overall Loss 3.073544    Objective Loss 3.073544                                        LR 0.000250    Time 0.203655    
2023-04-17 03:44:39,947 - Epoch: [61][  400/  518]    Overall Loss 3.079641    Objective Loss 3.079641                                        LR 0.000250    Time 0.203651    
2023-04-17 03:44:50,091 - Epoch: [61][  450/  518]    Overall Loss 3.080792    Objective Loss 3.080792                                        LR 0.000250    Time 0.203563    
2023-04-17 03:45:00,183 - Epoch: [61][  500/  518]    Overall Loss 3.084916    Objective Loss 3.084916                                        LR 0.000250    Time 0.203387    
2023-04-17 03:45:03,678 - Epoch: [61][  518/  518]    Overall Loss 3.087477    Objective Loss 3.087477                                        LR 0.000250    Time 0.203065    
2023-04-17 03:45:03,759 - --- validate (epoch=61)-----------
2023-04-17 03:45:03,759 - 4952 samples (32 per mini-batch)
2023-04-17 03:45:53,118 - Epoch: [61][   50/  155]    Loss 3.234220    mAP 0.479752    
2023-04-17 03:46:42,648 - Epoch: [61][  100/  155]    Loss 3.267987    mAP 0.474900    
2023-04-17 03:47:30,772 - Epoch: [61][  150/  155]    Loss 3.249522    mAP 0.478877    
2023-04-17 03:47:36,100 - Epoch: [61][  155/  155]    Loss 3.250317    mAP 0.480009    
2023-04-17 03:47:36,179 - ==> mAP: 0.48001    Loss: 3.250

2023-04-17 03:47:36,183 - ==> Best [mAP: 0.481423   vloss: 3.278624   Sparsity:0.00   Params: 2177088 on epoch: 58]
2023-04-17 03:47:36,183 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 03:47:36,217 - 

2023-04-17 03:47:36,218 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 03:47:47,160 - Epoch: [62][   50/  518]    Overall Loss 3.085439    Objective Loss 3.085439                                        LR 0.000250    Time 0.218801    
2023-04-17 03:47:57,286 - Epoch: [62][  100/  518]    Overall Loss 3.076371    Objective Loss 3.076371                                        LR 0.000250    Time 0.210639    
2023-04-17 03:48:07,445 - Epoch: [62][  150/  518]    Overall Loss 3.077705    Objective Loss 3.077705                                        LR 0.000250    Time 0.208141    
2023-04-17 03:48:17,541 - Epoch: [62][  200/  518]    Overall Loss 3.093843    Objective Loss 3.093843                                        LR 0.000250    Time 0.206579    
2023-04-17 03:48:27,647 - Epoch: [62][  250/  518]    Overall Loss 3.086663    Objective Loss 3.086663                                        LR 0.000250    Time 0.205681    
2023-04-17 03:48:37,744 - Epoch: [62][  300/  518]    Overall Loss 3.084705    Objective Loss 3.084705                                        LR 0.000250    Time 0.205054    
2023-04-17 03:48:47,907 - Epoch: [62][  350/  518]    Overall Loss 3.086219    Objective Loss 3.086219                                        LR 0.000250    Time 0.204793    
2023-04-17 03:48:57,942 - Epoch: [62][  400/  518]    Overall Loss 3.085758    Objective Loss 3.085758                                        LR 0.000250    Time 0.204277    
2023-04-17 03:49:07,975 - Epoch: [62][  450/  518]    Overall Loss 3.094347    Objective Loss 3.094347                                        LR 0.000250    Time 0.203872    
2023-04-17 03:49:18,124 - Epoch: [62][  500/  518]    Overall Loss 3.096282    Objective Loss 3.096282                                        LR 0.000250    Time 0.203780    
2023-04-17 03:49:21,625 - Epoch: [62][  518/  518]    Overall Loss 3.093933    Objective Loss 3.093933                                        LR 0.000250    Time 0.203455    
2023-04-17 03:49:21,706 - --- validate (epoch=62)-----------
2023-04-17 03:49:21,706 - 4952 samples (32 per mini-batch)
2023-04-17 03:50:08,377 - Epoch: [62][   50/  155]    Loss 3.268351    mAP 0.482611    
2023-04-17 03:50:56,798 - Epoch: [62][  100/  155]    Loss 3.270942    mAP 0.478638    
2023-04-17 03:51:44,761 - Epoch: [62][  150/  155]    Loss 3.278981    mAP 0.477717    
2023-04-17 03:51:49,305 - Epoch: [62][  155/  155]    Loss 3.276704    mAP 0.474477    
2023-04-17 03:51:49,383 - ==> mAP: 0.47448    Loss: 3.277

2023-04-17 03:51:49,386 - ==> Best [mAP: 0.481423   vloss: 3.278624   Sparsity:0.00   Params: 2177088 on epoch: 58]
2023-04-17 03:51:49,386 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 03:51:49,423 - 

2023-04-17 03:51:49,423 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 03:52:00,351 - Epoch: [63][   50/  518]    Overall Loss 3.062275    Objective Loss 3.062275                                        LR 0.000250    Time 0.218511    
2023-04-17 03:52:10,381 - Epoch: [63][  100/  518]    Overall Loss 3.058484    Objective Loss 3.058484                                        LR 0.000250    Time 0.209535    
2023-04-17 03:52:20,458 - Epoch: [63][  150/  518]    Overall Loss 3.050367    Objective Loss 3.050367                                        LR 0.000250    Time 0.206864    
2023-04-17 03:52:30,540 - Epoch: [63][  200/  518]    Overall Loss 3.063283    Objective Loss 3.063283                                        LR 0.000250    Time 0.205548    
2023-04-17 03:52:40,697 - Epoch: [63][  250/  518]    Overall Loss 3.078419    Objective Loss 3.078419                                        LR 0.000250    Time 0.205062    
2023-04-17 03:52:50,842 - Epoch: [63][  300/  518]    Overall Loss 3.083304    Objective Loss 3.083304                                        LR 0.000250    Time 0.204696    
2023-04-17 03:53:00,944 - Epoch: [63][  350/  518]    Overall Loss 3.084856    Objective Loss 3.084856                                        LR 0.000250    Time 0.204311    
2023-04-17 03:53:11,020 - Epoch: [63][  400/  518]    Overall Loss 3.079570    Objective Loss 3.079570                                        LR 0.000250    Time 0.203960    
2023-04-17 03:53:21,107 - Epoch: [63][  450/  518]    Overall Loss 3.081791    Objective Loss 3.081791                                        LR 0.000250    Time 0.203709    
2023-04-17 03:53:31,167 - Epoch: [63][  500/  518]    Overall Loss 3.078484    Objective Loss 3.078484                                        LR 0.000250    Time 0.203455    
2023-04-17 03:53:34,666 - Epoch: [63][  518/  518]    Overall Loss 3.079104    Objective Loss 3.079104                                        LR 0.000250    Time 0.203140    
2023-04-17 03:53:34,748 - --- validate (epoch=63)-----------
2023-04-17 03:53:34,748 - 4952 samples (32 per mini-batch)
2023-04-17 03:54:25,758 - Epoch: [63][   50/  155]    Loss 3.222575    mAP 0.475549    
2023-04-17 03:55:16,934 - Epoch: [63][  100/  155]    Loss 3.260364    mAP 0.462356    
2023-04-17 03:56:07,047 - Epoch: [63][  150/  155]    Loss 3.261272    mAP 0.475876    
2023-04-17 03:56:12,249 - Epoch: [63][  155/  155]    Loss 3.265322    mAP 0.476172    
2023-04-17 03:56:12,326 - ==> mAP: 0.47617    Loss: 3.265

2023-04-17 03:56:12,330 - ==> Best [mAP: 0.481423   vloss: 3.278624   Sparsity:0.00   Params: 2177088 on epoch: 58]
2023-04-17 03:56:12,330 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 03:56:12,365 - 

2023-04-17 03:56:12,365 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 03:56:23,116 - Epoch: [64][   50/  518]    Overall Loss 3.094529    Objective Loss 3.094529                                        LR 0.000250    Time 0.214970    
2023-04-17 03:56:33,143 - Epoch: [64][  100/  518]    Overall Loss 3.092941    Objective Loss 3.092941                                        LR 0.000250    Time 0.207742    
2023-04-17 03:56:43,229 - Epoch: [64][  150/  518]    Overall Loss 3.081572    Objective Loss 3.081572                                        LR 0.000250    Time 0.205722    
2023-04-17 03:56:53,378 - Epoch: [64][  200/  518]    Overall Loss 3.074605    Objective Loss 3.074605                                        LR 0.000250    Time 0.205028    
2023-04-17 03:57:03,439 - Epoch: [64][  250/  518]    Overall Loss 3.061469    Objective Loss 3.061469                                        LR 0.000250    Time 0.204260    
2023-04-17 03:57:13,503 - Epoch: [64][  300/  518]    Overall Loss 3.068878    Objective Loss 3.068878                                        LR 0.000250    Time 0.203760    
2023-04-17 03:57:23,660 - Epoch: [64][  350/  518]    Overall Loss 3.067227    Objective Loss 3.067227                                        LR 0.000250    Time 0.203665    
2023-04-17 03:57:33,780 - Epoch: [64][  400/  518]    Overall Loss 3.064225    Objective Loss 3.064225                                        LR 0.000250    Time 0.203505    
2023-04-17 03:57:43,975 - Epoch: [64][  450/  518]    Overall Loss 3.067886    Objective Loss 3.067886                                        LR 0.000250    Time 0.203544    
2023-04-17 03:57:54,046 - Epoch: [64][  500/  518]    Overall Loss 3.069731    Objective Loss 3.069731                                        LR 0.000250    Time 0.203330    
2023-04-17 03:57:57,596 - Epoch: [64][  518/  518]    Overall Loss 3.071063    Objective Loss 3.071063                                        LR 0.000250    Time 0.203116    
2023-04-17 03:57:57,678 - --- validate (epoch=64)-----------
2023-04-17 03:57:57,678 - 4952 samples (32 per mini-batch)
2023-04-17 03:58:49,258 - Epoch: [64][   50/  155]    Loss 3.270451    mAP 0.484651    
2023-04-17 03:59:40,943 - Epoch: [64][  100/  155]    Loss 3.253805    mAP 0.483292    
2023-04-17 04:00:32,681 - Epoch: [64][  150/  155]    Loss 3.271381    mAP 0.482006    
2023-04-17 04:00:37,334 - Epoch: [64][  155/  155]    Loss 3.270480    mAP 0.482203    
2023-04-17 04:00:37,411 - ==> mAP: 0.48220    Loss: 3.270

2023-04-17 04:00:37,415 - ==> Best [mAP: 0.482203   vloss: 3.270480   Sparsity:0.00   Params: 2177088 on epoch: 64]
2023-04-17 04:00:37,415 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 04:00:37,466 - 

2023-04-17 04:00:37,466 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 04:00:48,534 - Epoch: [65][   50/  518]    Overall Loss 3.067599    Objective Loss 3.067599                                        LR 0.000250    Time 0.221304    
2023-04-17 04:00:58,692 - Epoch: [65][  100/  518]    Overall Loss 3.080531    Objective Loss 3.080531                                        LR 0.000250    Time 0.212211    
2023-04-17 04:01:08,792 - Epoch: [65][  150/  518]    Overall Loss 3.054312    Objective Loss 3.054312                                        LR 0.000250    Time 0.208800    
2023-04-17 04:01:18,859 - Epoch: [65][  200/  518]    Overall Loss 3.055620    Objective Loss 3.055620                                        LR 0.000250    Time 0.206930    
2023-04-17 04:01:28,984 - Epoch: [65][  250/  518]    Overall Loss 3.058701    Objective Loss 3.058701                                        LR 0.000250    Time 0.206034    
2023-04-17 04:01:39,047 - Epoch: [65][  300/  518]    Overall Loss 3.070598    Objective Loss 3.070598                                        LR 0.000250    Time 0.205234    
2023-04-17 04:01:49,103 - Epoch: [65][  350/  518]    Overall Loss 3.061763    Objective Loss 3.061763                                        LR 0.000250    Time 0.204643    
2023-04-17 04:01:59,303 - Epoch: [65][  400/  518]    Overall Loss 3.063146    Objective Loss 3.063146                                        LR 0.000250    Time 0.204560    
2023-04-17 04:02:09,350 - Epoch: [65][  450/  518]    Overall Loss 3.064718    Objective Loss 3.064718                                        LR 0.000250    Time 0.204154    
2023-04-17 04:02:19,393 - Epoch: [65][  500/  518]    Overall Loss 3.065872    Objective Loss 3.065872                                        LR 0.000250    Time 0.203820    
2023-04-17 04:02:22,910 - Epoch: [65][  518/  518]    Overall Loss 3.066961    Objective Loss 3.066961                                        LR 0.000250    Time 0.203526    
2023-04-17 04:02:22,987 - --- validate (epoch=65)-----------
2023-04-17 04:02:22,987 - 4952 samples (32 per mini-batch)
2023-04-17 04:03:14,224 - Epoch: [65][   50/  155]    Loss 3.250264    mAP 0.475498    
2023-04-17 04:04:06,198 - Epoch: [65][  100/  155]    Loss 3.244809    mAP 0.477142    
2023-04-17 04:04:57,073 - Epoch: [65][  150/  155]    Loss 3.249773    mAP 0.476745    
2023-04-17 04:05:02,473 - Epoch: [65][  155/  155]    Loss 3.251678    mAP 0.477884    
2023-04-17 04:05:02,551 - ==> mAP: 0.47788    Loss: 3.252

2023-04-17 04:05:02,555 - ==> Best [mAP: 0.482203   vloss: 3.270480   Sparsity:0.00   Params: 2177088 on epoch: 64]
2023-04-17 04:05:02,555 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 04:05:02,590 - 

2023-04-17 04:05:02,590 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 04:05:13,474 - Epoch: [66][   50/  518]    Overall Loss 3.026444    Objective Loss 3.026444                                        LR 0.000250    Time 0.217611    
2023-04-17 04:05:23,604 - Epoch: [66][  100/  518]    Overall Loss 3.048264    Objective Loss 3.048264                                        LR 0.000250    Time 0.210090    
2023-04-17 04:05:33,652 - Epoch: [66][  150/  518]    Overall Loss 3.054870    Objective Loss 3.054870                                        LR 0.000250    Time 0.207040    
2023-04-17 04:05:43,734 - Epoch: [66][  200/  518]    Overall Loss 3.048176    Objective Loss 3.048176                                        LR 0.000250    Time 0.205684    
2023-04-17 04:05:53,911 - Epoch: [66][  250/  518]    Overall Loss 3.054989    Objective Loss 3.054989                                        LR 0.000250    Time 0.205246    
2023-04-17 04:06:04,087 - Epoch: [66][  300/  518]    Overall Loss 3.063446    Objective Loss 3.063446                                        LR 0.000250    Time 0.204953    
2023-04-17 04:06:14,233 - Epoch: [66][  350/  518]    Overall Loss 3.060501    Objective Loss 3.060501                                        LR 0.000250    Time 0.204660    
2023-04-17 04:06:24,291 - Epoch: [66][  400/  518]    Overall Loss 3.063600    Objective Loss 3.063600                                        LR 0.000250    Time 0.204219    
2023-04-17 04:06:34,369 - Epoch: [66][  450/  518]    Overall Loss 3.061057    Objective Loss 3.061057                                        LR 0.000250    Time 0.203920    
2023-04-17 04:06:44,533 - Epoch: [66][  500/  518]    Overall Loss 3.054976    Objective Loss 3.054976                                        LR 0.000250    Time 0.203852    
2023-04-17 04:06:48,059 - Epoch: [66][  518/  518]    Overall Loss 3.050564    Objective Loss 3.050564                                        LR 0.000250    Time 0.203574    
2023-04-17 04:06:48,138 - --- validate (epoch=66)-----------
2023-04-17 04:06:48,138 - 4952 samples (32 per mini-batch)
2023-04-17 04:07:34,969 - Epoch: [66][   50/  155]    Loss 3.257671    mAP 0.484348    
2023-04-17 04:08:18,057 - Epoch: [66][  100/  155]    Loss 3.240130    mAP 0.477320    
2023-04-17 04:09:01,084 - Epoch: [66][  150/  155]    Loss 3.241589    mAP 0.476181    
2023-04-17 04:09:05,524 - Epoch: [66][  155/  155]    Loss 3.242254    mAP 0.474982    
2023-04-17 04:09:05,605 - ==> mAP: 0.47498    Loss: 3.242

2023-04-17 04:09:05,609 - ==> Best [mAP: 0.482203   vloss: 3.270480   Sparsity:0.00   Params: 2177088 on epoch: 64]
2023-04-17 04:09:05,609 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 04:09:05,670 - 

2023-04-17 04:09:05,671 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 04:09:16,465 - Epoch: [67][   50/  518]    Overall Loss 3.023692    Objective Loss 3.023692                                        LR 0.000250    Time 0.215810    
2023-04-17 04:09:26,552 - Epoch: [67][  100/  518]    Overall Loss 3.055756    Objective Loss 3.055756                                        LR 0.000250    Time 0.208758    
2023-04-17 04:09:36,683 - Epoch: [67][  150/  518]    Overall Loss 3.054651    Objective Loss 3.054651                                        LR 0.000250    Time 0.206702    
2023-04-17 04:09:46,856 - Epoch: [67][  200/  518]    Overall Loss 3.059321    Objective Loss 3.059321                                        LR 0.000250    Time 0.205882    
2023-04-17 04:09:56,905 - Epoch: [67][  250/  518]    Overall Loss 3.052911    Objective Loss 3.052911                                        LR 0.000250    Time 0.204896    
2023-04-17 04:10:07,011 - Epoch: [67][  300/  518]    Overall Loss 3.051779    Objective Loss 3.051779                                        LR 0.000250    Time 0.204427    
2023-04-17 04:10:17,195 - Epoch: [67][  350/  518]    Overall Loss 3.057279    Objective Loss 3.057279                                        LR 0.000250    Time 0.204318    
2023-04-17 04:10:27,324 - Epoch: [67][  400/  518]    Overall Loss 3.058673    Objective Loss 3.058673                                        LR 0.000250    Time 0.204097    
2023-04-17 04:10:37,430 - Epoch: [67][  450/  518]    Overall Loss 3.059679    Objective Loss 3.059679                                        LR 0.000250    Time 0.203872    
2023-04-17 04:10:47,514 - Epoch: [67][  500/  518]    Overall Loss 3.057389    Objective Loss 3.057389                                        LR 0.000250    Time 0.203650    
2023-04-17 04:10:51,036 - Epoch: [67][  518/  518]    Overall Loss 3.056719    Objective Loss 3.056719                                        LR 0.000250    Time 0.203373    
2023-04-17 04:10:51,117 - --- validate (epoch=67)-----------
2023-04-17 04:10:51,117 - 4952 samples (32 per mini-batch)
2023-04-17 04:11:39,052 - Epoch: [67][   50/  155]    Loss 3.297742    mAP 0.464040    
2023-04-17 04:12:26,857 - Epoch: [67][  100/  155]    Loss 3.291664    mAP 0.469293    
2023-04-17 04:13:13,150 - Epoch: [67][  150/  155]    Loss 3.246702    mAP 0.477206    
2023-04-17 04:13:17,717 - Epoch: [67][  155/  155]    Loss 3.244829    mAP 0.480473    
2023-04-17 04:13:17,795 - ==> mAP: 0.48047    Loss: 3.245

2023-04-17 04:13:17,799 - ==> Best [mAP: 0.482203   vloss: 3.270480   Sparsity:0.00   Params: 2177088 on epoch: 64]
2023-04-17 04:13:17,799 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 04:13:17,835 - 

2023-04-17 04:13:17,835 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 04:13:28,663 - Epoch: [68][   50/  518]    Overall Loss 3.041379    Objective Loss 3.041379                                        LR 0.000250    Time 0.216498    
2023-04-17 04:13:38,834 - Epoch: [68][  100/  518]    Overall Loss 3.050756    Objective Loss 3.050756                                        LR 0.000250    Time 0.209947    
2023-04-17 04:13:48,966 - Epoch: [68][  150/  518]    Overall Loss 3.042562    Objective Loss 3.042562                                        LR 0.000250    Time 0.207498    
2023-04-17 04:13:59,105 - Epoch: [68][  200/  518]    Overall Loss 3.037596    Objective Loss 3.037596                                        LR 0.000250    Time 0.206312    
2023-04-17 04:14:09,232 - Epoch: [68][  250/  518]    Overall Loss 3.036637    Objective Loss 3.036637                                        LR 0.000250    Time 0.205552    
2023-04-17 04:14:19,301 - Epoch: [68][  300/  518]    Overall Loss 3.038747    Objective Loss 3.038747                                        LR 0.000250    Time 0.204852    
2023-04-17 04:14:29,371 - Epoch: [68][  350/  518]    Overall Loss 3.040296    Objective Loss 3.040296                                        LR 0.000250    Time 0.204352    
2023-04-17 04:14:39,495 - Epoch: [68][  400/  518]    Overall Loss 3.047107    Objective Loss 3.047107                                        LR 0.000250    Time 0.204116    
2023-04-17 04:14:49,621 - Epoch: [68][  450/  518]    Overall Loss 3.046108    Objective Loss 3.046108                                        LR 0.000250    Time 0.203935    
2023-04-17 04:14:59,727 - Epoch: [68][  500/  518]    Overall Loss 3.046017    Objective Loss 3.046017                                        LR 0.000250    Time 0.203751    
2023-04-17 04:15:03,282 - Epoch: [68][  518/  518]    Overall Loss 3.048039    Objective Loss 3.048039                                        LR 0.000250    Time 0.203532    
2023-04-17 04:15:03,362 - --- validate (epoch=68)-----------
2023-04-17 04:15:03,362 - 4952 samples (32 per mini-batch)
2023-04-17 04:15:52,097 - Epoch: [68][   50/  155]    Loss 3.254146    mAP 0.480316    
2023-04-17 04:16:36,852 - Epoch: [68][  100/  155]    Loss 3.248889    mAP 0.483374    
2023-04-17 04:17:23,461 - Epoch: [68][  150/  155]    Loss 3.244279    mAP 0.482602    
2023-04-17 04:17:27,471 - Epoch: [68][  155/  155]    Loss 3.240215    mAP 0.485838    
2023-04-17 04:17:27,547 - ==> mAP: 0.48584    Loss: 3.240

2023-04-17 04:17:27,551 - ==> Best [mAP: 0.485838   vloss: 3.240215   Sparsity:0.00   Params: 2177088 on epoch: 68]
2023-04-17 04:17:27,551 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 04:17:27,602 - 

2023-04-17 04:17:27,602 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 04:17:38,631 - Epoch: [69][   50/  518]    Overall Loss 2.970996    Objective Loss 2.970996                                        LR 0.000250    Time 0.220514    
2023-04-17 04:17:48,694 - Epoch: [69][  100/  518]    Overall Loss 3.022981    Objective Loss 3.022981                                        LR 0.000250    Time 0.210876    
2023-04-17 04:17:58,829 - Epoch: [69][  150/  518]    Overall Loss 3.028464    Objective Loss 3.028464                                        LR 0.000250    Time 0.208141    
2023-04-17 04:18:08,953 - Epoch: [69][  200/  518]    Overall Loss 3.018949    Objective Loss 3.018949                                        LR 0.000250    Time 0.206717    
2023-04-17 04:18:19,011 - Epoch: [69][  250/  518]    Overall Loss 3.033524    Objective Loss 3.033524                                        LR 0.000250    Time 0.205602    
2023-04-17 04:18:29,110 - Epoch: [69][  300/  518]    Overall Loss 3.036722    Objective Loss 3.036722                                        LR 0.000250    Time 0.204992    
2023-04-17 04:18:39,162 - Epoch: [69][  350/  518]    Overall Loss 3.033824    Objective Loss 3.033824                                        LR 0.000250    Time 0.204422    
2023-04-17 04:18:49,232 - Epoch: [69][  400/  518]    Overall Loss 3.042951    Objective Loss 3.042951                                        LR 0.000250    Time 0.204041    
2023-04-17 04:18:59,319 - Epoch: [69][  450/  518]    Overall Loss 3.046280    Objective Loss 3.046280                                        LR 0.000250    Time 0.203781    
2023-04-17 04:19:09,437 - Epoch: [69][  500/  518]    Overall Loss 3.045458    Objective Loss 3.045458                                        LR 0.000250    Time 0.203636    
2023-04-17 04:19:12,943 - Epoch: [69][  518/  518]    Overall Loss 3.046204    Objective Loss 3.046204                                        LR 0.000250    Time 0.203328    
2023-04-17 04:19:13,023 - --- validate (epoch=69)-----------
2023-04-17 04:19:13,023 - 4952 samples (32 per mini-batch)
2023-04-17 04:20:06,229 - Epoch: [69][   50/  155]    Loss 3.335735    mAP 0.476669    
2023-04-17 04:20:56,640 - Epoch: [69][  100/  155]    Loss 3.278074    mAP 0.471609    
2023-04-17 04:21:47,320 - Epoch: [69][  150/  155]    Loss 3.252259    mAP 0.483135    
2023-04-17 04:21:52,320 - Epoch: [69][  155/  155]    Loss 3.251048    mAP 0.483367    
2023-04-17 04:21:52,397 - ==> mAP: 0.48337    Loss: 3.251

2023-04-17 04:21:52,401 - ==> Best [mAP: 0.485838   vloss: 3.240215   Sparsity:0.00   Params: 2177088 on epoch: 68]
2023-04-17 04:21:52,401 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 04:21:52,437 - 

2023-04-17 04:21:52,437 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 04:22:03,293 - Epoch: [70][   50/  518]    Overall Loss 2.999757    Objective Loss 2.999757                                        LR 0.000250    Time 0.217057    
2023-04-17 04:22:13,333 - Epoch: [70][  100/  518]    Overall Loss 3.039120    Objective Loss 3.039120                                        LR 0.000250    Time 0.208908    
2023-04-17 04:22:23,494 - Epoch: [70][  150/  518]    Overall Loss 3.055603    Objective Loss 3.055603                                        LR 0.000250    Time 0.207004    
2023-04-17 04:22:33,649 - Epoch: [70][  200/  518]    Overall Loss 3.055149    Objective Loss 3.055149                                        LR 0.000250    Time 0.206021    
2023-04-17 04:22:43,735 - Epoch: [70][  250/  518]    Overall Loss 3.043348    Objective Loss 3.043348                                        LR 0.000250    Time 0.205155    
2023-04-17 04:22:53,942 - Epoch: [70][  300/  518]    Overall Loss 3.038080    Objective Loss 3.038080                                        LR 0.000250    Time 0.204982    
2023-04-17 04:23:04,141 - Epoch: [70][  350/  518]    Overall Loss 3.038946    Objective Loss 3.038946                                        LR 0.000250    Time 0.204834    
2023-04-17 04:23:14,285 - Epoch: [70][  400/  518]    Overall Loss 3.039439    Objective Loss 3.039439                                        LR 0.000250    Time 0.204585    
2023-04-17 04:23:24,381 - Epoch: [70][  450/  518]    Overall Loss 3.044290    Objective Loss 3.044290                                        LR 0.000250    Time 0.204286    
2023-04-17 04:23:34,454 - Epoch: [70][  500/  518]    Overall Loss 3.045844    Objective Loss 3.045844                                        LR 0.000250    Time 0.204000    
2023-04-17 04:23:37,972 - Epoch: [70][  518/  518]    Overall Loss 3.050398    Objective Loss 3.050398                                        LR 0.000250    Time 0.203701    
2023-04-17 04:23:38,053 - --- validate (epoch=70)-----------
2023-04-17 04:23:38,054 - 4952 samples (32 per mini-batch)
2023-04-17 04:24:28,195 - Epoch: [70][   50/  155]    Loss 3.277852    mAP 0.481223    
2023-04-17 04:25:17,385 - Epoch: [70][  100/  155]    Loss 3.268462    mAP 0.474016    
2023-04-17 04:26:05,186 - Epoch: [70][  150/  155]    Loss 3.264117    mAP 0.475789    
2023-04-17 04:26:09,499 - Epoch: [70][  155/  155]    Loss 3.263744    mAP 0.477813    
2023-04-17 04:26:09,578 - ==> mAP: 0.47781    Loss: 3.264

2023-04-17 04:26:09,582 - ==> Best [mAP: 0.485838   vloss: 3.240215   Sparsity:0.00   Params: 2177088 on epoch: 68]
2023-04-17 04:26:09,582 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 04:26:09,619 - 

2023-04-17 04:26:09,619 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 04:26:20,583 - Epoch: [71][   50/  518]    Overall Loss 3.045659    Objective Loss 3.045659                                        LR 0.000250    Time 0.219227    
2023-04-17 04:26:30,716 - Epoch: [71][  100/  518]    Overall Loss 3.057833    Objective Loss 3.057833                                        LR 0.000250    Time 0.210929    
2023-04-17 04:26:40,766 - Epoch: [71][  150/  518]    Overall Loss 3.057422    Objective Loss 3.057422                                        LR 0.000250    Time 0.207609    
2023-04-17 04:26:50,887 - Epoch: [71][  200/  518]    Overall Loss 3.045083    Objective Loss 3.045083                                        LR 0.000250    Time 0.206307    
2023-04-17 04:27:01,035 - Epoch: [71][  250/  518]    Overall Loss 3.057088    Objective Loss 3.057088                                        LR 0.000250    Time 0.205629    
2023-04-17 04:27:11,121 - Epoch: [71][  300/  518]    Overall Loss 3.068585    Objective Loss 3.068585                                        LR 0.000250    Time 0.204973    
2023-04-17 04:27:21,265 - Epoch: [71][  350/  518]    Overall Loss 3.060789    Objective Loss 3.060789                                        LR 0.000250    Time 0.204670    
2023-04-17 04:27:31,336 - Epoch: [71][  400/  518]    Overall Loss 3.060373    Objective Loss 3.060373                                        LR 0.000250    Time 0.204258    
2023-04-17 04:27:41,405 - Epoch: [71][  450/  518]    Overall Loss 3.061560    Objective Loss 3.061560                                        LR 0.000250    Time 0.203936    
2023-04-17 04:27:51,630 - Epoch: [71][  500/  518]    Overall Loss 3.055377    Objective Loss 3.055377                                        LR 0.000250    Time 0.203989    
2023-04-17 04:27:55,116 - Epoch: [71][  518/  518]    Overall Loss 3.051602    Objective Loss 3.051602                                        LR 0.000250    Time 0.203629    
2023-04-17 04:27:55,196 - --- validate (epoch=71)-----------
2023-04-17 04:27:55,196 - 4952 samples (32 per mini-batch)
2023-04-17 04:28:39,382 - Epoch: [71][   50/  155]    Loss 3.252507    mAP 0.496742    
2023-04-17 04:29:23,336 - Epoch: [71][  100/  155]    Loss 3.258415    mAP 0.491406    
2023-04-17 04:30:06,951 - Epoch: [71][  150/  155]    Loss 3.241808    mAP 0.486852    
2023-04-17 04:30:10,737 - Epoch: [71][  155/  155]    Loss 3.242096    mAP 0.487465    
2023-04-17 04:30:10,817 - ==> mAP: 0.48746    Loss: 3.242

2023-04-17 04:30:10,821 - ==> Best [mAP: 0.487465   vloss: 3.242096   Sparsity:0.00   Params: 2177088 on epoch: 71]
2023-04-17 04:30:10,821 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 04:30:10,872 - 

2023-04-17 04:30:10,872 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 04:30:21,810 - Epoch: [72][   50/  518]    Overall Loss 3.051068    Objective Loss 3.051068                                        LR 0.000250    Time 0.218701    
2023-04-17 04:30:31,901 - Epoch: [72][  100/  518]    Overall Loss 3.040920    Objective Loss 3.040920                                        LR 0.000250    Time 0.210240    
2023-04-17 04:30:41,951 - Epoch: [72][  150/  518]    Overall Loss 3.029642    Objective Loss 3.029642                                        LR 0.000250    Time 0.207155    
2023-04-17 04:30:52,028 - Epoch: [72][  200/  518]    Overall Loss 3.032419    Objective Loss 3.032419                                        LR 0.000250    Time 0.205742    
2023-04-17 04:31:02,186 - Epoch: [72][  250/  518]    Overall Loss 3.029690    Objective Loss 3.029690                                        LR 0.000250    Time 0.205219    
2023-04-17 04:31:12,315 - Epoch: [72][  300/  518]    Overall Loss 3.029335    Objective Loss 3.029335                                        LR 0.000250    Time 0.204775    
2023-04-17 04:31:22,388 - Epoch: [72][  350/  518]    Overall Loss 3.036048    Objective Loss 3.036048                                        LR 0.000250    Time 0.204296    
2023-04-17 04:31:32,418 - Epoch: [72][  400/  518]    Overall Loss 3.028614    Objective Loss 3.028614                                        LR 0.000250    Time 0.203830    
2023-04-17 04:31:42,542 - Epoch: [72][  450/  518]    Overall Loss 3.028243    Objective Loss 3.028243                                        LR 0.000250    Time 0.203676    
2023-04-17 04:31:52,593 - Epoch: [72][  500/  518]    Overall Loss 3.026570    Objective Loss 3.026570                                        LR 0.000250    Time 0.203407    
2023-04-17 04:31:56,063 - Epoch: [72][  518/  518]    Overall Loss 3.030087    Objective Loss 3.030087                                        LR 0.000250    Time 0.203038    
2023-04-17 04:31:56,142 - --- validate (epoch=72)-----------
2023-04-17 04:31:56,142 - 4952 samples (32 per mini-batch)
2023-04-17 04:32:45,667 - Epoch: [72][   50/  155]    Loss 3.251144    mAP 0.492285    
2023-04-17 04:33:34,286 - Epoch: [72][  100/  155]    Loss 3.269598    mAP 0.485463    
2023-04-17 04:34:24,057 - Epoch: [72][  150/  155]    Loss 3.276926    mAP 0.481527    
2023-04-17 04:34:28,124 - Epoch: [72][  155/  155]    Loss 3.278514    mAP 0.481212    
2023-04-17 04:34:28,213 - ==> mAP: 0.48121    Loss: 3.279

2023-04-17 04:34:28,217 - ==> Best [mAP: 0.487465   vloss: 3.242096   Sparsity:0.00   Params: 2177088 on epoch: 71]
2023-04-17 04:34:28,218 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 04:34:28,255 - 

2023-04-17 04:34:28,255 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 04:34:39,205 - Epoch: [73][   50/  518]    Overall Loss 3.046658    Objective Loss 3.046658                                        LR 0.000250    Time 0.218941    
2023-04-17 04:34:49,343 - Epoch: [73][  100/  518]    Overall Loss 3.056592    Objective Loss 3.056592                                        LR 0.000250    Time 0.210843    
2023-04-17 04:34:59,414 - Epoch: [73][  150/  518]    Overall Loss 3.056703    Objective Loss 3.056703                                        LR 0.000250    Time 0.207687    
2023-04-17 04:35:09,478 - Epoch: [73][  200/  518]    Overall Loss 3.047167    Objective Loss 3.047167                                        LR 0.000250    Time 0.206077    
2023-04-17 04:35:19,618 - Epoch: [73][  250/  518]    Overall Loss 3.040789    Objective Loss 3.040789                                        LR 0.000250    Time 0.205418    
2023-04-17 04:35:29,749 - Epoch: [73][  300/  518]    Overall Loss 3.041762    Objective Loss 3.041762                                        LR 0.000250    Time 0.204946    
2023-04-17 04:35:39,821 - Epoch: [73][  350/  518]    Overall Loss 3.044783    Objective Loss 3.044783                                        LR 0.000250    Time 0.204439    
2023-04-17 04:35:49,875 - Epoch: [73][  400/  518]    Overall Loss 3.042870    Objective Loss 3.042870                                        LR 0.000250    Time 0.204016    
2023-04-17 04:35:59,911 - Epoch: [73][  450/  518]    Overall Loss 3.046853    Objective Loss 3.046853                                        LR 0.000250    Time 0.203647    
2023-04-17 04:36:10,003 - Epoch: [73][  500/  518]    Overall Loss 3.040257    Objective Loss 3.040257                                        LR 0.000250    Time 0.203464    
2023-04-17 04:36:13,507 - Epoch: [73][  518/  518]    Overall Loss 3.040391    Objective Loss 3.040391                                        LR 0.000250    Time 0.203157    
2023-04-17 04:36:13,588 - --- validate (epoch=73)-----------
2023-04-17 04:36:13,588 - 4952 samples (32 per mini-batch)
2023-04-17 04:37:01,075 - Epoch: [73][   50/  155]    Loss 3.204649    mAP 0.502618    
2023-04-17 04:37:48,700 - Epoch: [73][  100/  155]    Loss 3.234196    mAP 0.480637    
2023-04-17 04:38:37,197 - Epoch: [73][  150/  155]    Loss 3.249019    mAP 0.481103    
2023-04-17 04:38:41,319 - Epoch: [73][  155/  155]    Loss 3.243029    mAP 0.482138    
2023-04-17 04:38:41,390 - ==> mAP: 0.48214    Loss: 3.243

2023-04-17 04:38:41,394 - ==> Best [mAP: 0.487465   vloss: 3.242096   Sparsity:0.00   Params: 2177088 on epoch: 71]
2023-04-17 04:38:41,394 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 04:38:41,430 - 

2023-04-17 04:38:41,430 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 04:38:52,406 - Epoch: [74][   50/  518]    Overall Loss 2.962961    Objective Loss 2.962961                                        LR 0.000250    Time 0.219473    
2023-04-17 04:39:02,462 - Epoch: [74][  100/  518]    Overall Loss 2.991234    Objective Loss 2.991234                                        LR 0.000250    Time 0.210275    
2023-04-17 04:39:12,513 - Epoch: [74][  150/  518]    Overall Loss 2.980755    Objective Loss 2.980755                                        LR 0.000250    Time 0.207179    
2023-04-17 04:39:22,600 - Epoch: [74][  200/  518]    Overall Loss 2.993800    Objective Loss 2.993800                                        LR 0.000250    Time 0.205814    
2023-04-17 04:39:32,717 - Epoch: [74][  250/  518]    Overall Loss 2.997195    Objective Loss 2.997195                                        LR 0.000250    Time 0.205112    
2023-04-17 04:39:42,812 - Epoch: [74][  300/  518]    Overall Loss 3.000904    Objective Loss 3.000904                                        LR 0.000250    Time 0.204571    
2023-04-17 04:39:52,824 - Epoch: [74][  350/  518]    Overall Loss 3.011844    Objective Loss 3.011844                                        LR 0.000250    Time 0.203950    
2023-04-17 04:40:02,879 - Epoch: [74][  400/  518]    Overall Loss 3.007187    Objective Loss 3.007187                                        LR 0.000250    Time 0.203590    
2023-04-17 04:40:13,041 - Epoch: [74][  450/  518]    Overall Loss 3.009840    Objective Loss 3.009840                                        LR 0.000250    Time 0.203547    
2023-04-17 04:40:23,165 - Epoch: [74][  500/  518]    Overall Loss 3.021912    Objective Loss 3.021912                                        LR 0.000250    Time 0.203436    
2023-04-17 04:40:26,652 - Epoch: [74][  518/  518]    Overall Loss 3.020265    Objective Loss 3.020265                                        LR 0.000250    Time 0.203098    
2023-04-17 04:40:26,733 - --- validate (epoch=74)-----------
2023-04-17 04:40:26,733 - 4952 samples (32 per mini-batch)
2023-04-17 04:41:12,230 - Epoch: [74][   50/  155]    Loss 3.218192    mAP 0.468819    
2023-04-17 04:41:56,863 - Epoch: [74][  100/  155]    Loss 3.216948    mAP 0.475078    
2023-04-17 04:42:43,101 - Epoch: [74][  150/  155]    Loss 3.227375    mAP 0.480371    
2023-04-17 04:42:47,029 - Epoch: [74][  155/  155]    Loss 3.225723    mAP 0.480913    
2023-04-17 04:42:47,118 - ==> mAP: 0.48091    Loss: 3.226

2023-04-17 04:42:47,122 - ==> Best [mAP: 0.487465   vloss: 3.242096   Sparsity:0.00   Params: 2177088 on epoch: 71]
2023-04-17 04:42:47,122 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 04:42:47,158 - 

2023-04-17 04:42:47,158 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 04:42:58,104 - Epoch: [75][   50/  518]    Overall Loss 2.963628    Objective Loss 2.963628                                        LR 0.000250    Time 0.218849    
2023-04-17 04:43:08,216 - Epoch: [75][  100/  518]    Overall Loss 2.997690    Objective Loss 2.997690                                        LR 0.000250    Time 0.210537    
2023-04-17 04:43:18,267 - Epoch: [75][  150/  518]    Overall Loss 3.016636    Objective Loss 3.016636                                        LR 0.000250    Time 0.207350    
2023-04-17 04:43:28,360 - Epoch: [75][  200/  518]    Overall Loss 3.029463    Objective Loss 3.029463                                        LR 0.000250    Time 0.205970    
2023-04-17 04:43:38,406 - Epoch: [75][  250/  518]    Overall Loss 3.029294    Objective Loss 3.029294                                        LR 0.000250    Time 0.204956    
2023-04-17 04:43:48,442 - Epoch: [75][  300/  518]    Overall Loss 3.038510    Objective Loss 3.038510                                        LR 0.000250    Time 0.204245    
2023-04-17 04:43:58,534 - Epoch: [75][  350/  518]    Overall Loss 3.039985    Objective Loss 3.039985                                        LR 0.000250    Time 0.203896    
2023-04-17 04:44:08,652 - Epoch: [75][  400/  518]    Overall Loss 3.044203    Objective Loss 3.044203                                        LR 0.000250    Time 0.203701    
2023-04-17 04:44:18,803 - Epoch: [75][  450/  518]    Overall Loss 3.035388    Objective Loss 3.035388                                        LR 0.000250    Time 0.203621    
2023-04-17 04:44:28,833 - Epoch: [75][  500/  518]    Overall Loss 3.031390    Objective Loss 3.031390                                        LR 0.000250    Time 0.203317    
2023-04-17 04:44:32,344 - Epoch: [75][  518/  518]    Overall Loss 3.033818    Objective Loss 3.033818                                        LR 0.000250    Time 0.203029    
2023-04-17 04:44:32,427 - --- validate (epoch=75)-----------
2023-04-17 04:44:32,427 - 4952 samples (32 per mini-batch)
2023-04-17 04:45:16,448 - Epoch: [75][   50/  155]    Loss 3.198947    mAP 0.486021    
2023-04-17 04:46:00,542 - Epoch: [75][  100/  155]    Loss 3.194124    mAP 0.494248    
2023-04-17 04:46:43,158 - Epoch: [75][  150/  155]    Loss 3.220352    mAP 0.486490    
2023-04-17 04:46:47,331 - Epoch: [75][  155/  155]    Loss 3.226287    mAP 0.484916    
2023-04-17 04:46:47,409 - ==> mAP: 0.48492    Loss: 3.226

2023-04-17 04:46:47,413 - ==> Best [mAP: 0.487465   vloss: 3.242096   Sparsity:0.00   Params: 2177088 on epoch: 71]
2023-04-17 04:46:47,413 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 04:46:47,449 - 

2023-04-17 04:46:47,449 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 04:46:58,362 - Epoch: [76][   50/  518]    Overall Loss 3.029179    Objective Loss 3.029179                                        LR 0.000250    Time 0.218201    
2023-04-17 04:47:08,428 - Epoch: [76][  100/  518]    Overall Loss 2.999647    Objective Loss 2.999647                                        LR 0.000250    Time 0.209748    
2023-04-17 04:47:18,527 - Epoch: [76][  150/  518]    Overall Loss 3.018574    Objective Loss 3.018574                                        LR 0.000250    Time 0.207149    
2023-04-17 04:47:28,545 - Epoch: [76][  200/  518]    Overall Loss 3.024807    Objective Loss 3.024807                                        LR 0.000250    Time 0.205444    
2023-04-17 04:47:38,665 - Epoch: [76][  250/  518]    Overall Loss 3.028192    Objective Loss 3.028192                                        LR 0.000250    Time 0.204829    
2023-04-17 04:47:48,778 - Epoch: [76][  300/  518]    Overall Loss 3.026463    Objective Loss 3.026463                                        LR 0.000250    Time 0.204396    
2023-04-17 04:47:58,873 - Epoch: [76][  350/  518]    Overall Loss 3.019447    Objective Loss 3.019447                                        LR 0.000250    Time 0.204034    
2023-04-17 04:48:08,934 - Epoch: [76][  400/  518]    Overall Loss 3.023345    Objective Loss 3.023345                                        LR 0.000250    Time 0.203678    
2023-04-17 04:48:19,014 - Epoch: [76][  450/  518]    Overall Loss 3.019281    Objective Loss 3.019281                                        LR 0.000250    Time 0.203444    
2023-04-17 04:48:29,173 - Epoch: [76][  500/  518]    Overall Loss 3.017208    Objective Loss 3.017208                                        LR 0.000250    Time 0.203415    
2023-04-17 04:48:32,706 - Epoch: [76][  518/  518]    Overall Loss 3.021392    Objective Loss 3.021392                                        LR 0.000250    Time 0.203167    
2023-04-17 04:48:32,786 - --- validate (epoch=76)-----------
2023-04-17 04:48:32,786 - 4952 samples (32 per mini-batch)
2023-04-17 04:49:22,724 - Epoch: [76][   50/  155]    Loss 3.188584    mAP 0.491832    
2023-04-17 04:50:11,120 - Epoch: [76][  100/  155]    Loss 3.196684    mAP 0.503137    
2023-04-17 04:50:59,556 - Epoch: [76][  150/  155]    Loss 3.195359    mAP 0.491888    
2023-04-17 04:51:04,477 - Epoch: [76][  155/  155]    Loss 3.199036    mAP 0.492514    
2023-04-17 04:51:04,553 - ==> mAP: 0.49251    Loss: 3.199

2023-04-17 04:51:04,557 - ==> Best [mAP: 0.492514   vloss: 3.199036   Sparsity:0.00   Params: 2177088 on epoch: 76]
2023-04-17 04:51:04,557 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 04:51:04,609 - 

2023-04-17 04:51:04,609 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 04:51:15,532 - Epoch: [77][   50/  518]    Overall Loss 3.025841    Objective Loss 3.025841                                        LR 0.000250    Time 0.218390    
2023-04-17 04:51:25,573 - Epoch: [77][  100/  518]    Overall Loss 3.005176    Objective Loss 3.005176                                        LR 0.000250    Time 0.209592    
2023-04-17 04:51:35,692 - Epoch: [77][  150/  518]    Overall Loss 3.018033    Objective Loss 3.018033                                        LR 0.000250    Time 0.207177    
2023-04-17 04:51:45,814 - Epoch: [77][  200/  518]    Overall Loss 3.001269    Objective Loss 3.001269                                        LR 0.000250    Time 0.205988    
2023-04-17 04:51:55,832 - Epoch: [77][  250/  518]    Overall Loss 3.004414    Objective Loss 3.004414                                        LR 0.000250    Time 0.204856    
2023-04-17 04:52:05,884 - Epoch: [77][  300/  518]    Overall Loss 3.014586    Objective Loss 3.014586                                        LR 0.000250    Time 0.204215    
2023-04-17 04:52:15,940 - Epoch: [77][  350/  518]    Overall Loss 3.020317    Objective Loss 3.020317                                        LR 0.000250    Time 0.203769    
2023-04-17 04:52:26,043 - Epoch: [77][  400/  518]    Overall Loss 3.014718    Objective Loss 3.014718                                        LR 0.000250    Time 0.203551    
2023-04-17 04:52:36,109 - Epoch: [77][  450/  518]    Overall Loss 3.021529    Objective Loss 3.021529                                        LR 0.000250    Time 0.203298    
2023-04-17 04:52:46,322 - Epoch: [77][  500/  518]    Overall Loss 3.024129    Objective Loss 3.024129                                        LR 0.000250    Time 0.203392    
2023-04-17 04:52:49,814 - Epoch: [77][  518/  518]    Overall Loss 3.027725    Objective Loss 3.027725                                        LR 0.000250    Time 0.203065    
2023-04-17 04:52:49,894 - --- validate (epoch=77)-----------
2023-04-17 04:52:49,895 - 4952 samples (32 per mini-batch)
2023-04-17 04:53:41,059 - Epoch: [77][   50/  155]    Loss 3.195656    mAP 0.503666    
2023-04-17 04:54:33,441 - Epoch: [77][  100/  155]    Loss 3.200028    mAP 0.485672    
2023-04-17 04:55:25,218 - Epoch: [77][  150/  155]    Loss 3.210112    mAP 0.482831    
2023-04-17 04:55:29,695 - Epoch: [77][  155/  155]    Loss 3.205317    mAP 0.483328    
2023-04-17 04:55:29,773 - ==> mAP: 0.48333    Loss: 3.205

2023-04-17 04:55:29,777 - ==> Best [mAP: 0.492514   vloss: 3.199036   Sparsity:0.00   Params: 2177088 on epoch: 76]
2023-04-17 04:55:29,777 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 04:55:29,813 - 

2023-04-17 04:55:29,813 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 04:55:40,597 - Epoch: [78][   50/  518]    Overall Loss 3.041278    Objective Loss 3.041278                                        LR 0.000250    Time 0.215624    
2023-04-17 04:55:50,704 - Epoch: [78][  100/  518]    Overall Loss 3.012115    Objective Loss 3.012115                                        LR 0.000250    Time 0.208862    
2023-04-17 04:56:00,858 - Epoch: [78][  150/  518]    Overall Loss 3.010585    Objective Loss 3.010585                                        LR 0.000250    Time 0.206930    
2023-04-17 04:56:10,950 - Epoch: [78][  200/  518]    Overall Loss 3.008552    Objective Loss 3.008552                                        LR 0.000250    Time 0.205648    
2023-04-17 04:56:21,097 - Epoch: [78][  250/  518]    Overall Loss 3.012721    Objective Loss 3.012721                                        LR 0.000250    Time 0.205102    
2023-04-17 04:56:31,232 - Epoch: [78][  300/  518]    Overall Loss 3.019928    Objective Loss 3.019928                                        LR 0.000250    Time 0.204695    
2023-04-17 04:56:41,283 - Epoch: [78][  350/  518]    Overall Loss 3.020737    Objective Loss 3.020737                                        LR 0.000250    Time 0.204166    
2023-04-17 04:56:51,380 - Epoch: [78][  400/  518]    Overall Loss 3.020602    Objective Loss 3.020602                                        LR 0.000250    Time 0.203884    
2023-04-17 04:57:01,444 - Epoch: [78][  450/  518]    Overall Loss 3.015242    Objective Loss 3.015242                                        LR 0.000250    Time 0.203590    
2023-04-17 04:57:11,430 - Epoch: [78][  500/  518]    Overall Loss 3.015512    Objective Loss 3.015512                                        LR 0.000250    Time 0.203201    
2023-04-17 04:57:14,910 - Epoch: [78][  518/  518]    Overall Loss 3.013271    Objective Loss 3.013271                                        LR 0.000250    Time 0.202857    
2023-04-17 04:57:14,990 - --- validate (epoch=78)-----------
2023-04-17 04:57:14,990 - 4952 samples (32 per mini-batch)
2023-04-17 04:58:07,603 - Epoch: [78][   50/  155]    Loss 3.238886    mAP 0.481368    
2023-04-17 04:58:59,684 - Epoch: [78][  100/  155]    Loss 3.254906    mAP 0.469097    
2023-04-17 04:59:51,680 - Epoch: [78][  150/  155]    Loss 3.245633    mAP 0.479428    
2023-04-17 04:59:56,464 - Epoch: [78][  155/  155]    Loss 3.249035    mAP 0.478060    
2023-04-17 04:59:56,538 - ==> mAP: 0.47806    Loss: 3.249

2023-04-17 04:59:56,542 - ==> Best [mAP: 0.492514   vloss: 3.199036   Sparsity:0.00   Params: 2177088 on epoch: 76]
2023-04-17 04:59:56,542 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 04:59:56,579 - 

2023-04-17 04:59:56,579 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 05:00:07,404 - Epoch: [79][   50/  518]    Overall Loss 2.994414    Objective Loss 2.994414                                        LR 0.000250    Time 0.216452    
2023-04-17 05:00:17,490 - Epoch: [79][  100/  518]    Overall Loss 3.012888    Objective Loss 3.012888                                        LR 0.000250    Time 0.209066    
2023-04-17 05:00:27,596 - Epoch: [79][  150/  518]    Overall Loss 3.024079    Objective Loss 3.024079                                        LR 0.000250    Time 0.206740    
2023-04-17 05:00:37,702 - Epoch: [79][  200/  518]    Overall Loss 3.023333    Objective Loss 3.023333                                        LR 0.000250    Time 0.205576    
2023-04-17 05:00:47,793 - Epoch: [79][  250/  518]    Overall Loss 3.025937    Objective Loss 3.025937                                        LR 0.000250    Time 0.204819    
2023-04-17 05:00:57,885 - Epoch: [79][  300/  518]    Overall Loss 3.016064    Objective Loss 3.016064                                        LR 0.000250    Time 0.204318    
2023-04-17 05:01:07,910 - Epoch: [79][  350/  518]    Overall Loss 3.019108    Objective Loss 3.019108                                        LR 0.000250    Time 0.203767    
2023-04-17 05:01:17,989 - Epoch: [79][  400/  518]    Overall Loss 3.010783    Objective Loss 3.010783                                        LR 0.000250    Time 0.203490    
2023-04-17 05:01:28,115 - Epoch: [79][  450/  518]    Overall Loss 3.017706    Objective Loss 3.017706                                        LR 0.000250    Time 0.203380    
2023-04-17 05:01:38,236 - Epoch: [79][  500/  518]    Overall Loss 3.016930    Objective Loss 3.016930                                        LR 0.000250    Time 0.203281    
2023-04-17 05:01:41,743 - Epoch: [79][  518/  518]    Overall Loss 3.019304    Objective Loss 3.019304                                        LR 0.000250    Time 0.202986    
2023-04-17 05:01:41,824 - --- validate (epoch=79)-----------
2023-04-17 05:01:41,824 - 4952 samples (32 per mini-batch)
2023-04-17 05:02:28,070 - Epoch: [79][   50/  155]    Loss 3.232715    mAP 0.466279    
2023-04-17 05:03:12,302 - Epoch: [79][  100/  155]    Loss 3.251544    mAP 0.471928    
2023-04-17 05:03:56,418 - Epoch: [79][  150/  155]    Loss 3.238235    mAP 0.478127    
2023-04-17 05:04:00,537 - Epoch: [79][  155/  155]    Loss 3.241141    mAP 0.478868    
2023-04-17 05:04:00,616 - ==> mAP: 0.47887    Loss: 3.241

2023-04-17 05:04:00,619 - ==> Best [mAP: 0.492514   vloss: 3.199036   Sparsity:0.00   Params: 2177088 on epoch: 76]
2023-04-17 05:04:00,619 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 05:04:00,655 - 

2023-04-17 05:04:00,655 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 05:04:11,443 - Epoch: [80][   50/  518]    Overall Loss 3.002629    Objective Loss 3.002629                                        LR 0.000250    Time 0.215690    
2023-04-17 05:04:21,479 - Epoch: [80][  100/  518]    Overall Loss 2.996442    Objective Loss 2.996442                                        LR 0.000250    Time 0.208198    
2023-04-17 05:04:31,527 - Epoch: [80][  150/  518]    Overall Loss 2.997512    Objective Loss 2.997512                                        LR 0.000250    Time 0.205773    
2023-04-17 05:04:41,644 - Epoch: [80][  200/  518]    Overall Loss 3.014435    Objective Loss 3.014435                                        LR 0.000250    Time 0.204905    
2023-04-17 05:04:51,762 - Epoch: [80][  250/  518]    Overall Loss 3.009391    Objective Loss 3.009391                                        LR 0.000250    Time 0.204391    
2023-04-17 05:05:01,831 - Epoch: [80][  300/  518]    Overall Loss 3.017991    Objective Loss 3.017991                                        LR 0.000250    Time 0.203884    
2023-04-17 05:05:11,851 - Epoch: [80][  350/  518]    Overall Loss 3.011672    Objective Loss 3.011672                                        LR 0.000250    Time 0.203383    
2023-04-17 05:05:21,968 - Epoch: [80][  400/  518]    Overall Loss 3.021165    Objective Loss 3.021165                                        LR 0.000250    Time 0.203248    
2023-04-17 05:05:31,989 - Epoch: [80][  450/  518]    Overall Loss 3.018078    Objective Loss 3.018078                                        LR 0.000250    Time 0.202931    
2023-04-17 05:05:42,077 - Epoch: [80][  500/  518]    Overall Loss 3.016886    Objective Loss 3.016886                                        LR 0.000250    Time 0.202811    
2023-04-17 05:05:45,617 - Epoch: [80][  518/  518]    Overall Loss 3.014494    Objective Loss 3.014494                                        LR 0.000250    Time 0.202596    
2023-04-17 05:05:45,697 - --- validate (epoch=80)-----------
2023-04-17 05:05:45,697 - 4952 samples (32 per mini-batch)
2023-04-17 05:06:32,167 - Epoch: [80][   50/  155]    Loss 3.226309    mAP 0.493589    
2023-04-17 05:07:15,864 - Epoch: [80][  100/  155]    Loss 3.216302    mAP 0.488554    
2023-04-17 05:07:59,231 - Epoch: [80][  150/  155]    Loss 3.204664    mAP 0.492117    
2023-04-17 05:08:03,458 - Epoch: [80][  155/  155]    Loss 3.203911    mAP 0.492551    
2023-04-17 05:08:03,531 - ==> mAP: 0.49255    Loss: 3.204

2023-04-17 05:08:03,535 - ==> Best [mAP: 0.492551   vloss: 3.203911   Sparsity:0.00   Params: 2177088 on epoch: 80]
2023-04-17 05:08:03,535 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 05:08:03,586 - 

2023-04-17 05:08:03,586 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 05:08:14,466 - Epoch: [81][   50/  518]    Overall Loss 3.033047    Objective Loss 3.033047                                        LR 0.000250    Time 0.217547    
2023-04-17 05:08:24,619 - Epoch: [81][  100/  518]    Overall Loss 3.006878    Objective Loss 3.006878                                        LR 0.000250    Time 0.210289    
2023-04-17 05:08:34,716 - Epoch: [81][  150/  518]    Overall Loss 3.008888    Objective Loss 3.008888                                        LR 0.000250    Time 0.207495    
2023-04-17 05:08:44,759 - Epoch: [81][  200/  518]    Overall Loss 3.009611    Objective Loss 3.009611                                        LR 0.000250    Time 0.205831    
2023-04-17 05:08:54,841 - Epoch: [81][  250/  518]    Overall Loss 3.004818    Objective Loss 3.004818                                        LR 0.000250    Time 0.204986    
2023-04-17 05:09:04,975 - Epoch: [81][  300/  518]    Overall Loss 3.008342    Objective Loss 3.008342                                        LR 0.000250    Time 0.204595    
2023-04-17 05:09:15,035 - Epoch: [81][  350/  518]    Overall Loss 3.012066    Objective Loss 3.012066                                        LR 0.000250    Time 0.204106    
2023-04-17 05:09:25,116 - Epoch: [81][  400/  518]    Overall Loss 3.014246    Objective Loss 3.014246                                        LR 0.000250    Time 0.203790    
2023-04-17 05:09:35,193 - Epoch: [81][  450/  518]    Overall Loss 3.011112    Objective Loss 3.011112                                        LR 0.000250    Time 0.203538    
2023-04-17 05:09:45,242 - Epoch: [81][  500/  518]    Overall Loss 3.012922    Objective Loss 3.012922                                        LR 0.000250    Time 0.203278    
2023-04-17 05:09:48,708 - Epoch: [81][  518/  518]    Overall Loss 3.010805    Objective Loss 3.010805                                        LR 0.000250    Time 0.202904    
2023-04-17 05:09:48,789 - --- validate (epoch=81)-----------
2023-04-17 05:09:48,790 - 4952 samples (32 per mini-batch)
2023-04-17 05:10:32,963 - Epoch: [81][   50/  155]    Loss 3.186749    mAP 0.512989    
2023-04-17 05:11:17,721 - Epoch: [81][  100/  155]    Loss 3.209382    mAP 0.490158    
2023-04-17 05:12:02,451 - Epoch: [81][  150/  155]    Loss 3.204249    mAP 0.489605    
2023-04-17 05:12:06,592 - Epoch: [81][  155/  155]    Loss 3.213648    mAP 0.489954    
2023-04-17 05:12:06,671 - ==> mAP: 0.48995    Loss: 3.214

2023-04-17 05:12:06,675 - ==> Best [mAP: 0.492551   vloss: 3.203911   Sparsity:0.00   Params: 2177088 on epoch: 80]
2023-04-17 05:12:06,675 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 05:12:06,711 - 

2023-04-17 05:12:06,711 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 05:12:17,495 - Epoch: [82][   50/  518]    Overall Loss 2.991764    Objective Loss 2.991764                                        LR 0.000250    Time 0.215625    
2023-04-17 05:12:27,553 - Epoch: [82][  100/  518]    Overall Loss 3.006470    Objective Loss 3.006470                                        LR 0.000250    Time 0.208368    
2023-04-17 05:12:37,617 - Epoch: [82][  150/  518]    Overall Loss 2.999382    Objective Loss 2.999382                                        LR 0.000250    Time 0.206001    
2023-04-17 05:12:47,863 - Epoch: [82][  200/  518]    Overall Loss 3.003703    Objective Loss 3.003703                                        LR 0.000250    Time 0.205721    
2023-04-17 05:12:57,900 - Epoch: [82][  250/  518]    Overall Loss 3.000182    Objective Loss 3.000182                                        LR 0.000250    Time 0.204720    
2023-04-17 05:13:07,995 - Epoch: [82][  300/  518]    Overall Loss 3.006115    Objective Loss 3.006115                                        LR 0.000250    Time 0.204242    
2023-04-17 05:13:18,090 - Epoch: [82][  350/  518]    Overall Loss 3.009320    Objective Loss 3.009320                                        LR 0.000250    Time 0.203904    
2023-04-17 05:13:28,169 - Epoch: [82][  400/  518]    Overall Loss 3.004812    Objective Loss 3.004812                                        LR 0.000250    Time 0.203611    
2023-04-17 05:13:38,298 - Epoch: [82][  450/  518]    Overall Loss 2.996761    Objective Loss 2.996761                                        LR 0.000250    Time 0.203493    
2023-04-17 05:13:48,417 - Epoch: [82][  500/  518]    Overall Loss 2.999697    Objective Loss 2.999697                                        LR 0.000250    Time 0.203378    
2023-04-17 05:13:51,970 - Epoch: [82][  518/  518]    Overall Loss 3.000463    Objective Loss 3.000463                                        LR 0.000250    Time 0.203168    
2023-04-17 05:13:52,048 - --- validate (epoch=82)-----------
2023-04-17 05:13:52,048 - 4952 samples (32 per mini-batch)
2023-04-17 05:14:36,989 - Epoch: [82][   50/  155]    Loss 3.182142    mAP 0.508324    
2023-04-17 05:15:20,806 - Epoch: [82][  100/  155]    Loss 3.184731    mAP 0.499057    
2023-04-17 05:16:05,057 - Epoch: [82][  150/  155]    Loss 3.205246    mAP 0.493987    
2023-04-17 05:16:09,300 - Epoch: [82][  155/  155]    Loss 3.209802    mAP 0.493626    
2023-04-17 05:16:09,378 - ==> mAP: 0.49363    Loss: 3.210

2023-04-17 05:16:09,382 - ==> Best [mAP: 0.493626   vloss: 3.209802   Sparsity:0.00   Params: 2177088 on epoch: 82]
2023-04-17 05:16:09,383 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 05:16:09,434 - 

2023-04-17 05:16:09,434 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 05:16:20,265 - Epoch: [83][   50/  518]    Overall Loss 2.989657    Objective Loss 2.989657                                        LR 0.000250    Time 0.216567    
2023-04-17 05:16:30,438 - Epoch: [83][  100/  518]    Overall Loss 3.013232    Objective Loss 3.013232                                        LR 0.000250    Time 0.209992    
2023-04-17 05:16:40,602 - Epoch: [83][  150/  518]    Overall Loss 2.995187    Objective Loss 2.995187                                        LR 0.000250    Time 0.207748    
2023-04-17 05:16:50,775 - Epoch: [83][  200/  518]    Overall Loss 2.991255    Objective Loss 2.991255                                        LR 0.000250    Time 0.206665    
2023-04-17 05:17:00,949 - Epoch: [83][  250/  518]    Overall Loss 2.994904    Objective Loss 2.994904                                        LR 0.000250    Time 0.206025    
2023-04-17 05:17:11,111 - Epoch: [83][  300/  518]    Overall Loss 2.996705    Objective Loss 2.996705                                        LR 0.000250    Time 0.205554    
2023-04-17 05:17:21,270 - Epoch: [83][  350/  518]    Overall Loss 3.003981    Objective Loss 3.003981                                        LR 0.000250    Time 0.205210    
2023-04-17 05:17:31,450 - Epoch: [83][  400/  518]    Overall Loss 3.003287    Objective Loss 3.003287                                        LR 0.000250    Time 0.205007    
2023-04-17 05:17:41,520 - Epoch: [83][  450/  518]    Overall Loss 3.006543    Objective Loss 3.006543                                        LR 0.000250    Time 0.204601    
2023-04-17 05:17:51,680 - Epoch: [83][  500/  518]    Overall Loss 3.007543    Objective Loss 3.007543                                        LR 0.000250    Time 0.204458    
2023-04-17 05:17:55,230 - Epoch: [83][  518/  518]    Overall Loss 3.008241    Objective Loss 3.008241                                        LR 0.000250    Time 0.204205    
2023-04-17 05:17:55,310 - --- validate (epoch=83)-----------
2023-04-17 05:17:55,310 - 4952 samples (32 per mini-batch)
2023-04-17 05:18:40,389 - Epoch: [83][   50/  155]    Loss 3.217313    mAP 0.501561    
2023-04-17 05:19:25,528 - Epoch: [83][  100/  155]    Loss 3.199958    mAP 0.502773    
2023-04-17 05:20:09,291 - Epoch: [83][  150/  155]    Loss 3.218064    mAP 0.496950    
2023-04-17 05:20:13,179 - Epoch: [83][  155/  155]    Loss 3.221867    mAP 0.495341    
2023-04-17 05:20:13,252 - ==> mAP: 0.49534    Loss: 3.222

2023-04-17 05:20:13,255 - ==> Best [mAP: 0.495341   vloss: 3.221867   Sparsity:0.00   Params: 2177088 on epoch: 83]
2023-04-17 05:20:13,255 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 05:20:13,306 - 

2023-04-17 05:20:13,306 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 05:20:24,288 - Epoch: [84][   50/  518]    Overall Loss 2.993758    Objective Loss 2.993758                                        LR 0.000250    Time 0.219576    
2023-04-17 05:20:34,402 - Epoch: [84][  100/  518]    Overall Loss 3.000255    Objective Loss 3.000255                                        LR 0.000250    Time 0.210913    
2023-04-17 05:20:44,480 - Epoch: [84][  150/  518]    Overall Loss 2.994853    Objective Loss 2.994853                                        LR 0.000250    Time 0.207782    
2023-04-17 05:20:54,633 - Epoch: [84][  200/  518]    Overall Loss 2.985980    Objective Loss 2.985980                                        LR 0.000250    Time 0.206597    
2023-04-17 05:21:04,668 - Epoch: [84][  250/  518]    Overall Loss 2.993530    Objective Loss 2.993530                                        LR 0.000250    Time 0.205410    
2023-04-17 05:21:14,787 - Epoch: [84][  300/  518]    Overall Loss 2.988239    Objective Loss 2.988239                                        LR 0.000250    Time 0.204900    
2023-04-17 05:21:24,875 - Epoch: [84][  350/  518]    Overall Loss 2.989819    Objective Loss 2.989819                                        LR 0.000250    Time 0.204448    
2023-04-17 05:21:34,946 - Epoch: [84][  400/  518]    Overall Loss 2.994763    Objective Loss 2.994763                                        LR 0.000250    Time 0.204066    
2023-04-17 05:21:45,125 - Epoch: [84][  450/  518]    Overall Loss 2.996817    Objective Loss 2.996817                                        LR 0.000250    Time 0.204008    
2023-04-17 05:21:55,196 - Epoch: [84][  500/  518]    Overall Loss 2.995164    Objective Loss 2.995164                                        LR 0.000250    Time 0.203746    
2023-04-17 05:21:58,717 - Epoch: [84][  518/  518]    Overall Loss 2.998320    Objective Loss 2.998320                                        LR 0.000250    Time 0.203463    
2023-04-17 05:21:58,799 - --- validate (epoch=84)-----------
2023-04-17 05:21:58,799 - 4952 samples (32 per mini-batch)
2023-04-17 05:22:44,994 - Epoch: [84][   50/  155]    Loss 3.185396    mAP 0.510156    
2023-04-17 05:23:32,077 - Epoch: [84][  100/  155]    Loss 3.198242    mAP 0.494643    
2023-04-17 05:24:18,562 - Epoch: [84][  150/  155]    Loss 3.206286    mAP 0.489676    
2023-04-17 05:24:22,627 - Epoch: [84][  155/  155]    Loss 3.207675    mAP 0.488453    
2023-04-17 05:24:22,707 - ==> mAP: 0.48845    Loss: 3.208

2023-04-17 05:24:22,711 - ==> Best [mAP: 0.495341   vloss: 3.221867   Sparsity:0.00   Params: 2177088 on epoch: 83]
2023-04-17 05:24:22,711 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 05:24:22,747 - 

2023-04-17 05:24:22,747 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 05:24:33,722 - Epoch: [85][   50/  518]    Overall Loss 3.032029    Objective Loss 3.032029                                        LR 0.000250    Time 0.219450    
2023-04-17 05:24:43,868 - Epoch: [85][  100/  518]    Overall Loss 3.028549    Objective Loss 3.028549                                        LR 0.000250    Time 0.211164    
2023-04-17 05:24:53,951 - Epoch: [85][  150/  518]    Overall Loss 3.023869    Objective Loss 3.023869                                        LR 0.000250    Time 0.207987    
2023-04-17 05:25:04,049 - Epoch: [85][  200/  518]    Overall Loss 3.017110    Objective Loss 3.017110                                        LR 0.000250    Time 0.206471    
2023-04-17 05:25:14,139 - Epoch: [85][  250/  518]    Overall Loss 3.011586    Objective Loss 3.011586                                        LR 0.000250    Time 0.205530    
2023-04-17 05:25:24,218 - Epoch: [85][  300/  518]    Overall Loss 3.009659    Objective Loss 3.009659                                        LR 0.000250    Time 0.204868    
2023-04-17 05:25:34,287 - Epoch: [85][  350/  518]    Overall Loss 3.016652    Objective Loss 3.016652                                        LR 0.000250    Time 0.204366    
2023-04-17 05:25:44,336 - Epoch: [85][  400/  518]    Overall Loss 3.013373    Objective Loss 3.013373                                        LR 0.000250    Time 0.203938    
2023-04-17 05:25:54,481 - Epoch: [85][  450/  518]    Overall Loss 3.004240    Objective Loss 3.004240                                        LR 0.000250    Time 0.203820    
2023-04-17 05:26:04,581 - Epoch: [85][  500/  518]    Overall Loss 3.003801    Objective Loss 3.003801                                        LR 0.000250    Time 0.203635    
2023-04-17 05:26:08,097 - Epoch: [85][  518/  518]    Overall Loss 3.005352    Objective Loss 3.005352                                        LR 0.000250    Time 0.203346    
2023-04-17 05:26:08,176 - --- validate (epoch=85)-----------
2023-04-17 05:26:08,176 - 4952 samples (32 per mini-batch)
2023-04-17 05:26:56,878 - Epoch: [85][   50/  155]    Loss 3.176931    mAP 0.510818    
2023-04-17 05:27:46,203 - Epoch: [85][  100/  155]    Loss 3.194305    mAP 0.506660    
2023-04-17 05:28:35,414 - Epoch: [85][  150/  155]    Loss 3.208810    mAP 0.505019    
2023-04-17 05:28:39,727 - Epoch: [85][  155/  155]    Loss 3.211834    mAP 0.505253    
2023-04-17 05:28:39,803 - ==> mAP: 0.50525    Loss: 3.212

2023-04-17 05:28:39,807 - ==> Best [mAP: 0.505253   vloss: 3.211834   Sparsity:0.00   Params: 2177088 on epoch: 85]
2023-04-17 05:28:39,807 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 05:28:39,858 - 

2023-04-17 05:28:39,858 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 05:28:50,691 - Epoch: [86][   50/  518]    Overall Loss 2.985016    Objective Loss 2.985016                                        LR 0.000250    Time 0.216603    
2023-04-17 05:29:00,879 - Epoch: [86][  100/  518]    Overall Loss 3.020394    Objective Loss 3.020394                                        LR 0.000250    Time 0.210169    
2023-04-17 05:29:10,987 - Epoch: [86][  150/  518]    Overall Loss 3.018222    Objective Loss 3.018222                                        LR 0.000250    Time 0.207486    
2023-04-17 05:29:21,067 - Epoch: [86][  200/  518]    Overall Loss 3.012759    Objective Loss 3.012759                                        LR 0.000250    Time 0.206007    
2023-04-17 05:29:31,096 - Epoch: [86][  250/  518]    Overall Loss 2.998790    Objective Loss 2.998790                                        LR 0.000250    Time 0.204914    
2023-04-17 05:29:41,228 - Epoch: [86][  300/  518]    Overall Loss 2.995190    Objective Loss 2.995190                                        LR 0.000250    Time 0.204532    
2023-04-17 05:29:51,325 - Epoch: [86][  350/  518]    Overall Loss 2.999582    Objective Loss 2.999582                                        LR 0.000250    Time 0.204157    
2023-04-17 05:30:01,373 - Epoch: [86][  400/  518]    Overall Loss 2.992954    Objective Loss 2.992954                                        LR 0.000250    Time 0.203755    
2023-04-17 05:30:11,489 - Epoch: [86][  450/  518]    Overall Loss 2.990042    Objective Loss 2.990042                                        LR 0.000250    Time 0.203591    
2023-04-17 05:30:21,658 - Epoch: [86][  500/  518]    Overall Loss 2.989864    Objective Loss 2.989864                                        LR 0.000250    Time 0.203566    
2023-04-17 05:30:25,159 - Epoch: [86][  518/  518]    Overall Loss 2.992552    Objective Loss 2.992552                                        LR 0.000250    Time 0.203251    
2023-04-17 05:30:25,240 - --- validate (epoch=86)-----------
2023-04-17 05:30:25,240 - 4952 samples (32 per mini-batch)
2023-04-17 05:31:15,797 - Epoch: [86][   50/  155]    Loss 3.246538    mAP 0.469207    
2023-04-17 05:32:06,497 - Epoch: [86][  100/  155]    Loss 3.224191    mAP 0.484992    
2023-04-17 05:32:55,928 - Epoch: [86][  150/  155]    Loss 3.205499    mAP 0.490061    
2023-04-17 05:33:01,199 - Epoch: [86][  155/  155]    Loss 3.205491    mAP 0.487981    
2023-04-17 05:33:01,277 - ==> mAP: 0.48798    Loss: 3.205

2023-04-17 05:33:01,281 - ==> Best [mAP: 0.505253   vloss: 3.211834   Sparsity:0.00   Params: 2177088 on epoch: 85]
2023-04-17 05:33:01,281 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 05:33:01,316 - 

2023-04-17 05:33:01,316 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 05:33:12,227 - Epoch: [87][   50/  518]    Overall Loss 3.017172    Objective Loss 3.017172                                        LR 0.000250    Time 0.218172    
2023-04-17 05:33:22,322 - Epoch: [87][  100/  518]    Overall Loss 2.995917    Objective Loss 2.995917                                        LR 0.000250    Time 0.210020    
2023-04-17 05:33:32,369 - Epoch: [87][  150/  518]    Overall Loss 2.991772    Objective Loss 2.991772                                        LR 0.000250    Time 0.206978    
2023-04-17 05:33:42,470 - Epoch: [87][  200/  518]    Overall Loss 2.989794    Objective Loss 2.989794                                        LR 0.000250    Time 0.205733    
2023-04-17 05:33:52,600 - Epoch: [87][  250/  518]    Overall Loss 2.995222    Objective Loss 2.995222                                        LR 0.000250    Time 0.205100    
2023-04-17 05:34:02,712 - Epoch: [87][  300/  518]    Overall Loss 2.988444    Objective Loss 2.988444                                        LR 0.000250    Time 0.204616    
2023-04-17 05:34:12,830 - Epoch: [87][  350/  518]    Overall Loss 2.987049    Objective Loss 2.987049                                        LR 0.000250    Time 0.204290    
2023-04-17 05:34:22,951 - Epoch: [87][  400/  518]    Overall Loss 2.989752    Objective Loss 2.989752                                        LR 0.000250    Time 0.204054    
2023-04-17 05:34:33,055 - Epoch: [87][  450/  518]    Overall Loss 2.986387    Objective Loss 2.986387                                        LR 0.000250    Time 0.203831    
2023-04-17 05:34:43,037 - Epoch: [87][  500/  518]    Overall Loss 2.979840    Objective Loss 2.979840                                        LR 0.000250    Time 0.203408    
2023-04-17 05:34:46,572 - Epoch: [87][  518/  518]    Overall Loss 2.977988    Objective Loss 2.977988                                        LR 0.000250    Time 0.203163    
2023-04-17 05:34:46,653 - --- validate (epoch=87)-----------
2023-04-17 05:34:46,653 - 4952 samples (32 per mini-batch)
2023-04-17 05:35:29,703 - Epoch: [87][   50/  155]    Loss 3.148583    mAP 0.511298    
2023-04-17 05:36:14,894 - Epoch: [87][  100/  155]    Loss 3.183021    mAP 0.499366    
2023-04-17 05:36:58,194 - Epoch: [87][  150/  155]    Loss 3.184105    mAP 0.498664    
2023-04-17 05:37:02,189 - Epoch: [87][  155/  155]    Loss 3.187220    mAP 0.497034    
2023-04-17 05:37:02,280 - ==> mAP: 0.49703    Loss: 3.187

2023-04-17 05:37:02,284 - ==> Best [mAP: 0.505253   vloss: 3.211834   Sparsity:0.00   Params: 2177088 on epoch: 85]
2023-04-17 05:37:02,284 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 05:37:02,320 - 

2023-04-17 05:37:02,320 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 05:37:13,174 - Epoch: [88][   50/  518]    Overall Loss 2.960863    Objective Loss 2.960863                                        LR 0.000250    Time 0.217015    
2023-04-17 05:37:23,320 - Epoch: [88][  100/  518]    Overall Loss 2.979912    Objective Loss 2.979912                                        LR 0.000250    Time 0.209956    
2023-04-17 05:37:33,415 - Epoch: [88][  150/  518]    Overall Loss 2.991642    Objective Loss 2.991642                                        LR 0.000250    Time 0.207261    
2023-04-17 05:37:43,520 - Epoch: [88][  200/  518]    Overall Loss 2.987260    Objective Loss 2.987260                                        LR 0.000250    Time 0.205963    
2023-04-17 05:37:53,668 - Epoch: [88][  250/  518]    Overall Loss 2.980613    Objective Loss 2.980613                                        LR 0.000250    Time 0.205356    
2023-04-17 05:38:03,775 - Epoch: [88][  300/  518]    Overall Loss 2.984933    Objective Loss 2.984933                                        LR 0.000250    Time 0.204814    
2023-04-17 05:38:13,907 - Epoch: [88][  350/  518]    Overall Loss 2.976380    Objective Loss 2.976380                                        LR 0.000250    Time 0.204500    
2023-04-17 05:38:23,986 - Epoch: [88][  400/  518]    Overall Loss 2.979077    Objective Loss 2.979077                                        LR 0.000250    Time 0.204131    
2023-04-17 05:38:34,048 - Epoch: [88][  450/  518]    Overall Loss 2.980283    Objective Loss 2.980283                                        LR 0.000250    Time 0.203805    
2023-04-17 05:38:44,127 - Epoch: [88][  500/  518]    Overall Loss 2.983509    Objective Loss 2.983509                                        LR 0.000250    Time 0.203579    
2023-04-17 05:38:47,602 - Epoch: [88][  518/  518]    Overall Loss 2.981896    Objective Loss 2.981896                                        LR 0.000250    Time 0.203214    
2023-04-17 05:38:47,683 - --- validate (epoch=88)-----------
2023-04-17 05:38:47,683 - 4952 samples (32 per mini-batch)
2023-04-17 05:39:37,419 - Epoch: [88][   50/  155]    Loss 3.236821    mAP 0.491854    
2023-04-17 05:40:28,747 - Epoch: [88][  100/  155]    Loss 3.226725    mAP 0.490820    
2023-04-17 05:41:19,731 - Epoch: [88][  150/  155]    Loss 3.227514    mAP 0.489662    
2023-04-17 05:41:24,796 - Epoch: [88][  155/  155]    Loss 3.228682    mAP 0.490952    
2023-04-17 05:41:24,876 - ==> mAP: 0.49095    Loss: 3.229

2023-04-17 05:41:24,880 - ==> Best [mAP: 0.505253   vloss: 3.211834   Sparsity:0.00   Params: 2177088 on epoch: 85]
2023-04-17 05:41:24,880 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 05:41:24,916 - 

2023-04-17 05:41:24,916 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 05:41:35,804 - Epoch: [89][   50/  518]    Overall Loss 2.956229    Objective Loss 2.956229                                        LR 0.000250    Time 0.217701    
2023-04-17 05:41:45,838 - Epoch: [89][  100/  518]    Overall Loss 2.968334    Objective Loss 2.968334                                        LR 0.000250    Time 0.209172    
2023-04-17 05:41:55,945 - Epoch: [89][  150/  518]    Overall Loss 2.974319    Objective Loss 2.974319                                        LR 0.000250    Time 0.206821    
2023-04-17 05:42:05,973 - Epoch: [89][  200/  518]    Overall Loss 2.969594    Objective Loss 2.969594                                        LR 0.000250    Time 0.205249    
2023-04-17 05:42:16,107 - Epoch: [89][  250/  518]    Overall Loss 2.979063    Objective Loss 2.979063                                        LR 0.000250    Time 0.204729    
2023-04-17 05:42:26,098 - Epoch: [89][  300/  518]    Overall Loss 2.978632    Objective Loss 2.978632                                        LR 0.000250    Time 0.203904    
2023-04-17 05:42:36,205 - Epoch: [89][  350/  518]    Overall Loss 2.973463    Objective Loss 2.973463                                        LR 0.000250    Time 0.203648    
2023-04-17 05:42:46,283 - Epoch: [89][  400/  518]    Overall Loss 2.979458    Objective Loss 2.979458                                        LR 0.000250    Time 0.203384    
2023-04-17 05:42:56,345 - Epoch: [89][  450/  518]    Overall Loss 2.980207    Objective Loss 2.980207                                        LR 0.000250    Time 0.203143    
2023-04-17 05:43:06,444 - Epoch: [89][  500/  518]    Overall Loss 2.979669    Objective Loss 2.979669                                        LR 0.000250    Time 0.203022    
2023-04-17 05:43:09,940 - Epoch: [89][  518/  518]    Overall Loss 2.977406    Objective Loss 2.977406                                        LR 0.000250    Time 0.202716    
2023-04-17 05:43:10,022 - --- validate (epoch=89)-----------
2023-04-17 05:43:10,022 - 4952 samples (32 per mini-batch)
2023-04-17 05:43:57,130 - Epoch: [89][   50/  155]    Loss 3.194818    mAP 0.498618    
2023-04-17 05:44:41,861 - Epoch: [89][  100/  155]    Loss 3.189652    mAP 0.497020    
2023-04-17 05:45:27,008 - Epoch: [89][  150/  155]    Loss 3.200607    mAP 0.491632    
2023-04-17 05:45:31,372 - Epoch: [89][  155/  155]    Loss 3.200489    mAP 0.490380    
2023-04-17 05:45:31,464 - ==> mAP: 0.49038    Loss: 3.200

2023-04-17 05:45:31,468 - ==> Best [mAP: 0.505253   vloss: 3.211834   Sparsity:0.00   Params: 2177088 on epoch: 85]
2023-04-17 05:45:31,469 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 05:45:31,504 - 

2023-04-17 05:45:31,504 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 05:45:42,366 - Epoch: [90][   50/  518]    Overall Loss 2.984711    Objective Loss 2.984711                                        LR 0.000250    Time 0.217171    
2023-04-17 05:45:52,444 - Epoch: [90][  100/  518]    Overall Loss 2.983005    Objective Loss 2.983005                                        LR 0.000250    Time 0.209351    
2023-04-17 05:46:02,501 - Epoch: [90][  150/  518]    Overall Loss 2.985652    Objective Loss 2.985652                                        LR 0.000250    Time 0.206606    
2023-04-17 05:46:12,540 - Epoch: [90][  200/  518]    Overall Loss 2.979444    Objective Loss 2.979444                                        LR 0.000250    Time 0.205142    
2023-04-17 05:46:22,623 - Epoch: [90][  250/  518]    Overall Loss 2.980108    Objective Loss 2.980108                                        LR 0.000250    Time 0.204438    
2023-04-17 05:46:32,834 - Epoch: [90][  300/  518]    Overall Loss 2.986327    Objective Loss 2.986327                                        LR 0.000250    Time 0.204396    
2023-04-17 05:46:42,917 - Epoch: [90][  350/  518]    Overall Loss 2.983276    Objective Loss 2.983276                                        LR 0.000250    Time 0.204001    
2023-04-17 05:46:53,001 - Epoch: [90][  400/  518]    Overall Loss 2.984378    Objective Loss 2.984378                                        LR 0.000250    Time 0.203706    
2023-04-17 05:47:03,127 - Epoch: [90][  450/  518]    Overall Loss 2.985874    Objective Loss 2.985874                                        LR 0.000250    Time 0.203571    
2023-04-17 05:47:13,318 - Epoch: [90][  500/  518]    Overall Loss 2.985982    Objective Loss 2.985982                                        LR 0.000250    Time 0.203594    
2023-04-17 05:47:16,854 - Epoch: [90][  518/  518]    Overall Loss 2.984272    Objective Loss 2.984272                                        LR 0.000250    Time 0.203344    
2023-04-17 05:47:16,933 - --- validate (epoch=90)-----------
2023-04-17 05:47:16,933 - 4952 samples (32 per mini-batch)
2023-04-17 05:48:00,250 - Epoch: [90][   50/  155]    Loss 3.178655    mAP 0.482086    
2023-04-17 05:48:44,353 - Epoch: [90][  100/  155]    Loss 3.195505    mAP 0.482679    
2023-04-17 05:49:29,369 - Epoch: [90][  150/  155]    Loss 3.196053    mAP 0.482883    
2023-04-17 05:49:33,585 - Epoch: [90][  155/  155]    Loss 3.204088    mAP 0.482611    
2023-04-17 05:49:33,660 - ==> mAP: 0.48261    Loss: 3.204

2023-04-17 05:49:33,664 - ==> Best [mAP: 0.505253   vloss: 3.211834   Sparsity:0.00   Params: 2177088 on epoch: 85]
2023-04-17 05:49:33,665 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 05:49:33,702 - 

2023-04-17 05:49:33,702 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 05:49:44,578 - Epoch: [91][   50/  518]    Overall Loss 2.951729    Objective Loss 2.951729                                        LR 0.000250    Time 0.217467    
2023-04-17 05:49:54,595 - Epoch: [91][  100/  518]    Overall Loss 2.948501    Objective Loss 2.948501                                        LR 0.000250    Time 0.208892    
2023-04-17 05:50:04,745 - Epoch: [91][  150/  518]    Overall Loss 2.971702    Objective Loss 2.971702                                        LR 0.000250    Time 0.206919    
2023-04-17 05:50:14,798 - Epoch: [91][  200/  518]    Overall Loss 2.974310    Objective Loss 2.974310                                        LR 0.000250    Time 0.205446    
2023-04-17 05:50:24,800 - Epoch: [91][  250/  518]    Overall Loss 2.988812    Objective Loss 2.988812                                        LR 0.000250    Time 0.204357    
2023-04-17 05:50:34,932 - Epoch: [91][  300/  518]    Overall Loss 2.978262    Objective Loss 2.978262                                        LR 0.000250    Time 0.204066    
2023-04-17 05:50:45,061 - Epoch: [91][  350/  518]    Overall Loss 2.983354    Objective Loss 2.983354                                        LR 0.000250    Time 0.203850    
2023-04-17 05:50:55,193 - Epoch: [91][  400/  518]    Overall Loss 2.980408    Objective Loss 2.980408                                        LR 0.000250    Time 0.203694    
2023-04-17 05:51:05,411 - Epoch: [91][  450/  518]    Overall Loss 2.982268    Objective Loss 2.982268                                        LR 0.000250    Time 0.203765    
2023-04-17 05:51:15,532 - Epoch: [91][  500/  518]    Overall Loss 2.981786    Objective Loss 2.981786                                        LR 0.000250    Time 0.203627    
2023-04-17 05:51:19,075 - Epoch: [91][  518/  518]    Overall Loss 2.982270    Objective Loss 2.982270                                        LR 0.000250    Time 0.203391    
2023-04-17 05:51:19,156 - --- validate (epoch=91)-----------
2023-04-17 05:51:19,156 - 4952 samples (32 per mini-batch)
2023-04-17 05:52:02,943 - Epoch: [91][   50/  155]    Loss 3.182506    mAP 0.490370    
2023-04-17 05:52:46,263 - Epoch: [91][  100/  155]    Loss 3.173292    mAP 0.492760    
2023-04-17 05:53:30,149 - Epoch: [91][  150/  155]    Loss 3.187819    mAP 0.493883    
2023-04-17 05:53:34,082 - Epoch: [91][  155/  155]    Loss 3.189981    mAP 0.494405    
2023-04-17 05:53:34,160 - ==> mAP: 0.49441    Loss: 3.190

2023-04-17 05:53:34,163 - ==> Best [mAP: 0.505253   vloss: 3.211834   Sparsity:0.00   Params: 2177088 on epoch: 85]
2023-04-17 05:53:34,163 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 05:53:34,199 - 

2023-04-17 05:53:34,199 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 05:53:45,091 - Epoch: [92][   50/  518]    Overall Loss 3.010831    Objective Loss 3.010831                                        LR 0.000250    Time 0.217772    
2023-04-17 05:53:55,331 - Epoch: [92][  100/  518]    Overall Loss 2.951548    Objective Loss 2.951548                                        LR 0.000250    Time 0.211272    
2023-04-17 05:54:05,400 - Epoch: [92][  150/  518]    Overall Loss 2.957410    Objective Loss 2.957410                                        LR 0.000250    Time 0.207960    
2023-04-17 05:54:15,460 - Epoch: [92][  200/  518]    Overall Loss 2.957222    Objective Loss 2.957222                                        LR 0.000250    Time 0.206264    
2023-04-17 05:54:25,605 - Epoch: [92][  250/  518]    Overall Loss 2.964847    Objective Loss 2.964847                                        LR 0.000250    Time 0.205584    
2023-04-17 05:54:35,670 - Epoch: [92][  300/  518]    Overall Loss 2.971767    Objective Loss 2.971767                                        LR 0.000250    Time 0.204868    
2023-04-17 05:54:45,767 - Epoch: [92][  350/  518]    Overall Loss 2.979108    Objective Loss 2.979108                                        LR 0.000250    Time 0.204445    
2023-04-17 05:54:55,781 - Epoch: [92][  400/  518]    Overall Loss 2.976258    Objective Loss 2.976258                                        LR 0.000250    Time 0.203920    
2023-04-17 05:55:05,858 - Epoch: [92][  450/  518]    Overall Loss 2.979908    Objective Loss 2.979908                                        LR 0.000250    Time 0.203652    
2023-04-17 05:55:15,967 - Epoch: [92][  500/  518]    Overall Loss 2.978193    Objective Loss 2.978193                                        LR 0.000250    Time 0.203501    
2023-04-17 05:55:19,543 - Epoch: [92][  518/  518]    Overall Loss 2.978095    Objective Loss 2.978095                                        LR 0.000250    Time 0.203333    
2023-04-17 05:55:19,624 - --- validate (epoch=92)-----------
2023-04-17 05:55:19,624 - 4952 samples (32 per mini-batch)
2023-04-17 05:56:04,212 - Epoch: [92][   50/  155]    Loss 3.179896    mAP 0.499304    
2023-04-17 05:56:48,644 - Epoch: [92][  100/  155]    Loss 3.190435    mAP 0.498729    
2023-04-17 05:57:32,509 - Epoch: [92][  150/  155]    Loss 3.177771    mAP 0.498987    
2023-04-17 05:57:37,100 - Epoch: [92][  155/  155]    Loss 3.178934    mAP 0.497300    
2023-04-17 05:57:37,180 - ==> mAP: 0.49730    Loss: 3.179

2023-04-17 05:57:37,183 - ==> Best [mAP: 0.505253   vloss: 3.211834   Sparsity:0.00   Params: 2177088 on epoch: 85]
2023-04-17 05:57:37,183 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 05:57:37,245 - 

2023-04-17 05:57:37,245 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 05:57:48,050 - Epoch: [93][   50/  518]    Overall Loss 2.993074    Objective Loss 2.993074                                        LR 0.000250    Time 0.216018    
2023-04-17 05:57:58,159 - Epoch: [93][  100/  518]    Overall Loss 2.980470    Objective Loss 2.980470                                        LR 0.000250    Time 0.209087    
2023-04-17 05:58:08,257 - Epoch: [93][  150/  518]    Overall Loss 2.988407    Objective Loss 2.988407                                        LR 0.000250    Time 0.206702    
2023-04-17 05:58:18,331 - Epoch: [93][  200/  518]    Overall Loss 2.982041    Objective Loss 2.982041                                        LR 0.000250    Time 0.205388    
2023-04-17 05:58:28,408 - Epoch: [93][  250/  518]    Overall Loss 2.977454    Objective Loss 2.977454                                        LR 0.000250    Time 0.204610    
2023-04-17 05:58:38,496 - Epoch: [93][  300/  518]    Overall Loss 2.970118    Objective Loss 2.970118                                        LR 0.000250    Time 0.204131    
2023-04-17 05:58:48,538 - Epoch: [93][  350/  518]    Overall Loss 2.968030    Objective Loss 2.968030                                        LR 0.000250    Time 0.203656    
2023-04-17 05:58:58,694 - Epoch: [93][  400/  518]    Overall Loss 2.977375    Objective Loss 2.977375                                        LR 0.000250    Time 0.203586    
2023-04-17 05:59:08,770 - Epoch: [93][  450/  518]    Overall Loss 2.974794    Objective Loss 2.974794                                        LR 0.000250    Time 0.203354    
2023-04-17 05:59:18,800 - Epoch: [93][  500/  518]    Overall Loss 2.972140    Objective Loss 2.972140                                        LR 0.000250    Time 0.203075    
2023-04-17 05:59:22,321 - Epoch: [93][  518/  518]    Overall Loss 2.972537    Objective Loss 2.972537                                        LR 0.000250    Time 0.202815    
2023-04-17 05:59:22,404 - --- validate (epoch=93)-----------
2023-04-17 05:59:22,404 - 4952 samples (32 per mini-batch)
2023-04-17 06:00:11,880 - Epoch: [93][   50/  155]    Loss 3.175765    mAP 0.493495    
2023-04-17 06:00:59,265 - Epoch: [93][  100/  155]    Loss 3.181805    mAP 0.493735    
2023-04-17 06:01:48,811 - Epoch: [93][  150/  155]    Loss 3.193017    mAP 0.491534    
2023-04-17 06:01:53,253 - Epoch: [93][  155/  155]    Loss 3.192104    mAP 0.490844    
2023-04-17 06:01:53,330 - ==> mAP: 0.49084    Loss: 3.192

2023-04-17 06:01:53,334 - ==> Best [mAP: 0.505253   vloss: 3.211834   Sparsity:0.00   Params: 2177088 on epoch: 85]
2023-04-17 06:01:53,334 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 06:01:53,371 - 

2023-04-17 06:01:53,371 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 06:02:04,181 - Epoch: [94][   50/  518]    Overall Loss 3.018525    Objective Loss 3.018525                                        LR 0.000250    Time 0.216154    
2023-04-17 06:02:14,230 - Epoch: [94][  100/  518]    Overall Loss 2.977305    Objective Loss 2.977305                                        LR 0.000250    Time 0.208543    
2023-04-17 06:02:24,304 - Epoch: [94][  150/  518]    Overall Loss 2.984244    Objective Loss 2.984244                                        LR 0.000250    Time 0.206180    
2023-04-17 06:02:34,349 - Epoch: [94][  200/  518]    Overall Loss 2.969234    Objective Loss 2.969234                                        LR 0.000250    Time 0.204854    
2023-04-17 06:02:44,489 - Epoch: [94][  250/  518]    Overall Loss 2.978766    Objective Loss 2.978766                                        LR 0.000250    Time 0.204438    
2023-04-17 06:02:54,568 - Epoch: [94][  300/  518]    Overall Loss 2.976311    Objective Loss 2.976311                                        LR 0.000250    Time 0.203954    
2023-04-17 06:03:04,658 - Epoch: [94][  350/  518]    Overall Loss 2.979614    Objective Loss 2.979614                                        LR 0.000250    Time 0.203642    
2023-04-17 06:03:14,707 - Epoch: [94][  400/  518]    Overall Loss 2.974977    Objective Loss 2.974977                                        LR 0.000250    Time 0.203306    
2023-04-17 06:03:24,787 - Epoch: [94][  450/  518]    Overall Loss 2.974768    Objective Loss 2.974768                                        LR 0.000250    Time 0.203113    
2023-04-17 06:03:34,878 - Epoch: [94][  500/  518]    Overall Loss 2.973619    Objective Loss 2.973619                                        LR 0.000250    Time 0.202980    
2023-04-17 06:03:38,364 - Epoch: [94][  518/  518]    Overall Loss 2.973935    Objective Loss 2.973935                                        LR 0.000250    Time 0.202656    
2023-04-17 06:03:38,444 - --- validate (epoch=94)-----------
2023-04-17 06:03:38,444 - 4952 samples (32 per mini-batch)
2023-04-17 06:04:25,061 - Epoch: [94][   50/  155]    Loss 3.158708    mAP 0.479691    
2023-04-17 06:05:12,649 - Epoch: [94][  100/  155]    Loss 3.191950    mAP 0.491388    
2023-04-17 06:06:01,864 - Epoch: [94][  150/  155]    Loss 3.178655    mAP 0.496092    
2023-04-17 06:06:06,261 - Epoch: [94][  155/  155]    Loss 3.182213    mAP 0.493983    
2023-04-17 06:06:06,340 - ==> mAP: 0.49398    Loss: 3.182

2023-04-17 06:06:06,343 - ==> Best [mAP: 0.505253   vloss: 3.211834   Sparsity:0.00   Params: 2177088 on epoch: 85]
2023-04-17 06:06:06,343 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 06:06:06,381 - 

2023-04-17 06:06:06,381 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 06:06:17,275 - Epoch: [95][   50/  518]    Overall Loss 2.984704    Objective Loss 2.984704                                        LR 0.000250    Time 0.217831    
2023-04-17 06:06:27,380 - Epoch: [95][  100/  518]    Overall Loss 2.957589    Objective Loss 2.957589                                        LR 0.000250    Time 0.209946    
2023-04-17 06:06:37,516 - Epoch: [95][  150/  518]    Overall Loss 2.961230    Objective Loss 2.961230                                        LR 0.000250    Time 0.207528    
2023-04-17 06:06:47,673 - Epoch: [95][  200/  518]    Overall Loss 2.953653    Objective Loss 2.953653                                        LR 0.000250    Time 0.206421    
2023-04-17 06:06:57,732 - Epoch: [95][  250/  518]    Overall Loss 2.962403    Objective Loss 2.962403                                        LR 0.000250    Time 0.205366    
2023-04-17 06:07:07,850 - Epoch: [95][  300/  518]    Overall Loss 2.963214    Objective Loss 2.963214                                        LR 0.000250    Time 0.204861    
2023-04-17 06:07:17,881 - Epoch: [95][  350/  518]    Overall Loss 2.964689    Objective Loss 2.964689                                        LR 0.000250    Time 0.204252    
2023-04-17 06:07:27,933 - Epoch: [95][  400/  518]    Overall Loss 2.968967    Objective Loss 2.968967                                        LR 0.000250    Time 0.203845    
2023-04-17 06:07:38,013 - Epoch: [95][  450/  518]    Overall Loss 2.971474    Objective Loss 2.971474                                        LR 0.000250    Time 0.203594    
2023-04-17 06:07:48,140 - Epoch: [95][  500/  518]    Overall Loss 2.968312    Objective Loss 2.968312                                        LR 0.000250    Time 0.203485    
2023-04-17 06:07:51,648 - Epoch: [95][  518/  518]    Overall Loss 2.969150    Objective Loss 2.969150                                        LR 0.000250    Time 0.203185    
2023-04-17 06:07:51,726 - --- validate (epoch=95)-----------
2023-04-17 06:07:51,727 - 4952 samples (32 per mini-batch)
2023-04-17 06:08:42,898 - Epoch: [95][   50/  155]    Loss 3.172814    mAP 0.491181    
2023-04-17 06:09:31,273 - Epoch: [95][  100/  155]    Loss 3.177067    mAP 0.499026    
2023-04-17 06:10:20,126 - Epoch: [95][  150/  155]    Loss 3.186301    mAP 0.499606    
2023-04-17 06:10:24,895 - Epoch: [95][  155/  155]    Loss 3.185009    mAP 0.498848    
2023-04-17 06:10:24,972 - ==> mAP: 0.49885    Loss: 3.185

2023-04-17 06:10:24,976 - ==> Best [mAP: 0.505253   vloss: 3.211834   Sparsity:0.00   Params: 2177088 on epoch: 85]
2023-04-17 06:10:24,976 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 06:10:25,012 - 

2023-04-17 06:10:25,012 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 06:10:35,955 - Epoch: [96][   50/  518]    Overall Loss 2.982983    Objective Loss 2.982983                                        LR 0.000250    Time 0.218796    
2023-04-17 06:10:46,004 - Epoch: [96][  100/  518]    Overall Loss 2.957751    Objective Loss 2.957751                                        LR 0.000250    Time 0.209881    
2023-04-17 06:10:56,009 - Epoch: [96][  150/  518]    Overall Loss 2.960423    Objective Loss 2.960423                                        LR 0.000250    Time 0.206605    
2023-04-17 06:11:06,062 - Epoch: [96][  200/  518]    Overall Loss 2.962844    Objective Loss 2.962844                                        LR 0.000250    Time 0.205213    
2023-04-17 06:11:16,203 - Epoch: [96][  250/  518]    Overall Loss 2.965617    Objective Loss 2.965617                                        LR 0.000250    Time 0.204728    
2023-04-17 06:11:26,280 - Epoch: [96][  300/  518]    Overall Loss 2.962547    Objective Loss 2.962547                                        LR 0.000250    Time 0.204193    
2023-04-17 06:11:36,404 - Epoch: [96][  350/  518]    Overall Loss 2.968813    Objective Loss 2.968813                                        LR 0.000250    Time 0.203943    
2023-04-17 06:11:46,547 - Epoch: [96][  400/  518]    Overall Loss 2.967370    Objective Loss 2.967370                                        LR 0.000250    Time 0.203803    
2023-04-17 06:11:56,610 - Epoch: [96][  450/  518]    Overall Loss 2.967608    Objective Loss 2.967608                                        LR 0.000250    Time 0.203517    
2023-04-17 06:12:06,792 - Epoch: [96][  500/  518]    Overall Loss 2.965143    Objective Loss 2.965143                                        LR 0.000250    Time 0.203528    
2023-04-17 06:12:10,300 - Epoch: [96][  518/  518]    Overall Loss 2.964794    Objective Loss 2.964794                                        LR 0.000250    Time 0.203226    
2023-04-17 06:12:10,380 - --- validate (epoch=96)-----------
2023-04-17 06:12:10,381 - 4952 samples (32 per mini-batch)
2023-04-17 06:12:54,124 - Epoch: [96][   50/  155]    Loss 3.205465    mAP 0.487809    
2023-04-17 06:13:37,639 - Epoch: [96][  100/  155]    Loss 3.186595    mAP 0.500768    
2023-04-17 06:14:20,699 - Epoch: [96][  150/  155]    Loss 3.190430    mAP 0.498687    
2023-04-17 06:14:24,597 - Epoch: [96][  155/  155]    Loss 3.189364    mAP 0.498473    
2023-04-17 06:14:24,677 - ==> mAP: 0.49847    Loss: 3.189

2023-04-17 06:14:24,681 - ==> Best [mAP: 0.505253   vloss: 3.211834   Sparsity:0.00   Params: 2177088 on epoch: 85]
2023-04-17 06:14:24,681 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 06:14:24,718 - 

2023-04-17 06:14:24,718 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 06:14:35,571 - Epoch: [97][   50/  518]    Overall Loss 2.975257    Objective Loss 2.975257                                        LR 0.000250    Time 0.217007    
2023-04-17 06:14:45,744 - Epoch: [97][  100/  518]    Overall Loss 2.961977    Objective Loss 2.961977                                        LR 0.000250    Time 0.210210    
2023-04-17 06:14:55,816 - Epoch: [97][  150/  518]    Overall Loss 2.970606    Objective Loss 2.970606                                        LR 0.000250    Time 0.207277    
2023-04-17 06:15:05,910 - Epoch: [97][  200/  518]    Overall Loss 2.969714    Objective Loss 2.969714                                        LR 0.000250    Time 0.205922    
2023-04-17 06:15:16,023 - Epoch: [97][  250/  518]    Overall Loss 2.965997    Objective Loss 2.965997                                        LR 0.000250    Time 0.205185    
2023-04-17 06:15:26,122 - Epoch: [97][  300/  518]    Overall Loss 2.965600    Objective Loss 2.965600                                        LR 0.000250    Time 0.204644    
2023-04-17 06:15:36,243 - Epoch: [97][  350/  518]    Overall Loss 2.965495    Objective Loss 2.965495                                        LR 0.000250    Time 0.204321    
2023-04-17 06:15:46,397 - Epoch: [97][  400/  518]    Overall Loss 2.961508    Objective Loss 2.961508                                        LR 0.000250    Time 0.204162    
2023-04-17 06:15:56,564 - Epoch: [97][  450/  518]    Overall Loss 2.961421    Objective Loss 2.961421                                        LR 0.000250    Time 0.204068    
2023-04-17 06:16:06,625 - Epoch: [97][  500/  518]    Overall Loss 2.960430    Objective Loss 2.960430                                        LR 0.000250    Time 0.203780    
2023-04-17 06:16:10,129 - Epoch: [97][  518/  518]    Overall Loss 2.962462    Objective Loss 2.962462                                        LR 0.000250    Time 0.203463    
2023-04-17 06:16:10,210 - --- validate (epoch=97)-----------
2023-04-17 06:16:10,210 - 4952 samples (32 per mini-batch)
2023-04-17 06:16:55,365 - Epoch: [97][   50/  155]    Loss 3.157220    mAP 0.491804    
2023-04-17 06:17:39,763 - Epoch: [97][  100/  155]    Loss 3.165460    mAP 0.496089    
2023-04-17 06:18:21,580 - Epoch: [97][  150/  155]    Loss 3.157114    mAP 0.495712    
2023-04-17 06:18:25,537 - Epoch: [97][  155/  155]    Loss 3.156157    mAP 0.494507    
2023-04-17 06:18:25,616 - ==> mAP: 0.49451    Loss: 3.156

2023-04-17 06:18:25,619 - ==> Best [mAP: 0.505253   vloss: 3.211834   Sparsity:0.00   Params: 2177088 on epoch: 85]
2023-04-17 06:18:25,619 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 06:18:25,655 - 

2023-04-17 06:18:25,655 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 06:18:36,568 - Epoch: [98][   50/  518]    Overall Loss 2.972130    Objective Loss 2.972130                                        LR 0.000250    Time 0.218207    
2023-04-17 06:18:46,611 - Epoch: [98][  100/  518]    Overall Loss 2.979301    Objective Loss 2.979301                                        LR 0.000250    Time 0.209510    
2023-04-17 06:18:56,707 - Epoch: [98][  150/  518]    Overall Loss 2.975957    Objective Loss 2.975957                                        LR 0.000250    Time 0.206975    
2023-04-17 06:19:06,769 - Epoch: [98][  200/  518]    Overall Loss 2.980465    Objective Loss 2.980465                                        LR 0.000250    Time 0.205530    
2023-04-17 06:19:16,893 - Epoch: [98][  250/  518]    Overall Loss 2.967115    Objective Loss 2.967115                                        LR 0.000250    Time 0.204917    
2023-04-17 06:19:27,029 - Epoch: [98][  300/  518]    Overall Loss 2.965153    Objective Loss 2.965153                                        LR 0.000250    Time 0.204545    
2023-04-17 06:19:37,223 - Epoch: [98][  350/  518]    Overall Loss 2.959541    Objective Loss 2.959541                                        LR 0.000250    Time 0.204444    
2023-04-17 06:19:47,396 - Epoch: [98][  400/  518]    Overall Loss 2.952329    Objective Loss 2.952329                                        LR 0.000250    Time 0.204317    
2023-04-17 06:19:57,462 - Epoch: [98][  450/  518]    Overall Loss 2.951642    Objective Loss 2.951642                                        LR 0.000250    Time 0.203982    
2023-04-17 06:20:07,589 - Epoch: [98][  500/  518]    Overall Loss 2.955550    Objective Loss 2.955550                                        LR 0.000250    Time 0.203835    
2023-04-17 06:20:11,087 - Epoch: [98][  518/  518]    Overall Loss 2.956723    Objective Loss 2.956723                                        LR 0.000250    Time 0.203503    
2023-04-17 06:20:11,166 - --- validate (epoch=98)-----------
2023-04-17 06:20:11,167 - 4952 samples (32 per mini-batch)
2023-04-17 06:20:54,303 - Epoch: [98][   50/  155]    Loss 3.197756    mAP 0.478650    
2023-04-17 06:21:37,229 - Epoch: [98][  100/  155]    Loss 3.175663    mAP 0.485620    
2023-04-17 06:22:20,646 - Epoch: [98][  150/  155]    Loss 3.183926    mAP 0.480464    
2023-04-17 06:22:24,844 - Epoch: [98][  155/  155]    Loss 3.186279    mAP 0.480775    
2023-04-17 06:22:24,922 - ==> mAP: 0.48077    Loss: 3.186

2023-04-17 06:22:24,926 - ==> Best [mAP: 0.505253   vloss: 3.211834   Sparsity:0.00   Params: 2177088 on epoch: 85]
2023-04-17 06:22:24,926 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 06:22:24,962 - 

2023-04-17 06:22:24,962 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 06:22:35,746 - Epoch: [99][   50/  518]    Overall Loss 2.984677    Objective Loss 2.984677                                        LR 0.000250    Time 0.215642    
2023-04-17 06:22:45,781 - Epoch: [99][  100/  518]    Overall Loss 2.976568    Objective Loss 2.976568                                        LR 0.000250    Time 0.208155    
2023-04-17 06:22:55,927 - Epoch: [99][  150/  518]    Overall Loss 2.955798    Objective Loss 2.955798                                        LR 0.000250    Time 0.206395    
2023-04-17 06:23:06,020 - Epoch: [99][  200/  518]    Overall Loss 2.965577    Objective Loss 2.965577                                        LR 0.000250    Time 0.205257    
2023-04-17 06:23:16,050 - Epoch: [99][  250/  518]    Overall Loss 2.969771    Objective Loss 2.969771                                        LR 0.000250    Time 0.204316    
2023-04-17 06:23:26,109 - Epoch: [99][  300/  518]    Overall Loss 2.961633    Objective Loss 2.961633                                        LR 0.000250    Time 0.203789    
2023-04-17 06:23:36,287 - Epoch: [99][  350/  518]    Overall Loss 2.959043    Objective Loss 2.959043                                        LR 0.000250    Time 0.203754    
2023-04-17 06:23:46,337 - Epoch: [99][  400/  518]    Overall Loss 2.955283    Objective Loss 2.955283                                        LR 0.000250    Time 0.203403    
2023-04-17 06:23:56,429 - Epoch: [99][  450/  518]    Overall Loss 2.960105    Objective Loss 2.960105                                        LR 0.000250    Time 0.203228    
2023-04-17 06:24:06,545 - Epoch: [99][  500/  518]    Overall Loss 2.956466    Objective Loss 2.956466                                        LR 0.000250    Time 0.203133    
2023-04-17 06:24:10,072 - Epoch: [99][  518/  518]    Overall Loss 2.956953    Objective Loss 2.956953                                        LR 0.000250    Time 0.202883    
2023-04-17 06:24:10,153 - --- validate (epoch=99)-----------
2023-04-17 06:24:10,154 - 4952 samples (32 per mini-batch)
2023-04-17 06:25:00,841 - Epoch: [99][   50/  155]    Loss 3.164255    mAP 0.496433    
2023-04-17 06:25:51,717 - Epoch: [99][  100/  155]    Loss 3.173248    mAP 0.496933    
2023-04-17 06:26:41,873 - Epoch: [99][  150/  155]    Loss 3.170573    mAP 0.495014    
2023-04-17 06:26:46,127 - Epoch: [99][  155/  155]    Loss 3.163744    mAP 0.496297    
2023-04-17 06:26:46,205 - ==> mAP: 0.49630    Loss: 3.164

2023-04-17 06:26:46,208 - ==> Best [mAP: 0.505253   vloss: 3.211834   Sparsity:0.00   Params: 2177088 on epoch: 85]
2023-04-17 06:26:46,208 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 06:26:46,244 - 

2023-04-17 06:26:46,244 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 06:26:57,173 - Epoch: [100][   50/  518]    Overall Loss 2.959729    Objective Loss 2.959729                                        LR 0.000063    Time 0.218521    
2023-04-17 06:27:07,190 - Epoch: [100][  100/  518]    Overall Loss 2.948278    Objective Loss 2.948278                                        LR 0.000063    Time 0.209419    
2023-04-17 06:27:17,308 - Epoch: [100][  150/  518]    Overall Loss 2.922494    Objective Loss 2.922494                                        LR 0.000063    Time 0.207052    
2023-04-17 06:27:27,364 - Epoch: [100][  200/  518]    Overall Loss 2.920192    Objective Loss 2.920192                                        LR 0.000063    Time 0.205562    
2023-04-17 06:27:37,505 - Epoch: [100][  250/  518]    Overall Loss 2.915970    Objective Loss 2.915970                                        LR 0.000063    Time 0.205008    
2023-04-17 06:27:47,631 - Epoch: [100][  300/  518]    Overall Loss 2.916706    Objective Loss 2.916706                                        LR 0.000063    Time 0.204587    
2023-04-17 06:27:57,706 - Epoch: [100][  350/  518]    Overall Loss 2.923299    Objective Loss 2.923299                                        LR 0.000063    Time 0.204142    
2023-04-17 06:28:07,824 - Epoch: [100][  400/  518]    Overall Loss 2.917272    Objective Loss 2.917272                                        LR 0.000063    Time 0.203916    
2023-04-17 06:28:17,851 - Epoch: [100][  450/  518]    Overall Loss 2.911024    Objective Loss 2.911024                                        LR 0.000063    Time 0.203537    
2023-04-17 06:28:27,940 - Epoch: [100][  500/  518]    Overall Loss 2.912060    Objective Loss 2.912060                                        LR 0.000063    Time 0.203358    
2023-04-17 06:28:31,483 - Epoch: [100][  518/  518]    Overall Loss 2.909271    Objective Loss 2.909271                                        LR 0.000063    Time 0.203130    
2023-04-17 06:28:31,565 - --- validate (epoch=100)-----------
2023-04-17 06:28:31,565 - 4952 samples (32 per mini-batch)
2023-04-17 06:29:18,972 - Epoch: [100][   50/  155]    Loss 3.140614    mAP 0.521461    
2023-04-17 06:30:06,390 - Epoch: [100][  100/  155]    Loss 3.118663    mAP 0.525769    
2023-04-17 06:30:52,693 - Epoch: [100][  150/  155]    Loss 3.122782    mAP 0.509831    
2023-04-17 06:30:56,902 - Epoch: [100][  155/  155]    Loss 3.124721    mAP 0.507116    
2023-04-17 06:30:56,981 - ==> mAP: 0.50712    Loss: 3.125

2023-04-17 06:30:56,985 - ==> Best [mAP: 0.507116   vloss: 3.124721   Sparsity:0.00   Params: 2177088 on epoch: 100]
2023-04-17 06:30:56,985 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 06:30:57,037 - 

2023-04-17 06:30:57,037 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 06:31:07,803 - Epoch: [101][   50/  518]    Overall Loss 2.844624    Objective Loss 2.844624                                        LR 0.000063    Time 0.215255    
2023-04-17 06:31:17,859 - Epoch: [101][  100/  518]    Overall Loss 2.871471    Objective Loss 2.871471                                        LR 0.000063    Time 0.208177    
2023-04-17 06:31:27,975 - Epoch: [101][  150/  518]    Overall Loss 2.871293    Objective Loss 2.871293                                        LR 0.000063    Time 0.206217    
2023-04-17 06:31:38,105 - Epoch: [101][  200/  518]    Overall Loss 2.881458    Objective Loss 2.881458                                        LR 0.000063    Time 0.205305    
2023-04-17 06:31:48,240 - Epoch: [101][  250/  518]    Overall Loss 2.881180    Objective Loss 2.881180                                        LR 0.000063    Time 0.204777    
2023-04-17 06:31:58,282 - Epoch: [101][  300/  518]    Overall Loss 2.885819    Objective Loss 2.885819                                        LR 0.000063    Time 0.204114    
2023-04-17 06:32:08,351 - Epoch: [101][  350/  518]    Overall Loss 2.888902    Objective Loss 2.888902                                        LR 0.000063    Time 0.203720    
2023-04-17 06:32:18,429 - Epoch: [101][  400/  518]    Overall Loss 2.899548    Objective Loss 2.899548                                        LR 0.000063    Time 0.203445    
2023-04-17 06:32:28,497 - Epoch: [101][  450/  518]    Overall Loss 2.895554    Objective Loss 2.895554                                        LR 0.000063    Time 0.203211    
2023-04-17 06:32:38,705 - Epoch: [101][  500/  518]    Overall Loss 2.897308    Objective Loss 2.897308                                        LR 0.000063    Time 0.203303    
2023-04-17 06:32:42,283 - Epoch: [101][  518/  518]    Overall Loss 2.899993    Objective Loss 2.899993                                        LR 0.000063    Time 0.203144    
2023-04-17 06:32:42,363 - --- validate (epoch=101)-----------
2023-04-17 06:32:42,363 - 4952 samples (32 per mini-batch)
2023-04-17 06:33:29,110 - Epoch: [101][   50/  155]    Loss 3.104975    mAP 0.529801    
2023-04-17 06:34:12,700 - Epoch: [101][  100/  155]    Loss 3.120087    mAP 0.512790    
2023-04-17 06:34:56,053 - Epoch: [101][  150/  155]    Loss 3.127627    mAP 0.512651    
2023-04-17 06:35:00,545 - Epoch: [101][  155/  155]    Loss 3.130139    mAP 0.512885    
2023-04-17 06:35:00,621 - ==> mAP: 0.51288    Loss: 3.130

2023-04-17 06:35:00,625 - ==> Best [mAP: 0.512885   vloss: 3.130139   Sparsity:0.00   Params: 2177088 on epoch: 101]
2023-04-17 06:35:00,625 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 06:35:00,677 - 

2023-04-17 06:35:00,678 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 06:35:11,592 - Epoch: [102][   50/  518]    Overall Loss 2.908771    Objective Loss 2.908771                                        LR 0.000063    Time 0.218241    
2023-04-17 06:35:21,667 - Epoch: [102][  100/  518]    Overall Loss 2.883645    Objective Loss 2.883645                                        LR 0.000063    Time 0.209849    
2023-04-17 06:35:31,815 - Epoch: [102][  150/  518]    Overall Loss 2.888467    Objective Loss 2.888467                                        LR 0.000063    Time 0.207546    
2023-04-17 06:35:41,916 - Epoch: [102][  200/  518]    Overall Loss 2.895420    Objective Loss 2.895420                                        LR 0.000063    Time 0.206153    
2023-04-17 06:35:52,023 - Epoch: [102][  250/  518]    Overall Loss 2.910908    Objective Loss 2.910908                                        LR 0.000063    Time 0.205344    
2023-04-17 06:36:02,062 - Epoch: [102][  300/  518]    Overall Loss 2.913185    Objective Loss 2.913185                                        LR 0.000063    Time 0.204579    
2023-04-17 06:36:12,187 - Epoch: [102][  350/  518]    Overall Loss 2.907977    Objective Loss 2.907977                                        LR 0.000063    Time 0.204278    
2023-04-17 06:36:22,375 - Epoch: [102][  400/  518]    Overall Loss 2.908159    Objective Loss 2.908159                                        LR 0.000063    Time 0.204211    
2023-04-17 06:36:32,510 - Epoch: [102][  450/  518]    Overall Loss 2.911239    Objective Loss 2.911239                                        LR 0.000063    Time 0.204039    
2023-04-17 06:36:42,557 - Epoch: [102][  500/  518]    Overall Loss 2.908873    Objective Loss 2.908873                                        LR 0.000063    Time 0.203726    
2023-04-17 06:36:46,067 - Epoch: [102][  518/  518]    Overall Loss 2.912030    Objective Loss 2.912030                                        LR 0.000063    Time 0.203421    
2023-04-17 06:36:46,149 - --- validate (epoch=102)-----------
2023-04-17 06:36:46,149 - 4952 samples (32 per mini-batch)
2023-04-17 06:37:32,235 - Epoch: [102][   50/  155]    Loss 3.120629    mAP 0.517141    
2023-04-17 06:38:19,177 - Epoch: [102][  100/  155]    Loss 3.124392    mAP 0.503209    
2023-04-17 06:39:04,404 - Epoch: [102][  150/  155]    Loss 3.116284    mAP 0.503027    
2023-04-17 06:39:08,642 - Epoch: [102][  155/  155]    Loss 3.118204    mAP 0.503301    
2023-04-17 06:39:08,718 - ==> mAP: 0.50330    Loss: 3.118

2023-04-17 06:39:08,722 - ==> Best [mAP: 0.512885   vloss: 3.130139   Sparsity:0.00   Params: 2177088 on epoch: 101]
2023-04-17 06:39:08,722 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 06:39:08,759 - 

2023-04-17 06:39:08,759 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 06:39:19,629 - Epoch: [103][   50/  518]    Overall Loss 2.896431    Objective Loss 2.896431                                        LR 0.000063    Time 0.217342    
2023-04-17 06:39:29,697 - Epoch: [103][  100/  518]    Overall Loss 2.884114    Objective Loss 2.884114                                        LR 0.000063    Time 0.209343    
2023-04-17 06:39:39,821 - Epoch: [103][  150/  518]    Overall Loss 2.882568    Objective Loss 2.882568                                        LR 0.000063    Time 0.207046    
2023-04-17 06:39:49,859 - Epoch: [103][  200/  518]    Overall Loss 2.882053    Objective Loss 2.882053                                        LR 0.000063    Time 0.205465    
2023-04-17 06:39:59,951 - Epoch: [103][  250/  518]    Overall Loss 2.890980    Objective Loss 2.890980                                        LR 0.000063    Time 0.204733    
2023-04-17 06:40:10,050 - Epoch: [103][  300/  518]    Overall Loss 2.897029    Objective Loss 2.897029                                        LR 0.000063    Time 0.204269    
2023-04-17 06:40:20,124 - Epoch: [103][  350/  518]    Overall Loss 2.897417    Objective Loss 2.897417                                        LR 0.000063    Time 0.203867    
2023-04-17 06:40:30,334 - Epoch: [103][  400/  518]    Overall Loss 2.890965    Objective Loss 2.890965                                        LR 0.000063    Time 0.203905    
2023-04-17 06:40:40,451 - Epoch: [103][  450/  518]    Overall Loss 2.892161    Objective Loss 2.892161                                        LR 0.000063    Time 0.203727    
2023-04-17 06:40:50,552 - Epoch: [103][  500/  518]    Overall Loss 2.893361    Objective Loss 2.893361                                        LR 0.000063    Time 0.203553    
2023-04-17 06:40:54,083 - Epoch: [103][  518/  518]    Overall Loss 2.894548    Objective Loss 2.894548                                        LR 0.000063    Time 0.203295    
2023-04-17 06:40:54,162 - --- validate (epoch=103)-----------
2023-04-17 06:40:54,162 - 4952 samples (32 per mini-batch)
2023-04-17 06:41:40,466 - Epoch: [103][   50/  155]    Loss 3.094409    mAP 0.518490    
2023-04-17 06:42:28,796 - Epoch: [103][  100/  155]    Loss 3.127116    mAP 0.514849    
2023-04-17 06:43:15,322 - Epoch: [103][  150/  155]    Loss 3.113703    mAP 0.512844    
2023-04-17 06:43:19,769 - Epoch: [103][  155/  155]    Loss 3.117644    mAP 0.510853    
2023-04-17 06:43:19,847 - ==> mAP: 0.51085    Loss: 3.118

2023-04-17 06:43:19,850 - ==> Best [mAP: 0.512885   vloss: 3.130139   Sparsity:0.00   Params: 2177088 on epoch: 101]
2023-04-17 06:43:19,851 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 06:43:19,887 - 

2023-04-17 06:43:19,887 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 06:43:30,980 - Epoch: [104][   50/  518]    Overall Loss 2.997736    Objective Loss 2.997736                                        LR 0.000063    Time 0.221813    
2023-04-17 06:43:41,044 - Epoch: [104][  100/  518]    Overall Loss 2.952518    Objective Loss 2.952518                                        LR 0.000063    Time 0.211534    
2023-04-17 06:43:51,149 - Epoch: [104][  150/  518]    Overall Loss 2.926077    Objective Loss 2.926077                                        LR 0.000063    Time 0.208374    
2023-04-17 06:44:01,257 - Epoch: [104][  200/  518]    Overall Loss 2.911239    Objective Loss 2.911239                                        LR 0.000063    Time 0.206813    
2023-04-17 06:44:11,391 - Epoch: [104][  250/  518]    Overall Loss 2.898521    Objective Loss 2.898521                                        LR 0.000063    Time 0.205982    
2023-04-17 06:44:21,429 - Epoch: [104][  300/  518]    Overall Loss 2.892563    Objective Loss 2.892563                                        LR 0.000063    Time 0.205107    
2023-04-17 06:44:31,644 - Epoch: [104][  350/  518]    Overall Loss 2.887825    Objective Loss 2.887825                                        LR 0.000063    Time 0.204988    
2023-04-17 06:44:41,779 - Epoch: [104][  400/  518]    Overall Loss 2.895676    Objective Loss 2.895676                                        LR 0.000063    Time 0.204697    
2023-04-17 06:44:51,916 - Epoch: [104][  450/  518]    Overall Loss 2.893914    Objective Loss 2.893914                                        LR 0.000063    Time 0.204476    
2023-04-17 06:45:02,136 - Epoch: [104][  500/  518]    Overall Loss 2.893576    Objective Loss 2.893576                                        LR 0.000063    Time 0.204465    
2023-04-17 06:45:05,620 - Epoch: [104][  518/  518]    Overall Loss 2.892749    Objective Loss 2.892749                                        LR 0.000063    Time 0.204086    
2023-04-17 06:45:05,702 - --- validate (epoch=104)-----------
2023-04-17 06:45:05,702 - 4952 samples (32 per mini-batch)
2023-04-17 06:45:52,789 - Epoch: [104][   50/  155]    Loss 3.105661    mAP 0.514323    
2023-04-17 06:46:38,145 - Epoch: [104][  100/  155]    Loss 3.117908    mAP 0.500977    
2023-04-17 06:47:24,894 - Epoch: [104][  150/  155]    Loss 3.117787    mAP 0.503218    
2023-04-17 06:47:29,433 - Epoch: [104][  155/  155]    Loss 3.121937    mAP 0.499380    
2023-04-17 06:47:29,509 - ==> mAP: 0.49938    Loss: 3.122

2023-04-17 06:47:29,512 - ==> Best [mAP: 0.512885   vloss: 3.130139   Sparsity:0.00   Params: 2177088 on epoch: 101]
2023-04-17 06:47:29,513 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 06:47:29,549 - 

2023-04-17 06:47:29,550 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 06:47:40,468 - Epoch: [105][   50/  518]    Overall Loss 2.897402    Objective Loss 2.897402                                        LR 0.000063    Time 0.218318    
2023-04-17 06:47:50,628 - Epoch: [105][  100/  518]    Overall Loss 2.908992    Objective Loss 2.908992                                        LR 0.000063    Time 0.210744    
2023-04-17 06:48:00,828 - Epoch: [105][  150/  518]    Overall Loss 2.902713    Objective Loss 2.902713                                        LR 0.000063    Time 0.208485    
2023-04-17 06:48:10,964 - Epoch: [105][  200/  518]    Overall Loss 2.909354    Objective Loss 2.909354                                        LR 0.000063    Time 0.207034    
2023-04-17 06:48:21,016 - Epoch: [105][  250/  518]    Overall Loss 2.903354    Objective Loss 2.903354                                        LR 0.000063    Time 0.205832    
2023-04-17 06:48:31,093 - Epoch: [105][  300/  518]    Overall Loss 2.905292    Objective Loss 2.905292                                        LR 0.000063    Time 0.205108    
2023-04-17 06:48:41,153 - Epoch: [105][  350/  518]    Overall Loss 2.897060    Objective Loss 2.897060                                        LR 0.000063    Time 0.204547    
2023-04-17 06:48:51,232 - Epoch: [105][  400/  518]    Overall Loss 2.893023    Objective Loss 2.893023                                        LR 0.000063    Time 0.204171    
2023-04-17 06:49:01,334 - Epoch: [105][  450/  518]    Overall Loss 2.894657    Objective Loss 2.894657                                        LR 0.000063    Time 0.203932    
2023-04-17 06:49:11,457 - Epoch: [105][  500/  518]    Overall Loss 2.893968    Objective Loss 2.893968                                        LR 0.000063    Time 0.203781    
2023-04-17 06:49:14,948 - Epoch: [105][  518/  518]    Overall Loss 2.894357    Objective Loss 2.894357                                        LR 0.000063    Time 0.203439    
2023-04-17 06:49:15,028 - --- validate (epoch=105)-----------
2023-04-17 06:49:15,028 - 4952 samples (32 per mini-batch)
2023-04-17 06:50:01,410 - Epoch: [105][   50/  155]    Loss 3.157078    mAP 0.494428    
2023-04-17 06:50:45,864 - Epoch: [105][  100/  155]    Loss 3.125866    mAP 0.498278    
2023-04-17 06:51:32,155 - Epoch: [105][  150/  155]    Loss 3.128366    mAP 0.500934    
2023-04-17 06:51:36,518 - Epoch: [105][  155/  155]    Loss 3.128313    mAP 0.500582    
2023-04-17 06:51:36,596 - ==> mAP: 0.50058    Loss: 3.128

2023-04-17 06:51:36,599 - ==> Best [mAP: 0.512885   vloss: 3.130139   Sparsity:0.00   Params: 2177088 on epoch: 101]
2023-04-17 06:51:36,599 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 06:51:36,635 - 

2023-04-17 06:51:36,636 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 06:51:47,483 - Epoch: [106][   50/  518]    Overall Loss 2.878723    Objective Loss 2.878723                                        LR 0.000063    Time 0.216901    
2023-04-17 06:51:57,643 - Epoch: [106][  100/  518]    Overall Loss 2.901169    Objective Loss 2.901169                                        LR 0.000063    Time 0.210033    
2023-04-17 06:52:07,626 - Epoch: [106][  150/  518]    Overall Loss 2.887172    Objective Loss 2.887172                                        LR 0.000063    Time 0.206566    
2023-04-17 06:52:17,676 - Epoch: [106][  200/  518]    Overall Loss 2.891697    Objective Loss 2.891697                                        LR 0.000063    Time 0.205167    
2023-04-17 06:52:27,772 - Epoch: [106][  250/  518]    Overall Loss 2.887305    Objective Loss 2.887305                                        LR 0.000063    Time 0.204512    
2023-04-17 06:52:37,910 - Epoch: [106][  300/  518]    Overall Loss 2.895022    Objective Loss 2.895022                                        LR 0.000063    Time 0.204215    
2023-04-17 06:52:48,007 - Epoch: [106][  350/  518]    Overall Loss 2.895029    Objective Loss 2.895029                                        LR 0.000063    Time 0.203884    
2023-04-17 06:52:58,018 - Epoch: [106][  400/  518]    Overall Loss 2.900404    Objective Loss 2.900404                                        LR 0.000063    Time 0.203422    
2023-04-17 06:53:08,141 - Epoch: [106][  450/  518]    Overall Loss 2.896330    Objective Loss 2.896330                                        LR 0.000063    Time 0.203311    
2023-04-17 06:53:18,168 - Epoch: [106][  500/  518]    Overall Loss 2.894130    Objective Loss 2.894130                                        LR 0.000063    Time 0.203031    
2023-04-17 06:53:21,655 - Epoch: [106][  518/  518]    Overall Loss 2.896792    Objective Loss 2.896792                                        LR 0.000063    Time 0.202707    
2023-04-17 06:53:21,735 - --- validate (epoch=106)-----------
2023-04-17 06:53:21,735 - 4952 samples (32 per mini-batch)
2023-04-17 06:54:08,556 - Epoch: [106][   50/  155]    Loss 3.089570    mAP 0.508465    
2023-04-17 06:54:55,930 - Epoch: [106][  100/  155]    Loss 3.105973    mAP 0.508936    
2023-04-17 06:55:45,745 - Epoch: [106][  150/  155]    Loss 3.118182    mAP 0.504965    
2023-04-17 06:55:50,076 - Epoch: [106][  155/  155]    Loss 3.118994    mAP 0.504518    
2023-04-17 06:55:50,153 - ==> mAP: 0.50452    Loss: 3.119

2023-04-17 06:55:50,158 - ==> Best [mAP: 0.512885   vloss: 3.130139   Sparsity:0.00   Params: 2177088 on epoch: 101]
2023-04-17 06:55:50,158 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 06:55:50,196 - 

2023-04-17 06:55:50,196 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 06:56:01,128 - Epoch: [107][   50/  518]    Overall Loss 2.896356    Objective Loss 2.896356                                        LR 0.000063    Time 0.218589    
2023-04-17 06:56:11,220 - Epoch: [107][  100/  518]    Overall Loss 2.889116    Objective Loss 2.889116                                        LR 0.000063    Time 0.210202    
2023-04-17 06:56:21,383 - Epoch: [107][  150/  518]    Overall Loss 2.899768    Objective Loss 2.899768                                        LR 0.000063    Time 0.207874    
2023-04-17 06:56:31,533 - Epoch: [107][  200/  518]    Overall Loss 2.904038    Objective Loss 2.904038                                        LR 0.000063    Time 0.206651    
2023-04-17 06:56:41,655 - Epoch: [107][  250/  518]    Overall Loss 2.904253    Objective Loss 2.904253                                        LR 0.000063    Time 0.205802    
2023-04-17 06:56:51,712 - Epoch: [107][  300/  518]    Overall Loss 2.892742    Objective Loss 2.892742                                        LR 0.000063    Time 0.205020    
2023-04-17 06:57:01,773 - Epoch: [107][  350/  518]    Overall Loss 2.889886    Objective Loss 2.889886                                        LR 0.000063    Time 0.204470    
2023-04-17 06:57:11,873 - Epoch: [107][  400/  518]    Overall Loss 2.899410    Objective Loss 2.899410                                        LR 0.000063    Time 0.204158    
2023-04-17 06:57:21,952 - Epoch: [107][  450/  518]    Overall Loss 2.899814    Objective Loss 2.899814                                        LR 0.000063    Time 0.203869    
2023-04-17 06:57:32,043 - Epoch: [107][  500/  518]    Overall Loss 2.904610    Objective Loss 2.904610                                        LR 0.000063    Time 0.203662    
2023-04-17 06:57:35,558 - Epoch: [107][  518/  518]    Overall Loss 2.902151    Objective Loss 2.902151                                        LR 0.000063    Time 0.203368    
2023-04-17 06:57:35,638 - --- validate (epoch=107)-----------
2023-04-17 06:57:35,638 - 4952 samples (32 per mini-batch)
2023-04-17 06:58:22,548 - Epoch: [107][   50/  155]    Loss 3.170150    mAP 0.503637    
2023-04-17 06:59:08,164 - Epoch: [107][  100/  155]    Loss 3.124399    mAP 0.498238    
2023-04-17 06:59:54,860 - Epoch: [107][  150/  155]    Loss 3.123092    mAP 0.502324    
2023-04-17 06:59:58,462 - Epoch: [107][  155/  155]    Loss 3.119244    mAP 0.503493    
2023-04-17 06:59:58,539 - ==> mAP: 0.50349    Loss: 3.119

2023-04-17 06:59:58,543 - ==> Best [mAP: 0.512885   vloss: 3.130139   Sparsity:0.00   Params: 2177088 on epoch: 101]
2023-04-17 06:59:58,543 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 06:59:58,579 - 

2023-04-17 06:59:58,579 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 07:00:09,531 - Epoch: [108][   50/  518]    Overall Loss 2.891253    Objective Loss 2.891253                                        LR 0.000063    Time 0.218989    
2023-04-17 07:00:19,590 - Epoch: [108][  100/  518]    Overall Loss 2.888362    Objective Loss 2.888362                                        LR 0.000063    Time 0.210070    
2023-04-17 07:00:29,734 - Epoch: [108][  150/  518]    Overall Loss 2.899996    Objective Loss 2.899996                                        LR 0.000063    Time 0.207664    
2023-04-17 07:00:39,843 - Epoch: [108][  200/  518]    Overall Loss 2.883529    Objective Loss 2.883529                                        LR 0.000063    Time 0.206286    
2023-04-17 07:00:49,935 - Epoch: [108][  250/  518]    Overall Loss 2.892398    Objective Loss 2.892398                                        LR 0.000063    Time 0.205390    
2023-04-17 07:01:00,021 - Epoch: [108][  300/  518]    Overall Loss 2.895356    Objective Loss 2.895356                                        LR 0.000063    Time 0.204774    
2023-04-17 07:01:10,077 - Epoch: [108][  350/  518]    Overall Loss 2.900611    Objective Loss 2.900611                                        LR 0.000063    Time 0.204246    
2023-04-17 07:01:20,287 - Epoch: [108][  400/  518]    Overall Loss 2.902384    Objective Loss 2.902384                                        LR 0.000063    Time 0.204236    
2023-04-17 07:01:30,317 - Epoch: [108][  450/  518]    Overall Loss 2.894341    Objective Loss 2.894341                                        LR 0.000063    Time 0.203828    
2023-04-17 07:01:40,434 - Epoch: [108][  500/  518]    Overall Loss 2.894427    Objective Loss 2.894427                                        LR 0.000063    Time 0.203676    
2023-04-17 07:01:43,924 - Epoch: [108][  518/  518]    Overall Loss 2.896341    Objective Loss 2.896341                                        LR 0.000063    Time 0.203337    
2023-04-17 07:01:44,001 - --- validate (epoch=108)-----------
2023-04-17 07:01:44,001 - 4952 samples (32 per mini-batch)
2023-04-17 07:02:31,094 - Epoch: [108][   50/  155]    Loss 3.127038    mAP 0.514917    
2023-04-17 07:03:15,579 - Epoch: [108][  100/  155]    Loss 3.118650    mAP 0.518047    
2023-04-17 07:03:58,858 - Epoch: [108][  150/  155]    Loss 3.113661    mAP 0.514609    
2023-04-17 07:04:03,844 - Epoch: [108][  155/  155]    Loss 3.114535    mAP 0.514787    
2023-04-17 07:04:03,918 - ==> mAP: 0.51479    Loss: 3.115

2023-04-17 07:04:03,921 - ==> Best [mAP: 0.514787   vloss: 3.114535   Sparsity:0.00   Params: 2177088 on epoch: 108]
2023-04-17 07:04:03,921 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 07:04:03,972 - 

2023-04-17 07:04:03,972 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 07:04:14,686 - Epoch: [109][   50/  518]    Overall Loss 2.881500    Objective Loss 2.881500                                        LR 0.000063    Time 0.214218    
2023-04-17 07:04:24,788 - Epoch: [109][  100/  518]    Overall Loss 2.875546    Objective Loss 2.875546                                        LR 0.000063    Time 0.208113    
2023-04-17 07:04:34,847 - Epoch: [109][  150/  518]    Overall Loss 2.877875    Objective Loss 2.877875                                        LR 0.000063    Time 0.205790    
2023-04-17 07:04:44,929 - Epoch: [109][  200/  518]    Overall Loss 2.893993    Objective Loss 2.893993                                        LR 0.000063    Time 0.204745    
2023-04-17 07:04:55,029 - Epoch: [109][  250/  518]    Overall Loss 2.903746    Objective Loss 2.903746                                        LR 0.000063    Time 0.204190    
2023-04-17 07:05:05,147 - Epoch: [109][  300/  518]    Overall Loss 2.898136    Objective Loss 2.898136                                        LR 0.000063    Time 0.203882    
2023-04-17 07:05:15,257 - Epoch: [109][  350/  518]    Overall Loss 2.898541    Objective Loss 2.898541                                        LR 0.000063    Time 0.203637    
2023-04-17 07:05:25,417 - Epoch: [109][  400/  518]    Overall Loss 2.900212    Objective Loss 2.900212                                        LR 0.000063    Time 0.203578    
2023-04-17 07:05:35,484 - Epoch: [109][  450/  518]    Overall Loss 2.892440    Objective Loss 2.892440                                        LR 0.000063    Time 0.203325    
2023-04-17 07:05:45,549 - Epoch: [109][  500/  518]    Overall Loss 2.891652    Objective Loss 2.891652                                        LR 0.000063    Time 0.203120    
2023-04-17 07:05:49,073 - Epoch: [109][  518/  518]    Overall Loss 2.892327    Objective Loss 2.892327                                        LR 0.000063    Time 0.202863    
2023-04-17 07:05:49,153 - --- validate (epoch=109)-----------
2023-04-17 07:05:49,153 - 4952 samples (32 per mini-batch)
2023-04-17 07:06:34,093 - Epoch: [109][   50/  155]    Loss 3.108529    mAP 0.514251    
2023-04-17 07:07:19,563 - Epoch: [109][  100/  155]    Loss 3.118592    mAP 0.510398    
2023-04-17 07:08:03,479 - Epoch: [109][  150/  155]    Loss 3.115570    mAP 0.510293    
2023-04-17 07:08:06,877 - Epoch: [109][  155/  155]    Loss 3.111706    mAP 0.510071    
2023-04-17 07:08:06,947 - ==> mAP: 0.51007    Loss: 3.112

2023-04-17 07:08:06,951 - ==> Best [mAP: 0.514787   vloss: 3.114535   Sparsity:0.00   Params: 2177088 on epoch: 108]
2023-04-17 07:08:06,951 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 07:08:06,987 - 

2023-04-17 07:08:06,987 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 07:08:17,750 - Epoch: [110][   50/  518]    Overall Loss 2.857969    Objective Loss 2.857969                                        LR 0.000063    Time 0.215204    
2023-04-17 07:08:27,945 - Epoch: [110][  100/  518]    Overall Loss 2.853209    Objective Loss 2.853209                                        LR 0.000063    Time 0.209540    
2023-04-17 07:08:37,937 - Epoch: [110][  150/  518]    Overall Loss 2.871187    Objective Loss 2.871187                                        LR 0.000063    Time 0.206292    
2023-04-17 07:08:48,046 - Epoch: [110][  200/  518]    Overall Loss 2.874185    Objective Loss 2.874185                                        LR 0.000063    Time 0.205259    
2023-04-17 07:08:58,148 - Epoch: [110][  250/  518]    Overall Loss 2.885281    Objective Loss 2.885281                                        LR 0.000063    Time 0.204611    
2023-04-17 07:09:08,284 - Epoch: [110][  300/  518]    Overall Loss 2.875083    Objective Loss 2.875083                                        LR 0.000063    Time 0.204290    
2023-04-17 07:09:18,283 - Epoch: [110][  350/  518]    Overall Loss 2.878751    Objective Loss 2.878751                                        LR 0.000063    Time 0.203669    
2023-04-17 07:09:28,273 - Epoch: [110][  400/  518]    Overall Loss 2.876643    Objective Loss 2.876643                                        LR 0.000063    Time 0.203183    
2023-04-17 07:09:38,361 - Epoch: [110][  450/  518]    Overall Loss 2.874185    Objective Loss 2.874185                                        LR 0.000063    Time 0.203020    
2023-04-17 07:09:48,510 - Epoch: [110][  500/  518]    Overall Loss 2.871158    Objective Loss 2.871158                                        LR 0.000063    Time 0.203012    
2023-04-17 07:09:52,016 - Epoch: [110][  518/  518]    Overall Loss 2.871881    Objective Loss 2.871881                                        LR 0.000063    Time 0.202726    
2023-04-17 07:09:52,097 - --- validate (epoch=110)-----------
2023-04-17 07:09:52,098 - 4952 samples (32 per mini-batch)
2023-04-17 07:10:37,443 - Epoch: [110][   50/  155]    Loss 3.106665    mAP 0.512309    
2023-04-17 07:11:22,115 - Epoch: [110][  100/  155]    Loss 3.126973    mAP 0.506862    
2023-04-17 07:12:07,328 - Epoch: [110][  150/  155]    Loss 3.115931    mAP 0.505704    
2023-04-17 07:12:11,850 - Epoch: [110][  155/  155]    Loss 3.119193    mAP 0.504363    
2023-04-17 07:12:11,924 - ==> mAP: 0.50436    Loss: 3.119

2023-04-17 07:12:11,928 - ==> Best [mAP: 0.514787   vloss: 3.114535   Sparsity:0.00   Params: 2177088 on epoch: 108]
2023-04-17 07:12:11,928 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 07:12:11,964 - 

2023-04-17 07:12:11,964 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 07:12:22,939 - Epoch: [111][   50/  518]    Overall Loss 2.910688    Objective Loss 2.910688                                        LR 0.000063    Time 0.219447    
2023-04-17 07:12:33,006 - Epoch: [111][  100/  518]    Overall Loss 2.913019    Objective Loss 2.913019                                        LR 0.000063    Time 0.210381    
2023-04-17 07:12:43,125 - Epoch: [111][  150/  518]    Overall Loss 2.888810    Objective Loss 2.888810                                        LR 0.000063    Time 0.207704    
2023-04-17 07:12:53,309 - Epoch: [111][  200/  518]    Overall Loss 2.890039    Objective Loss 2.890039                                        LR 0.000063    Time 0.206687    
2023-04-17 07:13:03,365 - Epoch: [111][  250/  518]    Overall Loss 2.881723    Objective Loss 2.881723                                        LR 0.000063    Time 0.205568    
2023-04-17 07:13:13,463 - Epoch: [111][  300/  518]    Overall Loss 2.889829    Objective Loss 2.889829                                        LR 0.000063    Time 0.204961    
2023-04-17 07:13:23,507 - Epoch: [111][  350/  518]    Overall Loss 2.889096    Objective Loss 2.889096                                        LR 0.000063    Time 0.204375    
2023-04-17 07:13:33,607 - Epoch: [111][  400/  518]    Overall Loss 2.884919    Objective Loss 2.884919                                        LR 0.000063    Time 0.204074    
2023-04-17 07:13:43,709 - Epoch: [111][  450/  518]    Overall Loss 2.889418    Objective Loss 2.889418                                        LR 0.000063    Time 0.203844    
2023-04-17 07:13:53,775 - Epoch: [111][  500/  518]    Overall Loss 2.885668    Objective Loss 2.885668                                        LR 0.000063    Time 0.203589    
2023-04-17 07:13:57,324 - Epoch: [111][  518/  518]    Overall Loss 2.886381    Objective Loss 2.886381                                        LR 0.000063    Time 0.203365    
2023-04-17 07:13:57,405 - --- validate (epoch=111)-----------
2023-04-17 07:13:57,405 - 4952 samples (32 per mini-batch)
2023-04-17 07:14:39,964 - Epoch: [111][   50/  155]    Loss 3.127950    mAP 0.510961    
2023-04-17 07:15:23,634 - Epoch: [111][  100/  155]    Loss 3.125316    mAP 0.510983    
2023-04-17 07:16:05,289 - Epoch: [111][  150/  155]    Loss 3.111261    mAP 0.506880    
2023-04-17 07:16:09,491 - Epoch: [111][  155/  155]    Loss 3.110850    mAP 0.508697    
2023-04-17 07:16:09,567 - ==> mAP: 0.50870    Loss: 3.111

2023-04-17 07:16:09,571 - ==> Best [mAP: 0.514787   vloss: 3.114535   Sparsity:0.00   Params: 2177088 on epoch: 108]
2023-04-17 07:16:09,571 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 07:16:09,607 - 

2023-04-17 07:16:09,607 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 07:16:20,471 - Epoch: [112][   50/  518]    Overall Loss 2.841560    Objective Loss 2.841560                                        LR 0.000063    Time 0.217225    
2023-04-17 07:16:30,611 - Epoch: [112][  100/  518]    Overall Loss 2.860213    Objective Loss 2.860213                                        LR 0.000063    Time 0.209996    
2023-04-17 07:16:40,724 - Epoch: [112][  150/  518]    Overall Loss 2.861680    Objective Loss 2.861680                                        LR 0.000063    Time 0.207407    
2023-04-17 07:16:50,808 - Epoch: [112][  200/  518]    Overall Loss 2.849387    Objective Loss 2.849387                                        LR 0.000063    Time 0.205965    
2023-04-17 07:17:00,897 - Epoch: [112][  250/  518]    Overall Loss 2.851482    Objective Loss 2.851482                                        LR 0.000063    Time 0.205122    
2023-04-17 07:17:10,998 - Epoch: [112][  300/  518]    Overall Loss 2.858777    Objective Loss 2.858777                                        LR 0.000063    Time 0.204602    
2023-04-17 07:17:21,173 - Epoch: [112][  350/  518]    Overall Loss 2.868278    Objective Loss 2.868278                                        LR 0.000063    Time 0.204439    
2023-04-17 07:17:31,420 - Epoch: [112][  400/  518]    Overall Loss 2.870857    Objective Loss 2.870857                                        LR 0.000063    Time 0.204496    
2023-04-17 07:17:41,521 - Epoch: [112][  450/  518]    Overall Loss 2.875944    Objective Loss 2.875944                                        LR 0.000063    Time 0.204218    
2023-04-17 07:17:51,579 - Epoch: [112][  500/  518]    Overall Loss 2.879730    Objective Loss 2.879730                                        LR 0.000063    Time 0.203909    
2023-04-17 07:17:55,089 - Epoch: [112][  518/  518]    Overall Loss 2.883706    Objective Loss 2.883706                                        LR 0.000063    Time 0.203600    
2023-04-17 07:17:55,175 - --- validate (epoch=112)-----------
2023-04-17 07:17:55,176 - 4952 samples (32 per mini-batch)
2023-04-17 07:18:41,679 - Epoch: [112][   50/  155]    Loss 3.093022    mAP 0.500616    
2023-04-17 07:19:27,833 - Epoch: [112][  100/  155]    Loss 3.112782    mAP 0.502822    
2023-04-17 07:20:13,052 - Epoch: [112][  150/  155]    Loss 3.107595    mAP 0.512526    
2023-04-17 07:20:16,916 - Epoch: [112][  155/  155]    Loss 3.109943    mAP 0.511958    
2023-04-17 07:20:16,996 - ==> mAP: 0.51196    Loss: 3.110

2023-04-17 07:20:16,999 - ==> Best [mAP: 0.514787   vloss: 3.114535   Sparsity:0.00   Params: 2177088 on epoch: 108]
2023-04-17 07:20:16,999 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 07:20:17,036 - 

2023-04-17 07:20:17,037 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 07:20:27,872 - Epoch: [113][   50/  518]    Overall Loss 2.876542    Objective Loss 2.876542                                        LR 0.000063    Time 0.216645    
2023-04-17 07:20:37,963 - Epoch: [113][  100/  518]    Overall Loss 2.843005    Objective Loss 2.843005                                        LR 0.000063    Time 0.209221    
2023-04-17 07:20:48,055 - Epoch: [113][  150/  518]    Overall Loss 2.845796    Objective Loss 2.845796                                        LR 0.000063    Time 0.206750    
2023-04-17 07:20:58,092 - Epoch: [113][  200/  518]    Overall Loss 2.845469    Objective Loss 2.845469                                        LR 0.000063    Time 0.205239    
2023-04-17 07:21:08,190 - Epoch: [113][  250/  518]    Overall Loss 2.859575    Objective Loss 2.859575                                        LR 0.000063    Time 0.204579    
2023-04-17 07:21:18,271 - Epoch: [113][  300/  518]    Overall Loss 2.867931    Objective Loss 2.867931                                        LR 0.000063    Time 0.204081    
2023-04-17 07:21:28,398 - Epoch: [113][  350/  518]    Overall Loss 2.870263    Objective Loss 2.870263                                        LR 0.000063    Time 0.203854    
2023-04-17 07:21:38,455 - Epoch: [113][  400/  518]    Overall Loss 2.871429    Objective Loss 2.871429                                        LR 0.000063    Time 0.203513    
2023-04-17 07:21:48,468 - Epoch: [113][  450/  518]    Overall Loss 2.872519    Objective Loss 2.872519                                        LR 0.000063    Time 0.203148    
2023-04-17 07:21:58,597 - Epoch: [113][  500/  518]    Overall Loss 2.872560    Objective Loss 2.872560                                        LR 0.000063    Time 0.203088    
2023-04-17 07:22:02,149 - Epoch: [113][  518/  518]    Overall Loss 2.873038    Objective Loss 2.873038                                        LR 0.000063    Time 0.202887    
2023-04-17 07:22:02,231 - --- validate (epoch=113)-----------
2023-04-17 07:22:02,232 - 4952 samples (32 per mini-batch)
2023-04-17 07:22:49,231 - Epoch: [113][   50/  155]    Loss 3.148167    mAP 0.483772    
2023-04-17 07:23:35,149 - Epoch: [113][  100/  155]    Loss 3.112435    mAP 0.502738    
2023-04-17 07:24:22,549 - Epoch: [113][  150/  155]    Loss 3.109897    mAP 0.505155    
2023-04-17 07:24:26,763 - Epoch: [113][  155/  155]    Loss 3.112253    mAP 0.505248    
2023-04-17 07:24:26,841 - ==> mAP: 0.50525    Loss: 3.112

2023-04-17 07:24:26,844 - ==> Best [mAP: 0.514787   vloss: 3.114535   Sparsity:0.00   Params: 2177088 on epoch: 108]
2023-04-17 07:24:26,844 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 07:24:26,881 - 

2023-04-17 07:24:26,882 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 07:24:37,624 - Epoch: [114][   50/  518]    Overall Loss 2.809958    Objective Loss 2.809958                                        LR 0.000063    Time 0.214800    
2023-04-17 07:24:47,708 - Epoch: [114][  100/  518]    Overall Loss 2.834666    Objective Loss 2.834666                                        LR 0.000063    Time 0.208226    
2023-04-17 07:24:57,767 - Epoch: [114][  150/  518]    Overall Loss 2.851877    Objective Loss 2.851877                                        LR 0.000063    Time 0.205863    
2023-04-17 07:25:07,901 - Epoch: [114][  200/  518]    Overall Loss 2.853671    Objective Loss 2.853671                                        LR 0.000063    Time 0.205062    
2023-04-17 07:25:17,982 - Epoch: [114][  250/  518]    Overall Loss 2.862224    Objective Loss 2.862224                                        LR 0.000063    Time 0.204365    
2023-04-17 07:25:28,027 - Epoch: [114][  300/  518]    Overall Loss 2.862112    Objective Loss 2.862112                                        LR 0.000063    Time 0.203782    
2023-04-17 07:25:38,149 - Epoch: [114][  350/  518]    Overall Loss 2.859658    Objective Loss 2.859658                                        LR 0.000063    Time 0.203587    
2023-04-17 07:25:48,144 - Epoch: [114][  400/  518]    Overall Loss 2.863695    Objective Loss 2.863695                                        LR 0.000063    Time 0.203122    
2023-04-17 07:25:58,228 - Epoch: [114][  450/  518]    Overall Loss 2.865413    Objective Loss 2.865413                                        LR 0.000063    Time 0.202959    
2023-04-17 07:26:08,302 - Epoch: [114][  500/  518]    Overall Loss 2.867739    Objective Loss 2.867739                                        LR 0.000063    Time 0.202808    
2023-04-17 07:26:11,809 - Epoch: [114][  518/  518]    Overall Loss 2.867964    Objective Loss 2.867964                                        LR 0.000063    Time 0.202529    
2023-04-17 07:26:11,891 - --- validate (epoch=114)-----------
2023-04-17 07:26:11,891 - 4952 samples (32 per mini-batch)
2023-04-17 07:26:58,305 - Epoch: [114][   50/  155]    Loss 3.135923    mAP 0.493616    
2023-04-17 07:27:45,422 - Epoch: [114][  100/  155]    Loss 3.121602    mAP 0.500217    
2023-04-17 07:28:30,866 - Epoch: [114][  150/  155]    Loss 3.118290    mAP 0.507137    
2023-04-17 07:28:34,518 - Epoch: [114][  155/  155]    Loss 3.117576    mAP 0.507241    
2023-04-17 07:28:34,593 - ==> mAP: 0.50724    Loss: 3.118

2023-04-17 07:28:34,597 - ==> Best [mAP: 0.514787   vloss: 3.114535   Sparsity:0.00   Params: 2177088 on epoch: 108]
2023-04-17 07:28:34,597 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 07:28:34,633 - 

2023-04-17 07:28:34,633 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 07:28:45,502 - Epoch: [115][   50/  518]    Overall Loss 2.882419    Objective Loss 2.882419                                        LR 0.000063    Time 0.217318    
2023-04-17 07:28:55,604 - Epoch: [115][  100/  518]    Overall Loss 2.887506    Objective Loss 2.887506                                        LR 0.000063    Time 0.209667    
2023-04-17 07:29:05,717 - Epoch: [115][  150/  518]    Overall Loss 2.881798    Objective Loss 2.881798                                        LR 0.000063    Time 0.207190    
2023-04-17 07:29:15,771 - Epoch: [115][  200/  518]    Overall Loss 2.882593    Objective Loss 2.882593                                        LR 0.000063    Time 0.205654    
2023-04-17 07:29:25,779 - Epoch: [115][  250/  518]    Overall Loss 2.886661    Objective Loss 2.886661                                        LR 0.000063    Time 0.204549    
2023-04-17 07:29:35,850 - Epoch: [115][  300/  518]    Overall Loss 2.871829    Objective Loss 2.871829                                        LR 0.000063    Time 0.204021    
2023-04-17 07:29:45,899 - Epoch: [115][  350/  518]    Overall Loss 2.878716    Objective Loss 2.878716                                        LR 0.000063    Time 0.203582    
2023-04-17 07:29:56,006 - Epoch: [115][  400/  518]    Overall Loss 2.880078    Objective Loss 2.880078                                        LR 0.000063    Time 0.203399    
2023-04-17 07:30:06,071 - Epoch: [115][  450/  518]    Overall Loss 2.881361    Objective Loss 2.881361                                        LR 0.000063    Time 0.203163    
2023-04-17 07:30:16,123 - Epoch: [115][  500/  518]    Overall Loss 2.880821    Objective Loss 2.880821                                        LR 0.000063    Time 0.202946    
2023-04-17 07:30:19,691 - Epoch: [115][  518/  518]    Overall Loss 2.880970    Objective Loss 2.880970                                        LR 0.000063    Time 0.202781    
2023-04-17 07:30:19,772 - --- validate (epoch=115)-----------
2023-04-17 07:30:19,772 - 4952 samples (32 per mini-batch)
2023-04-17 07:31:05,378 - Epoch: [115][   50/  155]    Loss 3.102997    mAP 0.503400    
2023-04-17 07:31:52,179 - Epoch: [115][  100/  155]    Loss 3.125961    mAP 0.501744    
2023-04-17 07:32:38,532 - Epoch: [115][  150/  155]    Loss 3.116501    mAP 0.502342    
2023-04-17 07:32:42,638 - Epoch: [115][  155/  155]    Loss 3.117949    mAP 0.502821    
2023-04-17 07:32:42,716 - ==> mAP: 0.50282    Loss: 3.118

2023-04-17 07:32:42,720 - ==> Best [mAP: 0.514787   vloss: 3.114535   Sparsity:0.00   Params: 2177088 on epoch: 108]
2023-04-17 07:32:42,720 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 07:32:42,757 - 

2023-04-17 07:32:42,757 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 07:32:53,612 - Epoch: [116][   50/  518]    Overall Loss 2.906006    Objective Loss 2.906006                                        LR 0.000063    Time 0.217047    
2023-04-17 07:33:03,689 - Epoch: [116][  100/  518]    Overall Loss 2.865785    Objective Loss 2.865785                                        LR 0.000063    Time 0.209274    
2023-04-17 07:33:13,747 - Epoch: [116][  150/  518]    Overall Loss 2.848322    Objective Loss 2.848322                                        LR 0.000063    Time 0.206564    
2023-04-17 07:33:23,776 - Epoch: [116][  200/  518]    Overall Loss 2.868716    Objective Loss 2.868716                                        LR 0.000063    Time 0.205060    
2023-04-17 07:33:33,867 - Epoch: [116][  250/  518]    Overall Loss 2.885080    Objective Loss 2.885080                                        LR 0.000063    Time 0.204404    
2023-04-17 07:33:44,050 - Epoch: [116][  300/  518]    Overall Loss 2.886376    Objective Loss 2.886376                                        LR 0.000063    Time 0.204274    
2023-04-17 07:33:54,272 - Epoch: [116][  350/  518]    Overall Loss 2.885609    Objective Loss 2.885609                                        LR 0.000063    Time 0.204295    
2023-04-17 07:34:04,448 - Epoch: [116][  400/  518]    Overall Loss 2.887692    Objective Loss 2.887692                                        LR 0.000063    Time 0.204194    
2023-04-17 07:34:14,572 - Epoch: [116][  450/  518]    Overall Loss 2.879181    Objective Loss 2.879181                                        LR 0.000063    Time 0.204000    
2023-04-17 07:34:24,719 - Epoch: [116][  500/  518]    Overall Loss 2.884209    Objective Loss 2.884209                                        LR 0.000063    Time 0.203891    
2023-04-17 07:34:28,186 - Epoch: [116][  518/  518]    Overall Loss 2.884638    Objective Loss 2.884638                                        LR 0.000063    Time 0.203498    
2023-04-17 07:34:28,264 - --- validate (epoch=116)-----------
2023-04-17 07:34:28,265 - 4952 samples (32 per mini-batch)
2023-04-17 07:35:12,092 - Epoch: [116][   50/  155]    Loss 3.133603    mAP 0.514669    
2023-04-17 07:35:55,578 - Epoch: [116][  100/  155]    Loss 3.110929    mAP 0.505995    
2023-04-17 07:36:41,203 - Epoch: [116][  150/  155]    Loss 3.116998    mAP 0.503208    
2023-04-17 07:36:45,227 - Epoch: [116][  155/  155]    Loss 3.111313    mAP 0.503910    
2023-04-17 07:36:45,306 - ==> mAP: 0.50391    Loss: 3.111

2023-04-17 07:36:45,310 - ==> Best [mAP: 0.514787   vloss: 3.114535   Sparsity:0.00   Params: 2177088 on epoch: 108]
2023-04-17 07:36:45,310 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 07:36:45,346 - 

2023-04-17 07:36:45,346 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 07:36:56,351 - Epoch: [117][   50/  518]    Overall Loss 2.841024    Objective Loss 2.841024                                        LR 0.000063    Time 0.220046    
2023-04-17 07:37:06,405 - Epoch: [117][  100/  518]    Overall Loss 2.852262    Objective Loss 2.852262                                        LR 0.000063    Time 0.210543    
2023-04-17 07:37:16,504 - Epoch: [117][  150/  518]    Overall Loss 2.858163    Objective Loss 2.858163                                        LR 0.000063    Time 0.207679    
2023-04-17 07:37:26,657 - Epoch: [117][  200/  518]    Overall Loss 2.865980    Objective Loss 2.865980                                        LR 0.000063    Time 0.206517    
2023-04-17 07:37:36,832 - Epoch: [117][  250/  518]    Overall Loss 2.886486    Objective Loss 2.886486                                        LR 0.000063    Time 0.205909    
2023-04-17 07:37:46,888 - Epoch: [117][  300/  518]    Overall Loss 2.882147    Objective Loss 2.882147                                        LR 0.000063    Time 0.205104    
2023-04-17 07:37:56,977 - Epoch: [117][  350/  518]    Overall Loss 2.878124    Objective Loss 2.878124                                        LR 0.000063    Time 0.204625    
2023-04-17 07:38:07,188 - Epoch: [117][  400/  518]    Overall Loss 2.876069    Objective Loss 2.876069                                        LR 0.000063    Time 0.204571    
2023-04-17 07:38:17,237 - Epoch: [117][  450/  518]    Overall Loss 2.872224    Objective Loss 2.872224                                        LR 0.000063    Time 0.204168    
2023-04-17 07:38:27,365 - Epoch: [117][  500/  518]    Overall Loss 2.873465    Objective Loss 2.873465                                        LR 0.000063    Time 0.204005    
2023-04-17 07:38:30,832 - Epoch: [117][  518/  518]    Overall Loss 2.875633    Objective Loss 2.875633                                        LR 0.000063    Time 0.203607    
2023-04-17 07:38:30,914 - --- validate (epoch=117)-----------
2023-04-17 07:38:30,914 - 4952 samples (32 per mini-batch)
2023-04-17 07:39:15,621 - Epoch: [117][   50/  155]    Loss 3.074799    mAP 0.516530    
2023-04-17 07:39:58,991 - Epoch: [117][  100/  155]    Loss 3.073976    mAP 0.516600    
2023-04-17 07:40:45,774 - Epoch: [117][  150/  155]    Loss 3.101593    mAP 0.516844    
2023-04-17 07:40:50,481 - Epoch: [117][  155/  155]    Loss 3.102653    mAP 0.517068    
2023-04-17 07:40:50,563 - ==> mAP: 0.51707    Loss: 3.103

2023-04-17 07:40:50,567 - ==> Best [mAP: 0.517068   vloss: 3.102653   Sparsity:0.00   Params: 2177088 on epoch: 117]
2023-04-17 07:40:50,567 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 07:40:50,619 - 

2023-04-17 07:40:50,619 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 07:41:01,334 - Epoch: [118][   50/  518]    Overall Loss 2.873420    Objective Loss 2.873420                                        LR 0.000063    Time 0.214257    
2023-04-17 07:41:11,392 - Epoch: [118][  100/  518]    Overall Loss 2.871272    Objective Loss 2.871272                                        LR 0.000063    Time 0.207688    
2023-04-17 07:41:21,492 - Epoch: [118][  150/  518]    Overall Loss 2.864185    Objective Loss 2.864185                                        LR 0.000063    Time 0.205779    
2023-04-17 07:41:31,515 - Epoch: [118][  200/  518]    Overall Loss 2.877857    Objective Loss 2.877857                                        LR 0.000063    Time 0.204444    
2023-04-17 07:41:41,588 - Epoch: [118][  250/  518]    Overall Loss 2.880856    Objective Loss 2.880856                                        LR 0.000063    Time 0.203839    
2023-04-17 07:41:51,712 - Epoch: [118][  300/  518]    Overall Loss 2.883039    Objective Loss 2.883039                                        LR 0.000063    Time 0.203608    
2023-04-17 07:42:01,872 - Epoch: [118][  350/  518]    Overall Loss 2.889585    Objective Loss 2.889585                                        LR 0.000063    Time 0.203545    
2023-04-17 07:42:11,938 - Epoch: [118][  400/  518]    Overall Loss 2.886289    Objective Loss 2.886289                                        LR 0.000063    Time 0.203264    
2023-04-17 07:42:21,988 - Epoch: [118][  450/  518]    Overall Loss 2.883140    Objective Loss 2.883140                                        LR 0.000063    Time 0.203009    
2023-04-17 07:42:32,126 - Epoch: [118][  500/  518]    Overall Loss 2.878896    Objective Loss 2.878896                                        LR 0.000063    Time 0.202980    
2023-04-17 07:42:35,612 - Epoch: [118][  518/  518]    Overall Loss 2.879613    Objective Loss 2.879613                                        LR 0.000063    Time 0.202657    
2023-04-17 07:42:35,694 - --- validate (epoch=118)-----------
2023-04-17 07:42:35,694 - 4952 samples (32 per mini-batch)
2023-04-17 07:43:20,700 - Epoch: [118][   50/  155]    Loss 3.093470    mAP 0.504150    
2023-04-17 07:44:04,329 - Epoch: [118][  100/  155]    Loss 3.092523    mAP 0.513861    
2023-04-17 07:44:49,184 - Epoch: [118][  150/  155]    Loss 3.099675    mAP 0.512079    
2023-04-17 07:44:53,259 - Epoch: [118][  155/  155]    Loss 3.100788    mAP 0.512525    
2023-04-17 07:44:53,330 - ==> mAP: 0.51252    Loss: 3.101

2023-04-17 07:44:53,334 - ==> Best [mAP: 0.517068   vloss: 3.102653   Sparsity:0.00   Params: 2177088 on epoch: 117]
2023-04-17 07:44:53,334 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 07:44:53,370 - 

2023-04-17 07:44:53,370 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 07:45:04,099 - Epoch: [119][   50/  518]    Overall Loss 2.867663    Objective Loss 2.867663                                        LR 0.000063    Time 0.214527    
2023-04-17 07:45:14,252 - Epoch: [119][  100/  518]    Overall Loss 2.862260    Objective Loss 2.862260                                        LR 0.000063    Time 0.208777    
2023-04-17 07:45:24,323 - Epoch: [119][  150/  518]    Overall Loss 2.878094    Objective Loss 2.878094                                        LR 0.000063    Time 0.206310    
2023-04-17 07:45:34,411 - Epoch: [119][  200/  518]    Overall Loss 2.865359    Objective Loss 2.865359                                        LR 0.000063    Time 0.205168    
2023-04-17 07:45:44,575 - Epoch: [119][  250/  518]    Overall Loss 2.871715    Objective Loss 2.871715                                        LR 0.000063    Time 0.204782    
2023-04-17 07:45:54,641 - Epoch: [119][  300/  518]    Overall Loss 2.876428    Objective Loss 2.876428                                        LR 0.000063    Time 0.204201    
2023-04-17 07:46:04,707 - Epoch: [119][  350/  518]    Overall Loss 2.879945    Objective Loss 2.879945                                        LR 0.000063    Time 0.203785    
2023-04-17 07:46:14,817 - Epoch: [119][  400/  518]    Overall Loss 2.883003    Objective Loss 2.883003                                        LR 0.000063    Time 0.203583    
2023-04-17 07:46:24,911 - Epoch: [119][  450/  518]    Overall Loss 2.877676    Objective Loss 2.877676                                        LR 0.000063    Time 0.203389    
2023-04-17 07:46:34,998 - Epoch: [119][  500/  518]    Overall Loss 2.876168    Objective Loss 2.876168                                        LR 0.000063    Time 0.203222    
2023-04-17 07:46:38,515 - Epoch: [119][  518/  518]    Overall Loss 2.875194    Objective Loss 2.875194                                        LR 0.000063    Time 0.202948    
2023-04-17 07:46:38,594 - --- validate (epoch=119)-----------
2023-04-17 07:46:38,595 - 4952 samples (32 per mini-batch)
2023-04-17 07:47:23,113 - Epoch: [119][   50/  155]    Loss 3.084269    mAP 0.492714    
2023-04-17 07:48:08,691 - Epoch: [119][  100/  155]    Loss 3.106364    mAP 0.512703    
2023-04-17 07:48:53,032 - Epoch: [119][  150/  155]    Loss 3.102549    mAP 0.507515    
2023-04-17 07:48:57,457 - Epoch: [119][  155/  155]    Loss 3.105854    mAP 0.507762    
2023-04-17 07:48:57,538 - ==> mAP: 0.50776    Loss: 3.106

2023-04-17 07:48:57,541 - ==> Best [mAP: 0.517068   vloss: 3.102653   Sparsity:0.00   Params: 2177088 on epoch: 117]
2023-04-17 07:48:57,541 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 07:48:57,578 - 

2023-04-17 07:48:57,578 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 07:49:08,383 - Epoch: [120][   50/  518]    Overall Loss 2.888253    Objective Loss 2.888253                                        LR 0.000063    Time 0.216048    
2023-04-17 07:49:18,485 - Epoch: [120][  100/  518]    Overall Loss 2.877310    Objective Loss 2.877310                                        LR 0.000063    Time 0.209029    
2023-04-17 07:49:28,589 - Epoch: [120][  150/  518]    Overall Loss 2.884525    Objective Loss 2.884525                                        LR 0.000063    Time 0.206703    
2023-04-17 07:49:38,642 - Epoch: [120][  200/  518]    Overall Loss 2.894626    Objective Loss 2.894626                                        LR 0.000063    Time 0.205284    
2023-04-17 07:49:48,804 - Epoch: [120][  250/  518]    Overall Loss 2.891071    Objective Loss 2.891071                                        LR 0.000063    Time 0.204869    
2023-04-17 07:49:58,891 - Epoch: [120][  300/  518]    Overall Loss 2.888698    Objective Loss 2.888698                                        LR 0.000063    Time 0.204341    
2023-04-17 07:50:09,077 - Epoch: [120][  350/  518]    Overall Loss 2.888551    Objective Loss 2.888551                                        LR 0.000063    Time 0.204250    
2023-04-17 07:50:19,203 - Epoch: [120][  400/  518]    Overall Loss 2.881464    Objective Loss 2.881464                                        LR 0.000063    Time 0.204030    
2023-04-17 07:50:29,364 - Epoch: [120][  450/  518]    Overall Loss 2.876794    Objective Loss 2.876794                                        LR 0.000063    Time 0.203936    
2023-04-17 07:50:39,386 - Epoch: [120][  500/  518]    Overall Loss 2.874837    Objective Loss 2.874837                                        LR 0.000063    Time 0.203584    
2023-04-17 07:50:42,916 - Epoch: [120][  518/  518]    Overall Loss 2.875922    Objective Loss 2.875922                                        LR 0.000063    Time 0.203324    
2023-04-17 07:50:42,997 - --- validate (epoch=120)-----------
2023-04-17 07:50:42,998 - 4952 samples (32 per mini-batch)
2023-04-17 07:51:28,821 - Epoch: [120][   50/  155]    Loss 3.109361    mAP 0.512939    
2023-04-17 07:52:14,581 - Epoch: [120][  100/  155]    Loss 3.108407    mAP 0.506820    
2023-04-17 07:53:02,118 - Epoch: [120][  150/  155]    Loss 3.096382    mAP 0.508638    
2023-04-17 07:53:06,676 - Epoch: [120][  155/  155]    Loss 3.098915    mAP 0.507909    
2023-04-17 07:53:06,753 - ==> mAP: 0.50791    Loss: 3.099

2023-04-17 07:53:06,757 - ==> Best [mAP: 0.517068   vloss: 3.102653   Sparsity:0.00   Params: 2177088 on epoch: 117]
2023-04-17 07:53:06,757 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 07:53:06,793 - 

2023-04-17 07:53:06,793 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 07:53:17,575 - Epoch: [121][   50/  518]    Overall Loss 2.913314    Objective Loss 2.913314                                        LR 0.000063    Time 0.215567    
2023-04-17 07:53:27,663 - Epoch: [121][  100/  518]    Overall Loss 2.888735    Objective Loss 2.888735                                        LR 0.000063    Time 0.208655    
2023-04-17 07:53:37,670 - Epoch: [121][  150/  518]    Overall Loss 2.883155    Objective Loss 2.883155                                        LR 0.000063    Time 0.205807    
2023-04-17 07:53:47,770 - Epoch: [121][  200/  518]    Overall Loss 2.881569    Objective Loss 2.881569                                        LR 0.000063    Time 0.204846    
2023-04-17 07:53:57,828 - Epoch: [121][  250/  518]    Overall Loss 2.881780    Objective Loss 2.881780                                        LR 0.000063    Time 0.204100    
2023-04-17 07:54:07,872 - Epoch: [121][  300/  518]    Overall Loss 2.885448    Objective Loss 2.885448                                        LR 0.000063    Time 0.203560    
2023-04-17 07:54:17,929 - Epoch: [121][  350/  518]    Overall Loss 2.878454    Objective Loss 2.878454                                        LR 0.000063    Time 0.203210    
2023-04-17 07:54:27,969 - Epoch: [121][  400/  518]    Overall Loss 2.874659    Objective Loss 2.874659                                        LR 0.000063    Time 0.202904    
2023-04-17 07:54:37,983 - Epoch: [121][  450/  518]    Overall Loss 2.876261    Objective Loss 2.876261                                        LR 0.000063    Time 0.202609    
2023-04-17 07:54:48,110 - Epoch: [121][  500/  518]    Overall Loss 2.872677    Objective Loss 2.872677                                        LR 0.000063    Time 0.202599    
2023-04-17 07:54:51,612 - Epoch: [121][  518/  518]    Overall Loss 2.871462    Objective Loss 2.871462                                        LR 0.000063    Time 0.202318    
2023-04-17 07:54:51,690 - --- validate (epoch=121)-----------
2023-04-17 07:54:51,691 - 4952 samples (32 per mini-batch)
2023-04-17 07:55:36,403 - Epoch: [121][   50/  155]    Loss 3.156896    mAP 0.504001    
2023-04-17 07:56:22,058 - Epoch: [121][  100/  155]    Loss 3.117909    mAP 0.508370    
2023-04-17 07:57:06,068 - Epoch: [121][  150/  155]    Loss 3.105243    mAP 0.509350    
2023-04-17 07:57:10,406 - Epoch: [121][  155/  155]    Loss 3.103978    mAP 0.509211    
2023-04-17 07:57:10,485 - ==> mAP: 0.50921    Loss: 3.104

2023-04-17 07:57:10,489 - ==> Best [mAP: 0.517068   vloss: 3.102653   Sparsity:0.00   Params: 2177088 on epoch: 117]
2023-04-17 07:57:10,489 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 07:57:10,546 - 

2023-04-17 07:57:10,547 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 07:57:21,349 - Epoch: [122][   50/  518]    Overall Loss 2.809556    Objective Loss 2.809556                                        LR 0.000063    Time 0.215960    
2023-04-17 07:57:31,486 - Epoch: [122][  100/  518]    Overall Loss 2.814370    Objective Loss 2.814370                                        LR 0.000063    Time 0.209336    
2023-04-17 07:57:41,543 - Epoch: [122][  150/  518]    Overall Loss 2.832174    Objective Loss 2.832174                                        LR 0.000063    Time 0.206593    
2023-04-17 07:57:51,580 - Epoch: [122][  200/  518]    Overall Loss 2.841934    Objective Loss 2.841934                                        LR 0.000063    Time 0.205123    
2023-04-17 07:58:01,633 - Epoch: [122][  250/  518]    Overall Loss 2.848985    Objective Loss 2.848985                                        LR 0.000063    Time 0.204305    
2023-04-17 07:58:11,788 - Epoch: [122][  300/  518]    Overall Loss 2.857111    Objective Loss 2.857111                                        LR 0.000063    Time 0.204099    
2023-04-17 07:58:21,995 - Epoch: [122][  350/  518]    Overall Loss 2.864499    Objective Loss 2.864499                                        LR 0.000063    Time 0.204102    
2023-04-17 07:58:31,997 - Epoch: [122][  400/  518]    Overall Loss 2.859746    Objective Loss 2.859746                                        LR 0.000063    Time 0.203588    
2023-04-17 07:58:42,122 - Epoch: [122][  450/  518]    Overall Loss 2.858476    Objective Loss 2.858476                                        LR 0.000063    Time 0.203465    
2023-04-17 07:58:52,195 - Epoch: [122][  500/  518]    Overall Loss 2.862148    Objective Loss 2.862148                                        LR 0.000063    Time 0.203260    
2023-04-17 07:58:55,709 - Epoch: [122][  518/  518]    Overall Loss 2.868394    Objective Loss 2.868394                                        LR 0.000063    Time 0.202981    
2023-04-17 07:58:55,788 - --- validate (epoch=122)-----------
2023-04-17 07:58:55,788 - 4952 samples (32 per mini-batch)
2023-04-17 07:59:43,228 - Epoch: [122][   50/  155]    Loss 3.113262    mAP 0.504889    
2023-04-17 08:00:29,719 - Epoch: [122][  100/  155]    Loss 3.123179    mAP 0.504767    
2023-04-17 08:01:15,966 - Epoch: [122][  150/  155]    Loss 3.112103    mAP 0.508505    
2023-04-17 08:01:19,904 - Epoch: [122][  155/  155]    Loss 3.109616    mAP 0.506153    
2023-04-17 08:01:19,982 - ==> mAP: 0.50615    Loss: 3.110

2023-04-17 08:01:19,986 - ==> Best [mAP: 0.517068   vloss: 3.102653   Sparsity:0.00   Params: 2177088 on epoch: 117]
2023-04-17 08:01:19,986 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 08:01:20,022 - 

2023-04-17 08:01:20,022 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 08:01:30,988 - Epoch: [123][   50/  518]    Overall Loss 2.858396    Objective Loss 2.858396                                        LR 0.000063    Time 0.219261    
2023-04-17 08:01:41,097 - Epoch: [123][  100/  518]    Overall Loss 2.862357    Objective Loss 2.862357                                        LR 0.000063    Time 0.210704    
2023-04-17 08:01:51,191 - Epoch: [123][  150/  518]    Overall Loss 2.862343    Objective Loss 2.862343                                        LR 0.000063    Time 0.207753    
2023-04-17 08:02:01,194 - Epoch: [123][  200/  518]    Overall Loss 2.864748    Objective Loss 2.864748                                        LR 0.000063    Time 0.205823    
2023-04-17 08:02:11,301 - Epoch: [123][  250/  518]    Overall Loss 2.871184    Objective Loss 2.871184                                        LR 0.000063    Time 0.205080    
2023-04-17 08:02:21,421 - Epoch: [123][  300/  518]    Overall Loss 2.876904    Objective Loss 2.876904                                        LR 0.000063    Time 0.204627    
2023-04-17 08:02:31,504 - Epoch: [123][  350/  518]    Overall Loss 2.873542    Objective Loss 2.873542                                        LR 0.000063    Time 0.204200    
2023-04-17 08:02:41,555 - Epoch: [123][  400/  518]    Overall Loss 2.874996    Objective Loss 2.874996                                        LR 0.000063    Time 0.203797    
2023-04-17 08:02:51,710 - Epoch: [123][  450/  518]    Overall Loss 2.872241    Objective Loss 2.872241                                        LR 0.000063    Time 0.203716    
2023-04-17 08:03:01,820 - Epoch: [123][  500/  518]    Overall Loss 2.868341    Objective Loss 2.868341                                        LR 0.000063    Time 0.203562    
2023-04-17 08:03:05,290 - Epoch: [123][  518/  518]    Overall Loss 2.865494    Objective Loss 2.865494                                        LR 0.000063    Time 0.203186    
2023-04-17 08:03:05,369 - --- validate (epoch=123)-----------
2023-04-17 08:03:05,370 - 4952 samples (32 per mini-batch)
2023-04-17 08:03:49,974 - Epoch: [123][   50/  155]    Loss 3.127507    mAP 0.474127    
2023-04-17 08:04:35,322 - Epoch: [123][  100/  155]    Loss 3.095305    mAP 0.503251    
2023-04-17 08:05:21,644 - Epoch: [123][  150/  155]    Loss 3.099034    mAP 0.505478    
2023-04-17 08:05:26,137 - Epoch: [123][  155/  155]    Loss 3.095775    mAP 0.504592    
2023-04-17 08:05:26,210 - ==> mAP: 0.50459    Loss: 3.096

2023-04-17 08:05:26,215 - ==> Best [mAP: 0.517068   vloss: 3.102653   Sparsity:0.00   Params: 2177088 on epoch: 117]
2023-04-17 08:05:26,215 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 08:05:26,251 - 

2023-04-17 08:05:26,251 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 08:05:36,994 - Epoch: [124][   50/  518]    Overall Loss 2.866005    Objective Loss 2.866005                                        LR 0.000063    Time 0.214808    
2023-04-17 08:05:47,047 - Epoch: [124][  100/  518]    Overall Loss 2.893555    Objective Loss 2.893555                                        LR 0.000063    Time 0.207912    
2023-04-17 08:05:57,196 - Epoch: [124][  150/  518]    Overall Loss 2.905969    Objective Loss 2.905969                                        LR 0.000063    Time 0.206260    
2023-04-17 08:06:07,290 - Epoch: [124][  200/  518]    Overall Loss 2.893794    Objective Loss 2.893794                                        LR 0.000063    Time 0.205157    
2023-04-17 08:06:17,409 - Epoch: [124][  250/  518]    Overall Loss 2.888770    Objective Loss 2.888770                                        LR 0.000063    Time 0.204595    
2023-04-17 08:06:27,523 - Epoch: [124][  300/  518]    Overall Loss 2.882974    Objective Loss 2.882974                                        LR 0.000063    Time 0.204205    
2023-04-17 08:06:37,626 - Epoch: [124][  350/  518]    Overall Loss 2.869648    Objective Loss 2.869648                                        LR 0.000063    Time 0.203893    
2023-04-17 08:06:47,713 - Epoch: [124][  400/  518]    Overall Loss 2.871414    Objective Loss 2.871414                                        LR 0.000063    Time 0.203621    
2023-04-17 08:06:57,916 - Epoch: [124][  450/  518]    Overall Loss 2.867002    Objective Loss 2.867002                                        LR 0.000063    Time 0.203665    
2023-04-17 08:07:08,072 - Epoch: [124][  500/  518]    Overall Loss 2.863667    Objective Loss 2.863667                                        LR 0.000063    Time 0.203609    
2023-04-17 08:07:11,619 - Epoch: [124][  518/  518]    Overall Loss 2.864128    Objective Loss 2.864128                                        LR 0.000063    Time 0.203379    
2023-04-17 08:07:11,699 - --- validate (epoch=124)-----------
2023-04-17 08:07:11,700 - 4952 samples (32 per mini-batch)
2023-04-17 08:07:58,035 - Epoch: [124][   50/  155]    Loss 3.114255    mAP 0.508795    
2023-04-17 08:08:44,115 - Epoch: [124][  100/  155]    Loss 3.123538    mAP 0.510958    
2023-04-17 08:09:30,519 - Epoch: [124][  150/  155]    Loss 3.109033    mAP 0.512377    
2023-04-17 08:09:34,584 - Epoch: [124][  155/  155]    Loss 3.107337    mAP 0.510340    
2023-04-17 08:09:34,663 - ==> mAP: 0.51034    Loss: 3.107

2023-04-17 08:09:34,667 - ==> Best [mAP: 0.517068   vloss: 3.102653   Sparsity:0.00   Params: 2177088 on epoch: 117]
2023-04-17 08:09:34,667 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 08:09:34,704 - 

2023-04-17 08:09:34,704 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 08:09:45,705 - Epoch: [125][   50/  518]    Overall Loss 2.934851    Objective Loss 2.934851                                        LR 0.000063    Time 0.219976    
2023-04-17 08:09:55,796 - Epoch: [125][  100/  518]    Overall Loss 2.864018    Objective Loss 2.864018                                        LR 0.000063    Time 0.210883    
2023-04-17 08:10:05,810 - Epoch: [125][  150/  518]    Overall Loss 2.869092    Objective Loss 2.869092                                        LR 0.000063    Time 0.207338    
2023-04-17 08:10:15,946 - Epoch: [125][  200/  518]    Overall Loss 2.874924    Objective Loss 2.874924                                        LR 0.000063    Time 0.206172    
2023-04-17 08:10:25,996 - Epoch: [125][  250/  518]    Overall Loss 2.865751    Objective Loss 2.865751                                        LR 0.000063    Time 0.205135    
2023-04-17 08:10:36,089 - Epoch: [125][  300/  518]    Overall Loss 2.863662    Objective Loss 2.863662                                        LR 0.000063    Time 0.204584    
2023-04-17 08:10:46,193 - Epoch: [125][  350/  518]    Overall Loss 2.861427    Objective Loss 2.861427                                        LR 0.000063    Time 0.204220    
2023-04-17 08:10:56,255 - Epoch: [125][  400/  518]    Overall Loss 2.865510    Objective Loss 2.865510                                        LR 0.000063    Time 0.203844    
2023-04-17 08:11:06,353 - Epoch: [125][  450/  518]    Overall Loss 2.870355    Objective Loss 2.870355                                        LR 0.000063    Time 0.203633    
2023-04-17 08:11:16,471 - Epoch: [125][  500/  518]    Overall Loss 2.868159    Objective Loss 2.868159                                        LR 0.000063    Time 0.203502    
2023-04-17 08:11:19,990 - Epoch: [125][  518/  518]    Overall Loss 2.867925    Objective Loss 2.867925                                        LR 0.000063    Time 0.203223    
2023-04-17 08:11:20,071 - --- validate (epoch=125)-----------
2023-04-17 08:11:20,072 - 4952 samples (32 per mini-batch)
2023-04-17 08:12:06,049 - Epoch: [125][   50/  155]    Loss 3.064845    mAP 0.517859    
2023-04-17 08:12:52,812 - Epoch: [125][  100/  155]    Loss 3.074576    mAP 0.514563    
2023-04-17 08:13:39,050 - Epoch: [125][  150/  155]    Loss 3.108231    mAP 0.511591    
2023-04-17 08:13:43,042 - Epoch: [125][  155/  155]    Loss 3.109513    mAP 0.511282    
2023-04-17 08:13:43,117 - ==> mAP: 0.51128    Loss: 3.110

2023-04-17 08:13:43,121 - ==> Best [mAP: 0.517068   vloss: 3.102653   Sparsity:0.00   Params: 2177088 on epoch: 117]
2023-04-17 08:13:43,122 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 08:13:43,158 - 

2023-04-17 08:13:43,158 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 08:13:54,080 - Epoch: [126][   50/  518]    Overall Loss 2.871757    Objective Loss 2.871757                                        LR 0.000063    Time 0.218378    
2023-04-17 08:14:04,252 - Epoch: [126][  100/  518]    Overall Loss 2.871348    Objective Loss 2.871348                                        LR 0.000063    Time 0.210893    
2023-04-17 08:14:14,324 - Epoch: [126][  150/  518]    Overall Loss 2.873430    Objective Loss 2.873430                                        LR 0.000063    Time 0.207732    
2023-04-17 08:14:24,445 - Epoch: [126][  200/  518]    Overall Loss 2.861148    Objective Loss 2.861148                                        LR 0.000063    Time 0.206398    
2023-04-17 08:14:34,529 - Epoch: [126][  250/  518]    Overall Loss 2.856904    Objective Loss 2.856904                                        LR 0.000063    Time 0.205446    
2023-04-17 08:14:44,608 - Epoch: [126][  300/  518]    Overall Loss 2.851090    Objective Loss 2.851090                                        LR 0.000063    Time 0.204797    
2023-04-17 08:14:54,716 - Epoch: [126][  350/  518]    Overall Loss 2.861693    Objective Loss 2.861693                                        LR 0.000063    Time 0.204416    
2023-04-17 08:15:04,867 - Epoch: [126][  400/  518]    Overall Loss 2.856919    Objective Loss 2.856919                                        LR 0.000063    Time 0.204238    
2023-04-17 08:15:14,975 - Epoch: [126][  450/  518]    Overall Loss 2.864303    Objective Loss 2.864303                                        LR 0.000063    Time 0.204004    
2023-04-17 08:15:25,111 - Epoch: [126][  500/  518]    Overall Loss 2.861204    Objective Loss 2.861204                                        LR 0.000063    Time 0.203873    
2023-04-17 08:15:28,615 - Epoch: [126][  518/  518]    Overall Loss 2.862585    Objective Loss 2.862585                                        LR 0.000063    Time 0.203551    
2023-04-17 08:15:28,697 - --- validate (epoch=126)-----------
2023-04-17 08:15:28,697 - 4952 samples (32 per mini-batch)
2023-04-17 08:16:14,489 - Epoch: [126][   50/  155]    Loss 3.119028    mAP 0.513588    
2023-04-17 08:16:58,955 - Epoch: [126][  100/  155]    Loss 3.099239    mAP 0.517565    
2023-04-17 08:17:43,353 - Epoch: [126][  150/  155]    Loss 3.111354    mAP 0.515797    
2023-04-17 08:17:48,396 - Epoch: [126][  155/  155]    Loss 3.112929    mAP 0.515352    
2023-04-17 08:17:48,477 - ==> mAP: 0.51535    Loss: 3.113

2023-04-17 08:17:48,481 - ==> Best [mAP: 0.517068   vloss: 3.102653   Sparsity:0.00   Params: 2177088 on epoch: 117]
2023-04-17 08:17:48,481 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 08:17:48,517 - 

2023-04-17 08:17:48,517 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 08:17:59,367 - Epoch: [127][   50/  518]    Overall Loss 2.845159    Objective Loss 2.845159                                        LR 0.000063    Time 0.216924    
2023-04-17 08:18:09,465 - Epoch: [127][  100/  518]    Overall Loss 2.846241    Objective Loss 2.846241                                        LR 0.000063    Time 0.209429    
2023-04-17 08:18:19,491 - Epoch: [127][  150/  518]    Overall Loss 2.832966    Objective Loss 2.832966                                        LR 0.000063    Time 0.206450    
2023-04-17 08:18:29,557 - Epoch: [127][  200/  518]    Overall Loss 2.840917    Objective Loss 2.840917                                        LR 0.000063    Time 0.205159    
2023-04-17 08:18:39,718 - Epoch: [127][  250/  518]    Overall Loss 2.849419    Objective Loss 2.849419                                        LR 0.000063    Time 0.204765    
2023-04-17 08:18:49,814 - Epoch: [127][  300/  518]    Overall Loss 2.854666    Objective Loss 2.854666                                        LR 0.000063    Time 0.204286    
2023-04-17 08:18:59,904 - Epoch: [127][  350/  518]    Overall Loss 2.846913    Objective Loss 2.846913                                        LR 0.000063    Time 0.203927    
2023-04-17 08:19:10,044 - Epoch: [127][  400/  518]    Overall Loss 2.850582    Objective Loss 2.850582                                        LR 0.000063    Time 0.203782    
2023-04-17 08:19:20,181 - Epoch: [127][  450/  518]    Overall Loss 2.851432    Objective Loss 2.851432                                        LR 0.000063    Time 0.203662    
2023-04-17 08:19:30,231 - Epoch: [127][  500/  518]    Overall Loss 2.847601    Objective Loss 2.847601                                        LR 0.000063    Time 0.203393    
2023-04-17 08:19:33,708 - Epoch: [127][  518/  518]    Overall Loss 2.847093    Objective Loss 2.847093                                        LR 0.000063    Time 0.203036    
2023-04-17 08:19:33,788 - --- validate (epoch=127)-----------
2023-04-17 08:19:33,788 - 4952 samples (32 per mini-batch)
2023-04-17 08:20:17,770 - Epoch: [127][   50/  155]    Loss 3.145075    mAP 0.515945    
2023-04-17 08:21:00,406 - Epoch: [127][  100/  155]    Loss 3.110969    mAP 0.513558    
2023-04-17 08:21:45,206 - Epoch: [127][  150/  155]    Loss 3.111581    mAP 0.512342    
2023-04-17 08:21:49,385 - Epoch: [127][  155/  155]    Loss 3.114955    mAP 0.511502    
2023-04-17 08:21:49,463 - ==> mAP: 0.51150    Loss: 3.115

2023-04-17 08:21:49,467 - ==> Best [mAP: 0.517068   vloss: 3.102653   Sparsity:0.00   Params: 2177088 on epoch: 117]
2023-04-17 08:21:49,467 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 08:21:49,503 - 

2023-04-17 08:21:49,503 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 08:22:00,280 - Epoch: [128][   50/  518]    Overall Loss 2.910833    Objective Loss 2.910833                                        LR 0.000063    Time 0.215486    
2023-04-17 08:22:10,335 - Epoch: [128][  100/  518]    Overall Loss 2.891987    Objective Loss 2.891987                                        LR 0.000063    Time 0.208275    
2023-04-17 08:22:20,464 - Epoch: [128][  150/  518]    Overall Loss 2.900010    Objective Loss 2.900010                                        LR 0.000063    Time 0.206367    
2023-04-17 08:22:30,546 - Epoch: [128][  200/  518]    Overall Loss 2.897108    Objective Loss 2.897108                                        LR 0.000063    Time 0.205178    
2023-04-17 08:22:40,646 - Epoch: [128][  250/  518]    Overall Loss 2.892857    Objective Loss 2.892857                                        LR 0.000063    Time 0.204534    
2023-04-17 08:22:50,660 - Epoch: [128][  300/  518]    Overall Loss 2.878562    Objective Loss 2.878562                                        LR 0.000063    Time 0.203820    
2023-04-17 08:23:00,757 - Epoch: [128][  350/  518]    Overall Loss 2.872451    Objective Loss 2.872451                                        LR 0.000063    Time 0.203548    
2023-04-17 08:23:10,816 - Epoch: [128][  400/  518]    Overall Loss 2.868344    Objective Loss 2.868344                                        LR 0.000063    Time 0.203248    
2023-04-17 08:23:20,907 - Epoch: [128][  450/  518]    Overall Loss 2.869644    Objective Loss 2.869644                                        LR 0.000063    Time 0.203086    
2023-04-17 08:23:31,085 - Epoch: [128][  500/  518]    Overall Loss 2.870423    Objective Loss 2.870423                                        LR 0.000063    Time 0.203132    
2023-04-17 08:23:34,590 - Epoch: [128][  518/  518]    Overall Loss 2.871977    Objective Loss 2.871977                                        LR 0.000063    Time 0.202837    
2023-04-17 08:23:34,668 - --- validate (epoch=128)-----------
2023-04-17 08:23:34,669 - 4952 samples (32 per mini-batch)
2023-04-17 08:24:18,611 - Epoch: [128][   50/  155]    Loss 3.082617    mAP 0.515818    
2023-04-17 08:25:03,419 - Epoch: [128][  100/  155]    Loss 3.116388    mAP 0.509966    
2023-04-17 08:25:48,546 - Epoch: [128][  150/  155]    Loss 3.100353    mAP 0.512750    
2023-04-17 08:25:53,519 - Epoch: [128][  155/  155]    Loss 3.106131    mAP 0.510499    
2023-04-17 08:25:53,595 - ==> mAP: 0.51050    Loss: 3.106

2023-04-17 08:25:53,599 - ==> Best [mAP: 0.517068   vloss: 3.102653   Sparsity:0.00   Params: 2177088 on epoch: 117]
2023-04-17 08:25:53,599 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 08:25:53,635 - 

2023-04-17 08:25:53,635 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 08:26:04,447 - Epoch: [129][   50/  518]    Overall Loss 2.831478    Objective Loss 2.831478                                        LR 0.000063    Time 0.216182    
2023-04-17 08:26:14,561 - Epoch: [129][  100/  518]    Overall Loss 2.841110    Objective Loss 2.841110                                        LR 0.000063    Time 0.209213    
2023-04-17 08:26:24,644 - Epoch: [129][  150/  518]    Overall Loss 2.856916    Objective Loss 2.856916                                        LR 0.000063    Time 0.206686    
2023-04-17 08:26:34,706 - Epoch: [129][  200/  518]    Overall Loss 2.857553    Objective Loss 2.857553                                        LR 0.000063    Time 0.205319    
2023-04-17 08:26:44,837 - Epoch: [129][  250/  518]    Overall Loss 2.869197    Objective Loss 2.869197                                        LR 0.000063    Time 0.204771    
2023-04-17 08:26:54,916 - Epoch: [129][  300/  518]    Overall Loss 2.874791    Objective Loss 2.874791                                        LR 0.000063    Time 0.204234    
2023-04-17 08:27:05,009 - Epoch: [129][  350/  518]    Overall Loss 2.873680    Objective Loss 2.873680                                        LR 0.000063    Time 0.203891    
2023-04-17 08:27:15,131 - Epoch: [129][  400/  518]    Overall Loss 2.874895    Objective Loss 2.874895                                        LR 0.000063    Time 0.203705    
2023-04-17 08:27:25,260 - Epoch: [129][  450/  518]    Overall Loss 2.873344    Objective Loss 2.873344                                        LR 0.000063    Time 0.203577    
2023-04-17 08:27:35,352 - Epoch: [129][  500/  518]    Overall Loss 2.873149    Objective Loss 2.873149                                        LR 0.000063    Time 0.203399    
2023-04-17 08:27:38,905 - Epoch: [129][  518/  518]    Overall Loss 2.868620    Objective Loss 2.868620                                        LR 0.000063    Time 0.203191    
2023-04-17 08:27:38,986 - --- validate (epoch=129)-----------
2023-04-17 08:27:38,987 - 4952 samples (32 per mini-batch)
2023-04-17 08:28:23,538 - Epoch: [129][   50/  155]    Loss 3.075043    mAP 0.506892    
2023-04-17 08:29:09,529 - Epoch: [129][  100/  155]    Loss 3.116871    mAP 0.507480    
2023-04-17 08:29:56,348 - Epoch: [129][  150/  155]    Loss 3.110948    mAP 0.510677    
2023-04-17 08:30:00,606 - Epoch: [129][  155/  155]    Loss 3.111325    mAP 0.509334    
2023-04-17 08:30:00,686 - ==> mAP: 0.50933    Loss: 3.111

2023-04-17 08:30:00,690 - ==> Best [mAP: 0.517068   vloss: 3.102653   Sparsity:0.00   Params: 2177088 on epoch: 117]
2023-04-17 08:30:00,690 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 08:30:00,727 - 

2023-04-17 08:30:00,727 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 08:30:11,637 - Epoch: [130][   50/  518]    Overall Loss 2.829058    Objective Loss 2.829058                                        LR 0.000063    Time 0.218137    
2023-04-17 08:30:21,753 - Epoch: [130][  100/  518]    Overall Loss 2.845446    Objective Loss 2.845446                                        LR 0.000063    Time 0.210211    
2023-04-17 08:30:31,788 - Epoch: [130][  150/  518]    Overall Loss 2.849201    Objective Loss 2.849201                                        LR 0.000063    Time 0.207030    
2023-04-17 08:30:41,895 - Epoch: [130][  200/  518]    Overall Loss 2.843586    Objective Loss 2.843586                                        LR 0.000063    Time 0.205801    
2023-04-17 08:30:51,991 - Epoch: [130][  250/  518]    Overall Loss 2.849546    Objective Loss 2.849546                                        LR 0.000063    Time 0.205018    
2023-04-17 08:31:02,106 - Epoch: [130][  300/  518]    Overall Loss 2.852148    Objective Loss 2.852148                                        LR 0.000063    Time 0.204559    
2023-04-17 08:31:12,192 - Epoch: [130][  350/  518]    Overall Loss 2.860910    Objective Loss 2.860910                                        LR 0.000063    Time 0.204151    
2023-04-17 08:31:22,243 - Epoch: [130][  400/  518]    Overall Loss 2.855038    Objective Loss 2.855038                                        LR 0.000063    Time 0.203753    
2023-04-17 08:31:32,304 - Epoch: [130][  450/  518]    Overall Loss 2.862909    Objective Loss 2.862909                                        LR 0.000063    Time 0.203469    
2023-04-17 08:31:42,409 - Epoch: [130][  500/  518]    Overall Loss 2.858293    Objective Loss 2.858293                                        LR 0.000063    Time 0.203330    
2023-04-17 08:31:45,899 - Epoch: [130][  518/  518]    Overall Loss 2.860318    Objective Loss 2.860318                                        LR 0.000063    Time 0.203000    
2023-04-17 08:31:45,979 - --- validate (epoch=130)-----------
2023-04-17 08:31:45,980 - 4952 samples (32 per mini-batch)
2023-04-17 08:32:29,932 - Epoch: [130][   50/  155]    Loss 3.145483    mAP 0.510186    
2023-04-17 08:33:15,131 - Epoch: [130][  100/  155]    Loss 3.111644    mAP 0.518992    
2023-04-17 08:34:00,788 - Epoch: [130][  150/  155]    Loss 3.109312    mAP 0.513051    
2023-04-17 08:34:05,312 - Epoch: [130][  155/  155]    Loss 3.105189    mAP 0.514001    
2023-04-17 08:34:05,394 - ==> mAP: 0.51400    Loss: 3.105

2023-04-17 08:34:05,397 - ==> Best [mAP: 0.517068   vloss: 3.102653   Sparsity:0.00   Params: 2177088 on epoch: 117]
2023-04-17 08:34:05,398 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 08:34:05,434 - 

2023-04-17 08:34:05,434 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 08:34:16,492 - Epoch: [131][   50/  518]    Overall Loss 2.906838    Objective Loss 2.906838                                        LR 0.000063    Time 0.221106    
2023-04-17 08:34:26,679 - Epoch: [131][  100/  518]    Overall Loss 2.843144    Objective Loss 2.843144                                        LR 0.000063    Time 0.212410    
2023-04-17 08:34:36,795 - Epoch: [131][  150/  518]    Overall Loss 2.846830    Objective Loss 2.846830                                        LR 0.000063    Time 0.209034    
2023-04-17 08:34:46,838 - Epoch: [131][  200/  518]    Overall Loss 2.860029    Objective Loss 2.860029                                        LR 0.000063    Time 0.206982    
2023-04-17 08:34:56,965 - Epoch: [131][  250/  518]    Overall Loss 2.859293    Objective Loss 2.859293                                        LR 0.000063    Time 0.206089    
2023-04-17 08:35:07,164 - Epoch: [131][  300/  518]    Overall Loss 2.860272    Objective Loss 2.860272                                        LR 0.000063    Time 0.205732    
2023-04-17 08:35:17,279 - Epoch: [131][  350/  518]    Overall Loss 2.859743    Objective Loss 2.859743                                        LR 0.000063    Time 0.205237    
2023-04-17 08:35:27,376 - Epoch: [131][  400/  518]    Overall Loss 2.857008    Objective Loss 2.857008                                        LR 0.000063    Time 0.204822    
2023-04-17 08:35:37,442 - Epoch: [131][  450/  518]    Overall Loss 2.852675    Objective Loss 2.852675                                        LR 0.000063    Time 0.204429    
2023-04-17 08:35:47,498 - Epoch: [131][  500/  518]    Overall Loss 2.860951    Objective Loss 2.860951                                        LR 0.000063    Time 0.204095    
2023-04-17 08:35:50,979 - Epoch: [131][  518/  518]    Overall Loss 2.863106    Objective Loss 2.863106                                        LR 0.000063    Time 0.203723    
2023-04-17 08:35:51,061 - --- validate (epoch=131)-----------
2023-04-17 08:35:51,061 - 4952 samples (32 per mini-batch)
2023-04-17 08:36:38,981 - Epoch: [131][   50/  155]    Loss 3.091780    mAP 0.510778    
2023-04-17 08:37:25,908 - Epoch: [131][  100/  155]    Loss 3.099594    mAP 0.511716    
2023-04-17 08:38:12,421 - Epoch: [131][  150/  155]    Loss 3.106447    mAP 0.507345    
2023-04-17 08:38:16,721 - Epoch: [131][  155/  155]    Loss 3.104211    mAP 0.507862    
2023-04-17 08:38:16,800 - ==> mAP: 0.50786    Loss: 3.104

2023-04-17 08:38:16,803 - ==> Best [mAP: 0.517068   vloss: 3.102653   Sparsity:0.00   Params: 2177088 on epoch: 117]
2023-04-17 08:38:16,803 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 08:38:16,840 - 

2023-04-17 08:38:16,840 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 08:38:27,843 - Epoch: [132][   50/  518]    Overall Loss 2.879051    Objective Loss 2.879051                                        LR 0.000063    Time 0.220001    
2023-04-17 08:38:37,900 - Epoch: [132][  100/  518]    Overall Loss 2.879397    Objective Loss 2.879397                                        LR 0.000063    Time 0.210552    
2023-04-17 08:38:47,971 - Epoch: [132][  150/  518]    Overall Loss 2.863739    Objective Loss 2.863739                                        LR 0.000063    Time 0.207498    
2023-04-17 08:38:58,016 - Epoch: [132][  200/  518]    Overall Loss 2.863762    Objective Loss 2.863762                                        LR 0.000063    Time 0.205843    
2023-04-17 08:39:08,128 - Epoch: [132][  250/  518]    Overall Loss 2.857451    Objective Loss 2.857451                                        LR 0.000063    Time 0.205115    
2023-04-17 08:39:18,207 - Epoch: [132][  300/  518]    Overall Loss 2.848872    Objective Loss 2.848872                                        LR 0.000063    Time 0.204520    
2023-04-17 08:39:28,278 - Epoch: [132][  350/  518]    Overall Loss 2.849114    Objective Loss 2.849114                                        LR 0.000063    Time 0.204073    
2023-04-17 08:39:38,319 - Epoch: [132][  400/  518]    Overall Loss 2.848996    Objective Loss 2.848996                                        LR 0.000063    Time 0.203663    
2023-04-17 08:39:48,499 - Epoch: [132][  450/  518]    Overall Loss 2.855263    Objective Loss 2.855263                                        LR 0.000063    Time 0.203652    
2023-04-17 08:39:58,707 - Epoch: [132][  500/  518]    Overall Loss 2.853667    Objective Loss 2.853667                                        LR 0.000063    Time 0.203701    
2023-04-17 08:40:02,230 - Epoch: [132][  518/  518]    Overall Loss 2.856981    Objective Loss 2.856981                                        LR 0.000063    Time 0.203422    
2023-04-17 08:40:02,311 - --- validate (epoch=132)-----------
2023-04-17 08:40:02,311 - 4952 samples (32 per mini-batch)
2023-04-17 08:40:49,104 - Epoch: [132][   50/  155]    Loss 3.076862    mAP 0.506087    
2023-04-17 08:41:32,824 - Epoch: [132][  100/  155]    Loss 3.059352    mAP 0.511804    
2023-04-17 08:42:17,668 - Epoch: [132][  150/  155]    Loss 3.090659    mAP 0.508867    
2023-04-17 08:42:21,817 - Epoch: [132][  155/  155]    Loss 3.098025    mAP 0.505693    
2023-04-17 08:42:21,891 - ==> mAP: 0.50569    Loss: 3.098

2023-04-17 08:42:21,895 - ==> Best [mAP: 0.517068   vloss: 3.102653   Sparsity:0.00   Params: 2177088 on epoch: 117]
2023-04-17 08:42:21,895 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 08:42:21,931 - 

2023-04-17 08:42:21,931 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 08:42:32,736 - Epoch: [133][   50/  518]    Overall Loss 2.820552    Objective Loss 2.820552                                        LR 0.000063    Time 0.216039    
2023-04-17 08:42:42,799 - Epoch: [133][  100/  518]    Overall Loss 2.847343    Objective Loss 2.847343                                        LR 0.000063    Time 0.208641    
2023-04-17 08:42:52,775 - Epoch: [133][  150/  518]    Overall Loss 2.863800    Objective Loss 2.863800                                        LR 0.000063    Time 0.205586    
2023-04-17 08:43:02,845 - Epoch: [133][  200/  518]    Overall Loss 2.858037    Objective Loss 2.858037                                        LR 0.000063    Time 0.204532    
2023-04-17 08:43:12,968 - Epoch: [133][  250/  518]    Overall Loss 2.849202    Objective Loss 2.849202                                        LR 0.000063    Time 0.204113    
2023-04-17 08:43:23,101 - Epoch: [133][  300/  518]    Overall Loss 2.838937    Objective Loss 2.838937                                        LR 0.000063    Time 0.203865    
2023-04-17 08:43:33,149 - Epoch: [133][  350/  518]    Overall Loss 2.845460    Objective Loss 2.845460                                        LR 0.000063    Time 0.203446    
2023-04-17 08:43:43,261 - Epoch: [133][  400/  518]    Overall Loss 2.846205    Objective Loss 2.846205                                        LR 0.000063    Time 0.203290    
2023-04-17 08:43:53,386 - Epoch: [133][  450/  518]    Overall Loss 2.845769    Objective Loss 2.845769                                        LR 0.000063    Time 0.203201    
2023-04-17 08:44:03,542 - Epoch: [133][  500/  518]    Overall Loss 2.850529    Objective Loss 2.850529                                        LR 0.000063    Time 0.203188    
2023-04-17 08:44:07,058 - Epoch: [133][  518/  518]    Overall Loss 2.851395    Objective Loss 2.851395                                        LR 0.000063    Time 0.202914    
2023-04-17 08:44:07,135 - --- validate (epoch=133)-----------
2023-04-17 08:44:07,136 - 4952 samples (32 per mini-batch)
2023-04-17 08:44:52,835 - Epoch: [133][   50/  155]    Loss 3.114747    mAP 0.518678    
2023-04-17 08:45:39,219 - Epoch: [133][  100/  155]    Loss 3.114647    mAP 0.512217    
2023-04-17 08:46:23,509 - Epoch: [133][  150/  155]    Loss 3.090343    mAP 0.508248    
2023-04-17 08:46:28,088 - Epoch: [133][  155/  155]    Loss 3.091961    mAP 0.508453    
2023-04-17 08:46:28,167 - ==> mAP: 0.50845    Loss: 3.092

2023-04-17 08:46:28,171 - ==> Best [mAP: 0.517068   vloss: 3.102653   Sparsity:0.00   Params: 2177088 on epoch: 117]
2023-04-17 08:46:28,171 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 08:46:28,206 - 

2023-04-17 08:46:28,207 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 08:46:39,093 - Epoch: [134][   50/  518]    Overall Loss 2.863411    Objective Loss 2.863411                                        LR 0.000063    Time 0.217665    
2023-04-17 08:46:49,258 - Epoch: [134][  100/  518]    Overall Loss 2.855038    Objective Loss 2.855038                                        LR 0.000063    Time 0.210472    
2023-04-17 08:46:59,308 - Epoch: [134][  150/  518]    Overall Loss 2.868852    Objective Loss 2.868852                                        LR 0.000063    Time 0.207301    
2023-04-17 08:47:09,368 - Epoch: [134][  200/  518]    Overall Loss 2.868352    Objective Loss 2.868352                                        LR 0.000063    Time 0.205768    
2023-04-17 08:47:19,330 - Epoch: [134][  250/  518]    Overall Loss 2.861615    Objective Loss 2.861615                                        LR 0.000063    Time 0.204457    
2023-04-17 08:47:29,460 - Epoch: [134][  300/  518]    Overall Loss 2.862745    Objective Loss 2.862745                                        LR 0.000063    Time 0.204144    
2023-04-17 08:47:39,530 - Epoch: [134][  350/  518]    Overall Loss 2.867825    Objective Loss 2.867825                                        LR 0.000063    Time 0.203747    
2023-04-17 08:47:49,679 - Epoch: [134][  400/  518]    Overall Loss 2.869307    Objective Loss 2.869307                                        LR 0.000063    Time 0.203647    
2023-04-17 08:47:59,780 - Epoch: [134][  450/  518]    Overall Loss 2.868061    Objective Loss 2.868061                                        LR 0.000063    Time 0.203463    
2023-04-17 08:48:09,906 - Epoch: [134][  500/  518]    Overall Loss 2.865159    Objective Loss 2.865159                                        LR 0.000063    Time 0.203366    
2023-04-17 08:48:13,458 - Epoch: [134][  518/  518]    Overall Loss 2.867990    Objective Loss 2.867990                                        LR 0.000063    Time 0.203154    
2023-04-17 08:48:13,538 - --- validate (epoch=134)-----------
2023-04-17 08:48:13,538 - 4952 samples (32 per mini-batch)
2023-04-17 08:48:59,349 - Epoch: [134][   50/  155]    Loss 3.086745    mAP 0.486023    
2023-04-17 08:49:44,879 - Epoch: [134][  100/  155]    Loss 3.099764    mAP 0.497254    
2023-04-17 08:50:29,563 - Epoch: [134][  150/  155]    Loss 3.100163    mAP 0.501440    
2023-04-17 08:50:33,513 - Epoch: [134][  155/  155]    Loss 3.098080    mAP 0.502477    
2023-04-17 08:50:33,591 - ==> mAP: 0.50248    Loss: 3.098

2023-04-17 08:50:33,594 - ==> Best [mAP: 0.517068   vloss: 3.102653   Sparsity:0.00   Params: 2177088 on epoch: 117]
2023-04-17 08:50:33,594 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 08:50:33,630 - 

2023-04-17 08:50:33,630 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 08:50:44,653 - Epoch: [135][   50/  518]    Overall Loss 2.850038    Objective Loss 2.850038                                        LR 0.000063    Time 0.220397    
2023-04-17 08:50:54,757 - Epoch: [135][  100/  518]    Overall Loss 2.805468    Objective Loss 2.805468                                        LR 0.000063    Time 0.211229    
2023-04-17 08:51:04,881 - Epoch: [135][  150/  518]    Overall Loss 2.814616    Objective Loss 2.814616                                        LR 0.000063    Time 0.208302    
2023-04-17 08:51:14,953 - Epoch: [135][  200/  518]    Overall Loss 2.825778    Objective Loss 2.825778                                        LR 0.000063    Time 0.206577    
2023-04-17 08:51:25,042 - Epoch: [135][  250/  518]    Overall Loss 2.828708    Objective Loss 2.828708                                        LR 0.000063    Time 0.205612    
2023-04-17 08:51:35,121 - Epoch: [135][  300/  518]    Overall Loss 2.833094    Objective Loss 2.833094                                        LR 0.000063    Time 0.204934    
2023-04-17 08:51:45,317 - Epoch: [135][  350/  518]    Overall Loss 2.844304    Objective Loss 2.844304                                        LR 0.000063    Time 0.204785    
2023-04-17 08:51:55,434 - Epoch: [135][  400/  518]    Overall Loss 2.846928    Objective Loss 2.846928                                        LR 0.000063    Time 0.204477    
2023-04-17 08:52:05,575 - Epoch: [135][  450/  518]    Overall Loss 2.849680    Objective Loss 2.849680                                        LR 0.000063    Time 0.204289    
2023-04-17 08:52:15,676 - Epoch: [135][  500/  518]    Overall Loss 2.853385    Objective Loss 2.853385                                        LR 0.000063    Time 0.204058    
2023-04-17 08:52:19,225 - Epoch: [135][  518/  518]    Overall Loss 2.853640    Objective Loss 2.853640                                        LR 0.000063    Time 0.203818    
2023-04-17 08:52:19,305 - --- validate (epoch=135)-----------
2023-04-17 08:52:19,306 - 4952 samples (32 per mini-batch)
2023-04-17 08:53:04,326 - Epoch: [135][   50/  155]    Loss 3.083372    mAP 0.512072    
2023-04-17 08:53:47,993 - Epoch: [135][  100/  155]    Loss 3.089620    mAP 0.508579    
2023-04-17 08:54:32,523 - Epoch: [135][  150/  155]    Loss 3.098979    mAP 0.501285    
2023-04-17 08:54:36,068 - Epoch: [135][  155/  155]    Loss 3.097078    mAP 0.502342    
2023-04-17 08:54:36,145 - ==> mAP: 0.50234    Loss: 3.097

2023-04-17 08:54:36,150 - ==> Best [mAP: 0.517068   vloss: 3.102653   Sparsity:0.00   Params: 2177088 on epoch: 117]
2023-04-17 08:54:36,150 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 08:54:36,186 - 

2023-04-17 08:54:36,186 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 08:54:47,089 - Epoch: [136][   50/  518]    Overall Loss 2.908783    Objective Loss 2.908783                                        LR 0.000063    Time 0.218005    
2023-04-17 08:54:57,136 - Epoch: [136][  100/  518]    Overall Loss 2.881332    Objective Loss 2.881332                                        LR 0.000063    Time 0.209458    
2023-04-17 08:55:07,231 - Epoch: [136][  150/  518]    Overall Loss 2.871688    Objective Loss 2.871688                                        LR 0.000063    Time 0.206923    
2023-04-17 08:55:17,310 - Epoch: [136][  200/  518]    Overall Loss 2.866733    Objective Loss 2.866733                                        LR 0.000063    Time 0.205582    
2023-04-17 08:55:27,434 - Epoch: [136][  250/  518]    Overall Loss 2.856163    Objective Loss 2.856163                                        LR 0.000063    Time 0.204955    
2023-04-17 08:55:37,487 - Epoch: [136][  300/  518]    Overall Loss 2.859043    Objective Loss 2.859043                                        LR 0.000063    Time 0.204301    
2023-04-17 08:55:47,586 - Epoch: [136][  350/  518]    Overall Loss 2.856325    Objective Loss 2.856325                                        LR 0.000063    Time 0.203966    
2023-04-17 08:55:57,669 - Epoch: [136][  400/  518]    Overall Loss 2.860594    Objective Loss 2.860594                                        LR 0.000063    Time 0.203673    
2023-04-17 08:56:07,835 - Epoch: [136][  450/  518]    Overall Loss 2.861440    Objective Loss 2.861440                                        LR 0.000063    Time 0.203630    
2023-04-17 08:56:17,911 - Epoch: [136][  500/  518]    Overall Loss 2.863085    Objective Loss 2.863085                                        LR 0.000063    Time 0.203417    
2023-04-17 08:56:21,460 - Epoch: [136][  518/  518]    Overall Loss 2.863576    Objective Loss 2.863576                                        LR 0.000063    Time 0.203198    
2023-04-17 08:56:21,542 - --- validate (epoch=136)-----------
2023-04-17 08:56:21,542 - 4952 samples (32 per mini-batch)
2023-04-17 08:57:08,248 - Epoch: [136][   50/  155]    Loss 3.122165    mAP 0.504451    
2023-04-17 08:57:54,136 - Epoch: [136][  100/  155]    Loss 3.105970    mAP 0.510541    
2023-04-17 08:58:38,193 - Epoch: [136][  150/  155]    Loss 3.097887    mAP 0.511569    
2023-04-17 08:58:42,262 - Epoch: [136][  155/  155]    Loss 3.096239    mAP 0.510635    
2023-04-17 08:58:42,342 - ==> mAP: 0.51064    Loss: 3.096

2023-04-17 08:58:42,346 - ==> Best [mAP: 0.517068   vloss: 3.102653   Sparsity:0.00   Params: 2177088 on epoch: 117]
2023-04-17 08:58:42,346 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 08:58:42,382 - 

2023-04-17 08:58:42,382 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 08:58:53,179 - Epoch: [137][   50/  518]    Overall Loss 2.782147    Objective Loss 2.782147                                        LR 0.000063    Time 0.215888    
2023-04-17 08:59:03,333 - Epoch: [137][  100/  518]    Overall Loss 2.802166    Objective Loss 2.802166                                        LR 0.000063    Time 0.209467    
2023-04-17 08:59:13,431 - Epoch: [137][  150/  518]    Overall Loss 2.805119    Objective Loss 2.805119                                        LR 0.000063    Time 0.206952    
2023-04-17 08:59:23,518 - Epoch: [137][  200/  518]    Overall Loss 2.804669    Objective Loss 2.804669                                        LR 0.000063    Time 0.205644    
2023-04-17 08:59:33,586 - Epoch: [137][  250/  518]    Overall Loss 2.820444    Objective Loss 2.820444                                        LR 0.000063    Time 0.204781    
2023-04-17 08:59:43,706 - Epoch: [137][  300/  518]    Overall Loss 2.816616    Objective Loss 2.816616                                        LR 0.000063    Time 0.204378    
2023-04-17 08:59:53,776 - Epoch: [137][  350/  518]    Overall Loss 2.822919    Objective Loss 2.822919                                        LR 0.000063    Time 0.203948    
2023-04-17 09:00:03,773 - Epoch: [137][  400/  518]    Overall Loss 2.824425    Objective Loss 2.824425                                        LR 0.000063    Time 0.203443    
2023-04-17 09:00:13,832 - Epoch: [137][  450/  518]    Overall Loss 2.830214    Objective Loss 2.830214                                        LR 0.000063    Time 0.203189    
2023-04-17 09:00:23,935 - Epoch: [137][  500/  518]    Overall Loss 2.833731    Objective Loss 2.833731                                        LR 0.000063    Time 0.203073    
2023-04-17 09:00:27,435 - Epoch: [137][  518/  518]    Overall Loss 2.834812    Objective Loss 2.834812                                        LR 0.000063    Time 0.202773    
2023-04-17 09:00:27,513 - --- validate (epoch=137)-----------
2023-04-17 09:00:27,514 - 4952 samples (32 per mini-batch)
2023-04-17 09:01:11,295 - Epoch: [137][   50/  155]    Loss 3.117737    mAP 0.502892    
2023-04-17 09:01:55,064 - Epoch: [137][  100/  155]    Loss 3.112778    mAP 0.503978    
2023-04-17 09:02:37,849 - Epoch: [137][  150/  155]    Loss 3.096857    mAP 0.507472    
2023-04-17 09:02:41,114 - Epoch: [137][  155/  155]    Loss 3.093236    mAP 0.506612    
2023-04-17 09:02:41,192 - ==> mAP: 0.50661    Loss: 3.093

2023-04-17 09:02:41,196 - ==> Best [mAP: 0.517068   vloss: 3.102653   Sparsity:0.00   Params: 2177088 on epoch: 117]
2023-04-17 09:02:41,196 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 09:02:41,232 - 

2023-04-17 09:02:41,233 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 09:02:52,063 - Epoch: [138][   50/  518]    Overall Loss 2.828703    Objective Loss 2.828703                                        LR 0.000063    Time 0.216555    
2023-04-17 09:03:02,215 - Epoch: [138][  100/  518]    Overall Loss 2.823448    Objective Loss 2.823448                                        LR 0.000063    Time 0.209778    
2023-04-17 09:03:12,344 - Epoch: [138][  150/  518]    Overall Loss 2.834792    Objective Loss 2.834792                                        LR 0.000063    Time 0.207372    
2023-04-17 09:03:22,424 - Epoch: [138][  200/  518]    Overall Loss 2.843613    Objective Loss 2.843613                                        LR 0.000063    Time 0.205922    
2023-04-17 09:03:32,647 - Epoch: [138][  250/  518]    Overall Loss 2.833944    Objective Loss 2.833944                                        LR 0.000063    Time 0.205621    
2023-04-17 09:03:42,789 - Epoch: [138][  300/  518]    Overall Loss 2.846456    Objective Loss 2.846456                                        LR 0.000063    Time 0.205155    
2023-04-17 09:03:52,897 - Epoch: [138][  350/  518]    Overall Loss 2.850288    Objective Loss 2.850288                                        LR 0.000063    Time 0.204722    
2023-04-17 09:04:02,991 - Epoch: [138][  400/  518]    Overall Loss 2.848960    Objective Loss 2.848960                                        LR 0.000063    Time 0.204362    
2023-04-17 09:04:13,116 - Epoch: [138][  450/  518]    Overall Loss 2.847335    Objective Loss 2.847335                                        LR 0.000063    Time 0.204153    
2023-04-17 09:04:23,287 - Epoch: [138][  500/  518]    Overall Loss 2.843316    Objective Loss 2.843316                                        LR 0.000063    Time 0.204075    
2023-04-17 09:04:26,791 - Epoch: [138][  518/  518]    Overall Loss 2.846747    Objective Loss 2.846747                                        LR 0.000063    Time 0.203747    
2023-04-17 09:04:26,874 - --- validate (epoch=138)-----------
2023-04-17 09:04:26,874 - 4952 samples (32 per mini-batch)
2023-04-17 09:05:11,845 - Epoch: [138][   50/  155]    Loss 3.057688    mAP 0.513141    
2023-04-17 09:05:56,464 - Epoch: [138][  100/  155]    Loss 3.107706    mAP 0.502615    
2023-04-17 09:06:40,767 - Epoch: [138][  150/  155]    Loss 3.091287    mAP 0.500323    
2023-04-17 09:06:44,952 - Epoch: [138][  155/  155]    Loss 3.091366    mAP 0.500444    
2023-04-17 09:06:45,044 - ==> mAP: 0.50044    Loss: 3.091

2023-04-17 09:06:45,048 - ==> Best [mAP: 0.517068   vloss: 3.102653   Sparsity:0.00   Params: 2177088 on epoch: 117]
2023-04-17 09:06:45,048 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 09:06:45,084 - 

2023-04-17 09:06:45,084 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 09:06:56,103 - Epoch: [139][   50/  518]    Overall Loss 2.804123    Objective Loss 2.804123                                        LR 0.000063    Time 0.220330    
2023-04-17 09:07:06,284 - Epoch: [139][  100/  518]    Overall Loss 2.843227    Objective Loss 2.843227                                        LR 0.000063    Time 0.211957    
2023-04-17 09:07:16,377 - Epoch: [139][  150/  518]    Overall Loss 2.845242    Objective Loss 2.845242                                        LR 0.000063    Time 0.208583    
2023-04-17 09:07:26,528 - Epoch: [139][  200/  518]    Overall Loss 2.859611    Objective Loss 2.859611                                        LR 0.000063    Time 0.207184    
2023-04-17 09:07:36,606 - Epoch: [139][  250/  518]    Overall Loss 2.846055    Objective Loss 2.846055                                        LR 0.000063    Time 0.206054    
2023-04-17 09:07:46,654 - Epoch: [139][  300/  518]    Overall Loss 2.851292    Objective Loss 2.851292                                        LR 0.000063    Time 0.205200    
2023-04-17 09:07:56,711 - Epoch: [139][  350/  518]    Overall Loss 2.846351    Objective Loss 2.846351                                        LR 0.000063    Time 0.204615    
2023-04-17 09:08:06,776 - Epoch: [139][  400/  518]    Overall Loss 2.850125    Objective Loss 2.850125                                        LR 0.000063    Time 0.204198    
2023-04-17 09:08:16,920 - Epoch: [139][  450/  518]    Overall Loss 2.846640    Objective Loss 2.846640                                        LR 0.000063    Time 0.204048    
2023-04-17 09:08:27,032 - Epoch: [139][  500/  518]    Overall Loss 2.852999    Objective Loss 2.852999                                        LR 0.000063    Time 0.203863    
2023-04-17 09:08:30,529 - Epoch: [139][  518/  518]    Overall Loss 2.854712    Objective Loss 2.854712                                        LR 0.000063    Time 0.203530    
2023-04-17 09:08:30,610 - --- validate (epoch=139)-----------
2023-04-17 09:08:30,610 - 4952 samples (32 per mini-batch)
2023-04-17 09:09:15,225 - Epoch: [139][   50/  155]    Loss 3.101543    mAP 0.507361    
2023-04-17 09:10:00,530 - Epoch: [139][  100/  155]    Loss 3.114523    mAP 0.509192    
2023-04-17 09:10:43,360 - Epoch: [139][  150/  155]    Loss 3.096911    mAP 0.512707    
2023-04-17 09:10:47,238 - Epoch: [139][  155/  155]    Loss 3.098412    mAP 0.512055    
2023-04-17 09:10:47,317 - ==> mAP: 0.51206    Loss: 3.098

2023-04-17 09:10:47,321 - ==> Best [mAP: 0.517068   vloss: 3.102653   Sparsity:0.00   Params: 2177088 on epoch: 117]
2023-04-17 09:10:47,321 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 09:10:47,357 - 

2023-04-17 09:10:47,357 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 09:10:58,274 - Epoch: [140][   50/  518]    Overall Loss 2.834044    Objective Loss 2.834044                                        LR 0.000063    Time 0.218280    
2023-04-17 09:11:08,444 - Epoch: [140][  100/  518]    Overall Loss 2.850994    Objective Loss 2.850994                                        LR 0.000063    Time 0.210824    
2023-04-17 09:11:18,629 - Epoch: [140][  150/  518]    Overall Loss 2.869267    Objective Loss 2.869267                                        LR 0.000063    Time 0.208439    
2023-04-17 09:11:28,726 - Epoch: [140][  200/  518]    Overall Loss 2.872141    Objective Loss 2.872141                                        LR 0.000063    Time 0.206806    
2023-04-17 09:11:38,847 - Epoch: [140][  250/  518]    Overall Loss 2.865723    Objective Loss 2.865723                                        LR 0.000063    Time 0.205925    
2023-04-17 09:11:48,991 - Epoch: [140][  300/  518]    Overall Loss 2.875174    Objective Loss 2.875174                                        LR 0.000063    Time 0.205411    
2023-04-17 09:11:59,079 - Epoch: [140][  350/  518]    Overall Loss 2.871175    Objective Loss 2.871175                                        LR 0.000063    Time 0.204886    
2023-04-17 09:12:09,232 - Epoch: [140][  400/  518]    Overall Loss 2.859001    Objective Loss 2.859001                                        LR 0.000063    Time 0.204653    
2023-04-17 09:12:19,278 - Epoch: [140][  450/  518]    Overall Loss 2.861859    Objective Loss 2.861859                                        LR 0.000063    Time 0.204236    
2023-04-17 09:12:29,398 - Epoch: [140][  500/  518]    Overall Loss 2.864006    Objective Loss 2.864006                                        LR 0.000063    Time 0.204049    
2023-04-17 09:12:32,961 - Epoch: [140][  518/  518]    Overall Loss 2.864704    Objective Loss 2.864704                                        LR 0.000063    Time 0.203835    
2023-04-17 09:12:33,042 - --- validate (epoch=140)-----------
2023-04-17 09:12:33,042 - 4952 samples (32 per mini-batch)
2023-04-17 09:13:17,532 - Epoch: [140][   50/  155]    Loss 3.072308    mAP 0.524643    
2023-04-17 09:14:03,548 - Epoch: [140][  100/  155]    Loss 3.077245    mAP 0.524762    
2023-04-17 09:14:49,848 - Epoch: [140][  150/  155]    Loss 3.093450    mAP 0.516967    
2023-04-17 09:14:53,964 - Epoch: [140][  155/  155]    Loss 3.091865    mAP 0.516169    
2023-04-17 09:14:54,054 - ==> mAP: 0.51617    Loss: 3.092

2023-04-17 09:14:54,058 - ==> Best [mAP: 0.517068   vloss: 3.102653   Sparsity:0.00   Params: 2177088 on epoch: 117]
2023-04-17 09:14:54,058 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 09:14:54,096 - 

2023-04-17 09:14:54,096 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 09:15:04,947 - Epoch: [141][   50/  518]    Overall Loss 2.874426    Objective Loss 2.874426                                        LR 0.000063    Time 0.216968    
2023-04-17 09:15:14,975 - Epoch: [141][  100/  518]    Overall Loss 2.870256    Objective Loss 2.870256                                        LR 0.000063    Time 0.208744    
2023-04-17 09:15:25,018 - Epoch: [141][  150/  518]    Overall Loss 2.848870    Objective Loss 2.848870                                        LR 0.000063    Time 0.206109    
2023-04-17 09:15:35,099 - Epoch: [141][  200/  518]    Overall Loss 2.859836    Objective Loss 2.859836                                        LR 0.000063    Time 0.204977    
2023-04-17 09:15:45,287 - Epoch: [141][  250/  518]    Overall Loss 2.850860    Objective Loss 2.850860                                        LR 0.000063    Time 0.204730    
2023-04-17 09:15:55,356 - Epoch: [141][  300/  518]    Overall Loss 2.852287    Objective Loss 2.852287                                        LR 0.000063    Time 0.204165    
2023-04-17 09:16:05,494 - Epoch: [141][  350/  518]    Overall Loss 2.853982    Objective Loss 2.853982                                        LR 0.000063    Time 0.203960    
2023-04-17 09:16:15,623 - Epoch: [141][  400/  518]    Overall Loss 2.849306    Objective Loss 2.849306                                        LR 0.000063    Time 0.203782    
2023-04-17 09:16:25,662 - Epoch: [141][  450/  518]    Overall Loss 2.849535    Objective Loss 2.849535                                        LR 0.000063    Time 0.203446    
2023-04-17 09:16:35,774 - Epoch: [141][  500/  518]    Overall Loss 2.849411    Objective Loss 2.849411                                        LR 0.000063    Time 0.203322    
2023-04-17 09:16:39,312 - Epoch: [141][  518/  518]    Overall Loss 2.851953    Objective Loss 2.851953                                        LR 0.000063    Time 0.203087    
2023-04-17 09:16:39,396 - --- validate (epoch=141)-----------
2023-04-17 09:16:39,396 - 4952 samples (32 per mini-batch)
2023-04-17 09:17:25,474 - Epoch: [141][   50/  155]    Loss 3.044018    mAP 0.508135    
2023-04-17 09:18:10,147 - Epoch: [141][  100/  155]    Loss 3.061384    mAP 0.522024    
2023-04-17 09:18:54,132 - Epoch: [141][  150/  155]    Loss 3.080883    mAP 0.516140    
2023-04-17 09:18:58,200 - Epoch: [141][  155/  155]    Loss 3.076723    mAP 0.516798    
2023-04-17 09:18:58,279 - ==> mAP: 0.51680    Loss: 3.077

2023-04-17 09:18:58,283 - ==> Best [mAP: 0.517068   vloss: 3.102653   Sparsity:0.00   Params: 2177088 on epoch: 117]
2023-04-17 09:18:58,283 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 09:18:58,319 - 

2023-04-17 09:18:58,319 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 09:19:09,193 - Epoch: [142][   50/  518]    Overall Loss 2.829841    Objective Loss 2.829841                                        LR 0.000063    Time 0.217414    
2023-04-17 09:19:19,194 - Epoch: [142][  100/  518]    Overall Loss 2.836140    Objective Loss 2.836140                                        LR 0.000063    Time 0.208702    
2023-04-17 09:19:29,298 - Epoch: [142][  150/  518]    Overall Loss 2.827595    Objective Loss 2.827595                                        LR 0.000063    Time 0.206484    
2023-04-17 09:19:39,399 - Epoch: [142][  200/  518]    Overall Loss 2.830574    Objective Loss 2.830574                                        LR 0.000063    Time 0.205364    
2023-04-17 09:19:49,525 - Epoch: [142][  250/  518]    Overall Loss 2.836585    Objective Loss 2.836585                                        LR 0.000063    Time 0.204787    
2023-04-17 09:19:59,647 - Epoch: [142][  300/  518]    Overall Loss 2.844206    Objective Loss 2.844206                                        LR 0.000063    Time 0.204392    
2023-04-17 09:20:09,702 - Epoch: [142][  350/  518]    Overall Loss 2.846239    Objective Loss 2.846239                                        LR 0.000063    Time 0.203916    
2023-04-17 09:20:19,853 - Epoch: [142][  400/  518]    Overall Loss 2.842129    Objective Loss 2.842129                                        LR 0.000063    Time 0.203801    
2023-04-17 09:20:30,016 - Epoch: [142][  450/  518]    Overall Loss 2.842586    Objective Loss 2.842586                                        LR 0.000063    Time 0.203737    
2023-04-17 09:20:40,159 - Epoch: [142][  500/  518]    Overall Loss 2.842973    Objective Loss 2.842973                                        LR 0.000063    Time 0.203648    
2023-04-17 09:20:43,673 - Epoch: [142][  518/  518]    Overall Loss 2.844675    Objective Loss 2.844675                                        LR 0.000063    Time 0.203353    
2023-04-17 09:20:43,753 - --- validate (epoch=142)-----------
2023-04-17 09:20:43,753 - 4952 samples (32 per mini-batch)
2023-04-17 09:21:27,947 - Epoch: [142][   50/  155]    Loss 3.116365    mAP 0.513189    
2023-04-17 09:22:12,878 - Epoch: [142][  100/  155]    Loss 3.096831    mAP 0.505100    
2023-04-17 09:22:58,024 - Epoch: [142][  150/  155]    Loss 3.094596    mAP 0.506148    
2023-04-17 09:23:02,674 - Epoch: [142][  155/  155]    Loss 3.093667    mAP 0.505871    
2023-04-17 09:23:02,753 - ==> mAP: 0.50587    Loss: 3.094

2023-04-17 09:23:02,757 - ==> Best [mAP: 0.517068   vloss: 3.102653   Sparsity:0.00   Params: 2177088 on epoch: 117]
2023-04-17 09:23:02,757 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 09:23:02,793 - 

2023-04-17 09:23:02,793 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 09:23:13,836 - Epoch: [143][   50/  518]    Overall Loss 2.813697    Objective Loss 2.813697                                        LR 0.000063    Time 0.220800    
2023-04-17 09:23:23,957 - Epoch: [143][  100/  518]    Overall Loss 2.829803    Objective Loss 2.829803                                        LR 0.000063    Time 0.211598    
2023-04-17 09:23:33,956 - Epoch: [143][  150/  518]    Overall Loss 2.830693    Objective Loss 2.830693                                        LR 0.000063    Time 0.207710    
2023-04-17 09:23:44,102 - Epoch: [143][  200/  518]    Overall Loss 2.850470    Objective Loss 2.850470                                        LR 0.000063    Time 0.206506    
2023-04-17 09:23:54,210 - Epoch: [143][  250/  518]    Overall Loss 2.860655    Objective Loss 2.860655                                        LR 0.000063    Time 0.205630    
2023-04-17 09:24:04,307 - Epoch: [143][  300/  518]    Overall Loss 2.857286    Objective Loss 2.857286                                        LR 0.000063    Time 0.205012    
2023-04-17 09:24:14,355 - Epoch: [143][  350/  518]    Overall Loss 2.852569    Objective Loss 2.852569                                        LR 0.000063    Time 0.204428    
2023-04-17 09:24:24,433 - Epoch: [143][  400/  518]    Overall Loss 2.856288    Objective Loss 2.856288                                        LR 0.000063    Time 0.204065    
2023-04-17 09:24:34,527 - Epoch: [143][  450/  518]    Overall Loss 2.855696    Objective Loss 2.855696                                        LR 0.000063    Time 0.203819    
2023-04-17 09:24:44,601 - Epoch: [143][  500/  518]    Overall Loss 2.855655    Objective Loss 2.855655                                        LR 0.000063    Time 0.203582    
2023-04-17 09:24:48,096 - Epoch: [143][  518/  518]    Overall Loss 2.853568    Objective Loss 2.853568                                        LR 0.000063    Time 0.203254    
2023-04-17 09:24:48,177 - --- validate (epoch=143)-----------
2023-04-17 09:24:48,177 - 4952 samples (32 per mini-batch)
2023-04-17 09:25:31,789 - Epoch: [143][   50/  155]    Loss 3.100018    mAP 0.514214    
2023-04-17 09:26:14,628 - Epoch: [143][  100/  155]    Loss 3.112448    mAP 0.508481    
2023-04-17 09:26:56,328 - Epoch: [143][  150/  155]    Loss 3.100132    mAP 0.508144    
2023-04-17 09:26:59,980 - Epoch: [143][  155/  155]    Loss 3.096344    mAP 0.509014    
2023-04-17 09:27:00,058 - ==> mAP: 0.50901    Loss: 3.096

2023-04-17 09:27:00,062 - ==> Best [mAP: 0.517068   vloss: 3.102653   Sparsity:0.00   Params: 2177088 on epoch: 117]
2023-04-17 09:27:00,062 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 09:27:00,099 - 

2023-04-17 09:27:00,099 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 09:27:10,931 - Epoch: [144][   50/  518]    Overall Loss 2.870736    Objective Loss 2.870736                                        LR 0.000063    Time 0.216584    
2023-04-17 09:27:20,987 - Epoch: [144][  100/  518]    Overall Loss 2.850618    Objective Loss 2.850618                                        LR 0.000063    Time 0.208840    
2023-04-17 09:27:31,045 - Epoch: [144][  150/  518]    Overall Loss 2.859682    Objective Loss 2.859682                                        LR 0.000063    Time 0.206268    
2023-04-17 09:27:41,261 - Epoch: [144][  200/  518]    Overall Loss 2.851679    Objective Loss 2.851679                                        LR 0.000063    Time 0.205775    
2023-04-17 09:27:51,357 - Epoch: [144][  250/  518]    Overall Loss 2.853475    Objective Loss 2.853475                                        LR 0.000063    Time 0.204999    
2023-04-17 09:28:01,487 - Epoch: [144][  300/  518]    Overall Loss 2.850721    Objective Loss 2.850721                                        LR 0.000063    Time 0.204594    
2023-04-17 09:28:11,537 - Epoch: [144][  350/  518]    Overall Loss 2.847716    Objective Loss 2.847716                                        LR 0.000063    Time 0.204075    
2023-04-17 09:28:21,709 - Epoch: [144][  400/  518]    Overall Loss 2.843062    Objective Loss 2.843062                                        LR 0.000063    Time 0.203992    
2023-04-17 09:28:31,781 - Epoch: [144][  450/  518]    Overall Loss 2.840014    Objective Loss 2.840014                                        LR 0.000063    Time 0.203705    
2023-04-17 09:28:41,833 - Epoch: [144][  500/  518]    Overall Loss 2.840345    Objective Loss 2.840345                                        LR 0.000063    Time 0.203436    
2023-04-17 09:28:45,333 - Epoch: [144][  518/  518]    Overall Loss 2.841609    Objective Loss 2.841609                                        LR 0.000063    Time 0.203122    
2023-04-17 09:28:45,412 - --- validate (epoch=144)-----------
2023-04-17 09:28:45,412 - 4952 samples (32 per mini-batch)
2023-04-17 09:29:28,202 - Epoch: [144][   50/  155]    Loss 3.087386    mAP 0.488098    
2023-04-17 09:30:13,003 - Epoch: [144][  100/  155]    Loss 3.095477    mAP 0.495779    
2023-04-17 09:30:56,992 - Epoch: [144][  150/  155]    Loss 3.097427    mAP 0.504458    
2023-04-17 09:31:01,167 - Epoch: [144][  155/  155]    Loss 3.094214    mAP 0.507268    
2023-04-17 09:31:01,244 - ==> mAP: 0.50727    Loss: 3.094

2023-04-17 09:31:01,249 - ==> Best [mAP: 0.517068   vloss: 3.102653   Sparsity:0.00   Params: 2177088 on epoch: 117]
2023-04-17 09:31:01,249 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 09:31:01,285 - 

2023-04-17 09:31:01,285 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 09:31:12,089 - Epoch: [145][   50/  518]    Overall Loss 2.868080    Objective Loss 2.868080                                        LR 0.000063    Time 0.216024    
2023-04-17 09:31:22,210 - Epoch: [145][  100/  518]    Overall Loss 2.857789    Objective Loss 2.857789                                        LR 0.000063    Time 0.209206    
2023-04-17 09:31:32,300 - Epoch: [145][  150/  518]    Overall Loss 2.841325    Objective Loss 2.841325                                        LR 0.000063    Time 0.206726    
2023-04-17 09:31:42,387 - Epoch: [145][  200/  518]    Overall Loss 2.843127    Objective Loss 2.843127                                        LR 0.000063    Time 0.205472    
2023-04-17 09:31:52,497 - Epoch: [145][  250/  518]    Overall Loss 2.849841    Objective Loss 2.849841                                        LR 0.000063    Time 0.204814    
2023-04-17 09:32:02,686 - Epoch: [145][  300/  518]    Overall Loss 2.850029    Objective Loss 2.850029                                        LR 0.000063    Time 0.204635    
2023-04-17 09:32:12,747 - Epoch: [145][  350/  518]    Overall Loss 2.852525    Objective Loss 2.852525                                        LR 0.000063    Time 0.204143    
2023-04-17 09:32:22,806 - Epoch: [145][  400/  518]    Overall Loss 2.857592    Objective Loss 2.857592                                        LR 0.000063    Time 0.203768    
2023-04-17 09:32:32,889 - Epoch: [145][  450/  518]    Overall Loss 2.860548    Objective Loss 2.860548                                        LR 0.000063    Time 0.203530    
2023-04-17 09:32:43,047 - Epoch: [145][  500/  518]    Overall Loss 2.860350    Objective Loss 2.860350                                        LR 0.000063    Time 0.203489    
2023-04-17 09:32:46,588 - Epoch: [145][  518/  518]    Overall Loss 2.860998    Objective Loss 2.860998                                        LR 0.000063    Time 0.203254    
2023-04-17 09:32:46,668 - --- validate (epoch=145)-----------
2023-04-17 09:32:46,669 - 4952 samples (32 per mini-batch)
2023-04-17 09:33:31,211 - Epoch: [145][   50/  155]    Loss 3.122944    mAP 0.503985    
2023-04-17 09:34:17,155 - Epoch: [145][  100/  155]    Loss 3.112451    mAP 0.510307    
2023-04-17 09:35:02,128 - Epoch: [145][  150/  155]    Loss 3.093170    mAP 0.511506    
2023-04-17 09:35:05,975 - Epoch: [145][  155/  155]    Loss 3.091752    mAP 0.512737    
2023-04-17 09:35:06,056 - ==> mAP: 0.51274    Loss: 3.092

2023-04-17 09:35:06,060 - ==> Best [mAP: 0.517068   vloss: 3.102653   Sparsity:0.00   Params: 2177088 on epoch: 117]
2023-04-17 09:35:06,060 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 09:35:06,096 - 

2023-04-17 09:35:06,096 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 09:35:17,015 - Epoch: [146][   50/  518]    Overall Loss 2.847493    Objective Loss 2.847493                                        LR 0.000063    Time 0.218315    
2023-04-17 09:35:27,159 - Epoch: [146][  100/  518]    Overall Loss 2.834439    Objective Loss 2.834439                                        LR 0.000063    Time 0.210588    
2023-04-17 09:35:37,187 - Epoch: [146][  150/  518]    Overall Loss 2.823559    Objective Loss 2.823559                                        LR 0.000063    Time 0.207230    
2023-04-17 09:35:47,333 - Epoch: [146][  200/  518]    Overall Loss 2.825482    Objective Loss 2.825482                                        LR 0.000063    Time 0.206147    
2023-04-17 09:35:57,446 - Epoch: [146][  250/  518]    Overall Loss 2.834405    Objective Loss 2.834405                                        LR 0.000063    Time 0.205363    
2023-04-17 09:36:07,527 - Epoch: [146][  300/  518]    Overall Loss 2.846977    Objective Loss 2.846977                                        LR 0.000063    Time 0.204733    
2023-04-17 09:36:17,633 - Epoch: [146][  350/  518]    Overall Loss 2.843341    Objective Loss 2.843341                                        LR 0.000063    Time 0.204356    
2023-04-17 09:36:27,737 - Epoch: [146][  400/  518]    Overall Loss 2.842942    Objective Loss 2.842942                                        LR 0.000063    Time 0.204068    
2023-04-17 09:36:37,951 - Epoch: [146][  450/  518]    Overall Loss 2.848046    Objective Loss 2.848046                                        LR 0.000063    Time 0.204089    
2023-04-17 09:36:48,061 - Epoch: [146][  500/  518]    Overall Loss 2.848040    Objective Loss 2.848040                                        LR 0.000063    Time 0.203896    
2023-04-17 09:36:51,561 - Epoch: [146][  518/  518]    Overall Loss 2.847902    Objective Loss 2.847902                                        LR 0.000063    Time 0.203567    
2023-04-17 09:36:51,642 - --- validate (epoch=146)-----------
2023-04-17 09:36:51,643 - 4952 samples (32 per mini-batch)
2023-04-17 09:37:38,818 - Epoch: [146][   50/  155]    Loss 3.100749    mAP 0.502832    
2023-04-17 09:38:25,776 - Epoch: [146][  100/  155]    Loss 3.081411    mAP 0.511757    
2023-04-17 09:39:11,259 - Epoch: [146][  150/  155]    Loss 3.080503    mAP 0.512245    
2023-04-17 09:39:15,682 - Epoch: [146][  155/  155]    Loss 3.081555    mAP 0.513063    
2023-04-17 09:39:15,761 - ==> mAP: 0.51306    Loss: 3.082

2023-04-17 09:39:15,765 - ==> Best [mAP: 0.517068   vloss: 3.102653   Sparsity:0.00   Params: 2177088 on epoch: 117]
2023-04-17 09:39:15,765 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 09:39:15,804 - 

2023-04-17 09:39:15,804 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 09:39:26,760 - Epoch: [147][   50/  518]    Overall Loss 2.838387    Objective Loss 2.838387                                        LR 0.000063    Time 0.219063    
2023-04-17 09:39:36,787 - Epoch: [147][  100/  518]    Overall Loss 2.833754    Objective Loss 2.833754                                        LR 0.000063    Time 0.209783    
2023-04-17 09:39:46,906 - Epoch: [147][  150/  518]    Overall Loss 2.837050    Objective Loss 2.837050                                        LR 0.000063    Time 0.207307    
2023-04-17 09:39:57,074 - Epoch: [147][  200/  518]    Overall Loss 2.840370    Objective Loss 2.840370                                        LR 0.000063    Time 0.206313    
2023-04-17 09:40:07,096 - Epoch: [147][  250/  518]    Overall Loss 2.845820    Objective Loss 2.845820                                        LR 0.000063    Time 0.205130    
2023-04-17 09:40:17,195 - Epoch: [147][  300/  518]    Overall Loss 2.837278    Objective Loss 2.837278                                        LR 0.000063    Time 0.204602    
2023-04-17 09:40:27,313 - Epoch: [147][  350/  518]    Overall Loss 2.836842    Objective Loss 2.836842                                        LR 0.000063    Time 0.204277    
2023-04-17 09:40:37,400 - Epoch: [147][  400/  518]    Overall Loss 2.842708    Objective Loss 2.842708                                        LR 0.000063    Time 0.203956    
2023-04-17 09:40:47,486 - Epoch: [147][  450/  518]    Overall Loss 2.842660    Objective Loss 2.842660                                        LR 0.000063    Time 0.203703    
2023-04-17 09:40:57,528 - Epoch: [147][  500/  518]    Overall Loss 2.843975    Objective Loss 2.843975                                        LR 0.000063    Time 0.203415    
2023-04-17 09:41:01,013 - Epoch: [147][  518/  518]    Overall Loss 2.847407    Objective Loss 2.847407                                        LR 0.000063    Time 0.203072    
2023-04-17 09:41:01,093 - --- validate (epoch=147)-----------
2023-04-17 09:41:01,094 - 4952 samples (32 per mini-batch)
2023-04-17 09:41:46,321 - Epoch: [147][   50/  155]    Loss 3.129327    mAP 0.522201    
2023-04-17 09:42:32,164 - Epoch: [147][  100/  155]    Loss 3.110897    mAP 0.514527    
2023-04-17 09:43:17,112 - Epoch: [147][  150/  155]    Loss 3.094734    mAP 0.518968    
2023-04-17 09:43:21,350 - Epoch: [147][  155/  155]    Loss 3.091767    mAP 0.520434    
2023-04-17 09:43:21,423 - ==> mAP: 0.52043    Loss: 3.092

2023-04-17 09:43:21,427 - ==> Best [mAP: 0.520434   vloss: 3.091767   Sparsity:0.00   Params: 2177088 on epoch: 147]
2023-04-17 09:43:21,427 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 09:43:21,478 - 

2023-04-17 09:43:21,478 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 09:43:32,326 - Epoch: [148][   50/  518]    Overall Loss 2.864306    Objective Loss 2.864306                                        LR 0.000063    Time 0.216905    
2023-04-17 09:43:42,456 - Epoch: [148][  100/  518]    Overall Loss 2.857688    Objective Loss 2.857688                                        LR 0.000063    Time 0.209733    
2023-04-17 09:43:52,494 - Epoch: [148][  150/  518]    Overall Loss 2.842068    Objective Loss 2.842068                                        LR 0.000063    Time 0.206732    
2023-04-17 09:44:02,588 - Epoch: [148][  200/  518]    Overall Loss 2.840501    Objective Loss 2.840501                                        LR 0.000063    Time 0.205513    
2023-04-17 09:44:12,685 - Epoch: [148][  250/  518]    Overall Loss 2.843994    Objective Loss 2.843994                                        LR 0.000063    Time 0.204792    
2023-04-17 09:44:22,772 - Epoch: [148][  300/  518]    Overall Loss 2.841619    Objective Loss 2.841619                                        LR 0.000063    Time 0.204277    
2023-04-17 09:44:32,926 - Epoch: [148][  350/  518]    Overall Loss 2.845180    Objective Loss 2.845180                                        LR 0.000063    Time 0.204101    
2023-04-17 09:44:43,090 - Epoch: [148][  400/  518]    Overall Loss 2.849560    Objective Loss 2.849560                                        LR 0.000063    Time 0.203994    
2023-04-17 09:44:53,237 - Epoch: [148][  450/  518]    Overall Loss 2.849615    Objective Loss 2.849615                                        LR 0.000063    Time 0.203874    
2023-04-17 09:45:03,389 - Epoch: [148][  500/  518]    Overall Loss 2.847494    Objective Loss 2.847494                                        LR 0.000063    Time 0.203787    
2023-04-17 09:45:06,905 - Epoch: [148][  518/  518]    Overall Loss 2.846426    Objective Loss 2.846426                                        LR 0.000063    Time 0.203494    
2023-04-17 09:45:06,986 - --- validate (epoch=148)-----------
2023-04-17 09:45:06,986 - 4952 samples (32 per mini-batch)
2023-04-17 09:45:51,077 - Epoch: [148][   50/  155]    Loss 3.081857    mAP 0.515106    
2023-04-17 09:46:34,480 - Epoch: [148][  100/  155]    Loss 3.100308    mAP 0.518736    
2023-04-17 09:47:18,747 - Epoch: [148][  150/  155]    Loss 3.094664    mAP 0.513208    
2023-04-17 09:47:23,079 - Epoch: [148][  155/  155]    Loss 3.092663    mAP 0.513103    
2023-04-17 09:47:23,157 - ==> mAP: 0.51310    Loss: 3.093

2023-04-17 09:47:23,161 - ==> Best [mAP: 0.520434   vloss: 3.091767   Sparsity:0.00   Params: 2177088 on epoch: 147]
2023-04-17 09:47:23,161 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 09:47:23,197 - 

2023-04-17 09:47:23,198 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 09:47:34,143 - Epoch: [149][   50/  518]    Overall Loss 2.870100    Objective Loss 2.870100                                        LR 0.000063    Time 0.218862    
2023-04-17 09:47:44,263 - Epoch: [149][  100/  518]    Overall Loss 2.859939    Objective Loss 2.859939                                        LR 0.000063    Time 0.210608    
2023-04-17 09:47:54,358 - Epoch: [149][  150/  518]    Overall Loss 2.847083    Objective Loss 2.847083                                        LR 0.000063    Time 0.207694    
2023-04-17 09:48:04,389 - Epoch: [149][  200/  518]    Overall Loss 2.850978    Objective Loss 2.850978                                        LR 0.000063    Time 0.205920    
2023-04-17 09:48:14,496 - Epoch: [149][  250/  518]    Overall Loss 2.849992    Objective Loss 2.849992                                        LR 0.000063    Time 0.205157    
2023-04-17 09:48:24,642 - Epoch: [149][  300/  518]    Overall Loss 2.847237    Objective Loss 2.847237                                        LR 0.000063    Time 0.204780    
2023-04-17 09:48:34,724 - Epoch: [149][  350/  518]    Overall Loss 2.843804    Objective Loss 2.843804                                        LR 0.000063    Time 0.204327    
2023-04-17 09:48:44,802 - Epoch: [149][  400/  518]    Overall Loss 2.843565    Objective Loss 2.843565                                        LR 0.000063    Time 0.203977    
2023-04-17 09:48:54,874 - Epoch: [149][  450/  518]    Overall Loss 2.848415    Objective Loss 2.848415                                        LR 0.000063    Time 0.203692    
2023-04-17 09:49:05,025 - Epoch: [149][  500/  518]    Overall Loss 2.848783    Objective Loss 2.848783                                        LR 0.000063    Time 0.203621    
2023-04-17 09:49:08,543 - Epoch: [149][  518/  518]    Overall Loss 2.852004    Objective Loss 2.852004                                        LR 0.000063    Time 0.203337    
2023-04-17 09:49:08,623 - --- validate (epoch=149)-----------
2023-04-17 09:49:08,623 - 4952 samples (32 per mini-batch)
2023-04-17 09:49:56,321 - Epoch: [149][   50/  155]    Loss 3.086892    mAP 0.521864    
2023-04-17 09:50:42,182 - Epoch: [149][  100/  155]    Loss 3.081159    mAP 0.517969    
2023-04-17 09:51:29,065 - Epoch: [149][  150/  155]    Loss 3.090829    mAP 0.516016    
2023-04-17 09:51:33,562 - Epoch: [149][  155/  155]    Loss 3.091161    mAP 0.514798    
2023-04-17 09:51:33,639 - ==> mAP: 0.51480    Loss: 3.091

2023-04-17 09:51:33,643 - ==> Best [mAP: 0.520434   vloss: 3.091767   Sparsity:0.00   Params: 2177088 on epoch: 147]
2023-04-17 09:51:33,643 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 09:51:33,680 - 

2023-04-17 09:51:33,680 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 09:51:44,502 - Epoch: [150][   50/  518]    Overall Loss 2.829634    Objective Loss 2.829634                                        LR 0.000016    Time 0.216401    
2023-04-17 09:51:54,583 - Epoch: [150][  100/  518]    Overall Loss 2.811845    Objective Loss 2.811845                                        LR 0.000016    Time 0.208986    
2023-04-17 09:52:04,684 - Epoch: [150][  150/  518]    Overall Loss 2.807329    Objective Loss 2.807329                                        LR 0.000016    Time 0.206657    
2023-04-17 09:52:14,825 - Epoch: [150][  200/  518]    Overall Loss 2.830755    Objective Loss 2.830755                                        LR 0.000016    Time 0.205689    
2023-04-17 09:52:24,899 - Epoch: [150][  250/  518]    Overall Loss 2.831147    Objective Loss 2.831147                                        LR 0.000016    Time 0.204843    
2023-04-17 09:52:35,070 - Epoch: [150][  300/  518]    Overall Loss 2.827361    Objective Loss 2.827361                                        LR 0.000016    Time 0.204598    
2023-04-17 09:52:45,162 - Epoch: [150][  350/  518]    Overall Loss 2.822416    Objective Loss 2.822416                                        LR 0.000016    Time 0.204201    
2023-04-17 09:52:55,371 - Epoch: [150][  400/  518]    Overall Loss 2.824310    Objective Loss 2.824310                                        LR 0.000016    Time 0.204193    
2023-04-17 09:53:05,465 - Epoch: [150][  450/  518]    Overall Loss 2.827150    Objective Loss 2.827150                                        LR 0.000016    Time 0.203933    
2023-04-17 09:53:15,591 - Epoch: [150][  500/  518]    Overall Loss 2.826868    Objective Loss 2.826868                                        LR 0.000016    Time 0.203789    
2023-04-17 09:53:19,073 - Epoch: [150][  518/  518]    Overall Loss 2.830717    Objective Loss 2.830717                                        LR 0.000016    Time 0.203430    
2023-04-17 09:53:19,154 - --- validate (epoch=150)-----------
2023-04-17 09:53:19,155 - 4952 samples (32 per mini-batch)
2023-04-17 09:54:04,024 - Epoch: [150][   50/  155]    Loss 3.062937    mAP 0.509443    
2023-04-17 09:54:48,145 - Epoch: [150][  100/  155]    Loss 3.082934    mAP 0.512022    
2023-04-17 09:55:32,252 - Epoch: [150][  150/  155]    Loss 3.075301    mAP 0.515778    
2023-04-17 09:55:36,415 - Epoch: [150][  155/  155]    Loss 3.079292    mAP 0.514097    
2023-04-17 09:55:36,490 - ==> mAP: 0.51410    Loss: 3.079

2023-04-17 09:55:36,494 - ==> Best [mAP: 0.520434   vloss: 3.091767   Sparsity:0.00   Params: 2177088 on epoch: 147]
2023-04-17 09:55:36,494 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 09:55:36,531 - 

2023-04-17 09:55:36,531 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 09:55:47,548 - Epoch: [151][   50/  518]    Overall Loss 2.888778    Objective Loss 2.888778                                        LR 0.000016    Time 0.220276    
2023-04-17 09:55:57,659 - Epoch: [151][  100/  518]    Overall Loss 2.870984    Objective Loss 2.870984                                        LR 0.000016    Time 0.211237    
2023-04-17 09:56:07,730 - Epoch: [151][  150/  518]    Overall Loss 2.849170    Objective Loss 2.849170                                        LR 0.000016    Time 0.207951    
2023-04-17 09:56:17,835 - Epoch: [151][  200/  518]    Overall Loss 2.840127    Objective Loss 2.840127                                        LR 0.000016    Time 0.206483    
2023-04-17 09:56:27,886 - Epoch: [151][  250/  518]    Overall Loss 2.835022    Objective Loss 2.835022                                        LR 0.000016    Time 0.205381    
2023-04-17 09:56:37,970 - Epoch: [151][  300/  518]    Overall Loss 2.826711    Objective Loss 2.826711                                        LR 0.000016    Time 0.204762    
2023-04-17 09:56:48,013 - Epoch: [151][  350/  518]    Overall Loss 2.825290    Objective Loss 2.825290                                        LR 0.000016    Time 0.204198    
2023-04-17 09:56:58,127 - Epoch: [151][  400/  518]    Overall Loss 2.818980    Objective Loss 2.818980                                        LR 0.000016    Time 0.203954    
2023-04-17 09:57:08,178 - Epoch: [151][  450/  518]    Overall Loss 2.820503    Objective Loss 2.820503                                        LR 0.000016    Time 0.203625    
2023-04-17 09:57:18,243 - Epoch: [151][  500/  518]    Overall Loss 2.822878    Objective Loss 2.822878                                        LR 0.000016    Time 0.203389    
2023-04-17 09:57:21,724 - Epoch: [151][  518/  518]    Overall Loss 2.819498    Objective Loss 2.819498                                        LR 0.000016    Time 0.203041    
2023-04-17 09:57:21,804 - --- validate (epoch=151)-----------
2023-04-17 09:57:21,804 - 4952 samples (32 per mini-batch)
2023-04-17 09:58:06,620 - Epoch: [151][   50/  155]    Loss 3.073176    mAP 0.520545    
2023-04-17 09:58:53,616 - Epoch: [151][  100/  155]    Loss 3.075350    mAP 0.512522    
2023-04-17 09:59:40,466 - Epoch: [151][  150/  155]    Loss 3.071799    mAP 0.512618    
2023-04-17 09:59:44,577 - Epoch: [151][  155/  155]    Loss 3.075564    mAP 0.511834    
2023-04-17 09:59:44,658 - ==> mAP: 0.51183    Loss: 3.076

2023-04-17 09:59:44,662 - ==> Best [mAP: 0.520434   vloss: 3.091767   Sparsity:0.00   Params: 2177088 on epoch: 147]
2023-04-17 09:59:44,662 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 09:59:44,700 - 

2023-04-17 09:59:44,700 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 09:59:55,613 - Epoch: [152][   50/  518]    Overall Loss 2.833986    Objective Loss 2.833986                                        LR 0.000016    Time 0.218218    
2023-04-17 10:00:05,687 - Epoch: [152][  100/  518]    Overall Loss 2.846909    Objective Loss 2.846909                                        LR 0.000016    Time 0.209826    
2023-04-17 10:00:15,689 - Epoch: [152][  150/  518]    Overall Loss 2.837214    Objective Loss 2.837214                                        LR 0.000016    Time 0.206559    
2023-04-17 10:00:25,786 - Epoch: [152][  200/  518]    Overall Loss 2.828313    Objective Loss 2.828313                                        LR 0.000016    Time 0.205393    
2023-04-17 10:00:35,963 - Epoch: [152][  250/  518]    Overall Loss 2.830975    Objective Loss 2.830975                                        LR 0.000016    Time 0.205015    
2023-04-17 10:00:46,033 - Epoch: [152][  300/  518]    Overall Loss 2.827306    Objective Loss 2.827306                                        LR 0.000016    Time 0.204408    
2023-04-17 10:00:56,108 - Epoch: [152][  350/  518]    Overall Loss 2.822047    Objective Loss 2.822047                                        LR 0.000016    Time 0.203990    
2023-04-17 10:01:06,268 - Epoch: [152][  400/  518]    Overall Loss 2.825150    Objective Loss 2.825150                                        LR 0.000016    Time 0.203887    
2023-04-17 10:01:16,308 - Epoch: [152][  450/  518]    Overall Loss 2.824795    Objective Loss 2.824795                                        LR 0.000016    Time 0.203540    
2023-04-17 10:01:26,264 - Epoch: [152][  500/  518]    Overall Loss 2.832025    Objective Loss 2.832025                                        LR 0.000016    Time 0.203096    
2023-04-17 10:01:29,736 - Epoch: [152][  518/  518]    Overall Loss 2.832280    Objective Loss 2.832280                                        LR 0.000016    Time 0.202740    
2023-04-17 10:01:29,818 - --- validate (epoch=152)-----------
2023-04-17 10:01:29,818 - 4952 samples (32 per mini-batch)
2023-04-17 10:02:15,461 - Epoch: [152][   50/  155]    Loss 3.076518    mAP 0.507456    
2023-04-17 10:03:00,021 - Epoch: [152][  100/  155]    Loss 3.071441    mAP 0.517172    
2023-04-17 10:03:44,948 - Epoch: [152][  150/  155]    Loss 3.078293    mAP 0.513875    
2023-04-17 10:03:48,925 - Epoch: [152][  155/  155]    Loss 3.076216    mAP 0.514979    
2023-04-17 10:03:49,004 - ==> mAP: 0.51498    Loss: 3.076

2023-04-17 10:03:49,008 - ==> Best [mAP: 0.520434   vloss: 3.091767   Sparsity:0.00   Params: 2177088 on epoch: 147]
2023-04-17 10:03:49,008 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 10:03:49,065 - 

2023-04-17 10:03:49,065 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 10:03:59,854 - Epoch: [153][   50/  518]    Overall Loss 2.731520    Objective Loss 2.731520                                        LR 0.000016    Time 0.215710    
2023-04-17 10:04:10,032 - Epoch: [153][  100/  518]    Overall Loss 2.813544    Objective Loss 2.813544                                        LR 0.000016    Time 0.209620    
2023-04-17 10:04:20,187 - Epoch: [153][  150/  518]    Overall Loss 2.810720    Objective Loss 2.810720                                        LR 0.000016    Time 0.207436    
2023-04-17 10:04:30,317 - Epoch: [153][  200/  518]    Overall Loss 2.823218    Objective Loss 2.823218                                        LR 0.000016    Time 0.206219    
2023-04-17 10:04:40,483 - Epoch: [153][  250/  518]    Overall Loss 2.825330    Objective Loss 2.825330                                        LR 0.000016    Time 0.205631    
2023-04-17 10:04:50,494 - Epoch: [153][  300/  518]    Overall Loss 2.825863    Objective Loss 2.825863                                        LR 0.000016    Time 0.204724    
2023-04-17 10:05:00,680 - Epoch: [153][  350/  518]    Overall Loss 2.824978    Objective Loss 2.824978                                        LR 0.000016    Time 0.204576    
2023-04-17 10:05:10,694 - Epoch: [153][  400/  518]    Overall Loss 2.824432    Objective Loss 2.824432                                        LR 0.000016    Time 0.204035    
2023-04-17 10:05:20,801 - Epoch: [153][  450/  518]    Overall Loss 2.823381    Objective Loss 2.823381                                        LR 0.000016    Time 0.203820    
2023-04-17 10:05:30,896 - Epoch: [153][  500/  518]    Overall Loss 2.823661    Objective Loss 2.823661                                        LR 0.000016    Time 0.203626    
2023-04-17 10:05:34,423 - Epoch: [153][  518/  518]    Overall Loss 2.826023    Objective Loss 2.826023                                        LR 0.000016    Time 0.203359    
2023-04-17 10:05:34,504 - --- validate (epoch=153)-----------
2023-04-17 10:05:34,504 - 4952 samples (32 per mini-batch)
2023-04-17 10:06:20,518 - Epoch: [153][   50/  155]    Loss 3.063953    mAP 0.526542    
2023-04-17 10:07:03,952 - Epoch: [153][  100/  155]    Loss 3.088235    mAP 0.518363    
2023-04-17 10:07:47,574 - Epoch: [153][  150/  155]    Loss 3.083785    mAP 0.517540    
2023-04-17 10:07:51,901 - Epoch: [153][  155/  155]    Loss 3.079729    mAP 0.518259    
2023-04-17 10:07:51,981 - ==> mAP: 0.51826    Loss: 3.080

2023-04-17 10:07:51,984 - ==> Best [mAP: 0.520434   vloss: 3.091767   Sparsity:0.00   Params: 2177088 on epoch: 147]
2023-04-17 10:07:51,984 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 10:07:52,021 - 

2023-04-17 10:07:52,021 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 10:08:02,910 - Epoch: [154][   50/  518]    Overall Loss 2.808100    Objective Loss 2.808100                                        LR 0.000016    Time 0.217735    
2023-04-17 10:08:12,940 - Epoch: [154][  100/  518]    Overall Loss 2.810407    Objective Loss 2.810407                                        LR 0.000016    Time 0.209148    
2023-04-17 10:08:23,066 - Epoch: [154][  150/  518]    Overall Loss 2.801817    Objective Loss 2.801817                                        LR 0.000016    Time 0.206931    
2023-04-17 10:08:33,247 - Epoch: [154][  200/  518]    Overall Loss 2.810083    Objective Loss 2.810083                                        LR 0.000016    Time 0.206092    
2023-04-17 10:08:43,216 - Epoch: [154][  250/  518]    Overall Loss 2.816434    Objective Loss 2.816434                                        LR 0.000016    Time 0.204744    
2023-04-17 10:08:53,339 - Epoch: [154][  300/  518]    Overall Loss 2.813023    Objective Loss 2.813023                                        LR 0.000016    Time 0.204358    
2023-04-17 10:09:03,471 - Epoch: [154][  350/  518]    Overall Loss 2.811434    Objective Loss 2.811434                                        LR 0.000016    Time 0.204108    
2023-04-17 10:09:13,552 - Epoch: [154][  400/  518]    Overall Loss 2.813746    Objective Loss 2.813746                                        LR 0.000016    Time 0.203795    
2023-04-17 10:09:23,671 - Epoch: [154][  450/  518]    Overall Loss 2.810900    Objective Loss 2.810900                                        LR 0.000016    Time 0.203633    
2023-04-17 10:09:33,793 - Epoch: [154][  500/  518]    Overall Loss 2.815989    Objective Loss 2.815989                                        LR 0.000016    Time 0.203511    
2023-04-17 10:09:37,312 - Epoch: [154][  518/  518]    Overall Loss 2.815037    Objective Loss 2.815037                                        LR 0.000016    Time 0.203232    
2023-04-17 10:09:37,394 - --- validate (epoch=154)-----------
2023-04-17 10:09:37,394 - 4952 samples (32 per mini-batch)
2023-04-17 10:10:23,219 - Epoch: [154][   50/  155]    Loss 3.052096    mAP 0.516930    
2023-04-17 10:11:08,257 - Epoch: [154][  100/  155]    Loss 3.060217    mAP 0.510821    
2023-04-17 10:11:53,939 - Epoch: [154][  150/  155]    Loss 3.075739    mAP 0.515714    
2023-04-17 10:11:58,010 - Epoch: [154][  155/  155]    Loss 3.081563    mAP 0.515909    
2023-04-17 10:11:58,087 - ==> mAP: 0.51591    Loss: 3.082

2023-04-17 10:11:58,091 - ==> Best [mAP: 0.520434   vloss: 3.091767   Sparsity:0.00   Params: 2177088 on epoch: 147]
2023-04-17 10:11:58,091 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 10:11:58,127 - 

2023-04-17 10:11:58,127 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 10:12:08,872 - Epoch: [155][   50/  518]    Overall Loss 2.808461    Objective Loss 2.808461                                        LR 0.000016    Time 0.214838    
2023-04-17 10:12:18,954 - Epoch: [155][  100/  518]    Overall Loss 2.831091    Objective Loss 2.831091                                        LR 0.000016    Time 0.208224    
2023-04-17 10:12:29,043 - Epoch: [155][  150/  518]    Overall Loss 2.831933    Objective Loss 2.831933                                        LR 0.000016    Time 0.206064    
2023-04-17 10:12:39,159 - Epoch: [155][  200/  518]    Overall Loss 2.823609    Objective Loss 2.823609                                        LR 0.000016    Time 0.205124    
2023-04-17 10:12:49,228 - Epoch: [155][  250/  518]    Overall Loss 2.826065    Objective Loss 2.826065                                        LR 0.000016    Time 0.204369    
2023-04-17 10:12:59,334 - Epoch: [155][  300/  518]    Overall Loss 2.831702    Objective Loss 2.831702                                        LR 0.000016    Time 0.203987    
2023-04-17 10:13:09,456 - Epoch: [155][  350/  518]    Overall Loss 2.825891    Objective Loss 2.825891                                        LR 0.000016    Time 0.203763    
2023-04-17 10:13:19,698 - Epoch: [155][  400/  518]    Overall Loss 2.833970    Objective Loss 2.833970                                        LR 0.000016    Time 0.203893    
2023-04-17 10:13:29,820 - Epoch: [155][  450/  518]    Overall Loss 2.829036    Objective Loss 2.829036                                        LR 0.000016    Time 0.203728    
2023-04-17 10:13:39,865 - Epoch: [155][  500/  518]    Overall Loss 2.829825    Objective Loss 2.829825                                        LR 0.000016    Time 0.203441    
2023-04-17 10:13:43,411 - Epoch: [155][  518/  518]    Overall Loss 2.832905    Objective Loss 2.832905                                        LR 0.000016    Time 0.203217    
2023-04-17 10:13:43,493 - --- validate (epoch=155)-----------
2023-04-17 10:13:43,493 - 4952 samples (32 per mini-batch)
2023-04-17 10:14:26,534 - Epoch: [155][   50/  155]    Loss 3.058640    mAP 0.511188    
2023-04-17 10:15:10,521 - Epoch: [155][  100/  155]    Loss 3.085289    mAP 0.508641    
2023-04-17 10:15:55,180 - Epoch: [155][  150/  155]    Loss 3.085708    mAP 0.513699    
2023-04-17 10:15:58,978 - Epoch: [155][  155/  155]    Loss 3.080524    mAP 0.513313    
2023-04-17 10:15:59,056 - ==> mAP: 0.51331    Loss: 3.081

2023-04-17 10:15:59,061 - ==> Best [mAP: 0.520434   vloss: 3.091767   Sparsity:0.00   Params: 2177088 on epoch: 147]
2023-04-17 10:15:59,061 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 10:15:59,098 - 

2023-04-17 10:15:59,098 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 10:16:09,887 - Epoch: [156][   50/  518]    Overall Loss 2.807912    Objective Loss 2.807912                                        LR 0.000016    Time 0.215731    
2023-04-17 10:16:19,977 - Epoch: [156][  100/  518]    Overall Loss 2.824061    Objective Loss 2.824061                                        LR 0.000016    Time 0.208749    
2023-04-17 10:16:30,078 - Epoch: [156][  150/  518]    Overall Loss 2.816923    Objective Loss 2.816923                                        LR 0.000016    Time 0.206497    
2023-04-17 10:16:40,102 - Epoch: [156][  200/  518]    Overall Loss 2.821807    Objective Loss 2.821807                                        LR 0.000016    Time 0.204984    
2023-04-17 10:16:50,168 - Epoch: [156][  250/  518]    Overall Loss 2.820707    Objective Loss 2.820707                                        LR 0.000016    Time 0.204243    
2023-04-17 10:17:00,214 - Epoch: [156][  300/  518]    Overall Loss 2.822954    Objective Loss 2.822954                                        LR 0.000016    Time 0.203687    
2023-04-17 10:17:10,283 - Epoch: [156][  350/  518]    Overall Loss 2.822146    Objective Loss 2.822146                                        LR 0.000016    Time 0.203351    
2023-04-17 10:17:20,328 - Epoch: [156][  400/  518]    Overall Loss 2.820995    Objective Loss 2.820995                                        LR 0.000016    Time 0.203041    
2023-04-17 10:17:30,538 - Epoch: [156][  450/  518]    Overall Loss 2.821199    Objective Loss 2.821199                                        LR 0.000016    Time 0.203166    
2023-04-17 10:17:40,635 - Epoch: [156][  500/  518]    Overall Loss 2.820740    Objective Loss 2.820740                                        LR 0.000016    Time 0.203041    
2023-04-17 10:17:44,172 - Epoch: [156][  518/  518]    Overall Loss 2.819529    Objective Loss 2.819529                                        LR 0.000016    Time 0.202813    
2023-04-17 10:17:44,254 - --- validate (epoch=156)-----------
2023-04-17 10:17:44,255 - 4952 samples (32 per mini-batch)
2023-04-17 10:18:31,009 - Epoch: [156][   50/  155]    Loss 3.108185    mAP 0.513019    
2023-04-17 10:19:15,825 - Epoch: [156][  100/  155]    Loss 3.087965    mAP 0.508843    
2023-04-17 10:20:01,181 - Epoch: [156][  150/  155]    Loss 3.081336    mAP 0.513067    
2023-04-17 10:20:05,566 - Epoch: [156][  155/  155]    Loss 3.077335    mAP 0.512496    
2023-04-17 10:20:05,648 - ==> mAP: 0.51250    Loss: 3.077

2023-04-17 10:20:05,652 - ==> Best [mAP: 0.520434   vloss: 3.091767   Sparsity:0.00   Params: 2177088 on epoch: 147]
2023-04-17 10:20:05,652 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 10:20:05,690 - 

2023-04-17 10:20:05,690 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 10:20:16,580 - Epoch: [157][   50/  518]    Overall Loss 2.868961    Objective Loss 2.868961                                        LR 0.000016    Time 0.217757    
2023-04-17 10:20:26,628 - Epoch: [157][  100/  518]    Overall Loss 2.829573    Objective Loss 2.829573                                        LR 0.000016    Time 0.209337    
2023-04-17 10:20:36,704 - Epoch: [157][  150/  518]    Overall Loss 2.811600    Objective Loss 2.811600                                        LR 0.000016    Time 0.206723    
2023-04-17 10:20:46,788 - Epoch: [157][  200/  518]    Overall Loss 2.820093    Objective Loss 2.820093                                        LR 0.000016    Time 0.205456    
2023-04-17 10:20:56,823 - Epoch: [157][  250/  518]    Overall Loss 2.824940    Objective Loss 2.824940                                        LR 0.000016    Time 0.204498    
2023-04-17 10:21:06,914 - Epoch: [157][  300/  518]    Overall Loss 2.826158    Objective Loss 2.826158                                        LR 0.000016    Time 0.204047    
2023-04-17 10:21:16,962 - Epoch: [157][  350/  518]    Overall Loss 2.822391    Objective Loss 2.822391                                        LR 0.000016    Time 0.203602    
2023-04-17 10:21:27,036 - Epoch: [157][  400/  518]    Overall Loss 2.827814    Objective Loss 2.827814                                        LR 0.000016    Time 0.203332    
2023-04-17 10:21:37,132 - Epoch: [157][  450/  518]    Overall Loss 2.822647    Objective Loss 2.822647                                        LR 0.000016    Time 0.203171    
2023-04-17 10:21:47,251 - Epoch: [157][  500/  518]    Overall Loss 2.818692    Objective Loss 2.818692                                        LR 0.000016    Time 0.203088    
2023-04-17 10:21:50,770 - Epoch: [157][  518/  518]    Overall Loss 2.821050    Objective Loss 2.821050                                        LR 0.000016    Time 0.202825    
2023-04-17 10:21:50,852 - --- validate (epoch=157)-----------
2023-04-17 10:21:50,852 - 4952 samples (32 per mini-batch)
2023-04-17 10:22:36,629 - Epoch: [157][   50/  155]    Loss 3.080289    mAP 0.517084    
2023-04-17 10:23:21,541 - Epoch: [157][  100/  155]    Loss 3.078315    mAP 0.518680    
2023-04-17 10:24:07,129 - Epoch: [157][  150/  155]    Loss 3.085567    mAP 0.510942    
2023-04-17 10:24:10,891 - Epoch: [157][  155/  155]    Loss 3.081065    mAP 0.511364    
2023-04-17 10:24:10,978 - ==> mAP: 0.51136    Loss: 3.081

2023-04-17 10:24:10,982 - ==> Best [mAP: 0.520434   vloss: 3.091767   Sparsity:0.00   Params: 2177088 on epoch: 147]
2023-04-17 10:24:10,982 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 10:24:11,020 - 

2023-04-17 10:24:11,020 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 10:24:21,922 - Epoch: [158][   50/  518]    Overall Loss 2.825098    Objective Loss 2.825098                                        LR 0.000016    Time 0.217991    
2023-04-17 10:24:31,972 - Epoch: [158][  100/  518]    Overall Loss 2.843093    Objective Loss 2.843093                                        LR 0.000016    Time 0.209479    
2023-04-17 10:24:42,032 - Epoch: [158][  150/  518]    Overall Loss 2.858612    Objective Loss 2.858612                                        LR 0.000016    Time 0.206708    
2023-04-17 10:24:52,177 - Epoch: [158][  200/  518]    Overall Loss 2.843934    Objective Loss 2.843934                                        LR 0.000016    Time 0.205752    
2023-04-17 10:25:02,247 - Epoch: [158][  250/  518]    Overall Loss 2.833959    Objective Loss 2.833959                                        LR 0.000016    Time 0.204872    
2023-04-17 10:25:12,390 - Epoch: [158][  300/  518]    Overall Loss 2.831353    Objective Loss 2.831353                                        LR 0.000016    Time 0.204533    
2023-04-17 10:25:22,481 - Epoch: [158][  350/  518]    Overall Loss 2.832227    Objective Loss 2.832227                                        LR 0.000016    Time 0.204140    
2023-04-17 10:25:32,638 - Epoch: [158][  400/  518]    Overall Loss 2.826629    Objective Loss 2.826629                                        LR 0.000016    Time 0.204011    
2023-04-17 10:25:42,735 - Epoch: [158][  450/  518]    Overall Loss 2.827566    Objective Loss 2.827566                                        LR 0.000016    Time 0.203777    
2023-04-17 10:25:52,829 - Epoch: [158][  500/  518]    Overall Loss 2.827022    Objective Loss 2.827022                                        LR 0.000016    Time 0.203586    
2023-04-17 10:25:56,396 - Epoch: [158][  518/  518]    Overall Loss 2.827545    Objective Loss 2.827545                                        LR 0.000016    Time 0.203396    
2023-04-17 10:25:56,477 - --- validate (epoch=158)-----------
2023-04-17 10:25:56,478 - 4952 samples (32 per mini-batch)
2023-04-17 10:26:43,047 - Epoch: [158][   50/  155]    Loss 3.100181    mAP 0.509208    
2023-04-17 10:27:30,572 - Epoch: [158][  100/  155]    Loss 3.078307    mAP 0.518648    
2023-04-17 10:28:15,417 - Epoch: [158][  150/  155]    Loss 3.076491    mAP 0.516631    
2023-04-17 10:28:19,619 - Epoch: [158][  155/  155]    Loss 3.080726    mAP 0.516884    
2023-04-17 10:28:19,695 - ==> mAP: 0.51688    Loss: 3.081

2023-04-17 10:28:19,699 - ==> Best [mAP: 0.520434   vloss: 3.091767   Sparsity:0.00   Params: 2177088 on epoch: 147]
2023-04-17 10:28:19,699 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 10:28:19,735 - 

2023-04-17 10:28:19,735 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 10:28:30,622 - Epoch: [159][   50/  518]    Overall Loss 2.827479    Objective Loss 2.827479                                        LR 0.000016    Time 0.217685    
2023-04-17 10:28:40,830 - Epoch: [159][  100/  518]    Overall Loss 2.830859    Objective Loss 2.830859                                        LR 0.000016    Time 0.210906    
2023-04-17 10:28:50,950 - Epoch: [159][  150/  518]    Overall Loss 2.818122    Objective Loss 2.818122                                        LR 0.000016    Time 0.208058    
2023-04-17 10:29:01,089 - Epoch: [159][  200/  518]    Overall Loss 2.816661    Objective Loss 2.816661                                        LR 0.000016    Time 0.206732    
2023-04-17 10:29:11,164 - Epoch: [159][  250/  518]    Overall Loss 2.831169    Objective Loss 2.831169                                        LR 0.000016    Time 0.205679    
2023-04-17 10:29:21,324 - Epoch: [159][  300/  518]    Overall Loss 2.834493    Objective Loss 2.834493                                        LR 0.000016    Time 0.205261    
2023-04-17 10:29:31,527 - Epoch: [159][  350/  518]    Overall Loss 2.837382    Objective Loss 2.837382                                        LR 0.000016    Time 0.205084    
2023-04-17 10:29:41,631 - Epoch: [159][  400/  518]    Overall Loss 2.837663    Objective Loss 2.837663                                        LR 0.000016    Time 0.204704    
2023-04-17 10:29:51,707 - Epoch: [159][  450/  518]    Overall Loss 2.839701    Objective Loss 2.839701                                        LR 0.000016    Time 0.204348    
2023-04-17 10:30:01,747 - Epoch: [159][  500/  518]    Overall Loss 2.838492    Objective Loss 2.838492                                        LR 0.000016    Time 0.203991    
2023-04-17 10:30:05,288 - Epoch: [159][  518/  518]    Overall Loss 2.837207    Objective Loss 2.837207                                        LR 0.000016    Time 0.203736    
2023-04-17 10:30:05,368 - --- validate (epoch=159)-----------
2023-04-17 10:30:05,369 - 4952 samples (32 per mini-batch)
2023-04-17 10:30:51,921 - Epoch: [159][   50/  155]    Loss 3.105690    mAP 0.500805    
2023-04-17 10:31:35,375 - Epoch: [159][  100/  155]    Loss 3.088342    mAP 0.516825    
2023-04-17 10:32:21,097 - Epoch: [159][  150/  155]    Loss 3.083154    mAP 0.518411    
2023-04-17 10:32:25,702 - Epoch: [159][  155/  155]    Loss 3.081514    mAP 0.517768    
2023-04-17 10:32:25,781 - ==> mAP: 0.51777    Loss: 3.082

2023-04-17 10:32:25,786 - ==> Best [mAP: 0.520434   vloss: 3.091767   Sparsity:0.00   Params: 2177088 on epoch: 147]
2023-04-17 10:32:25,786 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 10:32:25,823 - 

2023-04-17 10:32:25,823 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 10:32:36,671 - Epoch: [160][   50/  518]    Overall Loss 2.873408    Objective Loss 2.873408                                        LR 0.000016    Time 0.216906    
2023-04-17 10:32:46,840 - Epoch: [160][  100/  518]    Overall Loss 2.824803    Objective Loss 2.824803                                        LR 0.000016    Time 0.210122    
2023-04-17 10:32:56,920 - Epoch: [160][  150/  518]    Overall Loss 2.842854    Objective Loss 2.842854                                        LR 0.000016    Time 0.207273    
2023-04-17 10:33:07,042 - Epoch: [160][  200/  518]    Overall Loss 2.825104    Objective Loss 2.825104                                        LR 0.000016    Time 0.206059    
2023-04-17 10:33:17,152 - Epoch: [160][  250/  518]    Overall Loss 2.831381    Objective Loss 2.831381                                        LR 0.000016    Time 0.205280    
2023-04-17 10:33:27,220 - Epoch: [160][  300/  518]    Overall Loss 2.826006    Objective Loss 2.826006                                        LR 0.000016    Time 0.204619    
2023-04-17 10:33:37,350 - Epoch: [160][  350/  518]    Overall Loss 2.831704    Objective Loss 2.831704                                        LR 0.000016    Time 0.204329    
2023-04-17 10:33:47,572 - Epoch: [160][  400/  518]    Overall Loss 2.832614    Objective Loss 2.832614                                        LR 0.000016    Time 0.204337    
2023-04-17 10:33:57,615 - Epoch: [160][  450/  518]    Overall Loss 2.836404    Objective Loss 2.836404                                        LR 0.000016    Time 0.203948    
2023-04-17 10:34:07,690 - Epoch: [160][  500/  518]    Overall Loss 2.838445    Objective Loss 2.838445                                        LR 0.000016    Time 0.203699    
2023-04-17 10:34:11,162 - Epoch: [160][  518/  518]    Overall Loss 2.840176    Objective Loss 2.840176                                        LR 0.000016    Time 0.203324    
2023-04-17 10:34:11,240 - --- validate (epoch=160)-----------
2023-04-17 10:34:11,240 - 4952 samples (32 per mini-batch)
2023-04-17 10:34:56,643 - Epoch: [160][   50/  155]    Loss 3.054851    mAP 0.514368    
2023-04-17 10:35:41,776 - Epoch: [160][  100/  155]    Loss 3.064049    mAP 0.515626    
2023-04-17 10:36:28,827 - Epoch: [160][  150/  155]    Loss 3.079500    mAP 0.517417    
2023-04-17 10:36:33,021 - Epoch: [160][  155/  155]    Loss 3.082817    mAP 0.519158    
2023-04-17 10:36:33,099 - ==> mAP: 0.51916    Loss: 3.083

2023-04-17 10:36:33,103 - ==> Best [mAP: 0.520434   vloss: 3.091767   Sparsity:0.00   Params: 2177088 on epoch: 147]
2023-04-17 10:36:33,103 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 10:36:33,139 - 

2023-04-17 10:36:33,139 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 10:36:44,035 - Epoch: [161][   50/  518]    Overall Loss 2.818125    Objective Loss 2.818125                                        LR 0.000016    Time 0.217865    
2023-04-17 10:36:54,213 - Epoch: [161][  100/  518]    Overall Loss 2.807411    Objective Loss 2.807411                                        LR 0.000016    Time 0.210700    
2023-04-17 10:37:04,299 - Epoch: [161][  150/  518]    Overall Loss 2.812053    Objective Loss 2.812053                                        LR 0.000016    Time 0.207694    
2023-04-17 10:37:14,372 - Epoch: [161][  200/  518]    Overall Loss 2.833955    Objective Loss 2.833955                                        LR 0.000016    Time 0.206128    
2023-04-17 10:37:24,559 - Epoch: [161][  250/  518]    Overall Loss 2.835260    Objective Loss 2.835260                                        LR 0.000016    Time 0.205646    
2023-04-17 10:37:34,622 - Epoch: [161][  300/  518]    Overall Loss 2.833320    Objective Loss 2.833320                                        LR 0.000016    Time 0.204908    
2023-04-17 10:37:44,698 - Epoch: [161][  350/  518]    Overall Loss 2.838950    Objective Loss 2.838950                                        LR 0.000016    Time 0.204421    
2023-04-17 10:37:54,860 - Epoch: [161][  400/  518]    Overall Loss 2.829997    Objective Loss 2.829997                                        LR 0.000016    Time 0.204269    
2023-04-17 10:38:04,910 - Epoch: [161][  450/  518]    Overall Loss 2.832341    Objective Loss 2.832341                                        LR 0.000016    Time 0.203903    
2023-04-17 10:38:14,992 - Epoch: [161][  500/  518]    Overall Loss 2.833664    Objective Loss 2.833664                                        LR 0.000016    Time 0.203673    
2023-04-17 10:38:18,528 - Epoch: [161][  518/  518]    Overall Loss 2.834810    Objective Loss 2.834810                                        LR 0.000016    Time 0.203420    
2023-04-17 10:38:18,610 - --- validate (epoch=161)-----------
2023-04-17 10:38:18,610 - 4952 samples (32 per mini-batch)
2023-04-17 10:39:03,434 - Epoch: [161][   50/  155]    Loss 3.060012    mAP 0.516195    
2023-04-17 10:39:48,917 - Epoch: [161][  100/  155]    Loss 3.082526    mAP 0.510283    
2023-04-17 10:40:33,190 - Epoch: [161][  150/  155]    Loss 3.082317    mAP 0.512532    
2023-04-17 10:40:37,453 - Epoch: [161][  155/  155]    Loss 3.080954    mAP 0.514395    
2023-04-17 10:40:37,527 - ==> mAP: 0.51439    Loss: 3.081

2023-04-17 10:40:37,531 - ==> Best [mAP: 0.520434   vloss: 3.091767   Sparsity:0.00   Params: 2177088 on epoch: 147]
2023-04-17 10:40:37,531 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 10:40:37,567 - 

2023-04-17 10:40:37,567 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 10:40:48,372 - Epoch: [162][   50/  518]    Overall Loss 2.803229    Objective Loss 2.803229                                        LR 0.000016    Time 0.216042    
2023-04-17 10:40:58,424 - Epoch: [162][  100/  518]    Overall Loss 2.798101    Objective Loss 2.798101                                        LR 0.000016    Time 0.208520    
2023-04-17 10:41:08,511 - Epoch: [162][  150/  518]    Overall Loss 2.811551    Objective Loss 2.811551                                        LR 0.000016    Time 0.206252    
2023-04-17 10:41:18,620 - Epoch: [162][  200/  518]    Overall Loss 2.797421    Objective Loss 2.797421                                        LR 0.000016    Time 0.205227    
2023-04-17 10:41:28,670 - Epoch: [162][  250/  518]    Overall Loss 2.808158    Objective Loss 2.808158                                        LR 0.000016    Time 0.204376    
2023-04-17 10:41:38,737 - Epoch: [162][  300/  518]    Overall Loss 2.803214    Objective Loss 2.803214                                        LR 0.000016    Time 0.203865    
2023-04-17 10:41:48,814 - Epoch: [162][  350/  518]    Overall Loss 2.808793    Objective Loss 2.808793                                        LR 0.000016    Time 0.203529    
2023-04-17 10:41:58,893 - Epoch: [162][  400/  518]    Overall Loss 2.810997    Objective Loss 2.810997                                        LR 0.000016    Time 0.203280    
2023-04-17 10:42:09,084 - Epoch: [162][  450/  518]    Overall Loss 2.804979    Objective Loss 2.804979                                        LR 0.000016    Time 0.203338    
2023-04-17 10:42:19,200 - Epoch: [162][  500/  518]    Overall Loss 2.813631    Objective Loss 2.813631                                        LR 0.000016    Time 0.203233    
2023-04-17 10:42:22,752 - Epoch: [162][  518/  518]    Overall Loss 2.815020    Objective Loss 2.815020                                        LR 0.000016    Time 0.203026    
2023-04-17 10:42:22,832 - --- validate (epoch=162)-----------
2023-04-17 10:42:22,833 - 4952 samples (32 per mini-batch)
2023-04-17 10:43:08,447 - Epoch: [162][   50/  155]    Loss 3.090284    mAP 0.515100    
2023-04-17 10:43:54,098 - Epoch: [162][  100/  155]    Loss 3.091853    mAP 0.525451    
2023-04-17 10:44:38,210 - Epoch: [162][  150/  155]    Loss 3.082240    mAP 0.522447    
2023-04-17 10:44:43,031 - Epoch: [162][  155/  155]    Loss 3.081842    mAP 0.523314    
2023-04-17 10:44:43,112 - ==> mAP: 0.52331    Loss: 3.082

2023-04-17 10:44:43,115 - ==> Best [mAP: 0.523314   vloss: 3.081842   Sparsity:0.00   Params: 2177088 on epoch: 162]
2023-04-17 10:44:43,115 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 10:44:43,166 - 

2023-04-17 10:44:43,167 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 10:44:53,937 - Epoch: [163][   50/  518]    Overall Loss 2.819504    Objective Loss 2.819504                                        LR 0.000016    Time 0.215345    
2023-04-17 10:45:04,017 - Epoch: [163][  100/  518]    Overall Loss 2.791927    Objective Loss 2.791927                                        LR 0.000016    Time 0.208459    
2023-04-17 10:45:14,185 - Epoch: [163][  150/  518]    Overall Loss 2.803767    Objective Loss 2.803767                                        LR 0.000016    Time 0.206753    
2023-04-17 10:45:24,283 - Epoch: [163][  200/  518]    Overall Loss 2.802909    Objective Loss 2.802909                                        LR 0.000016    Time 0.205543    
2023-04-17 10:45:34,358 - Epoch: [163][  250/  518]    Overall Loss 2.813646    Objective Loss 2.813646                                        LR 0.000016    Time 0.204730    
2023-04-17 10:45:44,485 - Epoch: [163][  300/  518]    Overall Loss 2.820969    Objective Loss 2.820969                                        LR 0.000016    Time 0.204361    
2023-04-17 10:45:54,693 - Epoch: [163][  350/  518]    Overall Loss 2.823776    Objective Loss 2.823776                                        LR 0.000016    Time 0.204328    
2023-04-17 10:46:04,754 - Epoch: [163][  400/  518]    Overall Loss 2.822205    Objective Loss 2.822205                                        LR 0.000016    Time 0.203936    
2023-04-17 10:46:14,946 - Epoch: [163][  450/  518]    Overall Loss 2.821893    Objective Loss 2.821893                                        LR 0.000016    Time 0.203921    
2023-04-17 10:46:25,072 - Epoch: [163][  500/  518]    Overall Loss 2.821925    Objective Loss 2.821925                                        LR 0.000016    Time 0.203778    
2023-04-17 10:46:28,559 - Epoch: [163][  518/  518]    Overall Loss 2.828453    Objective Loss 2.828453                                        LR 0.000016    Time 0.203427    
2023-04-17 10:46:28,640 - --- validate (epoch=163)-----------
2023-04-17 10:46:28,640 - 4952 samples (32 per mini-batch)
2023-04-17 10:47:13,603 - Epoch: [163][   50/  155]    Loss 3.087832    mAP 0.504442    
2023-04-17 10:47:56,313 - Epoch: [163][  100/  155]    Loss 3.069300    mAP 0.508288    
2023-04-17 10:48:42,206 - Epoch: [163][  150/  155]    Loss 3.080739    mAP 0.510934    
2023-04-17 10:48:46,529 - Epoch: [163][  155/  155]    Loss 3.082940    mAP 0.509986    
2023-04-17 10:48:46,608 - ==> mAP: 0.50999    Loss: 3.083

2023-04-17 10:48:46,611 - ==> Best [mAP: 0.523314   vloss: 3.081842   Sparsity:0.00   Params: 2177088 on epoch: 162]
2023-04-17 10:48:46,611 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 10:48:46,648 - 

2023-04-17 10:48:46,648 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 10:48:57,605 - Epoch: [164][   50/  518]    Overall Loss 2.803386    Objective Loss 2.803386                                        LR 0.000016    Time 0.219083    
2023-04-17 10:49:07,710 - Epoch: [164][  100/  518]    Overall Loss 2.795686    Objective Loss 2.795686                                        LR 0.000016    Time 0.210578    
2023-04-17 10:49:17,787 - Epoch: [164][  150/  518]    Overall Loss 2.793746    Objective Loss 2.793746                                        LR 0.000016    Time 0.207556    
2023-04-17 10:49:27,832 - Epoch: [164][  200/  518]    Overall Loss 2.809412    Objective Loss 2.809412                                        LR 0.000016    Time 0.205881    
2023-04-17 10:49:37,981 - Epoch: [164][  250/  518]    Overall Loss 2.818830    Objective Loss 2.818830                                        LR 0.000016    Time 0.205294    
2023-04-17 10:49:48,143 - Epoch: [164][  300/  518]    Overall Loss 2.831875    Objective Loss 2.831875                                        LR 0.000016    Time 0.204949    
2023-04-17 10:49:58,324 - Epoch: [164][  350/  518]    Overall Loss 2.823413    Objective Loss 2.823413                                        LR 0.000016    Time 0.204754    
2023-04-17 10:50:08,456 - Epoch: [164][  400/  518]    Overall Loss 2.826406    Objective Loss 2.826406                                        LR 0.000016    Time 0.204485    
2023-04-17 10:50:18,623 - Epoch: [164][  450/  518]    Overall Loss 2.822756    Objective Loss 2.822756                                        LR 0.000016    Time 0.204355    
2023-04-17 10:50:28,845 - Epoch: [164][  500/  518]    Overall Loss 2.826001    Objective Loss 2.826001                                        LR 0.000016    Time 0.204360    
2023-04-17 10:50:32,365 - Epoch: [164][  518/  518]    Overall Loss 2.824828    Objective Loss 2.824828                                        LR 0.000016    Time 0.204054    
2023-04-17 10:50:32,446 - --- validate (epoch=164)-----------
2023-04-17 10:50:32,447 - 4952 samples (32 per mini-batch)
2023-04-17 10:51:15,207 - Epoch: [164][   50/  155]    Loss 3.048237    mAP 0.517228    
2023-04-17 10:51:59,475 - Epoch: [164][  100/  155]    Loss 3.066435    mAP 0.519259    
2023-04-17 10:52:42,435 - Epoch: [164][  150/  155]    Loss 3.074668    mAP 0.518385    
2023-04-17 10:52:46,336 - Epoch: [164][  155/  155]    Loss 3.078118    mAP 0.517707    
2023-04-17 10:52:46,414 - ==> mAP: 0.51771    Loss: 3.078

2023-04-17 10:52:46,418 - ==> Best [mAP: 0.523314   vloss: 3.081842   Sparsity:0.00   Params: 2177088 on epoch: 162]
2023-04-17 10:52:46,418 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 10:52:46,455 - 

2023-04-17 10:52:46,455 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 10:52:57,363 - Epoch: [165][   50/  518]    Overall Loss 2.827189    Objective Loss 2.827189                                        LR 0.000016    Time 0.218102    
2023-04-17 10:53:07,466 - Epoch: [165][  100/  518]    Overall Loss 2.820677    Objective Loss 2.820677                                        LR 0.000016    Time 0.210066    
2023-04-17 10:53:17,583 - Epoch: [165][  150/  518]    Overall Loss 2.812865    Objective Loss 2.812865                                        LR 0.000016    Time 0.207480    
2023-04-17 10:53:27,651 - Epoch: [165][  200/  518]    Overall Loss 2.828331    Objective Loss 2.828331                                        LR 0.000016    Time 0.205944    
2023-04-17 10:53:37,800 - Epoch: [165][  250/  518]    Overall Loss 2.830799    Objective Loss 2.830799                                        LR 0.000016    Time 0.205345    
2023-04-17 10:53:47,908 - Epoch: [165][  300/  518]    Overall Loss 2.832534    Objective Loss 2.832534                                        LR 0.000016    Time 0.204809    
2023-04-17 10:53:58,029 - Epoch: [165][  350/  518]    Overall Loss 2.833571    Objective Loss 2.833571                                        LR 0.000016    Time 0.204462    
2023-04-17 10:54:08,183 - Epoch: [165][  400/  518]    Overall Loss 2.827238    Objective Loss 2.827238                                        LR 0.000016    Time 0.204286    
2023-04-17 10:54:18,281 - Epoch: [165][  450/  518]    Overall Loss 2.826748    Objective Loss 2.826748                                        LR 0.000016    Time 0.204025    
2023-04-17 10:54:28,472 - Epoch: [165][  500/  518]    Overall Loss 2.832520    Objective Loss 2.832520                                        LR 0.000016    Time 0.204001    
2023-04-17 10:54:31,986 - Epoch: [165][  518/  518]    Overall Loss 2.828612    Objective Loss 2.828612                                        LR 0.000016    Time 0.203694    
2023-04-17 10:54:32,067 - --- validate (epoch=165)-----------
2023-04-17 10:54:32,068 - 4952 samples (32 per mini-batch)
2023-04-17 10:55:17,299 - Epoch: [165][   50/  155]    Loss 3.073571    mAP 0.520041    
2023-04-17 10:56:03,090 - Epoch: [165][  100/  155]    Loss 3.070817    mAP 0.510750    
2023-04-17 10:56:48,260 - Epoch: [165][  150/  155]    Loss 3.079423    mAP 0.511337    
2023-04-17 10:56:52,542 - Epoch: [165][  155/  155]    Loss 3.075636    mAP 0.512496    
2023-04-17 10:56:52,615 - ==> mAP: 0.51250    Loss: 3.076

2023-04-17 10:56:52,619 - ==> Best [mAP: 0.523314   vloss: 3.081842   Sparsity:0.00   Params: 2177088 on epoch: 162]
2023-04-17 10:56:52,619 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 10:56:52,657 - 

2023-04-17 10:56:52,657 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 10:57:03,555 - Epoch: [166][   50/  518]    Overall Loss 2.769312    Objective Loss 2.769312                                        LR 0.000016    Time 0.217892    
2023-04-17 10:57:13,666 - Epoch: [166][  100/  518]    Overall Loss 2.789417    Objective Loss 2.789417                                        LR 0.000016    Time 0.210048    
2023-04-17 10:57:23,759 - Epoch: [166][  150/  518]    Overall Loss 2.794217    Objective Loss 2.794217                                        LR 0.000016    Time 0.207304    
2023-04-17 10:57:33,966 - Epoch: [166][  200/  518]    Overall Loss 2.802951    Objective Loss 2.802951                                        LR 0.000016    Time 0.206507    
2023-04-17 10:57:44,095 - Epoch: [166][  250/  518]    Overall Loss 2.812601    Objective Loss 2.812601                                        LR 0.000016    Time 0.205716    
2023-04-17 10:57:54,237 - Epoch: [166][  300/  518]    Overall Loss 2.809294    Objective Loss 2.809294                                        LR 0.000016    Time 0.205230    
2023-04-17 10:58:04,360 - Epoch: [166][  350/  518]    Overall Loss 2.813785    Objective Loss 2.813785                                        LR 0.000016    Time 0.204829    
2023-04-17 10:58:14,524 - Epoch: [166][  400/  518]    Overall Loss 2.817937    Objective Loss 2.817937                                        LR 0.000016    Time 0.204634    
2023-04-17 10:58:24,613 - Epoch: [166][  450/  518]    Overall Loss 2.819814    Objective Loss 2.819814                                        LR 0.000016    Time 0.204311    
2023-04-17 10:58:34,734 - Epoch: [166][  500/  518]    Overall Loss 2.823301    Objective Loss 2.823301                                        LR 0.000016    Time 0.204121    
2023-04-17 10:58:38,240 - Epoch: [166][  518/  518]    Overall Loss 2.822064    Objective Loss 2.822064                                        LR 0.000016    Time 0.203794    
2023-04-17 10:58:38,321 - --- validate (epoch=166)-----------
2023-04-17 10:58:38,322 - 4952 samples (32 per mini-batch)
2023-04-17 10:59:22,629 - Epoch: [166][   50/  155]    Loss 3.069968    mAP 0.505833    
2023-04-17 11:00:07,312 - Epoch: [166][  100/  155]    Loss 3.071936    mAP 0.514891    
2023-04-17 11:00:52,238 - Epoch: [166][  150/  155]    Loss 3.080621    mAP 0.513744    
2023-04-17 11:00:56,520 - Epoch: [166][  155/  155]    Loss 3.080972    mAP 0.514294    
2023-04-17 11:00:56,599 - ==> mAP: 0.51429    Loss: 3.081

2023-04-17 11:00:56,603 - ==> Best [mAP: 0.523314   vloss: 3.081842   Sparsity:0.00   Params: 2177088 on epoch: 162]
2023-04-17 11:00:56,603 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 11:00:56,640 - 

2023-04-17 11:00:56,640 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 11:01:07,557 - Epoch: [167][   50/  518]    Overall Loss 2.777027    Objective Loss 2.777027                                        LR 0.000016    Time 0.218279    
2023-04-17 11:01:17,674 - Epoch: [167][  100/  518]    Overall Loss 2.810530    Objective Loss 2.810530                                        LR 0.000016    Time 0.210289    
2023-04-17 11:01:27,847 - Epoch: [167][  150/  518]    Overall Loss 2.824255    Objective Loss 2.824255                                        LR 0.000016    Time 0.208009    
2023-04-17 11:01:37,849 - Epoch: [167][  200/  518]    Overall Loss 2.822014    Objective Loss 2.822014                                        LR 0.000016    Time 0.206005    
2023-04-17 11:01:47,911 - Epoch: [167][  250/  518]    Overall Loss 2.822086    Objective Loss 2.822086                                        LR 0.000016    Time 0.205047    
2023-04-17 11:01:58,026 - Epoch: [167][  300/  518]    Overall Loss 2.823249    Objective Loss 2.823249                                        LR 0.000016    Time 0.204584    
2023-04-17 11:02:08,091 - Epoch: [167][  350/  518]    Overall Loss 2.822734    Objective Loss 2.822734                                        LR 0.000016    Time 0.204110    
2023-04-17 11:02:18,265 - Epoch: [167][  400/  518]    Overall Loss 2.823168    Objective Loss 2.823168                                        LR 0.000016    Time 0.204027    
2023-04-17 11:02:28,441 - Epoch: [167][  450/  518]    Overall Loss 2.821691    Objective Loss 2.821691                                        LR 0.000016    Time 0.203967    
2023-04-17 11:02:38,574 - Epoch: [167][  500/  518]    Overall Loss 2.828667    Objective Loss 2.828667                                        LR 0.000016    Time 0.203833    
2023-04-17 11:02:42,100 - Epoch: [167][  518/  518]    Overall Loss 2.826893    Objective Loss 2.826893                                        LR 0.000016    Time 0.203558    
2023-04-17 11:02:42,183 - --- validate (epoch=167)-----------
2023-04-17 11:02:42,184 - 4952 samples (32 per mini-batch)
2023-04-17 11:03:29,597 - Epoch: [167][   50/  155]    Loss 3.073549    mAP 0.506059    
2023-04-17 11:04:17,106 - Epoch: [167][  100/  155]    Loss 3.089834    mAP 0.522404    
2023-04-17 11:05:03,857 - Epoch: [167][  150/  155]    Loss 3.075469    mAP 0.521421    
2023-04-17 11:05:09,054 - Epoch: [167][  155/  155]    Loss 3.077094    mAP 0.518396    
2023-04-17 11:05:09,130 - ==> mAP: 0.51840    Loss: 3.077

2023-04-17 11:05:09,134 - ==> Best [mAP: 0.523314   vloss: 3.081842   Sparsity:0.00   Params: 2177088 on epoch: 162]
2023-04-17 11:05:09,134 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 11:05:09,172 - 

2023-04-17 11:05:09,172 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 11:05:19,993 - Epoch: [168][   50/  518]    Overall Loss 2.814029    Objective Loss 2.814029                                        LR 0.000016    Time 0.216353    
2023-04-17 11:05:30,091 - Epoch: [168][  100/  518]    Overall Loss 2.812260    Objective Loss 2.812260                                        LR 0.000016    Time 0.209143    
2023-04-17 11:05:40,261 - Epoch: [168][  150/  518]    Overall Loss 2.815659    Objective Loss 2.815659                                        LR 0.000016    Time 0.207215    
2023-04-17 11:05:50,362 - Epoch: [168][  200/  518]    Overall Loss 2.824703    Objective Loss 2.824703                                        LR 0.000016    Time 0.205911    
2023-04-17 11:06:00,524 - Epoch: [168][  250/  518]    Overall Loss 2.822276    Objective Loss 2.822276                                        LR 0.000016    Time 0.205371    
2023-04-17 11:06:10,606 - Epoch: [168][  300/  518]    Overall Loss 2.823063    Objective Loss 2.823063                                        LR 0.000016    Time 0.204743    
2023-04-17 11:06:20,812 - Epoch: [168][  350/  518]    Overall Loss 2.827482    Objective Loss 2.827482                                        LR 0.000016    Time 0.204649    
2023-04-17 11:06:30,977 - Epoch: [168][  400/  518]    Overall Loss 2.828428    Objective Loss 2.828428                                        LR 0.000016    Time 0.204477    
2023-04-17 11:06:41,205 - Epoch: [168][  450/  518]    Overall Loss 2.823712    Objective Loss 2.823712                                        LR 0.000016    Time 0.204483    
2023-04-17 11:06:51,383 - Epoch: [168][  500/  518]    Overall Loss 2.823862    Objective Loss 2.823862                                        LR 0.000016    Time 0.204387    
2023-04-17 11:06:54,915 - Epoch: [168][  518/  518]    Overall Loss 2.826942    Objective Loss 2.826942                                        LR 0.000016    Time 0.204103    
2023-04-17 11:06:54,997 - --- validate (epoch=168)-----------
2023-04-17 11:06:54,997 - 4952 samples (32 per mini-batch)
2023-04-17 11:07:40,174 - Epoch: [168][   50/  155]    Loss 3.089449    mAP 0.519704    
2023-04-17 11:08:24,862 - Epoch: [168][  100/  155]    Loss 3.084410    mAP 0.515001    
2023-04-17 11:09:09,518 - Epoch: [168][  150/  155]    Loss 3.075172    mAP 0.519227    
2023-04-17 11:09:13,617 - Epoch: [168][  155/  155]    Loss 3.075032    mAP 0.518331    
2023-04-17 11:09:13,693 - ==> mAP: 0.51833    Loss: 3.075

2023-04-17 11:09:13,697 - ==> Best [mAP: 0.523314   vloss: 3.081842   Sparsity:0.00   Params: 2177088 on epoch: 162]
2023-04-17 11:09:13,697 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 11:09:13,735 - 

2023-04-17 11:09:13,735 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 11:09:24,628 - Epoch: [169][   50/  518]    Overall Loss 2.861392    Objective Loss 2.861392                                        LR 0.000016    Time 0.217810    
2023-04-17 11:09:34,734 - Epoch: [169][  100/  518]    Overall Loss 2.835530    Objective Loss 2.835530                                        LR 0.000016    Time 0.209942    
2023-04-17 11:09:44,810 - Epoch: [169][  150/  518]    Overall Loss 2.842330    Objective Loss 2.842330                                        LR 0.000016    Time 0.207130    
2023-04-17 11:09:54,957 - Epoch: [169][  200/  518]    Overall Loss 2.851475    Objective Loss 2.851475                                        LR 0.000016    Time 0.206071    
2023-04-17 11:10:05,121 - Epoch: [169][  250/  518]    Overall Loss 2.839888    Objective Loss 2.839888                                        LR 0.000016    Time 0.205507    
2023-04-17 11:10:15,226 - Epoch: [169][  300/  518]    Overall Loss 2.840361    Objective Loss 2.840361                                        LR 0.000016    Time 0.204935    
2023-04-17 11:10:25,256 - Epoch: [169][  350/  518]    Overall Loss 2.839990    Objective Loss 2.839990                                        LR 0.000016    Time 0.204310    
2023-04-17 11:10:35,345 - Epoch: [169][  400/  518]    Overall Loss 2.836269    Objective Loss 2.836269                                        LR 0.000016    Time 0.203990    
2023-04-17 11:10:45,386 - Epoch: [169][  450/  518]    Overall Loss 2.823557    Objective Loss 2.823557                                        LR 0.000016    Time 0.203636    
2023-04-17 11:10:55,562 - Epoch: [169][  500/  518]    Overall Loss 2.821111    Objective Loss 2.821111                                        LR 0.000016    Time 0.203620    
2023-04-17 11:10:59,072 - Epoch: [169][  518/  518]    Overall Loss 2.822927    Objective Loss 2.822927                                        LR 0.000016    Time 0.203319    
2023-04-17 11:10:59,151 - --- validate (epoch=169)-----------
2023-04-17 11:10:59,152 - 4952 samples (32 per mini-batch)
2023-04-17 11:11:42,506 - Epoch: [169][   50/  155]    Loss 3.060050    mAP 0.510170    
2023-04-17 11:12:26,122 - Epoch: [169][  100/  155]    Loss 3.062767    mAP 0.512082    
2023-04-17 11:13:10,081 - Epoch: [169][  150/  155]    Loss 3.080281    mAP 0.509668    
2023-04-17 11:13:14,098 - Epoch: [169][  155/  155]    Loss 3.076459    mAP 0.509351    
2023-04-17 11:13:14,175 - ==> mAP: 0.50935    Loss: 3.076

2023-04-17 11:13:14,179 - ==> Best [mAP: 0.523314   vloss: 3.081842   Sparsity:0.00   Params: 2177088 on epoch: 162]
2023-04-17 11:13:14,179 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 11:13:14,217 - 

2023-04-17 11:13:14,217 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 11:13:24,896 - Epoch: [170][   50/  518]    Overall Loss 2.802789    Objective Loss 2.802789                                        LR 0.000016    Time 0.213521    
2023-04-17 11:13:34,939 - Epoch: [170][  100/  518]    Overall Loss 2.810423    Objective Loss 2.810423                                        LR 0.000016    Time 0.207175    
2023-04-17 11:13:45,183 - Epoch: [170][  150/  518]    Overall Loss 2.807345    Objective Loss 2.807345                                        LR 0.000016    Time 0.206399    
2023-04-17 11:13:55,277 - Epoch: [170][  200/  518]    Overall Loss 2.816920    Objective Loss 2.816920                                        LR 0.000016    Time 0.205263    
2023-04-17 11:14:05,401 - Epoch: [170][  250/  518]    Overall Loss 2.816329    Objective Loss 2.816329                                        LR 0.000016    Time 0.204700    
2023-04-17 11:14:15,586 - Epoch: [170][  300/  518]    Overall Loss 2.817826    Objective Loss 2.817826                                        LR 0.000016    Time 0.204527    
2023-04-17 11:14:25,660 - Epoch: [170][  350/  518]    Overall Loss 2.811932    Objective Loss 2.811932                                        LR 0.000016    Time 0.204087    
2023-04-17 11:14:35,824 - Epoch: [170][  400/  518]    Overall Loss 2.813547    Objective Loss 2.813547                                        LR 0.000016    Time 0.203983    
2023-04-17 11:14:45,956 - Epoch: [170][  450/  518]    Overall Loss 2.808152    Objective Loss 2.808152                                        LR 0.000016    Time 0.203831    
2023-04-17 11:14:56,082 - Epoch: [170][  500/  518]    Overall Loss 2.811098    Objective Loss 2.811098                                        LR 0.000016    Time 0.203696    
2023-04-17 11:14:59,650 - Epoch: [170][  518/  518]    Overall Loss 2.809273    Objective Loss 2.809273                                        LR 0.000016    Time 0.203506    
2023-04-17 11:14:59,731 - --- validate (epoch=170)-----------
2023-04-17 11:14:59,732 - 4952 samples (32 per mini-batch)
2023-04-17 11:15:44,500 - Epoch: [170][   50/  155]    Loss 3.064336    mAP 0.499130    
2023-04-17 11:16:31,765 - Epoch: [170][  100/  155]    Loss 3.085808    mAP 0.507873    
2023-04-17 11:17:19,005 - Epoch: [170][  150/  155]    Loss 3.086125    mAP 0.508415    
2023-04-17 11:17:23,447 - Epoch: [170][  155/  155]    Loss 3.082629    mAP 0.508624    
2023-04-17 11:17:23,528 - ==> mAP: 0.50862    Loss: 3.083

2023-04-17 11:17:23,531 - ==> Best [mAP: 0.523314   vloss: 3.081842   Sparsity:0.00   Params: 2177088 on epoch: 162]
2023-04-17 11:17:23,531 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 11:17:23,569 - 

2023-04-17 11:17:23,569 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 11:17:34,386 - Epoch: [171][   50/  518]    Overall Loss 2.848310    Objective Loss 2.848310                                        LR 0.000016    Time 0.216272    
2023-04-17 11:17:44,521 - Epoch: [171][  100/  518]    Overall Loss 2.838521    Objective Loss 2.838521                                        LR 0.000016    Time 0.209473    
2023-04-17 11:17:54,617 - Epoch: [171][  150/  518]    Overall Loss 2.824060    Objective Loss 2.824060                                        LR 0.000016    Time 0.206947    
2023-04-17 11:18:04,671 - Epoch: [171][  200/  518]    Overall Loss 2.826236    Objective Loss 2.826236                                        LR 0.000016    Time 0.205472    
2023-04-17 11:18:14,692 - Epoch: [171][  250/  518]    Overall Loss 2.825546    Objective Loss 2.825546                                        LR 0.000016    Time 0.204455    
2023-04-17 11:18:24,732 - Epoch: [171][  300/  518]    Overall Loss 2.822995    Objective Loss 2.822995                                        LR 0.000016    Time 0.203841    
2023-04-17 11:18:34,857 - Epoch: [171][  350/  518]    Overall Loss 2.820332    Objective Loss 2.820332                                        LR 0.000016    Time 0.203645    
2023-04-17 11:18:44,983 - Epoch: [171][  400/  518]    Overall Loss 2.826044    Objective Loss 2.826044                                        LR 0.000016    Time 0.203500    
2023-04-17 11:18:55,042 - Epoch: [171][  450/  518]    Overall Loss 2.820656    Objective Loss 2.820656                                        LR 0.000016    Time 0.203238    
2023-04-17 11:19:05,159 - Epoch: [171][  500/  518]    Overall Loss 2.825022    Objective Loss 2.825022                                        LR 0.000016    Time 0.203145    
2023-04-17 11:19:08,660 - Epoch: [171][  518/  518]    Overall Loss 2.825668    Objective Loss 2.825668                                        LR 0.000016    Time 0.202843    
2023-04-17 11:19:08,740 - --- validate (epoch=171)-----------
2023-04-17 11:19:08,741 - 4952 samples (32 per mini-batch)
2023-04-17 11:19:56,674 - Epoch: [171][   50/  155]    Loss 3.069118    mAP 0.531837    
2023-04-17 11:20:42,745 - Epoch: [171][  100/  155]    Loss 3.073631    mAP 0.523507    
2023-04-17 11:21:30,825 - Epoch: [171][  150/  155]    Loss 3.075704    mAP 0.518568    
2023-04-17 11:21:34,982 - Epoch: [171][  155/  155]    Loss 3.074612    mAP 0.519390    
2023-04-17 11:21:35,070 - ==> mAP: 0.51939    Loss: 3.075

2023-04-17 11:21:35,075 - ==> Best [mAP: 0.523314   vloss: 3.081842   Sparsity:0.00   Params: 2177088 on epoch: 162]
2023-04-17 11:21:35,075 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 11:21:35,113 - 

2023-04-17 11:21:35,113 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 11:21:45,983 - Epoch: [172][   50/  518]    Overall Loss 2.767772    Objective Loss 2.767772                                        LR 0.000016    Time 0.217342    
2023-04-17 11:21:56,111 - Epoch: [172][  100/  518]    Overall Loss 2.797740    Objective Loss 2.797740                                        LR 0.000016    Time 0.209942    
2023-04-17 11:22:06,302 - Epoch: [172][  150/  518]    Overall Loss 2.806960    Objective Loss 2.806960                                        LR 0.000016    Time 0.207888    
2023-04-17 11:22:16,445 - Epoch: [172][  200/  518]    Overall Loss 2.818356    Objective Loss 2.818356                                        LR 0.000016    Time 0.206625    
2023-04-17 11:22:26,595 - Epoch: [172][  250/  518]    Overall Loss 2.830193    Objective Loss 2.830193                                        LR 0.000016    Time 0.205892    
2023-04-17 11:22:36,802 - Epoch: [172][  300/  518]    Overall Loss 2.811118    Objective Loss 2.811118                                        LR 0.000016    Time 0.205597    
2023-04-17 11:22:46,977 - Epoch: [172][  350/  518]    Overall Loss 2.814985    Objective Loss 2.814985                                        LR 0.000016    Time 0.205293    
2023-04-17 11:22:57,107 - Epoch: [172][  400/  518]    Overall Loss 2.820071    Objective Loss 2.820071                                        LR 0.000016    Time 0.204952    
2023-04-17 11:23:07,166 - Epoch: [172][  450/  518]    Overall Loss 2.826359    Objective Loss 2.826359                                        LR 0.000016    Time 0.204529    
2023-04-17 11:23:17,314 - Epoch: [172][  500/  518]    Overall Loss 2.823742    Objective Loss 2.823742                                        LR 0.000016    Time 0.204370    
2023-04-17 11:23:20,831 - Epoch: [172][  518/  518]    Overall Loss 2.822347    Objective Loss 2.822347                                        LR 0.000016    Time 0.204057    
2023-04-17 11:23:20,910 - --- validate (epoch=172)-----------
2023-04-17 11:23:20,911 - 4952 samples (32 per mini-batch)
2023-04-17 11:24:06,897 - Epoch: [172][   50/  155]    Loss 3.075880    mAP 0.524025    
2023-04-17 11:24:51,460 - Epoch: [172][  100/  155]    Loss 3.086367    mAP 0.515177    
2023-04-17 11:25:38,017 - Epoch: [172][  150/  155]    Loss 3.084124    mAP 0.518646    
2023-04-17 11:25:41,872 - Epoch: [172][  155/  155]    Loss 3.075306    mAP 0.519242    
2023-04-17 11:25:41,950 - ==> mAP: 0.51924    Loss: 3.075

2023-04-17 11:25:41,954 - ==> Best [mAP: 0.523314   vloss: 3.081842   Sparsity:0.00   Params: 2177088 on epoch: 162]
2023-04-17 11:25:41,954 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 11:25:41,991 - 

2023-04-17 11:25:41,991 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 11:25:52,949 - Epoch: [173][   50/  518]    Overall Loss 2.804506    Objective Loss 2.804506                                        LR 0.000016    Time 0.219100    
2023-04-17 11:26:03,124 - Epoch: [173][  100/  518]    Overall Loss 2.822162    Objective Loss 2.822162                                        LR 0.000016    Time 0.211277    
2023-04-17 11:26:13,281 - Epoch: [173][  150/  518]    Overall Loss 2.835739    Objective Loss 2.835739                                        LR 0.000016    Time 0.208553    
2023-04-17 11:26:23,337 - Epoch: [173][  200/  518]    Overall Loss 2.813554    Objective Loss 2.813554                                        LR 0.000016    Time 0.206689    
2023-04-17 11:26:33,423 - Epoch: [173][  250/  518]    Overall Loss 2.807330    Objective Loss 2.807330                                        LR 0.000016    Time 0.205688    
2023-04-17 11:26:43,549 - Epoch: [173][  300/  518]    Overall Loss 2.805661    Objective Loss 2.805661                                        LR 0.000016    Time 0.205157    
2023-04-17 11:26:53,722 - Epoch: [173][  350/  518]    Overall Loss 2.803604    Objective Loss 2.803604                                        LR 0.000016    Time 0.204910    
2023-04-17 11:27:03,843 - Epoch: [173][  400/  518]    Overall Loss 2.815592    Objective Loss 2.815592                                        LR 0.000016    Time 0.204594    
2023-04-17 11:27:13,905 - Epoch: [173][  450/  518]    Overall Loss 2.817212    Objective Loss 2.817212                                        LR 0.000016    Time 0.204218    
2023-04-17 11:27:24,033 - Epoch: [173][  500/  518]    Overall Loss 2.819767    Objective Loss 2.819767                                        LR 0.000016    Time 0.204049    
2023-04-17 11:27:27,550 - Epoch: [173][  518/  518]    Overall Loss 2.822323    Objective Loss 2.822323                                        LR 0.000016    Time 0.203746    
2023-04-17 11:27:27,630 - --- validate (epoch=173)-----------
2023-04-17 11:27:27,630 - 4952 samples (32 per mini-batch)
2023-04-17 11:28:14,333 - Epoch: [173][   50/  155]    Loss 3.081738    mAP 0.517084    
2023-04-17 11:28:59,104 - Epoch: [173][  100/  155]    Loss 3.074923    mAP 0.508719    
2023-04-17 11:29:43,707 - Epoch: [173][  150/  155]    Loss 3.069787    mAP 0.512249    
2023-04-17 11:29:48,374 - Epoch: [173][  155/  155]    Loss 3.072957    mAP 0.511635    
2023-04-17 11:29:48,450 - ==> mAP: 0.51163    Loss: 3.073

2023-04-17 11:29:48,454 - ==> Best [mAP: 0.523314   vloss: 3.081842   Sparsity:0.00   Params: 2177088 on epoch: 162]
2023-04-17 11:29:48,454 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 11:29:48,492 - 

2023-04-17 11:29:48,492 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 11:29:59,277 - Epoch: [174][   50/  518]    Overall Loss 2.830722    Objective Loss 2.830722                                        LR 0.000016    Time 0.215634    
2023-04-17 11:30:09,312 - Epoch: [174][  100/  518]    Overall Loss 2.788230    Objective Loss 2.788230                                        LR 0.000016    Time 0.208151    
2023-04-17 11:30:19,366 - Epoch: [174][  150/  518]    Overall Loss 2.795753    Objective Loss 2.795753                                        LR 0.000016    Time 0.205788    
2023-04-17 11:30:29,435 - Epoch: [174][  200/  518]    Overall Loss 2.801961    Objective Loss 2.801961                                        LR 0.000016    Time 0.204677    
2023-04-17 11:30:39,543 - Epoch: [174][  250/  518]    Overall Loss 2.804481    Objective Loss 2.804481                                        LR 0.000016    Time 0.204167    
2023-04-17 11:30:49,696 - Epoch: [174][  300/  518]    Overall Loss 2.806466    Objective Loss 2.806466                                        LR 0.000016    Time 0.203978    
2023-04-17 11:30:59,778 - Epoch: [174][  350/  518]    Overall Loss 2.807553    Objective Loss 2.807553                                        LR 0.000016    Time 0.203641    
2023-04-17 11:31:09,852 - Epoch: [174][  400/  518]    Overall Loss 2.811065    Objective Loss 2.811065                                        LR 0.000016    Time 0.203366    
2023-04-17 11:31:19,975 - Epoch: [174][  450/  518]    Overall Loss 2.813445    Objective Loss 2.813445                                        LR 0.000016    Time 0.203263    
2023-04-17 11:31:30,026 - Epoch: [174][  500/  518]    Overall Loss 2.813459    Objective Loss 2.813459                                        LR 0.000016    Time 0.203035    
2023-04-17 11:31:33,573 - Epoch: [174][  518/  518]    Overall Loss 2.813823    Objective Loss 2.813823                                        LR 0.000016    Time 0.202826    
2023-04-17 11:31:33,653 - --- validate (epoch=174)-----------
2023-04-17 11:31:33,654 - 4952 samples (32 per mini-batch)
2023-04-17 11:32:19,701 - Epoch: [174][   50/  155]    Loss 3.035847    mAP 0.501099    
2023-04-17 11:33:04,333 - Epoch: [174][  100/  155]    Loss 3.058553    mAP 0.510683    
2023-04-17 11:33:48,994 - Epoch: [174][  150/  155]    Loss 3.082699    mAP 0.505483    
2023-04-17 11:33:53,271 - Epoch: [174][  155/  155]    Loss 3.077978    mAP 0.504314    
2023-04-17 11:33:53,348 - ==> mAP: 0.50431    Loss: 3.078

2023-04-17 11:33:53,351 - ==> Best [mAP: 0.523314   vloss: 3.081842   Sparsity:0.00   Params: 2177088 on epoch: 162]
2023-04-17 11:33:53,351 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 11:33:53,388 - 

2023-04-17 11:33:53,388 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 11:34:04,511 - Epoch: [175][   50/  518]    Overall Loss 2.803904    Objective Loss 2.803904                                        LR 0.000016    Time 0.222399    
2023-04-17 11:34:14,594 - Epoch: [175][  100/  518]    Overall Loss 2.828469    Objective Loss 2.828469                                        LR 0.000016    Time 0.212014    
2023-04-17 11:34:24,706 - Epoch: [175][  150/  518]    Overall Loss 2.827438    Objective Loss 2.827438                                        LR 0.000016    Time 0.208751    
2023-04-17 11:34:34,787 - Epoch: [175][  200/  518]    Overall Loss 2.832007    Objective Loss 2.832007                                        LR 0.000016    Time 0.206958    
2023-04-17 11:34:44,843 - Epoch: [175][  250/  518]    Overall Loss 2.827536    Objective Loss 2.827536                                        LR 0.000016    Time 0.205785    
2023-04-17 11:34:54,919 - Epoch: [175][  300/  518]    Overall Loss 2.823310    Objective Loss 2.823310                                        LR 0.000016    Time 0.205070    
2023-04-17 11:35:05,005 - Epoch: [175][  350/  518]    Overall Loss 2.825827    Objective Loss 2.825827                                        LR 0.000016    Time 0.204585    
2023-04-17 11:35:15,116 - Epoch: [175][  400/  518]    Overall Loss 2.818890    Objective Loss 2.818890                                        LR 0.000016    Time 0.204287    
2023-04-17 11:35:25,171 - Epoch: [175][  450/  518]    Overall Loss 2.818748    Objective Loss 2.818748                                        LR 0.000016    Time 0.203930    
2023-04-17 11:35:35,285 - Epoch: [175][  500/  518]    Overall Loss 2.815706    Objective Loss 2.815706                                        LR 0.000016    Time 0.203761    
2023-04-17 11:35:38,776 - Epoch: [175][  518/  518]    Overall Loss 2.815365    Objective Loss 2.815365                                        LR 0.000016    Time 0.203418    
2023-04-17 11:35:38,858 - --- validate (epoch=175)-----------
2023-04-17 11:35:38,858 - 4952 samples (32 per mini-batch)
2023-04-17 11:36:25,682 - Epoch: [175][   50/  155]    Loss 3.079803    mAP 0.519783    
2023-04-17 11:37:12,279 - Epoch: [175][  100/  155]    Loss 3.095039    mAP 0.521188    
2023-04-17 11:37:57,072 - Epoch: [175][  150/  155]    Loss 3.069868    mAP 0.524559    
2023-04-17 11:38:01,333 - Epoch: [175][  155/  155]    Loss 3.072943    mAP 0.523944    
2023-04-17 11:38:01,413 - ==> mAP: 0.52394    Loss: 3.073

2023-04-17 11:38:01,417 - ==> Best [mAP: 0.523944   vloss: 3.072943   Sparsity:0.00   Params: 2177088 on epoch: 175]
2023-04-17 11:38:01,417 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 11:38:01,470 - 

2023-04-17 11:38:01,470 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 11:38:12,334 - Epoch: [176][   50/  518]    Overall Loss 2.842463    Objective Loss 2.842463                                        LR 0.000016    Time 0.217225    
2023-04-17 11:38:22,404 - Epoch: [176][  100/  518]    Overall Loss 2.847842    Objective Loss 2.847842                                        LR 0.000016    Time 0.209297    
2023-04-17 11:38:32,558 - Epoch: [176][  150/  518]    Overall Loss 2.825515    Objective Loss 2.825515                                        LR 0.000016    Time 0.207212    
2023-04-17 11:38:42,799 - Epoch: [176][  200/  518]    Overall Loss 2.832120    Objective Loss 2.832120                                        LR 0.000016    Time 0.206609    
2023-04-17 11:38:52,866 - Epoch: [176][  250/  518]    Overall Loss 2.834574    Objective Loss 2.834574                                        LR 0.000016    Time 0.205549    
2023-04-17 11:39:02,909 - Epoch: [176][  300/  518]    Overall Loss 2.831032    Objective Loss 2.831032                                        LR 0.000016    Time 0.204761    
2023-04-17 11:39:12,963 - Epoch: [176][  350/  518]    Overall Loss 2.821372    Objective Loss 2.821372                                        LR 0.000016    Time 0.204231    
2023-04-17 11:39:23,057 - Epoch: [176][  400/  518]    Overall Loss 2.810981    Objective Loss 2.810981                                        LR 0.000016    Time 0.203934    
2023-04-17 11:39:33,154 - Epoch: [176][  450/  518]    Overall Loss 2.812581    Objective Loss 2.812581                                        LR 0.000016    Time 0.203710    
2023-04-17 11:39:43,207 - Epoch: [176][  500/  518]    Overall Loss 2.817278    Objective Loss 2.817278                                        LR 0.000016    Time 0.203441    
2023-04-17 11:39:46,705 - Epoch: [176][  518/  518]    Overall Loss 2.820103    Objective Loss 2.820103                                        LR 0.000016    Time 0.203123    
2023-04-17 11:39:46,782 - --- validate (epoch=176)-----------
2023-04-17 11:39:46,782 - 4952 samples (32 per mini-batch)
2023-04-17 11:40:34,082 - Epoch: [176][   50/  155]    Loss 3.059261    mAP 0.502192    
2023-04-17 11:41:20,233 - Epoch: [176][  100/  155]    Loss 3.083152    mAP 0.501094    
2023-04-17 11:42:07,284 - Epoch: [176][  150/  155]    Loss 3.077493    mAP 0.513363    
2023-04-17 11:42:11,288 - Epoch: [176][  155/  155]    Loss 3.077805    mAP 0.513733    
2023-04-17 11:42:11,366 - ==> mAP: 0.51373    Loss: 3.078

2023-04-17 11:42:11,370 - ==> Best [mAP: 0.523944   vloss: 3.072943   Sparsity:0.00   Params: 2177088 on epoch: 175]
2023-04-17 11:42:11,370 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 11:42:11,406 - 

2023-04-17 11:42:11,406 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 11:42:22,228 - Epoch: [177][   50/  518]    Overall Loss 2.873384    Objective Loss 2.873384                                        LR 0.000016    Time 0.216390    
2023-04-17 11:42:32,307 - Epoch: [177][  100/  518]    Overall Loss 2.857828    Objective Loss 2.857828                                        LR 0.000016    Time 0.208966    
2023-04-17 11:42:42,400 - Epoch: [177][  150/  518]    Overall Loss 2.838006    Objective Loss 2.838006                                        LR 0.000016    Time 0.206591    
2023-04-17 11:42:52,460 - Epoch: [177][  200/  518]    Overall Loss 2.825964    Objective Loss 2.825964                                        LR 0.000016    Time 0.205233    
2023-04-17 11:43:02,625 - Epoch: [177][  250/  518]    Overall Loss 2.828949    Objective Loss 2.828949                                        LR 0.000016    Time 0.204841    
2023-04-17 11:43:12,666 - Epoch: [177][  300/  518]    Overall Loss 2.830390    Objective Loss 2.830390                                        LR 0.000016    Time 0.204164    
2023-04-17 11:43:22,693 - Epoch: [177][  350/  518]    Overall Loss 2.825888    Objective Loss 2.825888                                        LR 0.000016    Time 0.203644    
2023-04-17 11:43:32,806 - Epoch: [177][  400/  518]    Overall Loss 2.818796    Objective Loss 2.818796                                        LR 0.000016    Time 0.203467    
2023-04-17 11:43:42,874 - Epoch: [177][  450/  518]    Overall Loss 2.817958    Objective Loss 2.817958                                        LR 0.000016    Time 0.203229    
2023-04-17 11:43:52,996 - Epoch: [177][  500/  518]    Overall Loss 2.821981    Objective Loss 2.821981                                        LR 0.000016    Time 0.203148    
2023-04-17 11:43:56,561 - Epoch: [177][  518/  518]    Overall Loss 2.824895    Objective Loss 2.824895                                        LR 0.000016    Time 0.202968    
2023-04-17 11:43:56,641 - --- validate (epoch=177)-----------
2023-04-17 11:43:56,641 - 4952 samples (32 per mini-batch)
2023-04-17 11:44:41,773 - Epoch: [177][   50/  155]    Loss 3.111557    mAP 0.532852    
2023-04-17 11:45:24,075 - Epoch: [177][  100/  155]    Loss 3.084337    mAP 0.527164    
2023-04-17 11:46:07,596 - Epoch: [177][  150/  155]    Loss 3.081718    mAP 0.520234    
2023-04-17 11:46:11,810 - Epoch: [177][  155/  155]    Loss 3.076770    mAP 0.520405    
2023-04-17 11:46:11,887 - ==> mAP: 0.52040    Loss: 3.077

2023-04-17 11:46:11,891 - ==> Best [mAP: 0.523944   vloss: 3.072943   Sparsity:0.00   Params: 2177088 on epoch: 175]
2023-04-17 11:46:11,891 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 11:46:11,928 - 

2023-04-17 11:46:11,928 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 11:46:22,777 - Epoch: [178][   50/  518]    Overall Loss 2.822578    Objective Loss 2.822578                                        LR 0.000016    Time 0.216917    
2023-04-17 11:46:32,901 - Epoch: [178][  100/  518]    Overall Loss 2.812563    Objective Loss 2.812563                                        LR 0.000016    Time 0.209680    
2023-04-17 11:46:43,057 - Epoch: [178][  150/  518]    Overall Loss 2.814830    Objective Loss 2.814830                                        LR 0.000016    Time 0.207484    
2023-04-17 11:46:53,208 - Epoch: [178][  200/  518]    Overall Loss 2.822788    Objective Loss 2.822788                                        LR 0.000016    Time 0.206361    
2023-04-17 11:47:03,254 - Epoch: [178][  250/  518]    Overall Loss 2.812045    Objective Loss 2.812045                                        LR 0.000016    Time 0.205266    
2023-04-17 11:47:13,269 - Epoch: [178][  300/  518]    Overall Loss 2.811404    Objective Loss 2.811404                                        LR 0.000016    Time 0.204433    
2023-04-17 11:47:23,397 - Epoch: [178][  350/  518]    Overall Loss 2.811339    Objective Loss 2.811339                                        LR 0.000016    Time 0.204163    
2023-04-17 11:47:33,514 - Epoch: [178][  400/  518]    Overall Loss 2.815458    Objective Loss 2.815458                                        LR 0.000016    Time 0.203931    
2023-04-17 11:47:43,633 - Epoch: [178][  450/  518]    Overall Loss 2.809807    Objective Loss 2.809807                                        LR 0.000016    Time 0.203755    
2023-04-17 11:47:53,745 - Epoch: [178][  500/  518]    Overall Loss 2.804009    Objective Loss 2.804009                                        LR 0.000016    Time 0.203599    
2023-04-17 11:47:57,276 - Epoch: [178][  518/  518]    Overall Loss 2.807462    Objective Loss 2.807462                                        LR 0.000016    Time 0.203341    
2023-04-17 11:47:57,355 - --- validate (epoch=178)-----------
2023-04-17 11:47:57,356 - 4952 samples (32 per mini-batch)
2023-04-17 11:48:41,006 - Epoch: [178][   50/  155]    Loss 3.072269    mAP 0.520011    
2023-04-17 11:49:24,223 - Epoch: [178][  100/  155]    Loss 3.069060    mAP 0.523058    
2023-04-17 11:50:07,853 - Epoch: [178][  150/  155]    Loss 3.078368    mAP 0.522699    
2023-04-17 11:50:12,298 - Epoch: [178][  155/  155]    Loss 3.080380    mAP 0.521817    
2023-04-17 11:50:12,367 - ==> mAP: 0.52182    Loss: 3.080

2023-04-17 11:50:12,371 - ==> Best [mAP: 0.523944   vloss: 3.072943   Sparsity:0.00   Params: 2177088 on epoch: 175]
2023-04-17 11:50:12,371 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 11:50:12,407 - 

2023-04-17 11:50:12,408 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 11:50:23,425 - Epoch: [179][   50/  518]    Overall Loss 2.863872    Objective Loss 2.863872                                        LR 0.000016    Time 0.220298    
2023-04-17 11:50:33,539 - Epoch: [179][  100/  518]    Overall Loss 2.824224    Objective Loss 2.824224                                        LR 0.000016    Time 0.211276    
2023-04-17 11:50:43,663 - Epoch: [179][  150/  518]    Overall Loss 2.818174    Objective Loss 2.818174                                        LR 0.000016    Time 0.208330    
2023-04-17 11:50:53,842 - Epoch: [179][  200/  518]    Overall Loss 2.812794    Objective Loss 2.812794                                        LR 0.000016    Time 0.207134    
2023-04-17 11:51:03,905 - Epoch: [179][  250/  518]    Overall Loss 2.822533    Objective Loss 2.822533                                        LR 0.000016    Time 0.205952    
2023-04-17 11:51:14,033 - Epoch: [179][  300/  518]    Overall Loss 2.813062    Objective Loss 2.813062                                        LR 0.000016    Time 0.205383    
2023-04-17 11:51:24,101 - Epoch: [179][  350/  518]    Overall Loss 2.811700    Objective Loss 2.811700                                        LR 0.000016    Time 0.204805    
2023-04-17 11:51:34,178 - Epoch: [179][  400/  518]    Overall Loss 2.818373    Objective Loss 2.818373                                        LR 0.000016    Time 0.204393    
2023-04-17 11:51:44,267 - Epoch: [179][  450/  518]    Overall Loss 2.820642    Objective Loss 2.820642                                        LR 0.000016    Time 0.204098    
2023-04-17 11:51:54,426 - Epoch: [179][  500/  518]    Overall Loss 2.816019    Objective Loss 2.816019                                        LR 0.000016    Time 0.204003    
2023-04-17 11:51:57,938 - Epoch: [179][  518/  518]    Overall Loss 2.816963    Objective Loss 2.816963                                        LR 0.000016    Time 0.203695    
2023-04-17 11:51:58,020 - --- validate (epoch=179)-----------
2023-04-17 11:51:58,021 - 4952 samples (32 per mini-batch)
2023-04-17 11:52:43,710 - Epoch: [179][   50/  155]    Loss 3.068859    mAP 0.521413    
2023-04-17 11:53:27,998 - Epoch: [179][  100/  155]    Loss 3.068900    mAP 0.516842    
2023-04-17 11:54:12,209 - Epoch: [179][  150/  155]    Loss 3.076322    mAP 0.512733    
2023-04-17 11:54:16,105 - Epoch: [179][  155/  155]    Loss 3.074382    mAP 0.513728    
2023-04-17 11:54:16,182 - ==> mAP: 0.51373    Loss: 3.074

2023-04-17 11:54:16,185 - ==> Best [mAP: 0.523944   vloss: 3.072943   Sparsity:0.00   Params: 2177088 on epoch: 175]
2023-04-17 11:54:16,186 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 11:54:16,221 - 

2023-04-17 11:54:16,222 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 11:54:27,259 - Epoch: [180][   50/  518]    Overall Loss 2.829558    Objective Loss 2.829558                                        LR 0.000016    Time 0.220692    
2023-04-17 11:54:37,370 - Epoch: [180][  100/  518]    Overall Loss 2.828122    Objective Loss 2.828122                                        LR 0.000016    Time 0.211442    
2023-04-17 11:54:47,455 - Epoch: [180][  150/  518]    Overall Loss 2.828651    Objective Loss 2.828651                                        LR 0.000016    Time 0.208184    
2023-04-17 11:54:57,498 - Epoch: [180][  200/  518]    Overall Loss 2.838409    Objective Loss 2.838409                                        LR 0.000016    Time 0.206343    
2023-04-17 11:55:07,593 - Epoch: [180][  250/  518]    Overall Loss 2.827264    Objective Loss 2.827264                                        LR 0.000016    Time 0.205449    
2023-04-17 11:55:17,750 - Epoch: [180][  300/  518]    Overall Loss 2.825859    Objective Loss 2.825859                                        LR 0.000016    Time 0.205061    
2023-04-17 11:55:27,841 - Epoch: [180][  350/  518]    Overall Loss 2.824581    Objective Loss 2.824581                                        LR 0.000016    Time 0.204594    
2023-04-17 11:55:38,002 - Epoch: [180][  400/  518]    Overall Loss 2.819632    Objective Loss 2.819632                                        LR 0.000016    Time 0.204417    
2023-04-17 11:55:48,109 - Epoch: [180][  450/  518]    Overall Loss 2.817736    Objective Loss 2.817736                                        LR 0.000016    Time 0.204160    
2023-04-17 11:55:58,295 - Epoch: [180][  500/  518]    Overall Loss 2.814165    Objective Loss 2.814165                                        LR 0.000016    Time 0.204113    
2023-04-17 11:56:01,832 - Epoch: [180][  518/  518]    Overall Loss 2.813320    Objective Loss 2.813320                                        LR 0.000016    Time 0.203848    
2023-04-17 11:56:01,914 - --- validate (epoch=180)-----------
2023-04-17 11:56:01,914 - 4952 samples (32 per mini-batch)
2023-04-17 11:56:47,852 - Epoch: [180][   50/  155]    Loss 3.068701    mAP 0.510295    
2023-04-17 11:57:31,636 - Epoch: [180][  100/  155]    Loss 3.084570    mAP 0.501394    
2023-04-17 11:58:14,580 - Epoch: [180][  150/  155]    Loss 3.075214    mAP 0.507481    
2023-04-17 11:58:19,008 - Epoch: [180][  155/  155]    Loss 3.077616    mAP 0.505810    
2023-04-17 11:58:19,086 - ==> mAP: 0.50581    Loss: 3.078

2023-04-17 11:58:19,090 - ==> Best [mAP: 0.523944   vloss: 3.072943   Sparsity:0.00   Params: 2177088 on epoch: 175]
2023-04-17 11:58:19,090 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 11:58:19,126 - 

2023-04-17 11:58:19,126 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 11:58:29,998 - Epoch: [181][   50/  518]    Overall Loss 2.825977    Objective Loss 2.825977                                        LR 0.000016    Time 0.217373    
2023-04-17 11:58:40,028 - Epoch: [181][  100/  518]    Overall Loss 2.819902    Objective Loss 2.819902                                        LR 0.000016    Time 0.208978    
2023-04-17 11:58:50,132 - Epoch: [181][  150/  518]    Overall Loss 2.823731    Objective Loss 2.823731                                        LR 0.000016    Time 0.206663    
2023-04-17 11:59:00,201 - Epoch: [181][  200/  518]    Overall Loss 2.827913    Objective Loss 2.827913                                        LR 0.000016    Time 0.205338    
2023-04-17 11:59:10,308 - Epoch: [181][  250/  518]    Overall Loss 2.835236    Objective Loss 2.835236                                        LR 0.000016    Time 0.204689    
2023-04-17 11:59:20,406 - Epoch: [181][  300/  518]    Overall Loss 2.836129    Objective Loss 2.836129                                        LR 0.000016    Time 0.204229    
2023-04-17 11:59:30,639 - Epoch: [181][  350/  518]    Overall Loss 2.833544    Objective Loss 2.833544                                        LR 0.000016    Time 0.204289    
2023-04-17 11:59:40,848 - Epoch: [181][  400/  518]    Overall Loss 2.833045    Objective Loss 2.833045                                        LR 0.000016    Time 0.204269    
2023-04-17 11:59:50,974 - Epoch: [181][  450/  518]    Overall Loss 2.827129    Objective Loss 2.827129                                        LR 0.000016    Time 0.204073    
2023-04-17 12:00:01,020 - Epoch: [181][  500/  518]    Overall Loss 2.827542    Objective Loss 2.827542                                        LR 0.000016    Time 0.203754    
2023-04-17 12:00:04,584 - Epoch: [181][  518/  518]    Overall Loss 2.830021    Objective Loss 2.830021                                        LR 0.000016    Time 0.203552    
2023-04-17 12:00:04,664 - --- validate (epoch=181)-----------
2023-04-17 12:00:04,664 - 4952 samples (32 per mini-batch)
2023-04-17 12:00:50,444 - Epoch: [181][   50/  155]    Loss 3.116970    mAP 0.515077    
2023-04-17 12:01:34,658 - Epoch: [181][  100/  155]    Loss 3.077216    mAP 0.525094    
2023-04-17 12:02:19,695 - Epoch: [181][  150/  155]    Loss 3.084069    mAP 0.517669    
2023-04-17 12:02:24,300 - Epoch: [181][  155/  155]    Loss 3.083986    mAP 0.517354    
2023-04-17 12:02:24,381 - ==> mAP: 0.51735    Loss: 3.084

2023-04-17 12:02:24,385 - ==> Best [mAP: 0.523944   vloss: 3.072943   Sparsity:0.00   Params: 2177088 on epoch: 175]
2023-04-17 12:02:24,385 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 12:02:24,447 - 

2023-04-17 12:02:24,447 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 12:02:35,395 - Epoch: [182][   50/  518]    Overall Loss 2.846836    Objective Loss 2.846836                                        LR 0.000016    Time 0.218873    
2023-04-17 12:02:45,414 - Epoch: [182][  100/  518]    Overall Loss 2.843299    Objective Loss 2.843299                                        LR 0.000016    Time 0.209606    
2023-04-17 12:02:55,537 - Epoch: [182][  150/  518]    Overall Loss 2.832718    Objective Loss 2.832718                                        LR 0.000016    Time 0.207219    
2023-04-17 12:03:05,620 - Epoch: [182][  200/  518]    Overall Loss 2.813095    Objective Loss 2.813095                                        LR 0.000016    Time 0.205820    
2023-04-17 12:03:15,695 - Epoch: [182][  250/  518]    Overall Loss 2.819173    Objective Loss 2.819173                                        LR 0.000016    Time 0.204948    
2023-04-17 12:03:25,788 - Epoch: [182][  300/  518]    Overall Loss 2.813828    Objective Loss 2.813828                                        LR 0.000016    Time 0.204430    
2023-04-17 12:03:35,871 - Epoch: [182][  350/  518]    Overall Loss 2.817211    Objective Loss 2.817211                                        LR 0.000016    Time 0.204030    
2023-04-17 12:03:45,966 - Epoch: [182][  400/  518]    Overall Loss 2.816081    Objective Loss 2.816081                                        LR 0.000016    Time 0.203760    
2023-04-17 12:03:56,022 - Epoch: [182][  450/  518]    Overall Loss 2.821928    Objective Loss 2.821928                                        LR 0.000016    Time 0.203463    
2023-04-17 12:04:06,193 - Epoch: [182][  500/  518]    Overall Loss 2.821659    Objective Loss 2.821659                                        LR 0.000016    Time 0.203455    
2023-04-17 12:04:09,686 - Epoch: [182][  518/  518]    Overall Loss 2.821532    Objective Loss 2.821532                                        LR 0.000016    Time 0.203127    
2023-04-17 12:04:09,766 - --- validate (epoch=182)-----------
2023-04-17 12:04:09,767 - 4952 samples (32 per mini-batch)
2023-04-17 12:04:55,192 - Epoch: [182][   50/  155]    Loss 3.047910    mAP 0.515559    
2023-04-17 12:05:39,122 - Epoch: [182][  100/  155]    Loss 3.066116    mAP 0.512920    
2023-04-17 12:06:25,291 - Epoch: [182][  150/  155]    Loss 3.072923    mAP 0.512937    
2023-04-17 12:06:29,251 - Epoch: [182][  155/  155]    Loss 3.069756    mAP 0.512111    
2023-04-17 12:06:29,330 - ==> mAP: 0.51211    Loss: 3.070

2023-04-17 12:06:29,334 - ==> Best [mAP: 0.523944   vloss: 3.072943   Sparsity:0.00   Params: 2177088 on epoch: 175]
2023-04-17 12:06:29,334 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 12:06:29,371 - 

2023-04-17 12:06:29,371 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 12:06:40,354 - Epoch: [183][   50/  518]    Overall Loss 2.801256    Objective Loss 2.801256                                        LR 0.000016    Time 0.219611    
2023-04-17 12:06:50,430 - Epoch: [183][  100/  518]    Overall Loss 2.791889    Objective Loss 2.791889                                        LR 0.000016    Time 0.210550    
2023-04-17 12:07:00,568 - Epoch: [183][  150/  518]    Overall Loss 2.793757    Objective Loss 2.793757                                        LR 0.000016    Time 0.207943    
2023-04-17 12:07:10,636 - Epoch: [183][  200/  518]    Overall Loss 2.809956    Objective Loss 2.809956                                        LR 0.000016    Time 0.206292    
2023-04-17 12:07:20,707 - Epoch: [183][  250/  518]    Overall Loss 2.804826    Objective Loss 2.804826                                        LR 0.000016    Time 0.205312    
2023-04-17 12:07:30,785 - Epoch: [183][  300/  518]    Overall Loss 2.805424    Objective Loss 2.805424                                        LR 0.000016    Time 0.204680    
2023-04-17 12:07:40,804 - Epoch: [183][  350/  518]    Overall Loss 2.812114    Objective Loss 2.812114                                        LR 0.000016    Time 0.204062    
2023-04-17 12:07:50,873 - Epoch: [183][  400/  518]    Overall Loss 2.816741    Objective Loss 2.816741                                        LR 0.000016    Time 0.203722    
2023-04-17 12:08:00,950 - Epoch: [183][  450/  518]    Overall Loss 2.820391    Objective Loss 2.820391                                        LR 0.000016    Time 0.203476    
2023-04-17 12:08:11,077 - Epoch: [183][  500/  518]    Overall Loss 2.819464    Objective Loss 2.819464                                        LR 0.000016    Time 0.203379    
2023-04-17 12:08:14,554 - Epoch: [183][  518/  518]    Overall Loss 2.819625    Objective Loss 2.819625                                        LR 0.000016    Time 0.203023    
2023-04-17 12:08:14,634 - --- validate (epoch=183)-----------
2023-04-17 12:08:14,635 - 4952 samples (32 per mini-batch)
2023-04-17 12:08:59,709 - Epoch: [183][   50/  155]    Loss 3.105455    mAP 0.516003    
2023-04-17 12:09:44,226 - Epoch: [183][  100/  155]    Loss 3.095927    mAP 0.517672    
2023-04-17 12:10:29,439 - Epoch: [183][  150/  155]    Loss 3.073816    mAP 0.520231    
2023-04-17 12:10:33,572 - Epoch: [183][  155/  155]    Loss 3.076529    mAP 0.520583    
2023-04-17 12:10:33,652 - ==> mAP: 0.52058    Loss: 3.077

2023-04-17 12:10:33,656 - ==> Best [mAP: 0.523944   vloss: 3.072943   Sparsity:0.00   Params: 2177088 on epoch: 175]
2023-04-17 12:10:33,656 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 12:10:33,693 - 

2023-04-17 12:10:33,693 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 12:10:44,552 - Epoch: [184][   50/  518]    Overall Loss 2.863744    Objective Loss 2.863744                                        LR 0.000016    Time 0.217117    
2023-04-17 12:10:54,586 - Epoch: [184][  100/  518]    Overall Loss 2.828738    Objective Loss 2.828738                                        LR 0.000016    Time 0.208887    
2023-04-17 12:11:04,720 - Epoch: [184][  150/  518]    Overall Loss 2.835595    Objective Loss 2.835595                                        LR 0.000016    Time 0.206807    
2023-04-17 12:11:14,733 - Epoch: [184][  200/  518]    Overall Loss 2.823887    Objective Loss 2.823887                                        LR 0.000016    Time 0.205162    
2023-04-17 12:11:24,862 - Epoch: [184][  250/  518]    Overall Loss 2.824607    Objective Loss 2.824607                                        LR 0.000016    Time 0.204642    
2023-04-17 12:11:34,890 - Epoch: [184][  300/  518]    Overall Loss 2.824839    Objective Loss 2.824839                                        LR 0.000016    Time 0.203956    
2023-04-17 12:11:45,003 - Epoch: [184][  350/  518]    Overall Loss 2.821808    Objective Loss 2.821808                                        LR 0.000016    Time 0.203708    
2023-04-17 12:11:55,093 - Epoch: [184][  400/  518]    Overall Loss 2.821219    Objective Loss 2.821219                                        LR 0.000016    Time 0.203467    
2023-04-17 12:12:05,167 - Epoch: [184][  450/  518]    Overall Loss 2.822275    Objective Loss 2.822275                                        LR 0.000016    Time 0.203243    
2023-04-17 12:12:15,200 - Epoch: [184][  500/  518]    Overall Loss 2.821098    Objective Loss 2.821098                                        LR 0.000016    Time 0.202981    
2023-04-17 12:12:18,715 - Epoch: [184][  518/  518]    Overall Loss 2.822841    Objective Loss 2.822841                                        LR 0.000016    Time 0.202712    
2023-04-17 12:12:18,794 - --- validate (epoch=184)-----------
2023-04-17 12:12:18,794 - 4952 samples (32 per mini-batch)
2023-04-17 12:13:02,856 - Epoch: [184][   50/  155]    Loss 3.071423    mAP 0.511013    
2023-04-17 12:13:46,933 - Epoch: [184][  100/  155]    Loss 3.066087    mAP 0.521031    
2023-04-17 12:14:28,828 - Epoch: [184][  150/  155]    Loss 3.071585    mAP 0.526511    
2023-04-17 12:14:33,138 - Epoch: [184][  155/  155]    Loss 3.074984    mAP 0.526061    
2023-04-17 12:14:33,217 - ==> mAP: 0.52606    Loss: 3.075

2023-04-17 12:14:33,221 - ==> Best [mAP: 0.526061   vloss: 3.074984   Sparsity:0.00   Params: 2177088 on epoch: 184]
2023-04-17 12:14:33,221 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 12:14:33,272 - 

2023-04-17 12:14:33,273 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 12:14:43,997 - Epoch: [185][   50/  518]    Overall Loss 2.789241    Objective Loss 2.789241                                        LR 0.000016    Time 0.214438    
2023-04-17 12:14:54,126 - Epoch: [185][  100/  518]    Overall Loss 2.819522    Objective Loss 2.819522                                        LR 0.000016    Time 0.208493    
2023-04-17 12:15:04,275 - Epoch: [185][  150/  518]    Overall Loss 2.811488    Objective Loss 2.811488                                        LR 0.000016    Time 0.206647    
2023-04-17 12:15:14,403 - Epoch: [185][  200/  518]    Overall Loss 2.805357    Objective Loss 2.805357                                        LR 0.000016    Time 0.205613    
2023-04-17 12:15:24,651 - Epoch: [185][  250/  518]    Overall Loss 2.813086    Objective Loss 2.813086                                        LR 0.000016    Time 0.205479    
2023-04-17 12:15:34,812 - Epoch: [185][  300/  518]    Overall Loss 2.817115    Objective Loss 2.817115                                        LR 0.000016    Time 0.205096    
2023-04-17 12:15:44,881 - Epoch: [185][  350/  518]    Overall Loss 2.816902    Objective Loss 2.816902                                        LR 0.000016    Time 0.204562    
2023-04-17 12:15:55,012 - Epoch: [185][  400/  518]    Overall Loss 2.824048    Objective Loss 2.824048                                        LR 0.000016    Time 0.204315    
2023-04-17 12:16:05,045 - Epoch: [185][  450/  518]    Overall Loss 2.821567    Objective Loss 2.821567                                        LR 0.000016    Time 0.203906    
2023-04-17 12:16:15,149 - Epoch: [185][  500/  518]    Overall Loss 2.820351    Objective Loss 2.820351                                        LR 0.000016    Time 0.203720    
2023-04-17 12:16:18,676 - Epoch: [185][  518/  518]    Overall Loss 2.822838    Objective Loss 2.822838                                        LR 0.000016    Time 0.203449    
2023-04-17 12:16:18,755 - --- validate (epoch=185)-----------
2023-04-17 12:16:18,756 - 4952 samples (32 per mini-batch)
2023-04-17 12:17:02,794 - Epoch: [185][   50/  155]    Loss 3.043874    mAP 0.527576    
2023-04-17 12:17:48,510 - Epoch: [185][  100/  155]    Loss 3.074278    mAP 0.513296    
2023-04-17 12:18:32,899 - Epoch: [185][  150/  155]    Loss 3.074915    mAP 0.516514    
2023-04-17 12:18:36,957 - Epoch: [185][  155/  155]    Loss 3.073663    mAP 0.515542    
2023-04-17 12:18:37,036 - ==> mAP: 0.51554    Loss: 3.074

2023-04-17 12:18:37,039 - ==> Best [mAP: 0.526061   vloss: 3.074984   Sparsity:0.00   Params: 2177088 on epoch: 184]
2023-04-17 12:18:37,039 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 12:18:37,075 - 

2023-04-17 12:18:37,075 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 12:18:48,009 - Epoch: [186][   50/  518]    Overall Loss 2.856649    Objective Loss 2.856649                                        LR 0.000016    Time 0.218608    
2023-04-17 12:18:58,098 - Epoch: [186][  100/  518]    Overall Loss 2.847959    Objective Loss 2.847959                                        LR 0.000016    Time 0.210185    
2023-04-17 12:19:08,138 - Epoch: [186][  150/  518]    Overall Loss 2.834364    Objective Loss 2.834364                                        LR 0.000016    Time 0.207046    
2023-04-17 12:19:18,187 - Epoch: [186][  200/  518]    Overall Loss 2.823556    Objective Loss 2.823556                                        LR 0.000016    Time 0.205521    
2023-04-17 12:19:28,323 - Epoch: [186][  250/  518]    Overall Loss 2.829347    Objective Loss 2.829347                                        LR 0.000016    Time 0.204954    
2023-04-17 12:19:38,376 - Epoch: [186][  300/  518]    Overall Loss 2.832445    Objective Loss 2.832445                                        LR 0.000016    Time 0.204300    
2023-04-17 12:19:48,432 - Epoch: [186][  350/  518]    Overall Loss 2.835979    Objective Loss 2.835979                                        LR 0.000016    Time 0.203840    
2023-04-17 12:19:58,527 - Epoch: [186][  400/  518]    Overall Loss 2.833990    Objective Loss 2.833990                                        LR 0.000016    Time 0.203594    
2023-04-17 12:20:08,600 - Epoch: [186][  450/  518]    Overall Loss 2.824369    Objective Loss 2.824369                                        LR 0.000016    Time 0.203355    
2023-04-17 12:20:18,675 - Epoch: [186][  500/  518]    Overall Loss 2.825258    Objective Loss 2.825258                                        LR 0.000016    Time 0.203167    
2023-04-17 12:20:22,212 - Epoch: [186][  518/  518]    Overall Loss 2.823259    Objective Loss 2.823259                                        LR 0.000016    Time 0.202934    
2023-04-17 12:20:22,297 - --- validate (epoch=186)-----------
2023-04-17 12:20:22,297 - 4952 samples (32 per mini-batch)
2023-04-17 12:21:06,956 - Epoch: [186][   50/  155]    Loss 3.052711    mAP 0.530550    
2023-04-17 12:21:51,944 - Epoch: [186][  100/  155]    Loss 3.056506    mAP 0.526314    
2023-04-17 12:22:37,870 - Epoch: [186][  150/  155]    Loss 3.077639    mAP 0.519799    
2023-04-17 12:22:42,039 - Epoch: [186][  155/  155]    Loss 3.073379    mAP 0.519848    
2023-04-17 12:22:42,118 - ==> mAP: 0.51985    Loss: 3.073

2023-04-17 12:22:42,122 - ==> Best [mAP: 0.526061   vloss: 3.074984   Sparsity:0.00   Params: 2177088 on epoch: 184]
2023-04-17 12:22:42,122 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 12:22:42,158 - 

2023-04-17 12:22:42,158 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 12:22:53,110 - Epoch: [187][   50/  518]    Overall Loss 2.812813    Objective Loss 2.812813                                        LR 0.000016    Time 0.218988    
2023-04-17 12:23:03,184 - Epoch: [187][  100/  518]    Overall Loss 2.818141    Objective Loss 2.818141                                        LR 0.000016    Time 0.210217    
2023-04-17 12:23:13,225 - Epoch: [187][  150/  518]    Overall Loss 2.822778    Objective Loss 2.822778                                        LR 0.000016    Time 0.207071    
2023-04-17 12:23:23,302 - Epoch: [187][  200/  518]    Overall Loss 2.812607    Objective Loss 2.812607                                        LR 0.000016    Time 0.205682    
2023-04-17 12:23:33,428 - Epoch: [187][  250/  518]    Overall Loss 2.818764    Objective Loss 2.818764                                        LR 0.000016    Time 0.205045    
2023-04-17 12:23:43,499 - Epoch: [187][  300/  518]    Overall Loss 2.811856    Objective Loss 2.811856                                        LR 0.000016    Time 0.204433    
2023-04-17 12:23:53,673 - Epoch: [187][  350/  518]    Overall Loss 2.818102    Objective Loss 2.818102                                        LR 0.000016    Time 0.204295    
2023-04-17 12:24:03,803 - Epoch: [187][  400/  518]    Overall Loss 2.815942    Objective Loss 2.815942                                        LR 0.000016    Time 0.204078    
2023-04-17 12:24:13,880 - Epoch: [187][  450/  518]    Overall Loss 2.814956    Objective Loss 2.814956                                        LR 0.000016    Time 0.203793    
2023-04-17 12:24:23,920 - Epoch: [187][  500/  518]    Overall Loss 2.820729    Objective Loss 2.820729                                        LR 0.000016    Time 0.203491    
2023-04-17 12:24:27,415 - Epoch: [187][  518/  518]    Overall Loss 2.818965    Objective Loss 2.818965                                        LR 0.000016    Time 0.203166    
2023-04-17 12:24:27,496 - --- validate (epoch=187)-----------
2023-04-17 12:24:27,497 - 4952 samples (32 per mini-batch)
2023-04-17 12:25:13,065 - Epoch: [187][   50/  155]    Loss 3.085468    mAP 0.531021    
2023-04-17 12:25:58,272 - Epoch: [187][  100/  155]    Loss 3.066696    mAP 0.521930    
2023-04-17 12:26:43,048 - Epoch: [187][  150/  155]    Loss 3.070871    mAP 0.514133    
2023-04-17 12:26:46,917 - Epoch: [187][  155/  155]    Loss 3.072529    mAP 0.512586    
2023-04-17 12:26:46,995 - ==> mAP: 0.51259    Loss: 3.073

2023-04-17 12:26:46,999 - ==> Best [mAP: 0.526061   vloss: 3.074984   Sparsity:0.00   Params: 2177088 on epoch: 184]
2023-04-17 12:26:46,999 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 12:26:47,035 - 

2023-04-17 12:26:47,035 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 12:26:57,894 - Epoch: [188][   50/  518]    Overall Loss 2.891077    Objective Loss 2.891077                                        LR 0.000016    Time 0.217122    
2023-04-17 12:27:07,934 - Epoch: [188][  100/  518]    Overall Loss 2.860741    Objective Loss 2.860741                                        LR 0.000016    Time 0.208942    
2023-04-17 12:27:18,059 - Epoch: [188][  150/  518]    Overall Loss 2.829134    Objective Loss 2.829134                                        LR 0.000016    Time 0.206785    
2023-04-17 12:27:28,153 - Epoch: [188][  200/  518]    Overall Loss 2.827748    Objective Loss 2.827748                                        LR 0.000016    Time 0.205551    
2023-04-17 12:27:38,348 - Epoch: [188][  250/  518]    Overall Loss 2.831738    Objective Loss 2.831738                                        LR 0.000016    Time 0.205214    
2023-04-17 12:27:48,456 - Epoch: [188][  300/  518]    Overall Loss 2.828162    Objective Loss 2.828162                                        LR 0.000016    Time 0.204701    
2023-04-17 12:27:58,540 - Epoch: [188][  350/  518]    Overall Loss 2.818150    Objective Loss 2.818150                                        LR 0.000016    Time 0.204265    
2023-04-17 12:28:08,680 - Epoch: [188][  400/  518]    Overall Loss 2.817673    Objective Loss 2.817673                                        LR 0.000016    Time 0.204077    
2023-04-17 12:28:18,742 - Epoch: [188][  450/  518]    Overall Loss 2.813509    Objective Loss 2.813509                                        LR 0.000016    Time 0.203759    
2023-04-17 12:28:28,784 - Epoch: [188][  500/  518]    Overall Loss 2.814951    Objective Loss 2.814951                                        LR 0.000016    Time 0.203464    
2023-04-17 12:28:32,311 - Epoch: [188][  518/  518]    Overall Loss 2.816653    Objective Loss 2.816653                                        LR 0.000016    Time 0.203202    
2023-04-17 12:28:32,391 - --- validate (epoch=188)-----------
2023-04-17 12:28:32,392 - 4952 samples (32 per mini-batch)
2023-04-17 12:29:17,285 - Epoch: [188][   50/  155]    Loss 3.093014    mAP 0.511684    
2023-04-17 12:30:00,501 - Epoch: [188][  100/  155]    Loss 3.084823    mAP 0.517767    
2023-04-17 12:30:46,530 - Epoch: [188][  150/  155]    Loss 3.081145    mAP 0.516384    
2023-04-17 12:30:50,470 - Epoch: [188][  155/  155]    Loss 3.073067    mAP 0.518015    
2023-04-17 12:30:50,548 - ==> mAP: 0.51802    Loss: 3.073

2023-04-17 12:30:50,553 - ==> Best [mAP: 0.526061   vloss: 3.074984   Sparsity:0.00   Params: 2177088 on epoch: 184]
2023-04-17 12:30:50,553 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 12:30:50,590 - 

2023-04-17 12:30:50,590 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 12:31:01,524 - Epoch: [189][   50/  518]    Overall Loss 2.785256    Objective Loss 2.785256                                        LR 0.000016    Time 0.218633    
2023-04-17 12:31:11,695 - Epoch: [189][  100/  518]    Overall Loss 2.819630    Objective Loss 2.819630                                        LR 0.000016    Time 0.211004    
2023-04-17 12:31:21,879 - Epoch: [189][  150/  518]    Overall Loss 2.814116    Objective Loss 2.814116                                        LR 0.000016    Time 0.208554    
2023-04-17 12:31:32,033 - Epoch: [189][  200/  518]    Overall Loss 2.809603    Objective Loss 2.809603                                        LR 0.000016    Time 0.207178    
2023-04-17 12:31:42,098 - Epoch: [189][  250/  518]    Overall Loss 2.807876    Objective Loss 2.807876                                        LR 0.000016    Time 0.205995    
2023-04-17 12:31:52,208 - Epoch: [189][  300/  518]    Overall Loss 2.808994    Objective Loss 2.808994                                        LR 0.000016    Time 0.205360    
2023-04-17 12:32:02,200 - Epoch: [189][  350/  518]    Overall Loss 2.813276    Objective Loss 2.813276                                        LR 0.000016    Time 0.204567    
2023-04-17 12:32:12,345 - Epoch: [189][  400/  518]    Overall Loss 2.803391    Objective Loss 2.803391                                        LR 0.000016    Time 0.204354    
2023-04-17 12:32:22,466 - Epoch: [189][  450/  518]    Overall Loss 2.804318    Objective Loss 2.804318                                        LR 0.000016    Time 0.204136    
2023-04-17 12:32:32,607 - Epoch: [189][  500/  518]    Overall Loss 2.807768    Objective Loss 2.807768                                        LR 0.000016    Time 0.204002    
2023-04-17 12:32:36,132 - Epoch: [189][  518/  518]    Overall Loss 2.809758    Objective Loss 2.809758                                        LR 0.000016    Time 0.203716    
2023-04-17 12:32:36,213 - --- validate (epoch=189)-----------
2023-04-17 12:32:36,214 - 4952 samples (32 per mini-batch)
2023-04-17 12:33:21,312 - Epoch: [189][   50/  155]    Loss 3.089611    mAP 0.498784    
2023-04-17 12:34:05,705 - Epoch: [189][  100/  155]    Loss 3.088801    mAP 0.512365    
2023-04-17 12:34:49,427 - Epoch: [189][  150/  155]    Loss 3.076616    mAP 0.508754    
2023-04-17 12:34:53,220 - Epoch: [189][  155/  155]    Loss 3.072956    mAP 0.507698    
2023-04-17 12:34:53,297 - ==> mAP: 0.50770    Loss: 3.073

2023-04-17 12:34:53,301 - ==> Best [mAP: 0.526061   vloss: 3.074984   Sparsity:0.00   Params: 2177088 on epoch: 184]
2023-04-17 12:34:53,301 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 12:34:53,339 - 

2023-04-17 12:34:53,339 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 12:35:04,413 - Epoch: [190][   50/  518]    Overall Loss 2.868499    Objective Loss 2.868499                                        LR 0.000016    Time 0.221422    
2023-04-17 12:35:14,585 - Epoch: [190][  100/  518]    Overall Loss 2.842394    Objective Loss 2.842394                                        LR 0.000016    Time 0.212416    
2023-04-17 12:35:24,684 - Epoch: [190][  150/  518]    Overall Loss 2.808976    Objective Loss 2.808976                                        LR 0.000016    Time 0.208929    
2023-04-17 12:35:34,788 - Epoch: [190][  200/  518]    Overall Loss 2.810630    Objective Loss 2.810630                                        LR 0.000016    Time 0.207207    
2023-04-17 12:35:44,811 - Epoch: [190][  250/  518]    Overall Loss 2.819606    Objective Loss 2.819606                                        LR 0.000016    Time 0.205853    
2023-04-17 12:35:54,982 - Epoch: [190][  300/  518]    Overall Loss 2.824484    Objective Loss 2.824484                                        LR 0.000016    Time 0.205442    
2023-04-17 12:36:04,998 - Epoch: [190][  350/  518]    Overall Loss 2.813290    Objective Loss 2.813290                                        LR 0.000016    Time 0.204705    
2023-04-17 12:36:15,135 - Epoch: [190][  400/  518]    Overall Loss 2.819479    Objective Loss 2.819479                                        LR 0.000016    Time 0.204456    
2023-04-17 12:36:25,234 - Epoch: [190][  450/  518]    Overall Loss 2.820244    Objective Loss 2.820244                                        LR 0.000016    Time 0.204176    
2023-04-17 12:36:35,281 - Epoch: [190][  500/  518]    Overall Loss 2.818081    Objective Loss 2.818081                                        LR 0.000016    Time 0.203851    
2023-04-17 12:36:38,806 - Epoch: [190][  518/  518]    Overall Loss 2.815726    Objective Loss 2.815726                                        LR 0.000016    Time 0.203571    
2023-04-17 12:36:38,888 - --- validate (epoch=190)-----------
2023-04-17 12:36:38,888 - 4952 samples (32 per mini-batch)
2023-04-17 12:37:23,347 - Epoch: [190][   50/  155]    Loss 3.094029    mAP 0.506344    
2023-04-17 12:38:06,916 - Epoch: [190][  100/  155]    Loss 3.067058    mAP 0.511847    
2023-04-17 12:38:51,820 - Epoch: [190][  150/  155]    Loss 3.074567    mAP 0.517176    
2023-04-17 12:38:55,678 - Epoch: [190][  155/  155]    Loss 3.070504    mAP 0.518539    
2023-04-17 12:38:55,754 - ==> mAP: 0.51854    Loss: 3.071

2023-04-17 12:38:55,761 - ==> Best [mAP: 0.526061   vloss: 3.074984   Sparsity:0.00   Params: 2177088 on epoch: 184]
2023-04-17 12:38:55,761 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 12:38:55,807 - 

2023-04-17 12:38:55,807 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 12:39:06,656 - Epoch: [191][   50/  518]    Overall Loss 2.896702    Objective Loss 2.896702                                        LR 0.000016    Time 0.216921    
2023-04-17 12:39:16,832 - Epoch: [191][  100/  518]    Overall Loss 2.844348    Objective Loss 2.844348                                        LR 0.000016    Time 0.210207    
2023-04-17 12:39:27,013 - Epoch: [191][  150/  518]    Overall Loss 2.839651    Objective Loss 2.839651                                        LR 0.000016    Time 0.208000    
2023-04-17 12:39:37,133 - Epoch: [191][  200/  518]    Overall Loss 2.845616    Objective Loss 2.845616                                        LR 0.000016    Time 0.206592    
2023-04-17 12:39:47,256 - Epoch: [191][  250/  518]    Overall Loss 2.842884    Objective Loss 2.842884                                        LR 0.000016    Time 0.205759    
2023-04-17 12:39:57,368 - Epoch: [191][  300/  518]    Overall Loss 2.845387    Objective Loss 2.845387                                        LR 0.000016    Time 0.205170    
2023-04-17 12:40:07,418 - Epoch: [191][  350/  518]    Overall Loss 2.841578    Objective Loss 2.841578                                        LR 0.000016    Time 0.204569    
2023-04-17 12:40:17,546 - Epoch: [191][  400/  518]    Overall Loss 2.836621    Objective Loss 2.836621                                        LR 0.000016    Time 0.204313    
2023-04-17 12:40:27,647 - Epoch: [191][  450/  518]    Overall Loss 2.834132    Objective Loss 2.834132                                        LR 0.000016    Time 0.204055    
2023-04-17 12:40:37,796 - Epoch: [191][  500/  518]    Overall Loss 2.829550    Objective Loss 2.829550                                        LR 0.000016    Time 0.203944    
2023-04-17 12:40:41,302 - Epoch: [191][  518/  518]    Overall Loss 2.825876    Objective Loss 2.825876                                        LR 0.000016    Time 0.203625    
2023-04-17 12:40:41,383 - --- validate (epoch=191)-----------
2023-04-17 12:40:41,383 - 4952 samples (32 per mini-batch)
2023-04-17 12:41:25,664 - Epoch: [191][   50/  155]    Loss 3.038563    mAP 0.524009    
2023-04-17 12:42:08,511 - Epoch: [191][  100/  155]    Loss 3.041056    mAP 0.516477    
2023-04-17 12:42:54,633 - Epoch: [191][  150/  155]    Loss 3.070508    mAP 0.515503    
2023-04-17 12:42:58,970 - Epoch: [191][  155/  155]    Loss 3.074545    mAP 0.514689    
2023-04-17 12:42:59,050 - ==> mAP: 0.51469    Loss: 3.075

2023-04-17 12:42:59,054 - ==> Best [mAP: 0.526061   vloss: 3.074984   Sparsity:0.00   Params: 2177088 on epoch: 184]
2023-04-17 12:42:59,054 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 12:42:59,090 - 

2023-04-17 12:42:59,090 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 12:43:09,967 - Epoch: [192][   50/  518]    Overall Loss 2.828610    Objective Loss 2.828610                                        LR 0.000016    Time 0.217498    
2023-04-17 12:43:20,030 - Epoch: [192][  100/  518]    Overall Loss 2.817576    Objective Loss 2.817576                                        LR 0.000016    Time 0.209362    
2023-04-17 12:43:30,085 - Epoch: [192][  150/  518]    Overall Loss 2.830022    Objective Loss 2.830022                                        LR 0.000016    Time 0.206594    
2023-04-17 12:43:40,284 - Epoch: [192][  200/  518]    Overall Loss 2.814302    Objective Loss 2.814302                                        LR 0.000016    Time 0.205934    
2023-04-17 12:43:50,420 - Epoch: [192][  250/  518]    Overall Loss 2.809739    Objective Loss 2.809739                                        LR 0.000016    Time 0.205286    
2023-04-17 12:44:00,521 - Epoch: [192][  300/  518]    Overall Loss 2.817807    Objective Loss 2.817807                                        LR 0.000016    Time 0.204737    
2023-04-17 12:44:10,608 - Epoch: [192][  350/  518]    Overall Loss 2.815610    Objective Loss 2.815610                                        LR 0.000016    Time 0.204303    
2023-04-17 12:44:20,714 - Epoch: [192][  400/  518]    Overall Loss 2.823108    Objective Loss 2.823108                                        LR 0.000016    Time 0.204027    
2023-04-17 12:44:30,786 - Epoch: [192][  450/  518]    Overall Loss 2.822621    Objective Loss 2.822621                                        LR 0.000016    Time 0.203736    
2023-04-17 12:44:40,905 - Epoch: [192][  500/  518]    Overall Loss 2.822268    Objective Loss 2.822268                                        LR 0.000016    Time 0.203598    
2023-04-17 12:44:44,436 - Epoch: [192][  518/  518]    Overall Loss 2.822570    Objective Loss 2.822570                                        LR 0.000016    Time 0.203338    
2023-04-17 12:44:44,516 - --- validate (epoch=192)-----------
2023-04-17 12:44:44,517 - 4952 samples (32 per mini-batch)
2023-04-17 12:45:29,390 - Epoch: [192][   50/  155]    Loss 3.041730    mAP 0.505502    
2023-04-17 12:46:12,071 - Epoch: [192][  100/  155]    Loss 3.084430    mAP 0.519003    
2023-04-17 12:46:56,190 - Epoch: [192][  150/  155]    Loss 3.074846    mAP 0.514636    
2023-04-17 12:47:00,700 - Epoch: [192][  155/  155]    Loss 3.077213    mAP 0.513764    
2023-04-17 12:47:00,777 - ==> mAP: 0.51376    Loss: 3.077

2023-04-17 12:47:00,781 - ==> Best [mAP: 0.526061   vloss: 3.074984   Sparsity:0.00   Params: 2177088 on epoch: 184]
2023-04-17 12:47:00,781 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 12:47:00,817 - 

2023-04-17 12:47:00,818 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 12:47:11,693 - Epoch: [193][   50/  518]    Overall Loss 2.821327    Objective Loss 2.821327                                        LR 0.000016    Time 0.217446    
2023-04-17 12:47:21,719 - Epoch: [193][  100/  518]    Overall Loss 2.822160    Objective Loss 2.822160                                        LR 0.000016    Time 0.208973    
2023-04-17 12:47:31,825 - Epoch: [193][  150/  518]    Overall Loss 2.824347    Objective Loss 2.824347                                        LR 0.000016    Time 0.206678    
2023-04-17 12:47:41,897 - Epoch: [193][  200/  518]    Overall Loss 2.825139    Objective Loss 2.825139                                        LR 0.000016    Time 0.205362    
2023-04-17 12:47:51,992 - Epoch: [193][  250/  518]    Overall Loss 2.818281    Objective Loss 2.818281                                        LR 0.000016    Time 0.204661    
2023-04-17 12:48:02,100 - Epoch: [193][  300/  518]    Overall Loss 2.824136    Objective Loss 2.824136                                        LR 0.000016    Time 0.204239    
2023-04-17 12:48:12,193 - Epoch: [193][  350/  518]    Overall Loss 2.816143    Objective Loss 2.816143                                        LR 0.000016    Time 0.203894    
2023-04-17 12:48:22,330 - Epoch: [193][  400/  518]    Overall Loss 2.817979    Objective Loss 2.817979                                        LR 0.000016    Time 0.203746    
2023-04-17 12:48:32,410 - Epoch: [193][  450/  518]    Overall Loss 2.813718    Objective Loss 2.813718                                        LR 0.000016    Time 0.203504    
2023-04-17 12:48:42,492 - Epoch: [193][  500/  518]    Overall Loss 2.814290    Objective Loss 2.814290                                        LR 0.000016    Time 0.203316    
2023-04-17 12:48:46,001 - Epoch: [193][  518/  518]    Overall Loss 2.815357    Objective Loss 2.815357                                        LR 0.000016    Time 0.203023    
2023-04-17 12:48:46,080 - --- validate (epoch=193)-----------
2023-04-17 12:48:46,080 - 4952 samples (32 per mini-batch)
2023-04-17 12:49:29,021 - Epoch: [193][   50/  155]    Loss 3.098269    mAP 0.495820    
2023-04-17 12:50:12,532 - Epoch: [193][  100/  155]    Loss 3.068158    mAP 0.514058    
2023-04-17 12:50:55,504 - Epoch: [193][  150/  155]    Loss 3.075422    mAP 0.520051    
2023-04-17 12:50:59,747 - Epoch: [193][  155/  155]    Loss 3.075800    mAP 0.520384    
2023-04-17 12:50:59,827 - ==> mAP: 0.52038    Loss: 3.076

2023-04-17 12:50:59,831 - ==> Best [mAP: 0.526061   vloss: 3.074984   Sparsity:0.00   Params: 2177088 on epoch: 184]
2023-04-17 12:50:59,831 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 12:50:59,867 - 

2023-04-17 12:50:59,867 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 12:51:10,728 - Epoch: [194][   50/  518]    Overall Loss 2.801711    Objective Loss 2.801711                                        LR 0.000016    Time 0.217164    
2023-04-17 12:51:20,746 - Epoch: [194][  100/  518]    Overall Loss 2.797005    Objective Loss 2.797005                                        LR 0.000016    Time 0.208747    
2023-04-17 12:51:30,845 - Epoch: [194][  150/  518]    Overall Loss 2.790248    Objective Loss 2.790248                                        LR 0.000016    Time 0.206484    
2023-04-17 12:51:41,029 - Epoch: [194][  200/  518]    Overall Loss 2.782236    Objective Loss 2.782236                                        LR 0.000016    Time 0.205776    
2023-04-17 12:51:51,176 - Epoch: [194][  250/  518]    Overall Loss 2.796567    Objective Loss 2.796567                                        LR 0.000016    Time 0.205202    
2023-04-17 12:52:01,258 - Epoch: [194][  300/  518]    Overall Loss 2.792034    Objective Loss 2.792034                                        LR 0.000016    Time 0.204602    
2023-04-17 12:52:11,349 - Epoch: [194][  350/  518]    Overall Loss 2.799790    Objective Loss 2.799790                                        LR 0.000016    Time 0.204199    
2023-04-17 12:52:21,380 - Epoch: [194][  400/  518]    Overall Loss 2.801861    Objective Loss 2.801861                                        LR 0.000016    Time 0.203749    
2023-04-17 12:52:31,457 - Epoch: [194][  450/  518]    Overall Loss 2.805772    Objective Loss 2.805772                                        LR 0.000016    Time 0.203499    
2023-04-17 12:52:41,567 - Epoch: [194][  500/  518]    Overall Loss 2.806233    Objective Loss 2.806233                                        LR 0.000016    Time 0.203367    
2023-04-17 12:52:45,082 - Epoch: [194][  518/  518]    Overall Loss 2.811081    Objective Loss 2.811081                                        LR 0.000016    Time 0.203085    
2023-04-17 12:52:45,164 - --- validate (epoch=194)-----------
2023-04-17 12:52:45,164 - 4952 samples (32 per mini-batch)
2023-04-17 12:53:30,108 - Epoch: [194][   50/  155]    Loss 3.073312    mAP 0.523630    
2023-04-17 12:54:14,422 - Epoch: [194][  100/  155]    Loss 3.054515    mAP 0.533231    
2023-04-17 12:55:00,561 - Epoch: [194][  150/  155]    Loss 3.075908    mAP 0.524958    
2023-04-17 12:55:05,160 - Epoch: [194][  155/  155]    Loss 3.074232    mAP 0.524022    
2023-04-17 12:55:05,237 - ==> mAP: 0.52402    Loss: 3.074

2023-04-17 12:55:05,241 - ==> Best [mAP: 0.526061   vloss: 3.074984   Sparsity:0.00   Params: 2177088 on epoch: 184]
2023-04-17 12:55:05,241 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 12:55:05,279 - 

2023-04-17 12:55:05,279 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 12:55:16,096 - Epoch: [195][   50/  518]    Overall Loss 2.793782    Objective Loss 2.793782                                        LR 0.000016    Time 0.216283    
2023-04-17 12:55:26,164 - Epoch: [195][  100/  518]    Overall Loss 2.810045    Objective Loss 2.810045                                        LR 0.000016    Time 0.208810    
2023-04-17 12:55:36,210 - Epoch: [195][  150/  518]    Overall Loss 2.805767    Objective Loss 2.805767                                        LR 0.000016    Time 0.206164    
2023-04-17 12:55:46,337 - Epoch: [195][  200/  518]    Overall Loss 2.809931    Objective Loss 2.809931                                        LR 0.000016    Time 0.205253    
2023-04-17 12:55:56,383 - Epoch: [195][  250/  518]    Overall Loss 2.805466    Objective Loss 2.805466                                        LR 0.000016    Time 0.204381    
2023-04-17 12:56:06,498 - Epoch: [195][  300/  518]    Overall Loss 2.807773    Objective Loss 2.807773                                        LR 0.000016    Time 0.204027    
2023-04-17 12:56:16,575 - Epoch: [195][  350/  518]    Overall Loss 2.805652    Objective Loss 2.805652                                        LR 0.000016    Time 0.203667    
2023-04-17 12:56:26,710 - Epoch: [195][  400/  518]    Overall Loss 2.813458    Objective Loss 2.813458                                        LR 0.000016    Time 0.203544    
2023-04-17 12:56:36,773 - Epoch: [195][  450/  518]    Overall Loss 2.815359    Objective Loss 2.815359                                        LR 0.000016    Time 0.203287    
2023-04-17 12:56:46,826 - Epoch: [195][  500/  518]    Overall Loss 2.810575    Objective Loss 2.810575                                        LR 0.000016    Time 0.203060    
2023-04-17 12:56:50,323 - Epoch: [195][  518/  518]    Overall Loss 2.814706    Objective Loss 2.814706                                        LR 0.000016    Time 0.202755    
2023-04-17 12:56:50,405 - --- validate (epoch=195)-----------
2023-04-17 12:56:50,406 - 4952 samples (32 per mini-batch)
2023-04-17 12:57:34,486 - Epoch: [195][   50/  155]    Loss 3.070994    mAP 0.504152    
2023-04-17 12:58:17,908 - Epoch: [195][  100/  155]    Loss 3.066240    mAP 0.509966    
2023-04-17 12:59:01,565 - Epoch: [195][  150/  155]    Loss 3.074289    mAP 0.509786    
2023-04-17 12:59:05,684 - Epoch: [195][  155/  155]    Loss 3.075676    mAP 0.509113    
2023-04-17 12:59:05,762 - ==> mAP: 0.50911    Loss: 3.076

2023-04-17 12:59:05,835 - ==> Best [mAP: 0.526061   vloss: 3.074984   Sparsity:0.00   Params: 2177088 on epoch: 184]
2023-04-17 12:59:05,835 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 12:59:05,871 - 

2023-04-17 12:59:05,872 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 12:59:16,727 - Epoch: [196][   50/  518]    Overall Loss 2.889293    Objective Loss 2.889293                                        LR 0.000016    Time 0.217052    
2023-04-17 12:59:26,803 - Epoch: [196][  100/  518]    Overall Loss 2.841856    Objective Loss 2.841856                                        LR 0.000016    Time 0.209274    
2023-04-17 12:59:36,870 - Epoch: [196][  150/  518]    Overall Loss 2.807852    Objective Loss 2.807852                                        LR 0.000016    Time 0.206616    
2023-04-17 12:59:47,005 - Epoch: [196][  200/  518]    Overall Loss 2.803875    Objective Loss 2.803875                                        LR 0.000016    Time 0.205628    
2023-04-17 12:59:57,073 - Epoch: [196][  250/  518]    Overall Loss 2.810386    Objective Loss 2.810386                                        LR 0.000016    Time 0.204770    
2023-04-17 13:00:07,189 - Epoch: [196][  300/  518]    Overall Loss 2.814252    Objective Loss 2.814252                                        LR 0.000016    Time 0.204358    
2023-04-17 13:00:17,276 - Epoch: [196][  350/  518]    Overall Loss 2.816828    Objective Loss 2.816828                                        LR 0.000016    Time 0.203978    
2023-04-17 13:00:27,474 - Epoch: [196][  400/  518]    Overall Loss 2.815309    Objective Loss 2.815309                                        LR 0.000016    Time 0.203973    
2023-04-17 13:00:37,521 - Epoch: [196][  450/  518]    Overall Loss 2.810542    Objective Loss 2.810542                                        LR 0.000016    Time 0.203633    
2023-04-17 13:00:47,679 - Epoch: [196][  500/  518]    Overall Loss 2.813040    Objective Loss 2.813040                                        LR 0.000016    Time 0.203582    
2023-04-17 13:00:51,197 - Epoch: [196][  518/  518]    Overall Loss 2.816704    Objective Loss 2.816704                                        LR 0.000016    Time 0.203298    
2023-04-17 13:00:51,276 - --- validate (epoch=196)-----------
2023-04-17 13:00:51,277 - 4952 samples (32 per mini-batch)
2023-04-17 13:01:36,910 - Epoch: [196][   50/  155]    Loss 3.057004    mAP 0.519463    
2023-04-17 13:02:22,416 - Epoch: [196][  100/  155]    Loss 3.087142    mAP 0.522242    
2023-04-17 13:03:08,144 - Epoch: [196][  150/  155]    Loss 3.072710    mAP 0.519288    
2023-04-17 13:03:12,020 - Epoch: [196][  155/  155]    Loss 3.072364    mAP 0.519230    
2023-04-17 13:03:12,101 - ==> mAP: 0.51923    Loss: 3.072

2023-04-17 13:03:12,105 - ==> Best [mAP: 0.526061   vloss: 3.074984   Sparsity:0.00   Params: 2177088 on epoch: 184]
2023-04-17 13:03:12,105 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 13:03:12,141 - 

2023-04-17 13:03:12,141 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 13:03:22,995 - Epoch: [197][   50/  518]    Overall Loss 2.818022    Objective Loss 2.818022                                        LR 0.000016    Time 0.217033    
2023-04-17 13:03:33,147 - Epoch: [197][  100/  518]    Overall Loss 2.816041    Objective Loss 2.816041                                        LR 0.000016    Time 0.210024    
2023-04-17 13:03:43,236 - Epoch: [197][  150/  518]    Overall Loss 2.818362    Objective Loss 2.818362                                        LR 0.000016    Time 0.207264    
2023-04-17 13:03:53,312 - Epoch: [197][  200/  518]    Overall Loss 2.824157    Objective Loss 2.824157                                        LR 0.000016    Time 0.205821    
2023-04-17 13:04:03,386 - Epoch: [197][  250/  518]    Overall Loss 2.820577    Objective Loss 2.820577                                        LR 0.000016    Time 0.204945    
2023-04-17 13:04:13,401 - Epoch: [197][  300/  518]    Overall Loss 2.819524    Objective Loss 2.819524                                        LR 0.000016    Time 0.204166    
2023-04-17 13:04:23,496 - Epoch: [197][  350/  518]    Overall Loss 2.829089    Objective Loss 2.829089                                        LR 0.000016    Time 0.203840    
2023-04-17 13:04:33,705 - Epoch: [197][  400/  518]    Overall Loss 2.817174    Objective Loss 2.817174                                        LR 0.000016    Time 0.203878    
2023-04-17 13:04:43,738 - Epoch: [197][  450/  518]    Overall Loss 2.811408    Objective Loss 2.811408                                        LR 0.000016    Time 0.203515    
2023-04-17 13:04:53,877 - Epoch: [197][  500/  518]    Overall Loss 2.812524    Objective Loss 2.812524                                        LR 0.000016    Time 0.203440    
2023-04-17 13:04:57,362 - Epoch: [197][  518/  518]    Overall Loss 2.814688    Objective Loss 2.814688                                        LR 0.000016    Time 0.203098    
2023-04-17 13:04:57,444 - --- validate (epoch=197)-----------
2023-04-17 13:04:57,444 - 4952 samples (32 per mini-batch)
2023-04-17 13:05:42,075 - Epoch: [197][   50/  155]    Loss 3.068701    mAP 0.513880    
2023-04-17 13:06:26,544 - Epoch: [197][  100/  155]    Loss 3.081660    mAP 0.521573    
2023-04-17 13:07:10,115 - Epoch: [197][  150/  155]    Loss 3.074075    mAP 0.517739    
2023-04-17 13:07:14,124 - Epoch: [197][  155/  155]    Loss 3.068648    mAP 0.517698    
2023-04-17 13:07:14,199 - ==> mAP: 0.51770    Loss: 3.069

2023-04-17 13:07:14,203 - ==> Best [mAP: 0.526061   vloss: 3.074984   Sparsity:0.00   Params: 2177088 on epoch: 184]
2023-04-17 13:07:14,203 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 13:07:14,239 - 

2023-04-17 13:07:14,239 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 13:07:25,186 - Epoch: [198][   50/  518]    Overall Loss 2.838796    Objective Loss 2.838796                                        LR 0.000016    Time 0.218889    
2023-04-17 13:07:35,287 - Epoch: [198][  100/  518]    Overall Loss 2.838666    Objective Loss 2.838666                                        LR 0.000016    Time 0.210436    
2023-04-17 13:07:45,370 - Epoch: [198][  150/  518]    Overall Loss 2.830501    Objective Loss 2.830501                                        LR 0.000016    Time 0.207500    
2023-04-17 13:07:55,417 - Epoch: [198][  200/  518]    Overall Loss 2.821875    Objective Loss 2.821875                                        LR 0.000016    Time 0.205854    
2023-04-17 13:08:05,597 - Epoch: [198][  250/  518]    Overall Loss 2.825665    Objective Loss 2.825665                                        LR 0.000016    Time 0.205396    
2023-04-17 13:08:15,704 - Epoch: [198][  300/  518]    Overall Loss 2.824417    Objective Loss 2.824417                                        LR 0.000016    Time 0.204850    
2023-04-17 13:08:25,814 - Epoch: [198][  350/  518]    Overall Loss 2.830242    Objective Loss 2.830242                                        LR 0.000016    Time 0.204466    
2023-04-17 13:08:35,951 - Epoch: [198][  400/  518]    Overall Loss 2.827486    Objective Loss 2.827486                                        LR 0.000016    Time 0.204247    
2023-04-17 13:08:46,007 - Epoch: [198][  450/  518]    Overall Loss 2.826754    Objective Loss 2.826754                                        LR 0.000016    Time 0.203895    
2023-04-17 13:08:56,056 - Epoch: [198][  500/  518]    Overall Loss 2.822033    Objective Loss 2.822033                                        LR 0.000016    Time 0.203601    
2023-04-17 13:08:59,580 - Epoch: [198][  518/  518]    Overall Loss 2.823069    Objective Loss 2.823069                                        LR 0.000016    Time 0.203328    
2023-04-17 13:08:59,662 - --- validate (epoch=198)-----------
2023-04-17 13:08:59,662 - 4952 samples (32 per mini-batch)
2023-04-17 13:09:45,422 - Epoch: [198][   50/  155]    Loss 3.060639    mAP 0.534526    
2023-04-17 13:10:30,487 - Epoch: [198][  100/  155]    Loss 3.042180    mAP 0.531394    
2023-04-17 13:11:15,884 - Epoch: [198][  150/  155]    Loss 3.071703    mAP 0.521268    
2023-04-17 13:11:19,710 - Epoch: [198][  155/  155]    Loss 3.073556    mAP 0.519489    
2023-04-17 13:11:19,788 - ==> mAP: 0.51949    Loss: 3.074

2023-04-17 13:11:19,792 - ==> Best [mAP: 0.526061   vloss: 3.074984   Sparsity:0.00   Params: 2177088 on epoch: 184]
2023-04-17 13:11:19,792 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 13:11:19,828 - 

2023-04-17 13:11:19,828 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 13:11:30,638 - Epoch: [199][   50/  518]    Overall Loss 2.857795    Objective Loss 2.857795                                        LR 0.000016    Time 0.216155    
2023-04-17 13:11:40,798 - Epoch: [199][  100/  518]    Overall Loss 2.849898    Objective Loss 2.849898                                        LR 0.000016    Time 0.209655    
2023-04-17 13:11:50,821 - Epoch: [199][  150/  518]    Overall Loss 2.832197    Objective Loss 2.832197                                        LR 0.000016    Time 0.206580    
2023-04-17 13:12:00,991 - Epoch: [199][  200/  518]    Overall Loss 2.826109    Objective Loss 2.826109                                        LR 0.000016    Time 0.205777    
2023-04-17 13:12:11,132 - Epoch: [199][  250/  518]    Overall Loss 2.833506    Objective Loss 2.833506                                        LR 0.000016    Time 0.205182    
2023-04-17 13:12:21,240 - Epoch: [199][  300/  518]    Overall Loss 2.831733    Objective Loss 2.831733                                        LR 0.000016    Time 0.204673    
2023-04-17 13:12:31,329 - Epoch: [199][  350/  518]    Overall Loss 2.836035    Objective Loss 2.836035                                        LR 0.000016    Time 0.204255    
2023-04-17 13:12:41,439 - Epoch: [199][  400/  518]    Overall Loss 2.827988    Objective Loss 2.827988                                        LR 0.000016    Time 0.203995    
2023-04-17 13:12:51,488 - Epoch: [199][  450/  518]    Overall Loss 2.833115    Objective Loss 2.833115                                        LR 0.000016    Time 0.203655    
2023-04-17 13:13:01,586 - Epoch: [199][  500/  518]    Overall Loss 2.831723    Objective Loss 2.831723                                        LR 0.000016    Time 0.203484    
2023-04-17 13:13:05,117 - Epoch: [199][  518/  518]    Overall Loss 2.829924    Objective Loss 2.829924                                        LR 0.000016    Time 0.203229    
2023-04-17 13:13:05,198 - --- validate (epoch=199)-----------
2023-04-17 13:13:05,198 - 4952 samples (32 per mini-batch)
2023-04-17 13:13:50,681 - Epoch: [199][   50/  155]    Loss 3.101277    mAP 0.519462    
2023-04-17 13:14:36,061 - Epoch: [199][  100/  155]    Loss 3.059151    mAP 0.527570    
2023-04-17 13:15:21,165 - Epoch: [199][  150/  155]    Loss 3.064233    mAP 0.519220    
2023-04-17 13:15:25,255 - Epoch: [199][  155/  155]    Loss 3.066580    mAP 0.520217    
2023-04-17 13:15:25,333 - ==> mAP: 0.52022    Loss: 3.067

2023-04-17 13:15:25,337 - ==> Best [mAP: 0.526061   vloss: 3.074984   Sparsity:0.00   Params: 2177088 on epoch: 184]
2023-04-17 13:15:25,337 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 13:15:25,374 - 

2023-04-17 13:15:25,374 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 13:15:36,317 - Epoch: [200][   50/  518]    Overall Loss 2.805471    Objective Loss 2.805471                                        LR 0.000004    Time 0.218811    
2023-04-17 13:15:46,431 - Epoch: [200][  100/  518]    Overall Loss 2.805604    Objective Loss 2.805604                                        LR 0.000004    Time 0.210531    
2023-04-17 13:15:56,589 - Epoch: [200][  150/  518]    Overall Loss 2.801007    Objective Loss 2.801007                                        LR 0.000004    Time 0.208063    
2023-04-17 13:16:06,668 - Epoch: [200][  200/  518]    Overall Loss 2.801228    Objective Loss 2.801228                                        LR 0.000004    Time 0.206435    
2023-04-17 13:16:16,857 - Epoch: [200][  250/  518]    Overall Loss 2.801465    Objective Loss 2.801465                                        LR 0.000004    Time 0.205899    
2023-04-17 13:16:26,957 - Epoch: [200][  300/  518]    Overall Loss 2.804614    Objective Loss 2.804614                                        LR 0.000004    Time 0.205241    
2023-04-17 13:16:37,099 - Epoch: [200][  350/  518]    Overall Loss 2.803678    Objective Loss 2.803678                                        LR 0.000004    Time 0.204894    
2023-04-17 13:16:47,175 - Epoch: [200][  400/  518]    Overall Loss 2.802684    Objective Loss 2.802684                                        LR 0.000004    Time 0.204469    
2023-04-17 13:16:57,336 - Epoch: [200][  450/  518]    Overall Loss 2.807211    Objective Loss 2.807211                                        LR 0.000004    Time 0.204327    
2023-04-17 13:17:07,537 - Epoch: [200][  500/  518]    Overall Loss 2.817653    Objective Loss 2.817653                                        LR 0.000004    Time 0.204294    
2023-04-17 13:17:11,053 - Epoch: [200][  518/  518]    Overall Loss 2.817980    Objective Loss 2.817980                                        LR 0.000004    Time 0.203981    
2023-04-17 13:17:11,136 - --- validate (epoch=200)-----------
2023-04-17 13:17:11,137 - 4952 samples (32 per mini-batch)
2023-04-17 13:17:56,188 - Epoch: [200][   50/  155]    Loss 3.114031    mAP 0.504479    
2023-04-17 13:18:40,927 - Epoch: [200][  100/  155]    Loss 3.081475    mAP 0.513347    
2023-04-17 13:19:25,369 - Epoch: [200][  150/  155]    Loss 3.068256    mAP 0.515730    
2023-04-17 13:19:29,304 - Epoch: [200][  155/  155]    Loss 3.069469    mAP 0.515491    
2023-04-17 13:19:29,382 - ==> mAP: 0.51549    Loss: 3.069

2023-04-17 13:19:29,385 - ==> Best [mAP: 0.526061   vloss: 3.074984   Sparsity:0.00   Params: 2177088 on epoch: 184]
2023-04-17 13:19:29,385 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 13:19:29,421 - 

2023-04-17 13:19:29,422 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 13:19:40,376 - Epoch: [201][   50/  518]    Overall Loss 2.859322    Objective Loss 2.859322                                        LR 0.000004    Time 0.219040    
2023-04-17 13:19:50,457 - Epoch: [201][  100/  518]    Overall Loss 2.848719    Objective Loss 2.848719                                        LR 0.000004    Time 0.210310    
2023-04-17 13:20:00,453 - Epoch: [201][  150/  518]    Overall Loss 2.830702    Objective Loss 2.830702                                        LR 0.000004    Time 0.206839    
2023-04-17 13:20:10,487 - Epoch: [201][  200/  518]    Overall Loss 2.818877    Objective Loss 2.818877                                        LR 0.000004    Time 0.205293    
2023-04-17 13:20:20,715 - Epoch: [201][  250/  518]    Overall Loss 2.815789    Objective Loss 2.815789                                        LR 0.000004    Time 0.205138    
2023-04-17 13:20:30,773 - Epoch: [201][  300/  518]    Overall Loss 2.821531    Objective Loss 2.821531                                        LR 0.000004    Time 0.204470    
2023-04-17 13:20:40,966 - Epoch: [201][  350/  518]    Overall Loss 2.816565    Objective Loss 2.816565                                        LR 0.000004    Time 0.204379    
2023-04-17 13:20:51,083 - Epoch: [201][  400/  518]    Overall Loss 2.819787    Objective Loss 2.819787                                        LR 0.000004    Time 0.204119    
2023-04-17 13:21:01,204 - Epoch: [201][  450/  518]    Overall Loss 2.817299    Objective Loss 2.817299                                        LR 0.000004    Time 0.203928    
2023-04-17 13:21:11,399 - Epoch: [201][  500/  518]    Overall Loss 2.808875    Objective Loss 2.808875                                        LR 0.000004    Time 0.203922    
2023-04-17 13:21:14,925 - Epoch: [201][  518/  518]    Overall Loss 2.812102    Objective Loss 2.812102                                        LR 0.000004    Time 0.203642    
2023-04-17 13:21:15,006 - --- validate (epoch=201)-----------
2023-04-17 13:21:15,006 - 4952 samples (32 per mini-batch)
2023-04-17 13:21:59,983 - Epoch: [201][   50/  155]    Loss 3.131044    mAP 0.521703    
2023-04-17 13:22:44,369 - Epoch: [201][  100/  155]    Loss 3.101069    mAP 0.523517    
2023-04-17 13:23:28,695 - Epoch: [201][  150/  155]    Loss 3.064355    mAP 0.522063    
2023-04-17 13:23:33,177 - Epoch: [201][  155/  155]    Loss 3.067466    mAP 0.525304    
2023-04-17 13:23:33,254 - ==> mAP: 0.52530    Loss: 3.067

2023-04-17 13:23:33,258 - ==> Best [mAP: 0.526061   vloss: 3.074984   Sparsity:0.00   Params: 2177088 on epoch: 184]
2023-04-17 13:23:33,258 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 13:23:33,295 - 

2023-04-17 13:23:33,295 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 13:23:44,153 - Epoch: [202][   50/  518]    Overall Loss 2.761722    Objective Loss 2.761722                                        LR 0.000004    Time 0.217097    
2023-04-17 13:23:54,208 - Epoch: [202][  100/  518]    Overall Loss 2.779607    Objective Loss 2.779607                                        LR 0.000004    Time 0.209083    
2023-04-17 13:24:04,382 - Epoch: [202][  150/  518]    Overall Loss 2.805158    Objective Loss 2.805158                                        LR 0.000004    Time 0.207210    
2023-04-17 13:24:14,479 - Epoch: [202][  200/  518]    Overall Loss 2.798444    Objective Loss 2.798444                                        LR 0.000004    Time 0.205882    
2023-04-17 13:24:24,525 - Epoch: [202][  250/  518]    Overall Loss 2.796837    Objective Loss 2.796837                                        LR 0.000004    Time 0.204883    
2023-04-17 13:24:34,652 - Epoch: [202][  300/  518]    Overall Loss 2.797740    Objective Loss 2.797740                                        LR 0.000004    Time 0.204488    
2023-04-17 13:24:44,767 - Epoch: [202][  350/  518]    Overall Loss 2.805291    Objective Loss 2.805291                                        LR 0.000004    Time 0.204170    
2023-04-17 13:24:54,818 - Epoch: [202][  400/  518]    Overall Loss 2.809990    Objective Loss 2.809990                                        LR 0.000004    Time 0.203774    
2023-04-17 13:25:04,850 - Epoch: [202][  450/  518]    Overall Loss 2.810121    Objective Loss 2.810121                                        LR 0.000004    Time 0.203421    
2023-04-17 13:25:14,954 - Epoch: [202][  500/  518]    Overall Loss 2.811325    Objective Loss 2.811325                                        LR 0.000004    Time 0.203285    
2023-04-17 13:25:18,479 - Epoch: [202][  518/  518]    Overall Loss 2.813366    Objective Loss 2.813366                                        LR 0.000004    Time 0.203025    
2023-04-17 13:25:18,558 - --- validate (epoch=202)-----------
2023-04-17 13:25:18,558 - 4952 samples (32 per mini-batch)
2023-04-17 13:26:02,910 - Epoch: [202][   50/  155]    Loss 3.042377    mAP 0.532816    
2023-04-17 13:26:46,820 - Epoch: [202][  100/  155]    Loss 3.068636    mAP 0.509457    
2023-04-17 13:27:31,007 - Epoch: [202][  150/  155]    Loss 3.073228    mAP 0.511988    
2023-04-17 13:27:34,929 - Epoch: [202][  155/  155]    Loss 3.072311    mAP 0.509873    
2023-04-17 13:27:35,004 - ==> mAP: 0.50987    Loss: 3.072

2023-04-17 13:27:35,008 - ==> Best [mAP: 0.526061   vloss: 3.074984   Sparsity:0.00   Params: 2177088 on epoch: 184]
2023-04-17 13:27:35,008 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 13:27:35,045 - 

2023-04-17 13:27:35,045 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 13:27:45,986 - Epoch: [203][   50/  518]    Overall Loss 2.849055    Objective Loss 2.849055                                        LR 0.000004    Time 0.218782    
2023-04-17 13:27:56,008 - Epoch: [203][  100/  518]    Overall Loss 2.851383    Objective Loss 2.851383                                        LR 0.000004    Time 0.209593    
2023-04-17 13:28:06,101 - Epoch: [203][  150/  518]    Overall Loss 2.862860    Objective Loss 2.862860                                        LR 0.000004    Time 0.207007    
2023-04-17 13:28:16,167 - Epoch: [203][  200/  518]    Overall Loss 2.836804    Objective Loss 2.836804                                        LR 0.000004    Time 0.205576    
2023-04-17 13:28:26,274 - Epoch: [203][  250/  518]    Overall Loss 2.822553    Objective Loss 2.822553                                        LR 0.000004    Time 0.204882    
2023-04-17 13:28:36,341 - Epoch: [203][  300/  518]    Overall Loss 2.819430    Objective Loss 2.819430                                        LR 0.000004    Time 0.204286    
2023-04-17 13:28:46,341 - Epoch: [203][  350/  518]    Overall Loss 2.818377    Objective Loss 2.818377                                        LR 0.000004    Time 0.203669    
2023-04-17 13:28:56,437 - Epoch: [203][  400/  518]    Overall Loss 2.816324    Objective Loss 2.816324                                        LR 0.000004    Time 0.203446    
2023-04-17 13:29:06,520 - Epoch: [203][  450/  518]    Overall Loss 2.818610    Objective Loss 2.818610                                        LR 0.000004    Time 0.203245    
2023-04-17 13:29:16,639 - Epoch: [203][  500/  518]    Overall Loss 2.814183    Objective Loss 2.814183                                        LR 0.000004    Time 0.203156    
2023-04-17 13:29:20,153 - Epoch: [203][  518/  518]    Overall Loss 2.820774    Objective Loss 2.820774                                        LR 0.000004    Time 0.202879    
2023-04-17 13:29:20,231 - --- validate (epoch=203)-----------
2023-04-17 13:29:20,232 - 4952 samples (32 per mini-batch)
2023-04-17 13:30:05,767 - Epoch: [203][   50/  155]    Loss 3.071912    mAP 0.516270    
2023-04-17 13:30:50,622 - Epoch: [203][  100/  155]    Loss 3.076577    mAP 0.515724    
2023-04-17 13:31:36,754 - Epoch: [203][  150/  155]    Loss 3.068742    mAP 0.515602    
2023-04-17 13:31:41,488 - Epoch: [203][  155/  155]    Loss 3.071168    mAP 0.515575    
2023-04-17 13:31:41,568 - ==> mAP: 0.51557    Loss: 3.071

2023-04-17 13:31:41,571 - ==> Best [mAP: 0.526061   vloss: 3.074984   Sparsity:0.00   Params: 2177088 on epoch: 184]
2023-04-17 13:31:41,571 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 13:31:41,608 - 

2023-04-17 13:31:41,608 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 13:31:52,807 - Epoch: [204][   50/  518]    Overall Loss 2.778337    Objective Loss 2.778337                                        LR 0.000004    Time 0.223910    
2023-04-17 13:32:02,940 - Epoch: [204][  100/  518]    Overall Loss 2.771408    Objective Loss 2.771408                                        LR 0.000004    Time 0.213270    
2023-04-17 13:32:13,092 - Epoch: [204][  150/  518]    Overall Loss 2.789717    Objective Loss 2.789717                                        LR 0.000004    Time 0.209849    
2023-04-17 13:32:23,196 - Epoch: [204][  200/  518]    Overall Loss 2.800754    Objective Loss 2.800754                                        LR 0.000004    Time 0.207899    
2023-04-17 13:32:33,251 - Epoch: [204][  250/  518]    Overall Loss 2.809642    Objective Loss 2.809642                                        LR 0.000004    Time 0.206534    
2023-04-17 13:32:43,242 - Epoch: [204][  300/  518]    Overall Loss 2.814534    Objective Loss 2.814534                                        LR 0.000004    Time 0.205410    
2023-04-17 13:32:53,386 - Epoch: [204][  350/  518]    Overall Loss 2.807636    Objective Loss 2.807636                                        LR 0.000004    Time 0.205045    
2023-04-17 13:33:03,506 - Epoch: [204][  400/  518]    Overall Loss 2.807685    Objective Loss 2.807685                                        LR 0.000004    Time 0.204709    
2023-04-17 13:33:13,586 - Epoch: [204][  450/  518]    Overall Loss 2.812232    Objective Loss 2.812232                                        LR 0.000004    Time 0.204361    
2023-04-17 13:33:23,716 - Epoch: [204][  500/  518]    Overall Loss 2.808662    Objective Loss 2.808662                                        LR 0.000004    Time 0.204182    
2023-04-17 13:33:27,254 - Epoch: [204][  518/  518]    Overall Loss 2.813189    Objective Loss 2.813189                                        LR 0.000004    Time 0.203915    
2023-04-17 13:33:27,332 - --- validate (epoch=204)-----------
2023-04-17 13:33:27,333 - 4952 samples (32 per mini-batch)
2023-04-17 13:34:13,125 - Epoch: [204][   50/  155]    Loss 3.130475    mAP 0.493120    
2023-04-17 13:34:56,878 - Epoch: [204][  100/  155]    Loss 3.069974    mAP 0.504051    
2023-04-17 13:35:39,574 - Epoch: [204][  150/  155]    Loss 3.063902    mAP 0.501777    
2023-04-17 13:35:43,877 - Epoch: [204][  155/  155]    Loss 3.065966    mAP 0.500076    
2023-04-17 13:35:43,956 - ==> mAP: 0.50008    Loss: 3.066

2023-04-17 13:35:43,961 - ==> Best [mAP: 0.526061   vloss: 3.074984   Sparsity:0.00   Params: 2177088 on epoch: 184]
2023-04-17 13:35:43,961 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 13:35:43,998 - 

2023-04-17 13:35:43,998 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 13:35:54,885 - Epoch: [205][   50/  518]    Overall Loss 2.853837    Objective Loss 2.853837                                        LR 0.000004    Time 0.217684    
2023-04-17 13:36:05,028 - Epoch: [205][  100/  518]    Overall Loss 2.842266    Objective Loss 2.842266                                        LR 0.000004    Time 0.210257    
2023-04-17 13:36:15,257 - Epoch: [205][  150/  518]    Overall Loss 2.826600    Objective Loss 2.826600                                        LR 0.000004    Time 0.208355    
2023-04-17 13:36:25,424 - Epoch: [205][  200/  518]    Overall Loss 2.822007    Objective Loss 2.822007                                        LR 0.000004    Time 0.207093    
2023-04-17 13:36:35,520 - Epoch: [205][  250/  518]    Overall Loss 2.817655    Objective Loss 2.817655                                        LR 0.000004    Time 0.206051    
2023-04-17 13:36:45,566 - Epoch: [205][  300/  518]    Overall Loss 2.821739    Objective Loss 2.821739                                        LR 0.000004    Time 0.205191    
2023-04-17 13:36:55,731 - Epoch: [205][  350/  518]    Overall Loss 2.814394    Objective Loss 2.814394                                        LR 0.000004    Time 0.204916    
2023-04-17 13:37:05,863 - Epoch: [205][  400/  518]    Overall Loss 2.812789    Objective Loss 2.812789                                        LR 0.000004    Time 0.204629    
2023-04-17 13:37:15,986 - Epoch: [205][  450/  518]    Overall Loss 2.809384    Objective Loss 2.809384                                        LR 0.000004    Time 0.204384    
2023-04-17 13:37:26,123 - Epoch: [205][  500/  518]    Overall Loss 2.807295    Objective Loss 2.807295                                        LR 0.000004    Time 0.204217    
2023-04-17 13:37:29,695 - Epoch: [205][  518/  518]    Overall Loss 2.809796    Objective Loss 2.809796                                        LR 0.000004    Time 0.204014    
2023-04-17 13:37:29,777 - --- validate (epoch=205)-----------
2023-04-17 13:37:29,777 - 4952 samples (32 per mini-batch)
2023-04-17 13:38:17,785 - Epoch: [205][   50/  155]    Loss 3.108930    mAP 0.500196    
2023-04-17 13:39:02,259 - Epoch: [205][  100/  155]    Loss 3.070222    mAP 0.520838    
2023-04-17 13:39:47,832 - Epoch: [205][  150/  155]    Loss 3.064120    mAP 0.520415    
2023-04-17 13:39:52,085 - Epoch: [205][  155/  155]    Loss 3.063548    mAP 0.519711    
2023-04-17 13:39:52,162 - ==> mAP: 0.51971    Loss: 3.064

2023-04-17 13:39:52,167 - ==> Best [mAP: 0.526061   vloss: 3.074984   Sparsity:0.00   Params: 2177088 on epoch: 184]
2023-04-17 13:39:52,167 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 13:39:52,204 - 

2023-04-17 13:39:52,204 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 13:40:02,931 - Epoch: [206][   50/  518]    Overall Loss 2.844391    Objective Loss 2.844391                                        LR 0.000004    Time 0.214479    
2023-04-17 13:40:12,979 - Epoch: [206][  100/  518]    Overall Loss 2.820419    Objective Loss 2.820419                                        LR 0.000004    Time 0.207709    
2023-04-17 13:40:23,063 - Epoch: [206][  150/  518]    Overall Loss 2.811107    Objective Loss 2.811107                                        LR 0.000004    Time 0.205684    
2023-04-17 13:40:33,198 - Epoch: [206][  200/  518]    Overall Loss 2.818218    Objective Loss 2.818218                                        LR 0.000004    Time 0.204932    
2023-04-17 13:40:43,237 - Epoch: [206][  250/  518]    Overall Loss 2.819085    Objective Loss 2.819085                                        LR 0.000004    Time 0.204093    
2023-04-17 13:40:53,316 - Epoch: [206][  300/  518]    Overall Loss 2.812987    Objective Loss 2.812987                                        LR 0.000004    Time 0.203669    
2023-04-17 13:41:03,333 - Epoch: [206][  350/  518]    Overall Loss 2.806166    Objective Loss 2.806166                                        LR 0.000004    Time 0.203189    
2023-04-17 13:41:13,485 - Epoch: [206][  400/  518]    Overall Loss 2.796326    Objective Loss 2.796326                                        LR 0.000004    Time 0.203167    
2023-04-17 13:41:23,686 - Epoch: [206][  450/  518]    Overall Loss 2.799716    Objective Loss 2.799716                                        LR 0.000004    Time 0.203258    
2023-04-17 13:41:33,842 - Epoch: [206][  500/  518]    Overall Loss 2.796849    Objective Loss 2.796849                                        LR 0.000004    Time 0.203242    
2023-04-17 13:41:37,369 - Epoch: [206][  518/  518]    Overall Loss 2.795912    Objective Loss 2.795912                                        LR 0.000004    Time 0.202986    
2023-04-17 13:41:37,450 - --- validate (epoch=206)-----------
2023-04-17 13:41:37,451 - 4952 samples (32 per mini-batch)
2023-04-17 13:42:23,748 - Epoch: [206][   50/  155]    Loss 3.136034    mAP 0.504912    
2023-04-17 13:43:09,035 - Epoch: [206][  100/  155]    Loss 3.081171    mAP 0.520397    
2023-04-17 13:43:53,946 - Epoch: [206][  150/  155]    Loss 3.072535    mAP 0.514040    
2023-04-17 13:43:58,431 - Epoch: [206][  155/  155]    Loss 3.069948    mAP 0.513773    
2023-04-17 13:43:58,507 - ==> mAP: 0.51377    Loss: 3.070

2023-04-17 13:43:58,511 - ==> Best [mAP: 0.526061   vloss: 3.074984   Sparsity:0.00   Params: 2177088 on epoch: 184]
2023-04-17 13:43:58,511 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 13:43:58,548 - 

2023-04-17 13:43:58,548 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 13:44:09,520 - Epoch: [207][   50/  518]    Overall Loss 2.861147    Objective Loss 2.861147                                        LR 0.000004    Time 0.219379    
2023-04-17 13:44:19,613 - Epoch: [207][  100/  518]    Overall Loss 2.811146    Objective Loss 2.811146                                        LR 0.000004    Time 0.210608    
2023-04-17 13:44:29,701 - Epoch: [207][  150/  518]    Overall Loss 2.797507    Objective Loss 2.797507                                        LR 0.000004    Time 0.207646    
2023-04-17 13:44:39,763 - Epoch: [207][  200/  518]    Overall Loss 2.808915    Objective Loss 2.808915                                        LR 0.000004    Time 0.206040    
2023-04-17 13:44:49,906 - Epoch: [207][  250/  518]    Overall Loss 2.814820    Objective Loss 2.814820                                        LR 0.000004    Time 0.205397    
2023-04-17 13:45:00,135 - Epoch: [207][  300/  518]    Overall Loss 2.816321    Objective Loss 2.816321                                        LR 0.000004    Time 0.205254    
2023-04-17 13:45:10,280 - Epoch: [207][  350/  518]    Overall Loss 2.821960    Objective Loss 2.821960                                        LR 0.000004    Time 0.204914    
2023-04-17 13:45:20,363 - Epoch: [207][  400/  518]    Overall Loss 2.817827    Objective Loss 2.817827                                        LR 0.000004    Time 0.204503    
2023-04-17 13:45:30,428 - Epoch: [207][  450/  518]    Overall Loss 2.817399    Objective Loss 2.817399                                        LR 0.000004    Time 0.204144    
2023-04-17 13:45:40,481 - Epoch: [207][  500/  518]    Overall Loss 2.817018    Objective Loss 2.817018                                        LR 0.000004    Time 0.203832    
2023-04-17 13:45:44,062 - Epoch: [207][  518/  518]    Overall Loss 2.815026    Objective Loss 2.815026                                        LR 0.000004    Time 0.203662    
2023-04-17 13:45:44,143 - --- validate (epoch=207)-----------
2023-04-17 13:45:44,144 - 4952 samples (32 per mini-batch)
2023-04-17 13:46:31,622 - Epoch: [207][   50/  155]    Loss 3.035542    mAP 0.526599    
2023-04-17 13:47:18,910 - Epoch: [207][  100/  155]    Loss 3.065585    mAP 0.521307    
2023-04-17 13:48:04,935 - Epoch: [207][  150/  155]    Loss 3.064885    mAP 0.514743    
2023-04-17 13:48:09,358 - Epoch: [207][  155/  155]    Loss 3.069456    mAP 0.512945    
2023-04-17 13:48:09,431 - ==> mAP: 0.51295    Loss: 3.069

2023-04-17 13:48:09,435 - ==> Best [mAP: 0.526061   vloss: 3.074984   Sparsity:0.00   Params: 2177088 on epoch: 184]
2023-04-17 13:48:09,435 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 13:48:09,471 - 

2023-04-17 13:48:09,471 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 13:48:20,605 - Epoch: [208][   50/  518]    Overall Loss 2.816417    Objective Loss 2.816417                                        LR 0.000004    Time 0.222624    
2023-04-17 13:48:30,704 - Epoch: [208][  100/  518]    Overall Loss 2.851213    Objective Loss 2.851213                                        LR 0.000004    Time 0.212284    
2023-04-17 13:48:40,834 - Epoch: [208][  150/  518]    Overall Loss 2.813673    Objective Loss 2.813673                                        LR 0.000004    Time 0.209044    
2023-04-17 13:48:50,936 - Epoch: [208][  200/  518]    Overall Loss 2.827405    Objective Loss 2.827405                                        LR 0.000004    Time 0.207285    
2023-04-17 13:49:00,992 - Epoch: [208][  250/  518]    Overall Loss 2.829465    Objective Loss 2.829465                                        LR 0.000004    Time 0.206046    
2023-04-17 13:49:11,115 - Epoch: [208][  300/  518]    Overall Loss 2.827745    Objective Loss 2.827745                                        LR 0.000004    Time 0.205445    
2023-04-17 13:49:21,213 - Epoch: [208][  350/  518]    Overall Loss 2.823961    Objective Loss 2.823961                                        LR 0.000004    Time 0.204943    
2023-04-17 13:49:31,391 - Epoch: [208][  400/  518]    Overall Loss 2.816610    Objective Loss 2.816610                                        LR 0.000004    Time 0.204766    
2023-04-17 13:49:41,590 - Epoch: [208][  450/  518]    Overall Loss 2.820025    Objective Loss 2.820025                                        LR 0.000004    Time 0.204676    
2023-04-17 13:49:51,685 - Epoch: [208][  500/  518]    Overall Loss 2.822773    Objective Loss 2.822773                                        LR 0.000004    Time 0.204393    
2023-04-17 13:49:55,262 - Epoch: [208][  518/  518]    Overall Loss 2.819403    Objective Loss 2.819403                                        LR 0.000004    Time 0.204195    
2023-04-17 13:49:55,343 - --- validate (epoch=208)-----------
2023-04-17 13:49:55,343 - 4952 samples (32 per mini-batch)
2023-04-17 13:50:41,495 - Epoch: [208][   50/  155]    Loss 3.086787    mAP 0.504910    
2023-04-17 13:51:26,805 - Epoch: [208][  100/  155]    Loss 3.071675    mAP 0.509988    
2023-04-17 13:52:11,002 - Epoch: [208][  150/  155]    Loss 3.072355    mAP 0.514406    
2023-04-17 13:52:14,897 - Epoch: [208][  155/  155]    Loss 3.070016    mAP 0.516013    
2023-04-17 13:52:14,975 - ==> mAP: 0.51601    Loss: 3.070

2023-04-17 13:52:14,978 - ==> Best [mAP: 0.526061   vloss: 3.074984   Sparsity:0.00   Params: 2177088 on epoch: 184]
2023-04-17 13:52:14,979 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 13:52:15,016 - 

2023-04-17 13:52:15,016 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 13:52:25,856 - Epoch: [209][   50/  518]    Overall Loss 2.820781    Objective Loss 2.820781                                        LR 0.000004    Time 0.216740    
2023-04-17 13:52:35,996 - Epoch: [209][  100/  518]    Overall Loss 2.852328    Objective Loss 2.852328                                        LR 0.000004    Time 0.209748    
2023-04-17 13:52:46,144 - Epoch: [209][  150/  518]    Overall Loss 2.837877    Objective Loss 2.837877                                        LR 0.000004    Time 0.207475    
2023-04-17 13:52:56,277 - Epoch: [209][  200/  518]    Overall Loss 2.824754    Objective Loss 2.824754                                        LR 0.000004    Time 0.206265    
2023-04-17 13:53:06,411 - Epoch: [209][  250/  518]    Overall Loss 2.813893    Objective Loss 2.813893                                        LR 0.000004    Time 0.205542    
2023-04-17 13:53:16,455 - Epoch: [209][  300/  518]    Overall Loss 2.812340    Objective Loss 2.812340                                        LR 0.000004    Time 0.204761    
2023-04-17 13:53:26,553 - Epoch: [209][  350/  518]    Overall Loss 2.812700    Objective Loss 2.812700                                        LR 0.000004    Time 0.204355    
2023-04-17 13:53:36,635 - Epoch: [209][  400/  518]    Overall Loss 2.809080    Objective Loss 2.809080                                        LR 0.000004    Time 0.204012    
2023-04-17 13:53:46,778 - Epoch: [209][  450/  518]    Overall Loss 2.812738    Objective Loss 2.812738                                        LR 0.000004    Time 0.203880    
2023-04-17 13:53:56,814 - Epoch: [209][  500/  518]    Overall Loss 2.816749    Objective Loss 2.816749                                        LR 0.000004    Time 0.203561    
2023-04-17 13:54:00,349 - Epoch: [209][  518/  518]    Overall Loss 2.814184    Objective Loss 2.814184                                        LR 0.000004    Time 0.203311    
2023-04-17 13:54:00,429 - --- validate (epoch=209)-----------
2023-04-17 13:54:00,430 - 4952 samples (32 per mini-batch)
2023-04-17 13:54:46,669 - Epoch: [209][   50/  155]    Loss 3.074425    mAP 0.522090    
2023-04-17 13:55:31,285 - Epoch: [209][  100/  155]    Loss 3.083410    mAP 0.520721    
2023-04-17 13:56:12,968 - Epoch: [209][  150/  155]    Loss 3.077871    mAP 0.523540    
2023-04-17 13:56:16,831 - Epoch: [209][  155/  155]    Loss 3.074018    mAP 0.522398    
2023-04-17 13:56:16,909 - ==> mAP: 0.52240    Loss: 3.074

2023-04-17 13:56:16,913 - ==> Best [mAP: 0.526061   vloss: 3.074984   Sparsity:0.00   Params: 2177088 on epoch: 184]
2023-04-17 13:56:16,913 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 13:56:16,950 - 

2023-04-17 13:56:16,950 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 13:56:27,816 - Epoch: [210][   50/  518]    Overall Loss 2.814001    Objective Loss 2.814001                                        LR 0.000004    Time 0.217268    
2023-04-17 13:56:37,953 - Epoch: [210][  100/  518]    Overall Loss 2.799131    Objective Loss 2.799131                                        LR 0.000004    Time 0.209990    
2023-04-17 13:56:48,100 - Epoch: [210][  150/  518]    Overall Loss 2.787565    Objective Loss 2.787565                                        LR 0.000004    Time 0.207624    
2023-04-17 13:56:58,303 - Epoch: [210][  200/  518]    Overall Loss 2.798184    Objective Loss 2.798184                                        LR 0.000004    Time 0.206727    
2023-04-17 13:57:08,522 - Epoch: [210][  250/  518]    Overall Loss 2.798211    Objective Loss 2.798211                                        LR 0.000004    Time 0.206253    
2023-04-17 13:57:18,683 - Epoch: [210][  300/  518]    Overall Loss 2.800446    Objective Loss 2.800446                                        LR 0.000004    Time 0.205742    
2023-04-17 13:57:28,838 - Epoch: [210][  350/  518]    Overall Loss 2.797923    Objective Loss 2.797923                                        LR 0.000004    Time 0.205358    
2023-04-17 13:57:39,015 - Epoch: [210][  400/  518]    Overall Loss 2.802838    Objective Loss 2.802838                                        LR 0.000004    Time 0.205128    
2023-04-17 13:57:49,125 - Epoch: [210][  450/  518]    Overall Loss 2.806386    Objective Loss 2.806386                                        LR 0.000004    Time 0.204799    
2023-04-17 13:57:59,339 - Epoch: [210][  500/  518]    Overall Loss 2.809684    Objective Loss 2.809684                                        LR 0.000004    Time 0.204744    
2023-04-17 13:58:02,880 - Epoch: [210][  518/  518]    Overall Loss 2.807939    Objective Loss 2.807939                                        LR 0.000004    Time 0.204465    
2023-04-17 13:58:02,961 - --- validate (epoch=210)-----------
2023-04-17 13:58:02,961 - 4952 samples (32 per mini-batch)
2023-04-17 13:58:48,175 - Epoch: [210][   50/  155]    Loss 3.052670    mAP 0.529220    
2023-04-17 13:59:32,357 - Epoch: [210][  100/  155]    Loss 3.067244    mAP 0.529892    
2023-04-17 14:00:16,615 - Epoch: [210][  150/  155]    Loss 3.071887    mAP 0.518048    
2023-04-17 14:00:20,995 - Epoch: [210][  155/  155]    Loss 3.069503    mAP 0.518390    
2023-04-17 14:00:21,074 - ==> mAP: 0.51839    Loss: 3.070

2023-04-17 14:00:21,078 - ==> Best [mAP: 0.526061   vloss: 3.074984   Sparsity:0.00   Params: 2177088 on epoch: 184]
2023-04-17 14:00:21,079 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 14:00:21,117 - 

2023-04-17 14:00:21,117 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 14:00:31,900 - Epoch: [211][   50/  518]    Overall Loss 2.810177    Objective Loss 2.810177                                        LR 0.000004    Time 0.215605    
2023-04-17 14:00:42,020 - Epoch: [211][  100/  518]    Overall Loss 2.817254    Objective Loss 2.817254                                        LR 0.000004    Time 0.208980    
2023-04-17 14:00:52,137 - Epoch: [211][  150/  518]    Overall Loss 2.806832    Objective Loss 2.806832                                        LR 0.000004    Time 0.206757    
2023-04-17 14:01:02,294 - Epoch: [211][  200/  518]    Overall Loss 2.804519    Objective Loss 2.804519                                        LR 0.000004    Time 0.205848    
2023-04-17 14:01:12,514 - Epoch: [211][  250/  518]    Overall Loss 2.809452    Objective Loss 2.809452                                        LR 0.000004    Time 0.205552    
2023-04-17 14:01:22,651 - Epoch: [211][  300/  518]    Overall Loss 2.814753    Objective Loss 2.814753                                        LR 0.000004    Time 0.205077    
2023-04-17 14:01:32,780 - Epoch: [211][  350/  518]    Overall Loss 2.810796    Objective Loss 2.810796                                        LR 0.000004    Time 0.204717    
2023-04-17 14:01:42,929 - Epoch: [211][  400/  518]    Overall Loss 2.800556    Objective Loss 2.800556                                        LR 0.000004    Time 0.204495    
2023-04-17 14:01:53,147 - Epoch: [211][  450/  518]    Overall Loss 2.795484    Objective Loss 2.795484                                        LR 0.000004    Time 0.204476    
2023-04-17 14:02:03,250 - Epoch: [211][  500/  518]    Overall Loss 2.798598    Objective Loss 2.798598                                        LR 0.000004    Time 0.204232    
2023-04-17 14:02:06,727 - Epoch: [211][  518/  518]    Overall Loss 2.797730    Objective Loss 2.797730                                        LR 0.000004    Time 0.203847    
2023-04-17 14:02:06,806 - --- validate (epoch=211)-----------
2023-04-17 14:02:06,807 - 4952 samples (32 per mini-batch)
2023-04-17 14:02:50,784 - Epoch: [211][   50/  155]    Loss 3.107519    mAP 0.514214    
2023-04-17 14:03:34,663 - Epoch: [211][  100/  155]    Loss 3.084723    mAP 0.524279    
2023-04-17 14:04:19,858 - Epoch: [211][  150/  155]    Loss 3.078485    mAP 0.521526    
2023-04-17 14:04:23,988 - Epoch: [211][  155/  155]    Loss 3.072487    mAP 0.520705    
2023-04-17 14:04:24,067 - ==> mAP: 0.52070    Loss: 3.072

2023-04-17 14:04:24,071 - ==> Best [mAP: 0.526061   vloss: 3.074984   Sparsity:0.00   Params: 2177088 on epoch: 184]
2023-04-17 14:04:24,071 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 14:04:24,108 - 

2023-04-17 14:04:24,108 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 14:04:34,996 - Epoch: [212][   50/  518]    Overall Loss 2.817564    Objective Loss 2.817564                                        LR 0.000004    Time 0.217699    
2023-04-17 14:04:45,228 - Epoch: [212][  100/  518]    Overall Loss 2.798759    Objective Loss 2.798759                                        LR 0.000004    Time 0.211146    
2023-04-17 14:04:55,345 - Epoch: [212][  150/  518]    Overall Loss 2.807725    Objective Loss 2.807725                                        LR 0.000004    Time 0.208201    
2023-04-17 14:05:05,462 - Epoch: [212][  200/  518]    Overall Loss 2.816225    Objective Loss 2.816225                                        LR 0.000004    Time 0.206730    
2023-04-17 14:05:15,562 - Epoch: [212][  250/  518]    Overall Loss 2.820449    Objective Loss 2.820449                                        LR 0.000004    Time 0.205776    
2023-04-17 14:05:25,634 - Epoch: [212][  300/  518]    Overall Loss 2.811954    Objective Loss 2.811954                                        LR 0.000004    Time 0.205049    
2023-04-17 14:05:35,779 - Epoch: [212][  350/  518]    Overall Loss 2.815537    Objective Loss 2.815537                                        LR 0.000004    Time 0.204738    
2023-04-17 14:05:45,879 - Epoch: [212][  400/  518]    Overall Loss 2.818486    Objective Loss 2.818486                                        LR 0.000004    Time 0.204390    
2023-04-17 14:05:56,071 - Epoch: [212][  450/  518]    Overall Loss 2.819028    Objective Loss 2.819028                                        LR 0.000004    Time 0.204326    
2023-04-17 14:06:06,185 - Epoch: [212][  500/  518]    Overall Loss 2.821362    Objective Loss 2.821362                                        LR 0.000004    Time 0.204120    
2023-04-17 14:06:09,696 - Epoch: [212][  518/  518]    Overall Loss 2.820362    Objective Loss 2.820362                                        LR 0.000004    Time 0.203802    
2023-04-17 14:06:09,777 - --- validate (epoch=212)-----------
2023-04-17 14:06:09,777 - 4952 samples (32 per mini-batch)
2023-04-17 14:06:55,436 - Epoch: [212][   50/  155]    Loss 3.096008    mAP 0.514786    
2023-04-17 14:07:39,943 - Epoch: [212][  100/  155]    Loss 3.058564    mAP 0.510410    
2023-04-17 14:08:25,784 - Epoch: [212][  150/  155]    Loss 3.062748    mAP 0.515171    
2023-04-17 14:08:30,214 - Epoch: [212][  155/  155]    Loss 3.064631    mAP 0.516467    
2023-04-17 14:08:30,295 - ==> mAP: 0.51647    Loss: 3.065

2023-04-17 14:08:30,298 - ==> Best [mAP: 0.526061   vloss: 3.074984   Sparsity:0.00   Params: 2177088 on epoch: 184]
2023-04-17 14:08:30,298 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 14:08:30,335 - 

2023-04-17 14:08:30,336 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 14:08:41,215 - Epoch: [213][   50/  518]    Overall Loss 2.814762    Objective Loss 2.814762                                        LR 0.000004    Time 0.217526    
2023-04-17 14:08:51,327 - Epoch: [213][  100/  518]    Overall Loss 2.818781    Objective Loss 2.818781                                        LR 0.000004    Time 0.209864    
2023-04-17 14:09:01,575 - Epoch: [213][  150/  518]    Overall Loss 2.821535    Objective Loss 2.821535                                        LR 0.000004    Time 0.208222    
2023-04-17 14:09:11,773 - Epoch: [213][  200/  518]    Overall Loss 2.825060    Objective Loss 2.825060                                        LR 0.000004    Time 0.207148    
2023-04-17 14:09:21,915 - Epoch: [213][  250/  518]    Overall Loss 2.822478    Objective Loss 2.822478                                        LR 0.000004    Time 0.206281    
2023-04-17 14:09:32,006 - Epoch: [213][  300/  518]    Overall Loss 2.819337    Objective Loss 2.819337                                        LR 0.000004    Time 0.205533    
2023-04-17 14:09:42,146 - Epoch: [213][  350/  518]    Overall Loss 2.817974    Objective Loss 2.817974                                        LR 0.000004    Time 0.205138    
2023-04-17 14:09:52,303 - Epoch: [213][  400/  518]    Overall Loss 2.812577    Objective Loss 2.812577                                        LR 0.000004    Time 0.204883    
2023-04-17 14:10:02,434 - Epoch: [213][  450/  518]    Overall Loss 2.816029    Objective Loss 2.816029                                        LR 0.000004    Time 0.204629    
2023-04-17 14:10:12,535 - Epoch: [213][  500/  518]    Overall Loss 2.815582    Objective Loss 2.815582                                        LR 0.000004    Time 0.204364    
2023-04-17 14:10:16,032 - Epoch: [213][  518/  518]    Overall Loss 2.817213    Objective Loss 2.817213                                        LR 0.000004    Time 0.204013    
2023-04-17 14:10:16,114 - --- validate (epoch=213)-----------
2023-04-17 14:10:16,114 - 4952 samples (32 per mini-batch)
2023-04-17 14:11:00,063 - Epoch: [213][   50/  155]    Loss 3.048440    mAP 0.503446    
2023-04-17 14:11:44,382 - Epoch: [213][  100/  155]    Loss 3.054491    mAP 0.503539    
2023-04-17 14:12:30,098 - Epoch: [213][  150/  155]    Loss 3.064437    mAP 0.511057    
2023-04-17 14:12:34,312 - Epoch: [213][  155/  155]    Loss 3.064635    mAP 0.511656    
2023-04-17 14:12:34,389 - ==> mAP: 0.51166    Loss: 3.065

2023-04-17 14:12:34,393 - ==> Best [mAP: 0.526061   vloss: 3.074984   Sparsity:0.00   Params: 2177088 on epoch: 184]
2023-04-17 14:12:34,393 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 14:12:34,451 - 

2023-04-17 14:12:34,452 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 14:12:45,380 - Epoch: [214][   50/  518]    Overall Loss 2.847041    Objective Loss 2.847041                                        LR 0.000004    Time 0.218485    
2023-04-17 14:12:55,523 - Epoch: [214][  100/  518]    Overall Loss 2.841908    Objective Loss 2.841908                                        LR 0.000004    Time 0.210661    
2023-04-17 14:13:05,682 - Epoch: [214][  150/  518]    Overall Loss 2.842694    Objective Loss 2.842694                                        LR 0.000004    Time 0.208159    
2023-04-17 14:13:15,833 - Epoch: [214][  200/  518]    Overall Loss 2.837179    Objective Loss 2.837179                                        LR 0.000004    Time 0.206866    
2023-04-17 14:13:25,992 - Epoch: [214][  250/  518]    Overall Loss 2.831820    Objective Loss 2.831820                                        LR 0.000004    Time 0.206120    
2023-04-17 14:13:36,171 - Epoch: [214][  300/  518]    Overall Loss 2.820499    Objective Loss 2.820499                                        LR 0.000004    Time 0.205692    
2023-04-17 14:13:46,270 - Epoch: [214][  350/  518]    Overall Loss 2.821415    Objective Loss 2.821415                                        LR 0.000004    Time 0.205156    
2023-04-17 14:13:56,381 - Epoch: [214][  400/  518]    Overall Loss 2.816384    Objective Loss 2.816384                                        LR 0.000004    Time 0.204787    
2023-04-17 14:14:06,488 - Epoch: [214][  450/  518]    Overall Loss 2.810708    Objective Loss 2.810708                                        LR 0.000004    Time 0.204489    
2023-04-17 14:14:16,585 - Epoch: [214][  500/  518]    Overall Loss 2.808812    Objective Loss 2.808812                                        LR 0.000004    Time 0.204231    
2023-04-17 14:14:20,102 - Epoch: [214][  518/  518]    Overall Loss 2.810910    Objective Loss 2.810910                                        LR 0.000004    Time 0.203923    
2023-04-17 14:14:20,182 - --- validate (epoch=214)-----------
2023-04-17 14:14:20,182 - 4952 samples (32 per mini-batch)
2023-04-17 14:15:03,631 - Epoch: [214][   50/  155]    Loss 3.071436    mAP 0.508233    
2023-04-17 14:15:48,318 - Epoch: [214][  100/  155]    Loss 3.069527    mAP 0.517385    
2023-04-17 14:16:31,907 - Epoch: [214][  150/  155]    Loss 3.066391    mAP 0.521494    
2023-04-17 14:16:36,029 - Epoch: [214][  155/  155]    Loss 3.067481    mAP 0.520151    
2023-04-17 14:16:36,106 - ==> mAP: 0.52015    Loss: 3.067

2023-04-17 14:16:36,110 - ==> Best [mAP: 0.526061   vloss: 3.074984   Sparsity:0.00   Params: 2177088 on epoch: 184]
2023-04-17 14:16:36,110 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 14:16:36,148 - 

2023-04-17 14:16:36,148 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 14:16:46,950 - Epoch: [215][   50/  518]    Overall Loss 2.746489    Objective Loss 2.746489                                        LR 0.000004    Time 0.215986    
2023-04-17 14:16:57,124 - Epoch: [215][  100/  518]    Overall Loss 2.757861    Objective Loss 2.757861                                        LR 0.000004    Time 0.209717    
2023-04-17 14:17:07,275 - Epoch: [215][  150/  518]    Overall Loss 2.789097    Objective Loss 2.789097                                        LR 0.000004    Time 0.207471    
2023-04-17 14:17:17,365 - Epoch: [215][  200/  518]    Overall Loss 2.790239    Objective Loss 2.790239                                        LR 0.000004    Time 0.206048    
2023-04-17 14:17:27,506 - Epoch: [215][  250/  518]    Overall Loss 2.792431    Objective Loss 2.792431                                        LR 0.000004    Time 0.205395    
2023-04-17 14:17:37,704 - Epoch: [215][  300/  518]    Overall Loss 2.797308    Objective Loss 2.797308                                        LR 0.000004    Time 0.205150    
2023-04-17 14:17:47,770 - Epoch: [215][  350/  518]    Overall Loss 2.798506    Objective Loss 2.798506                                        LR 0.000004    Time 0.204600    
2023-04-17 14:17:57,902 - Epoch: [215][  400/  518]    Overall Loss 2.801604    Objective Loss 2.801604                                        LR 0.000004    Time 0.204350    
2023-04-17 14:18:08,058 - Epoch: [215][  450/  518]    Overall Loss 2.800130    Objective Loss 2.800130                                        LR 0.000004    Time 0.204209    
2023-04-17 14:18:18,153 - Epoch: [215][  500/  518]    Overall Loss 2.803456    Objective Loss 2.803456                                        LR 0.000004    Time 0.203976    
2023-04-17 14:18:21,720 - Epoch: [215][  518/  518]    Overall Loss 2.803731    Objective Loss 2.803731                                        LR 0.000004    Time 0.203773    
2023-04-17 14:18:21,799 - --- validate (epoch=215)-----------
2023-04-17 14:18:21,799 - 4952 samples (32 per mini-batch)
2023-04-17 14:19:05,777 - Epoch: [215][   50/  155]    Loss 3.032093    mAP 0.533227    
2023-04-17 14:19:50,885 - Epoch: [215][  100/  155]    Loss 3.076451    mAP 0.528941    
2023-04-17 14:20:33,905 - Epoch: [215][  150/  155]    Loss 3.070783    mAP 0.529763    
2023-04-17 14:20:38,142 - Epoch: [215][  155/  155]    Loss 3.072769    mAP 0.528215    
2023-04-17 14:20:38,240 - ==> mAP: 0.52822    Loss: 3.073

2023-04-17 14:20:38,243 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 14:20:38,243 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 14:20:38,296 - 

2023-04-17 14:20:38,296 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 14:20:49,196 - Epoch: [216][   50/  518]    Overall Loss 2.809493    Objective Loss 2.809493                                        LR 0.000004    Time 0.217946    
2023-04-17 14:20:59,383 - Epoch: [216][  100/  518]    Overall Loss 2.818471    Objective Loss 2.818471                                        LR 0.000004    Time 0.210825    
2023-04-17 14:21:09,566 - Epoch: [216][  150/  518]    Overall Loss 2.800961    Objective Loss 2.800961                                        LR 0.000004    Time 0.208426    
2023-04-17 14:21:19,674 - Epoch: [216][  200/  518]    Overall Loss 2.812568    Objective Loss 2.812568                                        LR 0.000004    Time 0.206852    
2023-04-17 14:21:29,868 - Epoch: [216][  250/  518]    Overall Loss 2.810563    Objective Loss 2.810563                                        LR 0.000004    Time 0.206249    
2023-04-17 14:21:40,064 - Epoch: [216][  300/  518]    Overall Loss 2.809572    Objective Loss 2.809572                                        LR 0.000004    Time 0.205857    
2023-04-17 14:21:50,264 - Epoch: [216][  350/  518]    Overall Loss 2.814024    Objective Loss 2.814024                                        LR 0.000004    Time 0.205587    
2023-04-17 14:22:00,402 - Epoch: [216][  400/  518]    Overall Loss 2.815527    Objective Loss 2.815527                                        LR 0.000004    Time 0.205229    
2023-04-17 14:22:10,580 - Epoch: [216][  450/  518]    Overall Loss 2.812759    Objective Loss 2.812759                                        LR 0.000004    Time 0.205041    
2023-04-17 14:22:20,725 - Epoch: [216][  500/  518]    Overall Loss 2.812105    Objective Loss 2.812105                                        LR 0.000004    Time 0.204823    
2023-04-17 14:22:24,259 - Epoch: [216][  518/  518]    Overall Loss 2.807050    Objective Loss 2.807050                                        LR 0.000004    Time 0.204527    
2023-04-17 14:22:24,340 - --- validate (epoch=216)-----------
2023-04-17 14:22:24,340 - 4952 samples (32 per mini-batch)
2023-04-17 14:23:11,086 - Epoch: [216][   50/  155]    Loss 3.084596    mAP 0.516503    
2023-04-17 14:23:57,566 - Epoch: [216][  100/  155]    Loss 3.062318    mAP 0.512838    
2023-04-17 14:24:43,537 - Epoch: [216][  150/  155]    Loss 3.068049    mAP 0.510921    
2023-04-17 14:24:47,902 - Epoch: [216][  155/  155]    Loss 3.066354    mAP 0.509923    
2023-04-17 14:24:47,979 - ==> mAP: 0.50992    Loss: 3.066

2023-04-17 14:24:47,983 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 14:24:47,983 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 14:24:48,020 - 

2023-04-17 14:24:48,020 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 14:24:58,916 - Epoch: [217][   50/  518]    Overall Loss 2.824570    Objective Loss 2.824570                                        LR 0.000004    Time 0.217864    
2023-04-17 14:25:09,044 - Epoch: [217][  100/  518]    Overall Loss 2.813244    Objective Loss 2.813244                                        LR 0.000004    Time 0.210191    
2023-04-17 14:25:19,182 - Epoch: [217][  150/  518]    Overall Loss 2.805007    Objective Loss 2.805007                                        LR 0.000004    Time 0.207703    
2023-04-17 14:25:29,285 - Epoch: [217][  200/  518]    Overall Loss 2.808525    Objective Loss 2.808525                                        LR 0.000004    Time 0.206288    
2023-04-17 14:25:39,400 - Epoch: [217][  250/  518]    Overall Loss 2.796181    Objective Loss 2.796181                                        LR 0.000004    Time 0.205482    
2023-04-17 14:25:49,630 - Epoch: [217][  300/  518]    Overall Loss 2.802086    Objective Loss 2.802086                                        LR 0.000004    Time 0.205331    
2023-04-17 14:25:59,828 - Epoch: [217][  350/  518]    Overall Loss 2.800653    Objective Loss 2.800653                                        LR 0.000004    Time 0.205131    
2023-04-17 14:26:10,029 - Epoch: [217][  400/  518]    Overall Loss 2.795746    Objective Loss 2.795746                                        LR 0.000004    Time 0.204986    
2023-04-17 14:26:20,139 - Epoch: [217][  450/  518]    Overall Loss 2.792718    Objective Loss 2.792718                                        LR 0.000004    Time 0.204674    
2023-04-17 14:26:30,329 - Epoch: [217][  500/  518]    Overall Loss 2.795187    Objective Loss 2.795187                                        LR 0.000004    Time 0.204585    
2023-04-17 14:26:33,913 - Epoch: [217][  518/  518]    Overall Loss 2.798431    Objective Loss 2.798431                                        LR 0.000004    Time 0.204392    
2023-04-17 14:26:33,993 - --- validate (epoch=217)-----------
2023-04-17 14:26:33,993 - 4952 samples (32 per mini-batch)
2023-04-17 14:27:17,377 - Epoch: [217][   50/  155]    Loss 3.006798    mAP 0.516284    
2023-04-17 14:28:01,974 - Epoch: [217][  100/  155]    Loss 3.046031    mAP 0.516544    
2023-04-17 14:28:46,159 - Epoch: [217][  150/  155]    Loss 3.069873    mAP 0.513246    
2023-04-17 14:28:50,328 - Epoch: [217][  155/  155]    Loss 3.067927    mAP 0.513848    
2023-04-17 14:28:50,405 - ==> mAP: 0.51385    Loss: 3.068

2023-04-17 14:28:50,409 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 14:28:50,409 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 14:28:50,447 - 

2023-04-17 14:28:50,447 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 14:29:01,456 - Epoch: [218][   50/  518]    Overall Loss 2.760385    Objective Loss 2.760385                                        LR 0.000004    Time 0.220123    
2023-04-17 14:29:11,512 - Epoch: [218][  100/  518]    Overall Loss 2.755347    Objective Loss 2.755347                                        LR 0.000004    Time 0.210601    
2023-04-17 14:29:21,638 - Epoch: [218][  150/  518]    Overall Loss 2.785734    Objective Loss 2.785734                                        LR 0.000004    Time 0.207897    
2023-04-17 14:29:31,792 - Epoch: [218][  200/  518]    Overall Loss 2.784497    Objective Loss 2.784497                                        LR 0.000004    Time 0.206688    
2023-04-17 14:29:42,002 - Epoch: [218][  250/  518]    Overall Loss 2.788094    Objective Loss 2.788094                                        LR 0.000004    Time 0.206180    
2023-04-17 14:29:52,134 - Epoch: [218][  300/  518]    Overall Loss 2.787309    Objective Loss 2.787309                                        LR 0.000004    Time 0.205587    
2023-04-17 14:30:02,235 - Epoch: [218][  350/  518]    Overall Loss 2.796673    Objective Loss 2.796673                                        LR 0.000004    Time 0.205071    
2023-04-17 14:30:12,377 - Epoch: [218][  400/  518]    Overall Loss 2.799167    Objective Loss 2.799167                                        LR 0.000004    Time 0.204789    
2023-04-17 14:30:22,428 - Epoch: [218][  450/  518]    Overall Loss 2.793825    Objective Loss 2.793825                                        LR 0.000004    Time 0.204367    
2023-04-17 14:30:32,538 - Epoch: [218][  500/  518]    Overall Loss 2.793397    Objective Loss 2.793397                                        LR 0.000004    Time 0.204148    
2023-04-17 14:30:36,043 - Epoch: [218][  518/  518]    Overall Loss 2.793995    Objective Loss 2.793995                                        LR 0.000004    Time 0.203819    
2023-04-17 14:30:36,125 - --- validate (epoch=218)-----------
2023-04-17 14:30:36,126 - 4952 samples (32 per mini-batch)
2023-04-17 14:31:20,343 - Epoch: [218][   50/  155]    Loss 3.049740    mAP 0.513324    
2023-04-17 14:32:03,477 - Epoch: [218][  100/  155]    Loss 3.065730    mAP 0.508372    
2023-04-17 14:32:47,814 - Epoch: [218][  150/  155]    Loss 3.071079    mAP 0.511285    
2023-04-17 14:32:52,251 - Epoch: [218][  155/  155]    Loss 3.067931    mAP 0.512041    
2023-04-17 14:32:52,332 - ==> mAP: 0.51204    Loss: 3.068

2023-04-17 14:32:52,339 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 14:32:52,339 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 14:32:52,383 - 

2023-04-17 14:32:52,384 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 14:33:03,551 - Epoch: [219][   50/  518]    Overall Loss 2.779156    Objective Loss 2.779156                                        LR 0.000004    Time 0.223288    
2023-04-17 14:33:13,736 - Epoch: [219][  100/  518]    Overall Loss 2.809828    Objective Loss 2.809828                                        LR 0.000004    Time 0.213484    
2023-04-17 14:33:23,884 - Epoch: [219][  150/  518]    Overall Loss 2.803256    Objective Loss 2.803256                                        LR 0.000004    Time 0.209965    
2023-04-17 14:33:34,060 - Epoch: [219][  200/  518]    Overall Loss 2.799656    Objective Loss 2.799656                                        LR 0.000004    Time 0.208345    
2023-04-17 14:33:44,149 - Epoch: [219][  250/  518]    Overall Loss 2.801416    Objective Loss 2.801416                                        LR 0.000004    Time 0.207026    
2023-04-17 14:33:54,290 - Epoch: [219][  300/  518]    Overall Loss 2.806375    Objective Loss 2.806375                                        LR 0.000004    Time 0.206319    
2023-04-17 14:34:04,507 - Epoch: [219][  350/  518]    Overall Loss 2.806472    Objective Loss 2.806472                                        LR 0.000004    Time 0.206032    
2023-04-17 14:34:14,636 - Epoch: [219][  400/  518]    Overall Loss 2.808087    Objective Loss 2.808087                                        LR 0.000004    Time 0.205598    
2023-04-17 14:34:24,763 - Epoch: [219][  450/  518]    Overall Loss 2.812466    Objective Loss 2.812466                                        LR 0.000004    Time 0.205253    
2023-04-17 14:34:34,858 - Epoch: [219][  500/  518]    Overall Loss 2.808035    Objective Loss 2.808035                                        LR 0.000004    Time 0.204916    
2023-04-17 14:34:38,374 - Epoch: [219][  518/  518]    Overall Loss 2.805562    Objective Loss 2.805562                                        LR 0.000004    Time 0.204582    
2023-04-17 14:34:38,454 - --- validate (epoch=219)-----------
2023-04-17 14:34:38,455 - 4952 samples (32 per mini-batch)
2023-04-17 14:35:24,870 - Epoch: [219][   50/  155]    Loss 3.103832    mAP 0.507006    
2023-04-17 14:36:10,000 - Epoch: [219][  100/  155]    Loss 3.067750    mAP 0.512623    
2023-04-17 14:36:55,639 - Epoch: [219][  150/  155]    Loss 3.068939    mAP 0.514711    
2023-04-17 14:36:59,930 - Epoch: [219][  155/  155]    Loss 3.070012    mAP 0.516389    
2023-04-17 14:37:00,008 - ==> mAP: 0.51639    Loss: 3.070

2023-04-17 14:37:00,011 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 14:37:00,011 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 14:37:00,049 - 

2023-04-17 14:37:00,049 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 14:37:10,867 - Epoch: [220][   50/  518]    Overall Loss 2.841366    Objective Loss 2.841366                                        LR 0.000004    Time 0.216294    
2023-04-17 14:37:21,022 - Epoch: [220][  100/  518]    Overall Loss 2.814544    Objective Loss 2.814544                                        LR 0.000004    Time 0.209689    
2023-04-17 14:37:31,046 - Epoch: [220][  150/  518]    Overall Loss 2.797291    Objective Loss 2.797291                                        LR 0.000004    Time 0.206608    
2023-04-17 14:37:41,094 - Epoch: [220][  200/  518]    Overall Loss 2.807407    Objective Loss 2.807407                                        LR 0.000004    Time 0.205185    
2023-04-17 14:37:51,171 - Epoch: [220][  250/  518]    Overall Loss 2.812375    Objective Loss 2.812375                                        LR 0.000004    Time 0.204449    
2023-04-17 14:38:01,318 - Epoch: [220][  300/  518]    Overall Loss 2.806681    Objective Loss 2.806681                                        LR 0.000004    Time 0.204195    
2023-04-17 14:38:11,381 - Epoch: [220][  350/  518]    Overall Loss 2.806470    Objective Loss 2.806470                                        LR 0.000004    Time 0.203771    
2023-04-17 14:38:21,484 - Epoch: [220][  400/  518]    Overall Loss 2.803252    Objective Loss 2.803252                                        LR 0.000004    Time 0.203552    
2023-04-17 14:38:31,649 - Epoch: [220][  450/  518]    Overall Loss 2.802562    Objective Loss 2.802562                                        LR 0.000004    Time 0.203522    
2023-04-17 14:38:41,698 - Epoch: [220][  500/  518]    Overall Loss 2.805578    Objective Loss 2.805578                                        LR 0.000004    Time 0.203264    
2023-04-17 14:38:45,231 - Epoch: [220][  518/  518]    Overall Loss 2.806008    Objective Loss 2.806008                                        LR 0.000004    Time 0.203020    
2023-04-17 14:38:45,313 - --- validate (epoch=220)-----------
2023-04-17 14:38:45,313 - 4952 samples (32 per mini-batch)
2023-04-17 14:39:29,754 - Epoch: [220][   50/  155]    Loss 3.055875    mAP 0.504112    
2023-04-17 14:40:15,920 - Epoch: [220][  100/  155]    Loss 3.058129    mAP 0.509973    
2023-04-17 14:41:01,270 - Epoch: [220][  150/  155]    Loss 3.074626    mAP 0.506752    
2023-04-17 14:41:05,315 - Epoch: [220][  155/  155]    Loss 3.069718    mAP 0.509714    
2023-04-17 14:41:05,405 - ==> mAP: 0.50971    Loss: 3.070

2023-04-17 14:41:05,409 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 14:41:05,410 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 14:41:05,447 - 

2023-04-17 14:41:05,447 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 14:41:16,462 - Epoch: [221][   50/  518]    Overall Loss 2.787364    Objective Loss 2.787364                                        LR 0.000004    Time 0.220244    
2023-04-17 14:41:26,564 - Epoch: [221][  100/  518]    Overall Loss 2.804126    Objective Loss 2.804126                                        LR 0.000004    Time 0.211124    
2023-04-17 14:41:36,771 - Epoch: [221][  150/  518]    Overall Loss 2.800486    Objective Loss 2.800486                                        LR 0.000004    Time 0.208785    
2023-04-17 14:41:47,010 - Epoch: [221][  200/  518]    Overall Loss 2.801643    Objective Loss 2.801643                                        LR 0.000004    Time 0.207777    
2023-04-17 14:41:57,198 - Epoch: [221][  250/  518]    Overall Loss 2.799078    Objective Loss 2.799078                                        LR 0.000004    Time 0.206965    
2023-04-17 14:42:07,361 - Epoch: [221][  300/  518]    Overall Loss 2.801351    Objective Loss 2.801351                                        LR 0.000004    Time 0.206343    
2023-04-17 14:42:17,452 - Epoch: [221][  350/  518]    Overall Loss 2.806726    Objective Loss 2.806726                                        LR 0.000004    Time 0.205693    
2023-04-17 14:42:27,617 - Epoch: [221][  400/  518]    Overall Loss 2.807703    Objective Loss 2.807703                                        LR 0.000004    Time 0.205391    
2023-04-17 14:42:37,751 - Epoch: [221][  450/  518]    Overall Loss 2.811180    Objective Loss 2.811180                                        LR 0.000004    Time 0.205085    
2023-04-17 14:42:47,844 - Epoch: [221][  500/  518]    Overall Loss 2.807779    Objective Loss 2.807779                                        LR 0.000004    Time 0.204760    
2023-04-17 14:42:51,322 - Epoch: [221][  518/  518]    Overall Loss 2.806648    Objective Loss 2.806648                                        LR 0.000004    Time 0.204358    
2023-04-17 14:42:51,403 - --- validate (epoch=221)-----------
2023-04-17 14:42:51,403 - 4952 samples (32 per mini-batch)
2023-04-17 14:43:36,534 - Epoch: [221][   50/  155]    Loss 3.050703    mAP 0.533531    
2023-04-17 14:44:22,208 - Epoch: [221][  100/  155]    Loss 3.078482    mAP 0.522726    
2023-04-17 14:45:05,927 - Epoch: [221][  150/  155]    Loss 3.070259    mAP 0.522243    
2023-04-17 14:45:10,116 - Epoch: [221][  155/  155]    Loss 3.071414    mAP 0.521957    
2023-04-17 14:45:10,194 - ==> mAP: 0.52196    Loss: 3.071

2023-04-17 14:45:10,197 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 14:45:10,197 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 14:45:10,235 - 

2023-04-17 14:45:10,235 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 14:45:21,016 - Epoch: [222][   50/  518]    Overall Loss 2.836364    Objective Loss 2.836364                                        LR 0.000004    Time 0.215550    
2023-04-17 14:45:31,229 - Epoch: [222][  100/  518]    Overall Loss 2.821020    Objective Loss 2.821020                                        LR 0.000004    Time 0.209894    
2023-04-17 14:45:41,474 - Epoch: [222][  150/  518]    Overall Loss 2.809634    Objective Loss 2.809634                                        LR 0.000004    Time 0.208215    
2023-04-17 14:45:51,604 - Epoch: [222][  200/  518]    Overall Loss 2.813516    Objective Loss 2.813516                                        LR 0.000004    Time 0.206805    
2023-04-17 14:46:01,741 - Epoch: [222][  250/  518]    Overall Loss 2.807060    Objective Loss 2.807060                                        LR 0.000004    Time 0.205986    
2023-04-17 14:46:11,973 - Epoch: [222][  300/  518]    Overall Loss 2.803474    Objective Loss 2.803474                                        LR 0.000004    Time 0.205755    
2023-04-17 14:46:22,139 - Epoch: [222][  350/  518]    Overall Loss 2.810086    Objective Loss 2.810086                                        LR 0.000004    Time 0.205405    
2023-04-17 14:46:32,383 - Epoch: [222][  400/  518]    Overall Loss 2.810381    Objective Loss 2.810381                                        LR 0.000004    Time 0.205334    
2023-04-17 14:46:42,596 - Epoch: [222][  450/  518]    Overall Loss 2.809682    Objective Loss 2.809682                                        LR 0.000004    Time 0.205211    
2023-04-17 14:46:52,696 - Epoch: [222][  500/  518]    Overall Loss 2.804537    Objective Loss 2.804537                                        LR 0.000004    Time 0.204888    
2023-04-17 14:46:56,249 - Epoch: [222][  518/  518]    Overall Loss 2.807881    Objective Loss 2.807881                                        LR 0.000004    Time 0.204625    
2023-04-17 14:46:56,330 - --- validate (epoch=222)-----------
2023-04-17 14:46:56,330 - 4952 samples (32 per mini-batch)
2023-04-17 14:47:40,634 - Epoch: [222][   50/  155]    Loss 3.055701    mAP 0.506482    
2023-04-17 14:48:25,019 - Epoch: [222][  100/  155]    Loss 3.056219    mAP 0.527078    
2023-04-17 14:49:08,232 - Epoch: [222][  150/  155]    Loss 3.075615    mAP 0.520856    
2023-04-17 14:49:12,299 - Epoch: [222][  155/  155]    Loss 3.071968    mAP 0.520586    
2023-04-17 14:49:12,377 - ==> mAP: 0.52059    Loss: 3.072

2023-04-17 14:49:12,380 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 14:49:12,381 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 14:49:12,417 - 

2023-04-17 14:49:12,417 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 14:49:23,392 - Epoch: [223][   50/  518]    Overall Loss 2.850576    Objective Loss 2.850576                                        LR 0.000004    Time 0.219444    
2023-04-17 14:49:33,608 - Epoch: [223][  100/  518]    Overall Loss 2.798992    Objective Loss 2.798992                                        LR 0.000004    Time 0.211863    
2023-04-17 14:49:43,693 - Epoch: [223][  150/  518]    Overall Loss 2.811586    Objective Loss 2.811586                                        LR 0.000004    Time 0.208469    
2023-04-17 14:49:53,824 - Epoch: [223][  200/  518]    Overall Loss 2.808508    Objective Loss 2.808508                                        LR 0.000004    Time 0.206999    
2023-04-17 14:50:03,895 - Epoch: [223][  250/  518]    Overall Loss 2.806670    Objective Loss 2.806670                                        LR 0.000004    Time 0.205876    
2023-04-17 14:50:14,032 - Epoch: [223][  300/  518]    Overall Loss 2.813358    Objective Loss 2.813358                                        LR 0.000004    Time 0.205349    
2023-04-17 14:50:24,187 - Epoch: [223][  350/  518]    Overall Loss 2.806680    Objective Loss 2.806680                                        LR 0.000004    Time 0.205021    
2023-04-17 14:50:34,311 - Epoch: [223][  400/  518]    Overall Loss 2.811474    Objective Loss 2.811474                                        LR 0.000004    Time 0.204700    
2023-04-17 14:50:44,510 - Epoch: [223][  450/  518]    Overall Loss 2.809367    Objective Loss 2.809367                                        LR 0.000004    Time 0.204617    
2023-04-17 14:50:54,639 - Epoch: [223][  500/  518]    Overall Loss 2.813788    Objective Loss 2.813788                                        LR 0.000004    Time 0.204409    
2023-04-17 14:50:58,176 - Epoch: [223][  518/  518]    Overall Loss 2.816438    Objective Loss 2.816438                                        LR 0.000004    Time 0.204135    
2023-04-17 14:50:58,258 - --- validate (epoch=223)-----------
2023-04-17 14:50:58,259 - 4952 samples (32 per mini-batch)
2023-04-17 14:51:42,713 - Epoch: [223][   50/  155]    Loss 3.088998    mAP 0.522777    
2023-04-17 14:52:27,726 - Epoch: [223][  100/  155]    Loss 3.077950    mAP 0.525418    
2023-04-17 14:53:12,650 - Epoch: [223][  150/  155]    Loss 3.072463    mAP 0.525245    
2023-04-17 14:53:16,206 - Epoch: [223][  155/  155]    Loss 3.069088    mAP 0.526975    
2023-04-17 14:53:16,289 - ==> mAP: 0.52697    Loss: 3.069

2023-04-17 14:53:16,361 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 14:53:16,361 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 14:53:16,399 - 

2023-04-17 14:53:16,399 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 14:53:27,527 - Epoch: [224][   50/  518]    Overall Loss 2.810001    Objective Loss 2.810001                                        LR 0.000004    Time 0.222509    
2023-04-17 14:53:37,711 - Epoch: [224][  100/  518]    Overall Loss 2.812920    Objective Loss 2.812920                                        LR 0.000004    Time 0.213078    
2023-04-17 14:53:47,877 - Epoch: [224][  150/  518]    Overall Loss 2.809630    Objective Loss 2.809630                                        LR 0.000004    Time 0.209814    
2023-04-17 14:53:58,050 - Epoch: [224][  200/  518]    Overall Loss 2.791688    Objective Loss 2.791688                                        LR 0.000004    Time 0.208218    
2023-04-17 14:54:08,153 - Epoch: [224][  250/  518]    Overall Loss 2.792967    Objective Loss 2.792967                                        LR 0.000004    Time 0.206979    
2023-04-17 14:54:18,237 - Epoch: [224][  300/  518]    Overall Loss 2.786064    Objective Loss 2.786064                                        LR 0.000004    Time 0.206090    
2023-04-17 14:54:28,421 - Epoch: [224][  350/  518]    Overall Loss 2.787778    Objective Loss 2.787778                                        LR 0.000004    Time 0.205742    
2023-04-17 14:54:38,588 - Epoch: [224][  400/  518]    Overall Loss 2.789596    Objective Loss 2.789596                                        LR 0.000004    Time 0.205439    
2023-04-17 14:54:48,731 - Epoch: [224][  450/  518]    Overall Loss 2.793811    Objective Loss 2.793811                                        LR 0.000004    Time 0.205148    
2023-04-17 14:54:58,822 - Epoch: [224][  500/  518]    Overall Loss 2.793447    Objective Loss 2.793447                                        LR 0.000004    Time 0.204812    
2023-04-17 14:55:02,330 - Epoch: [224][  518/  518]    Overall Loss 2.795736    Objective Loss 2.795736                                        LR 0.000004    Time 0.204467    
2023-04-17 14:55:02,409 - --- validate (epoch=224)-----------
2023-04-17 14:55:02,409 - 4952 samples (32 per mini-batch)
2023-04-17 14:55:46,614 - Epoch: [224][   50/  155]    Loss 3.075724    mAP 0.519635    
2023-04-17 14:56:29,745 - Epoch: [224][  100/  155]    Loss 3.066192    mAP 0.515371    
2023-04-17 14:57:12,319 - Epoch: [224][  150/  155]    Loss 3.076569    mAP 0.511202    
2023-04-17 14:57:16,252 - Epoch: [224][  155/  155]    Loss 3.070196    mAP 0.512455    
2023-04-17 14:57:16,333 - ==> mAP: 0.51246    Loss: 3.070

2023-04-17 14:57:16,337 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 14:57:16,337 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 14:57:16,373 - 

2023-04-17 14:57:16,374 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 14:57:27,189 - Epoch: [225][   50/  518]    Overall Loss 2.827272    Objective Loss 2.827272                                        LR 0.000004    Time 0.216251    
2023-04-17 14:57:37,193 - Epoch: [225][  100/  518]    Overall Loss 2.840431    Objective Loss 2.840431                                        LR 0.000004    Time 0.208149    
2023-04-17 14:57:47,354 - Epoch: [225][  150/  518]    Overall Loss 2.826992    Objective Loss 2.826992                                        LR 0.000004    Time 0.206492    
2023-04-17 14:57:57,533 - Epoch: [225][  200/  518]    Overall Loss 2.816758    Objective Loss 2.816758                                        LR 0.000004    Time 0.205761    
2023-04-17 14:58:07,735 - Epoch: [225][  250/  518]    Overall Loss 2.821809    Objective Loss 2.821809                                        LR 0.000004    Time 0.205409    
2023-04-17 14:58:17,827 - Epoch: [225][  300/  518]    Overall Loss 2.807743    Objective Loss 2.807743                                        LR 0.000004    Time 0.204807    
2023-04-17 14:58:28,033 - Epoch: [225][  350/  518]    Overall Loss 2.812522    Objective Loss 2.812522                                        LR 0.000004    Time 0.204707    
2023-04-17 14:58:38,182 - Epoch: [225][  400/  518]    Overall Loss 2.808949    Objective Loss 2.808949                                        LR 0.000004    Time 0.204486    
2023-04-17 14:58:48,399 - Epoch: [225][  450/  518]    Overall Loss 2.810303    Objective Loss 2.810303                                        LR 0.000004    Time 0.204467    
2023-04-17 14:58:58,561 - Epoch: [225][  500/  518]    Overall Loss 2.814437    Objective Loss 2.814437                                        LR 0.000004    Time 0.204340    
2023-04-17 14:59:02,080 - Epoch: [225][  518/  518]    Overall Loss 2.814325    Objective Loss 2.814325                                        LR 0.000004    Time 0.204033    
2023-04-17 14:59:02,162 - --- validate (epoch=225)-----------
2023-04-17 14:59:02,163 - 4952 samples (32 per mini-batch)
2023-04-17 14:59:47,551 - Epoch: [225][   50/  155]    Loss 3.046501    mAP 0.513041    
2023-04-17 15:00:32,810 - Epoch: [225][  100/  155]    Loss 3.061858    mAP 0.514782    
2023-04-17 15:01:18,573 - Epoch: [225][  150/  155]    Loss 3.069690    mAP 0.512830    
2023-04-17 15:01:22,881 - Epoch: [225][  155/  155]    Loss 3.068991    mAP 0.513057    
2023-04-17 15:01:22,960 - ==> mAP: 0.51306    Loss: 3.069

2023-04-17 15:01:22,964 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 15:01:22,964 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 15:01:23,002 - 

2023-04-17 15:01:23,002 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 15:01:33,815 - Epoch: [226][   50/  518]    Overall Loss 2.812548    Objective Loss 2.812548                                        LR 0.000004    Time 0.216196    
2023-04-17 15:01:43,963 - Epoch: [226][  100/  518]    Overall Loss 2.799273    Objective Loss 2.799273                                        LR 0.000004    Time 0.209569    
2023-04-17 15:01:54,193 - Epoch: [226][  150/  518]    Overall Loss 2.807051    Objective Loss 2.807051                                        LR 0.000004    Time 0.207898    
2023-04-17 15:02:04,355 - Epoch: [226][  200/  518]    Overall Loss 2.802702    Objective Loss 2.802702                                        LR 0.000004    Time 0.206729    
2023-04-17 15:02:14,528 - Epoch: [226][  250/  518]    Overall Loss 2.803647    Objective Loss 2.803647                                        LR 0.000004    Time 0.206068    
2023-04-17 15:02:24,589 - Epoch: [226][  300/  518]    Overall Loss 2.804624    Objective Loss 2.804624                                        LR 0.000004    Time 0.205254    
2023-04-17 15:02:34,656 - Epoch: [226][  350/  518]    Overall Loss 2.802576    Objective Loss 2.802576                                        LR 0.000004    Time 0.204692    
2023-04-17 15:02:44,804 - Epoch: [226][  400/  518]    Overall Loss 2.802595    Objective Loss 2.802595                                        LR 0.000004    Time 0.204470    
2023-04-17 15:02:54,901 - Epoch: [226][  450/  518]    Overall Loss 2.804987    Objective Loss 2.804987                                        LR 0.000004    Time 0.204185    
2023-04-17 15:03:04,928 - Epoch: [226][  500/  518]    Overall Loss 2.797087    Objective Loss 2.797087                                        LR 0.000004    Time 0.203819    
2023-04-17 15:03:08,526 - Epoch: [226][  518/  518]    Overall Loss 2.798130    Objective Loss 2.798130                                        LR 0.000004    Time 0.203682    
2023-04-17 15:03:08,610 - --- validate (epoch=226)-----------
2023-04-17 15:03:08,610 - 4952 samples (32 per mini-batch)
2023-04-17 15:03:55,854 - Epoch: [226][   50/  155]    Loss 3.039515    mAP 0.506416    
2023-04-17 15:04:42,002 - Epoch: [226][  100/  155]    Loss 3.060814    mAP 0.512377    
2023-04-17 15:05:27,262 - Epoch: [226][  150/  155]    Loss 3.072299    mAP 0.517658    
2023-04-17 15:05:31,386 - Epoch: [226][  155/  155]    Loss 3.071814    mAP 0.517894    
2023-04-17 15:05:31,465 - ==> mAP: 0.51789    Loss: 3.072

2023-04-17 15:05:31,469 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 15:05:31,469 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 15:05:31,505 - 

2023-04-17 15:05:31,505 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 15:05:42,436 - Epoch: [227][   50/  518]    Overall Loss 2.802626    Objective Loss 2.802626                                        LR 0.000004    Time 0.218555    
2023-04-17 15:05:52,482 - Epoch: [227][  100/  518]    Overall Loss 2.799673    Objective Loss 2.799673                                        LR 0.000004    Time 0.209726    
2023-04-17 15:06:02,565 - Epoch: [227][  150/  518]    Overall Loss 2.798845    Objective Loss 2.798845                                        LR 0.000004    Time 0.207029    
2023-04-17 15:06:12,562 - Epoch: [227][  200/  518]    Overall Loss 2.810318    Objective Loss 2.810318                                        LR 0.000004    Time 0.205247    
2023-04-17 15:06:22,635 - Epoch: [227][  250/  518]    Overall Loss 2.808041    Objective Loss 2.808041                                        LR 0.000004    Time 0.204484    
2023-04-17 15:06:32,752 - Epoch: [227][  300/  518]    Overall Loss 2.797393    Objective Loss 2.797393                                        LR 0.000004    Time 0.204120    
2023-04-17 15:06:42,795 - Epoch: [227][  350/  518]    Overall Loss 2.804072    Objective Loss 2.804072                                        LR 0.000004    Time 0.203652    
2023-04-17 15:06:52,884 - Epoch: [227][  400/  518]    Overall Loss 2.807159    Objective Loss 2.807159                                        LR 0.000004    Time 0.203413    
2023-04-17 15:07:03,033 - Epoch: [227][  450/  518]    Overall Loss 2.804727    Objective Loss 2.804727                                        LR 0.000004    Time 0.203361    
2023-04-17 15:07:13,164 - Epoch: [227][  500/  518]    Overall Loss 2.804419    Objective Loss 2.804419                                        LR 0.000004    Time 0.203285    
2023-04-17 15:07:16,660 - Epoch: [227][  518/  518]    Overall Loss 2.805448    Objective Loss 2.805448                                        LR 0.000004    Time 0.202967    
2023-04-17 15:07:16,739 - --- validate (epoch=227)-----------
2023-04-17 15:07:16,739 - 4952 samples (32 per mini-batch)
2023-04-17 15:07:59,957 - Epoch: [227][   50/  155]    Loss 3.013878    mAP 0.531273    
2023-04-17 15:08:45,537 - Epoch: [227][  100/  155]    Loss 3.038970    mAP 0.525888    
2023-04-17 15:09:29,185 - Epoch: [227][  150/  155]    Loss 3.059127    mAP 0.519521    
2023-04-17 15:09:33,226 - Epoch: [227][  155/  155]    Loss 3.062053    mAP 0.519037    
2023-04-17 15:09:33,306 - ==> mAP: 0.51904    Loss: 3.062

2023-04-17 15:09:33,310 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 15:09:33,310 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 15:09:33,346 - 

2023-04-17 15:09:33,346 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 15:09:44,326 - Epoch: [228][   50/  518]    Overall Loss 2.801108    Objective Loss 2.801108                                        LR 0.000004    Time 0.219536    
2023-04-17 15:09:54,444 - Epoch: [228][  100/  518]    Overall Loss 2.779410    Objective Loss 2.779410                                        LR 0.000004    Time 0.210930    
2023-04-17 15:10:04,668 - Epoch: [228][  150/  518]    Overall Loss 2.783418    Objective Loss 2.783418                                        LR 0.000004    Time 0.208769    
2023-04-17 15:10:14,769 - Epoch: [228][  200/  518]    Overall Loss 2.780201    Objective Loss 2.780201                                        LR 0.000004    Time 0.207074    
2023-04-17 15:10:24,838 - Epoch: [228][  250/  518]    Overall Loss 2.789344    Objective Loss 2.789344                                        LR 0.000004    Time 0.205929    
2023-04-17 15:10:34,879 - Epoch: [228][  300/  518]    Overall Loss 2.801531    Objective Loss 2.801531                                        LR 0.000004    Time 0.205075    
2023-04-17 15:10:44,965 - Epoch: [228][  350/  518]    Overall Loss 2.796496    Objective Loss 2.796496                                        LR 0.000004    Time 0.204591    
2023-04-17 15:10:55,063 - Epoch: [228][  400/  518]    Overall Loss 2.801522    Objective Loss 2.801522                                        LR 0.000004    Time 0.204256    
2023-04-17 15:11:05,127 - Epoch: [228][  450/  518]    Overall Loss 2.799555    Objective Loss 2.799555                                        LR 0.000004    Time 0.203922    
2023-04-17 15:11:15,212 - Epoch: [228][  500/  518]    Overall Loss 2.801071    Objective Loss 2.801071                                        LR 0.000004    Time 0.203699    
2023-04-17 15:11:18,696 - Epoch: [228][  518/  518]    Overall Loss 2.801585    Objective Loss 2.801585                                        LR 0.000004    Time 0.203345    
2023-04-17 15:11:18,777 - --- validate (epoch=228)-----------
2023-04-17 15:11:18,777 - 4952 samples (32 per mini-batch)
2023-04-17 15:12:04,422 - Epoch: [228][   50/  155]    Loss 3.067039    mAP 0.527464    
2023-04-17 15:12:50,525 - Epoch: [228][  100/  155]    Loss 3.073361    mAP 0.522422    
2023-04-17 15:13:35,342 - Epoch: [228][  150/  155]    Loss 3.064426    mAP 0.521425    
2023-04-17 15:13:39,852 - Epoch: [228][  155/  155]    Loss 3.066867    mAP 0.519704    
2023-04-17 15:13:39,932 - ==> mAP: 0.51970    Loss: 3.067

2023-04-17 15:13:39,935 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 15:13:39,935 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 15:13:39,973 - 

2023-04-17 15:13:39,974 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 15:13:50,966 - Epoch: [229][   50/  518]    Overall Loss 2.815158    Objective Loss 2.815158                                        LR 0.000004    Time 0.219796    
2023-04-17 15:14:01,027 - Epoch: [229][  100/  518]    Overall Loss 2.809915    Objective Loss 2.809915                                        LR 0.000004    Time 0.210494    
2023-04-17 15:14:11,114 - Epoch: [229][  150/  518]    Overall Loss 2.813421    Objective Loss 2.813421                                        LR 0.000004    Time 0.207560    
2023-04-17 15:14:21,318 - Epoch: [229][  200/  518]    Overall Loss 2.802094    Objective Loss 2.802094                                        LR 0.000004    Time 0.206686    
2023-04-17 15:14:31,401 - Epoch: [229][  250/  518]    Overall Loss 2.796372    Objective Loss 2.796372                                        LR 0.000004    Time 0.205675    
2023-04-17 15:14:41,523 - Epoch: [229][  300/  518]    Overall Loss 2.800385    Objective Loss 2.800385                                        LR 0.000004    Time 0.205129    
2023-04-17 15:14:51,693 - Epoch: [229][  350/  518]    Overall Loss 2.797761    Objective Loss 2.797761                                        LR 0.000004    Time 0.204879    
2023-04-17 15:15:01,846 - Epoch: [229][  400/  518]    Overall Loss 2.794949    Objective Loss 2.794949                                        LR 0.000004    Time 0.204647    
2023-04-17 15:15:11,941 - Epoch: [229][  450/  518]    Overall Loss 2.795280    Objective Loss 2.795280                                        LR 0.000004    Time 0.204339    
2023-04-17 15:15:22,112 - Epoch: [229][  500/  518]    Overall Loss 2.800391    Objective Loss 2.800391                                        LR 0.000004    Time 0.204243    
2023-04-17 15:15:25,601 - Epoch: [229][  518/  518]    Overall Loss 2.801775    Objective Loss 2.801775                                        LR 0.000004    Time 0.203880    
2023-04-17 15:15:25,680 - --- validate (epoch=229)-----------
2023-04-17 15:15:25,680 - 4952 samples (32 per mini-batch)
2023-04-17 15:16:11,576 - Epoch: [229][   50/  155]    Loss 3.071923    mAP 0.521968    
2023-04-17 15:16:54,534 - Epoch: [229][  100/  155]    Loss 3.078626    mAP 0.516693    
2023-04-17 15:17:39,786 - Epoch: [229][  150/  155]    Loss 3.069393    mAP 0.520286    
2023-04-17 15:17:43,883 - Epoch: [229][  155/  155]    Loss 3.069936    mAP 0.520510    
2023-04-17 15:17:43,963 - ==> mAP: 0.52051    Loss: 3.070

2023-04-17 15:17:43,966 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 15:17:43,966 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 15:17:44,003 - 

2023-04-17 15:17:44,003 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 15:17:54,898 - Epoch: [230][   50/  518]    Overall Loss 2.815916    Objective Loss 2.815916                                        LR 0.000004    Time 0.217845    
2023-04-17 15:18:05,032 - Epoch: [230][  100/  518]    Overall Loss 2.802209    Objective Loss 2.802209                                        LR 0.000004    Time 0.210251    
2023-04-17 15:18:15,145 - Epoch: [230][  150/  518]    Overall Loss 2.811208    Objective Loss 2.811208                                        LR 0.000004    Time 0.207578    
2023-04-17 15:18:25,248 - Epoch: [230][  200/  518]    Overall Loss 2.813467    Objective Loss 2.813467                                        LR 0.000004    Time 0.206190    
2023-04-17 15:18:35,401 - Epoch: [230][  250/  518]    Overall Loss 2.802618    Objective Loss 2.802618                                        LR 0.000004    Time 0.205558    
2023-04-17 15:18:45,471 - Epoch: [230][  300/  518]    Overall Loss 2.799094    Objective Loss 2.799094                                        LR 0.000004    Time 0.204859    
2023-04-17 15:18:55,587 - Epoch: [230][  350/  518]    Overall Loss 2.799008    Objective Loss 2.799008                                        LR 0.000004    Time 0.204492    
2023-04-17 15:19:05,564 - Epoch: [230][  400/  518]    Overall Loss 2.798010    Objective Loss 2.798010                                        LR 0.000004    Time 0.203870    
2023-04-17 15:19:15,705 - Epoch: [230][  450/  518]    Overall Loss 2.800173    Objective Loss 2.800173                                        LR 0.000004    Time 0.203748    
2023-04-17 15:19:25,847 - Epoch: [230][  500/  518]    Overall Loss 2.801844    Objective Loss 2.801844                                        LR 0.000004    Time 0.203655    
2023-04-17 15:19:29,340 - Epoch: [230][  518/  518]    Overall Loss 2.800363    Objective Loss 2.800363                                        LR 0.000004    Time 0.203320    
2023-04-17 15:19:29,420 - --- validate (epoch=230)-----------
2023-04-17 15:19:29,420 - 4952 samples (32 per mini-batch)
2023-04-17 15:20:13,348 - Epoch: [230][   50/  155]    Loss 3.083514    mAP 0.497964    
2023-04-17 15:20:55,637 - Epoch: [230][  100/  155]    Loss 3.065616    mAP 0.521532    
2023-04-17 15:21:39,179 - Epoch: [230][  150/  155]    Loss 3.062964    mAP 0.518775    
2023-04-17 15:21:43,069 - Epoch: [230][  155/  155]    Loss 3.067001    mAP 0.516916    
2023-04-17 15:21:43,148 - ==> mAP: 0.51692    Loss: 3.067

2023-04-17 15:21:43,152 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 15:21:43,152 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 15:21:43,188 - 

2023-04-17 15:21:43,189 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 15:21:53,994 - Epoch: [231][   50/  518]    Overall Loss 2.807606    Objective Loss 2.807606                                        LR 0.000004    Time 0.216044    
2023-04-17 15:22:04,013 - Epoch: [231][  100/  518]    Overall Loss 2.785174    Objective Loss 2.785174                                        LR 0.000004    Time 0.208197    
2023-04-17 15:22:14,150 - Epoch: [231][  150/  518]    Overall Loss 2.793912    Objective Loss 2.793912                                        LR 0.000004    Time 0.206367    
2023-04-17 15:22:24,199 - Epoch: [231][  200/  518]    Overall Loss 2.791706    Objective Loss 2.791706                                        LR 0.000004    Time 0.205014    
2023-04-17 15:22:34,286 - Epoch: [231][  250/  518]    Overall Loss 2.802790    Objective Loss 2.802790                                        LR 0.000004    Time 0.204353    
2023-04-17 15:22:44,446 - Epoch: [231][  300/  518]    Overall Loss 2.793330    Objective Loss 2.793330                                        LR 0.000004    Time 0.204157    
2023-04-17 15:22:54,589 - Epoch: [231][  350/  518]    Overall Loss 2.797260    Objective Loss 2.797260                                        LR 0.000004    Time 0.203968    
2023-04-17 15:23:04,789 - Epoch: [231][  400/  518]    Overall Loss 2.797086    Objective Loss 2.797086                                        LR 0.000004    Time 0.203968    
2023-04-17 15:23:14,877 - Epoch: [231][  450/  518]    Overall Loss 2.794213    Objective Loss 2.794213                                        LR 0.000004    Time 0.203718    
2023-04-17 15:23:24,964 - Epoch: [231][  500/  518]    Overall Loss 2.799030    Objective Loss 2.799030                                        LR 0.000004    Time 0.203517    
2023-04-17 15:23:28,486 - Epoch: [231][  518/  518]    Overall Loss 2.803018    Objective Loss 2.803018                                        LR 0.000004    Time 0.203244    
2023-04-17 15:23:28,564 - --- validate (epoch=231)-----------
2023-04-17 15:23:28,565 - 4952 samples (32 per mini-batch)
2023-04-17 15:24:12,227 - Epoch: [231][   50/  155]    Loss 3.141648    mAP 0.523329    
2023-04-17 15:24:55,617 - Epoch: [231][  100/  155]    Loss 3.095493    mAP 0.523940    
2023-04-17 15:25:37,907 - Epoch: [231][  150/  155]    Loss 3.078653    mAP 0.519280    
2023-04-17 15:25:41,989 - Epoch: [231][  155/  155]    Loss 3.075033    mAP 0.519284    
2023-04-17 15:25:42,065 - ==> mAP: 0.51928    Loss: 3.075

2023-04-17 15:25:42,070 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 15:25:42,070 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 15:25:42,107 - 

2023-04-17 15:25:42,107 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 15:25:52,995 - Epoch: [232][   50/  518]    Overall Loss 2.785535    Objective Loss 2.785535                                        LR 0.000004    Time 0.217706    
2023-04-17 15:26:03,084 - Epoch: [232][  100/  518]    Overall Loss 2.773749    Objective Loss 2.773749                                        LR 0.000004    Time 0.209728    
2023-04-17 15:26:13,219 - Epoch: [232][  150/  518]    Overall Loss 2.788623    Objective Loss 2.788623                                        LR 0.000004    Time 0.207370    
2023-04-17 15:26:23,287 - Epoch: [232][  200/  518]    Overall Loss 2.789950    Objective Loss 2.789950                                        LR 0.000004    Time 0.205862    
2023-04-17 15:26:33,335 - Epoch: [232][  250/  518]    Overall Loss 2.788298    Objective Loss 2.788298                                        LR 0.000004    Time 0.204874    
2023-04-17 15:26:43,488 - Epoch: [232][  300/  518]    Overall Loss 2.796286    Objective Loss 2.796286                                        LR 0.000004    Time 0.204566    
2023-04-17 15:26:53,701 - Epoch: [232][  350/  518]    Overall Loss 2.793545    Objective Loss 2.793545                                        LR 0.000004    Time 0.204521    
2023-04-17 15:27:03,791 - Epoch: [232][  400/  518]    Overall Loss 2.794420    Objective Loss 2.794420                                        LR 0.000004    Time 0.204176    
2023-04-17 15:27:13,816 - Epoch: [232][  450/  518]    Overall Loss 2.794987    Objective Loss 2.794987                                        LR 0.000004    Time 0.203763    
2023-04-17 15:27:23,960 - Epoch: [232][  500/  518]    Overall Loss 2.798615    Objective Loss 2.798615                                        LR 0.000004    Time 0.203672    
2023-04-17 15:27:27,508 - Epoch: [232][  518/  518]    Overall Loss 2.798157    Objective Loss 2.798157                                        LR 0.000004    Time 0.203444    
2023-04-17 15:27:27,588 - --- validate (epoch=232)-----------
2023-04-17 15:27:27,588 - 4952 samples (32 per mini-batch)
2023-04-17 15:28:13,404 - Epoch: [232][   50/  155]    Loss 3.093846    mAP 0.530671    
2023-04-17 15:28:56,760 - Epoch: [232][  100/  155]    Loss 3.064740    mAP 0.519535    
2023-04-17 15:29:41,411 - Epoch: [232][  150/  155]    Loss 3.067165    mAP 0.517628    
2023-04-17 15:29:45,748 - Epoch: [232][  155/  155]    Loss 3.066288    mAP 0.516560    
2023-04-17 15:29:45,825 - ==> mAP: 0.51656    Loss: 3.066

2023-04-17 15:29:45,829 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 15:29:45,829 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 15:29:45,865 - 

2023-04-17 15:29:45,865 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 15:29:56,777 - Epoch: [233][   50/  518]    Overall Loss 2.808391    Objective Loss 2.808391                                        LR 0.000004    Time 0.218187    
2023-04-17 15:30:06,907 - Epoch: [233][  100/  518]    Overall Loss 2.847796    Objective Loss 2.847796                                        LR 0.000004    Time 0.210381    
2023-04-17 15:30:16,994 - Epoch: [233][  150/  518]    Overall Loss 2.831742    Objective Loss 2.831742                                        LR 0.000004    Time 0.207486    
2023-04-17 15:30:27,108 - Epoch: [233][  200/  518]    Overall Loss 2.823563    Objective Loss 2.823563                                        LR 0.000004    Time 0.206180    
2023-04-17 15:30:37,146 - Epoch: [233][  250/  518]    Overall Loss 2.835270    Objective Loss 2.835270                                        LR 0.000004    Time 0.205088    
2023-04-17 15:30:47,190 - Epoch: [233][  300/  518]    Overall Loss 2.829044    Objective Loss 2.829044                                        LR 0.000004    Time 0.204381    
2023-04-17 15:30:57,281 - Epoch: [233][  350/  518]    Overall Loss 2.826131    Objective Loss 2.826131                                        LR 0.000004    Time 0.204013    
2023-04-17 15:31:07,418 - Epoch: [233][  400/  518]    Overall Loss 2.816814    Objective Loss 2.816814                                        LR 0.000004    Time 0.203849    
2023-04-17 15:31:17,530 - Epoch: [233][  450/  518]    Overall Loss 2.811146    Objective Loss 2.811146                                        LR 0.000004    Time 0.203667    
2023-04-17 15:31:27,604 - Epoch: [233][  500/  518]    Overall Loss 2.810889    Objective Loss 2.810889                                        LR 0.000004    Time 0.203444    
2023-04-17 15:31:31,084 - Epoch: [233][  518/  518]    Overall Loss 2.808755    Objective Loss 2.808755                                        LR 0.000004    Time 0.203092    
2023-04-17 15:31:31,166 - --- validate (epoch=233)-----------
2023-04-17 15:31:31,166 - 4952 samples (32 per mini-batch)
2023-04-17 15:32:15,002 - Epoch: [233][   50/  155]    Loss 3.063879    mAP 0.523683    
2023-04-17 15:32:59,277 - Epoch: [233][  100/  155]    Loss 3.059699    mAP 0.530111    
2023-04-17 15:33:44,514 - Epoch: [233][  150/  155]    Loss 3.065230    mAP 0.526221    
2023-04-17 15:33:48,695 - Epoch: [233][  155/  155]    Loss 3.066865    mAP 0.522025    
2023-04-17 15:33:48,774 - ==> mAP: 0.52202    Loss: 3.067

2023-04-17 15:33:48,779 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 15:33:48,779 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 15:33:48,815 - 

2023-04-17 15:33:48,815 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 15:33:59,816 - Epoch: [234][   50/  518]    Overall Loss 2.780849    Objective Loss 2.780849                                        LR 0.000004    Time 0.219968    
2023-04-17 15:34:09,925 - Epoch: [234][  100/  518]    Overall Loss 2.807246    Objective Loss 2.807246                                        LR 0.000004    Time 0.211055    
2023-04-17 15:34:20,065 - Epoch: [234][  150/  518]    Overall Loss 2.806157    Objective Loss 2.806157                                        LR 0.000004    Time 0.208291    
2023-04-17 15:34:30,191 - Epoch: [234][  200/  518]    Overall Loss 2.808936    Objective Loss 2.808936                                        LR 0.000004    Time 0.206843    
2023-04-17 15:34:40,319 - Epoch: [234][  250/  518]    Overall Loss 2.808169    Objective Loss 2.808169                                        LR 0.000004    Time 0.205982    
2023-04-17 15:34:50,387 - Epoch: [234][  300/  518]    Overall Loss 2.815510    Objective Loss 2.815510                                        LR 0.000004    Time 0.205206    
2023-04-17 15:35:00,436 - Epoch: [234][  350/  518]    Overall Loss 2.810135    Objective Loss 2.810135                                        LR 0.000004    Time 0.204597    
2023-04-17 15:35:10,536 - Epoch: [234][  400/  518]    Overall Loss 2.816537    Objective Loss 2.816537                                        LR 0.000004    Time 0.204268    
2023-04-17 15:35:20,632 - Epoch: [234][  450/  518]    Overall Loss 2.808587    Objective Loss 2.808587                                        LR 0.000004    Time 0.204004    
2023-04-17 15:35:30,695 - Epoch: [234][  500/  518]    Overall Loss 2.809055    Objective Loss 2.809055                                        LR 0.000004    Time 0.203727    
2023-04-17 15:35:34,181 - Epoch: [234][  518/  518]    Overall Loss 2.808291    Objective Loss 2.808291                                        LR 0.000004    Time 0.203376    
2023-04-17 15:35:34,262 - --- validate (epoch=234)-----------
2023-04-17 15:35:34,262 - 4952 samples (32 per mini-batch)
2023-04-17 15:36:18,313 - Epoch: [234][   50/  155]    Loss 3.007854    mAP 0.509180    
2023-04-17 15:37:02,843 - Epoch: [234][  100/  155]    Loss 3.050947    mAP 0.510776    
2023-04-17 15:37:47,986 - Epoch: [234][  150/  155]    Loss 3.064421    mAP 0.516884    
2023-04-17 15:37:52,860 - Epoch: [234][  155/  155]    Loss 3.067252    mAP 0.517475    
2023-04-17 15:37:52,937 - ==> mAP: 0.51747    Loss: 3.067

2023-04-17 15:37:52,942 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 15:37:52,942 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 15:37:52,998 - 

2023-04-17 15:37:52,998 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 15:38:03,926 - Epoch: [235][   50/  518]    Overall Loss 2.869447    Objective Loss 2.869447                                        LR 0.000004    Time 0.218493    
2023-04-17 15:38:14,039 - Epoch: [235][  100/  518]    Overall Loss 2.832513    Objective Loss 2.832513                                        LR 0.000004    Time 0.210364    
2023-04-17 15:38:24,181 - Epoch: [235][  150/  518]    Overall Loss 2.815149    Objective Loss 2.815149                                        LR 0.000004    Time 0.207844    
2023-04-17 15:38:34,302 - Epoch: [235][  200/  518]    Overall Loss 2.804666    Objective Loss 2.804666                                        LR 0.000004    Time 0.206477    
2023-04-17 15:38:44,405 - Epoch: [235][  250/  518]    Overall Loss 2.804925    Objective Loss 2.804925                                        LR 0.000004    Time 0.205588    
2023-04-17 15:38:54,620 - Epoch: [235][  300/  518]    Overall Loss 2.813147    Objective Loss 2.813147                                        LR 0.000004    Time 0.205369    
2023-04-17 15:39:04,654 - Epoch: [235][  350/  518]    Overall Loss 2.811754    Objective Loss 2.811754                                        LR 0.000004    Time 0.204695    
2023-04-17 15:39:14,835 - Epoch: [235][  400/  518]    Overall Loss 2.806950    Objective Loss 2.806950                                        LR 0.000004    Time 0.204556    
2023-04-17 15:39:24,971 - Epoch: [235][  450/  518]    Overall Loss 2.801777    Objective Loss 2.801777                                        LR 0.000004    Time 0.204349    
2023-04-17 15:39:35,059 - Epoch: [235][  500/  518]    Overall Loss 2.807750    Objective Loss 2.807750                                        LR 0.000004    Time 0.204088    
2023-04-17 15:39:38,598 - Epoch: [235][  518/  518]    Overall Loss 2.806781    Objective Loss 2.806781                                        LR 0.000004    Time 0.203827    
2023-04-17 15:39:38,677 - --- validate (epoch=235)-----------
2023-04-17 15:39:38,678 - 4952 samples (32 per mini-batch)
2023-04-17 15:40:22,678 - Epoch: [235][   50/  155]    Loss 3.074694    mAP 0.520972    
2023-04-17 15:41:08,956 - Epoch: [235][  100/  155]    Loss 3.082700    mAP 0.517061    
2023-04-17 15:41:53,634 - Epoch: [235][  150/  155]    Loss 3.074125    mAP 0.513892    
2023-04-17 15:41:58,324 - Epoch: [235][  155/  155]    Loss 3.070641    mAP 0.514293    
2023-04-17 15:41:58,407 - ==> mAP: 0.51429    Loss: 3.071

2023-04-17 15:41:58,411 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 15:41:58,411 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 15:41:58,448 - 

2023-04-17 15:41:58,448 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 15:42:09,436 - Epoch: [236][   50/  518]    Overall Loss 2.814439    Objective Loss 2.814439                                        LR 0.000004    Time 0.219707    
2023-04-17 15:42:19,555 - Epoch: [236][  100/  518]    Overall Loss 2.798891    Objective Loss 2.798891                                        LR 0.000004    Time 0.211026    
2023-04-17 15:42:29,686 - Epoch: [236][  150/  518]    Overall Loss 2.788793    Objective Loss 2.788793                                        LR 0.000004    Time 0.208219    
2023-04-17 15:42:39,821 - Epoch: [236][  200/  518]    Overall Loss 2.789419    Objective Loss 2.789419                                        LR 0.000004    Time 0.206830    
2023-04-17 15:42:49,934 - Epoch: [236][  250/  518]    Overall Loss 2.797491    Objective Loss 2.797491                                        LR 0.000004    Time 0.205908    
2023-04-17 15:43:00,051 - Epoch: [236][  300/  518]    Overall Loss 2.797325    Objective Loss 2.797325                                        LR 0.000004    Time 0.205308    
2023-04-17 15:43:10,075 - Epoch: [236][  350/  518]    Overall Loss 2.794159    Objective Loss 2.794159                                        LR 0.000004    Time 0.204615    
2023-04-17 15:43:20,152 - Epoch: [236][  400/  518]    Overall Loss 2.795206    Objective Loss 2.795206                                        LR 0.000004    Time 0.204226    
2023-04-17 15:43:30,300 - Epoch: [236][  450/  518]    Overall Loss 2.791218    Objective Loss 2.791218                                        LR 0.000004    Time 0.204083    
2023-04-17 15:43:40,375 - Epoch: [236][  500/  518]    Overall Loss 2.794819    Objective Loss 2.794819                                        LR 0.000004    Time 0.203822    
2023-04-17 15:43:43,892 - Epoch: [236][  518/  518]    Overall Loss 2.792944    Objective Loss 2.792944                                        LR 0.000004    Time 0.203527    
2023-04-17 15:43:43,973 - --- validate (epoch=236)-----------
2023-04-17 15:43:43,973 - 4952 samples (32 per mini-batch)
2023-04-17 15:44:29,397 - Epoch: [236][   50/  155]    Loss 3.073305    mAP 0.524218    
2023-04-17 15:45:14,694 - Epoch: [236][  100/  155]    Loss 3.073583    mAP 0.511675    
2023-04-17 15:46:00,277 - Epoch: [236][  150/  155]    Loss 3.076195    mAP 0.510286    
2023-04-17 15:46:04,046 - Epoch: [236][  155/  155]    Loss 3.070771    mAP 0.510857    
2023-04-17 15:46:04,126 - ==> mAP: 0.51086    Loss: 3.071

2023-04-17 15:46:04,130 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 15:46:04,131 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 15:46:04,167 - 

2023-04-17 15:46:04,167 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 15:46:14,994 - Epoch: [237][   50/  518]    Overall Loss 2.808377    Objective Loss 2.808377                                        LR 0.000004    Time 0.216471    
2023-04-17 15:46:25,012 - Epoch: [237][  100/  518]    Overall Loss 2.800508    Objective Loss 2.800508                                        LR 0.000004    Time 0.208401    
2023-04-17 15:46:35,148 - Epoch: [237][  150/  518]    Overall Loss 2.811879    Objective Loss 2.811879                                        LR 0.000004    Time 0.206500    
2023-04-17 15:46:45,274 - Epoch: [237][  200/  518]    Overall Loss 2.810800    Objective Loss 2.810800                                        LR 0.000004    Time 0.205494    
2023-04-17 15:46:55,419 - Epoch: [237][  250/  518]    Overall Loss 2.805932    Objective Loss 2.805932                                        LR 0.000004    Time 0.204971    
2023-04-17 15:47:05,526 - Epoch: [237][  300/  518]    Overall Loss 2.806862    Objective Loss 2.806862                                        LR 0.000004    Time 0.204493    
2023-04-17 15:47:15,603 - Epoch: [237][  350/  518]    Overall Loss 2.810792    Objective Loss 2.810792                                        LR 0.000004    Time 0.204068    
2023-04-17 15:47:25,723 - Epoch: [237][  400/  518]    Overall Loss 2.810391    Objective Loss 2.810391                                        LR 0.000004    Time 0.203855    
2023-04-17 15:47:35,764 - Epoch: [237][  450/  518]    Overall Loss 2.817034    Objective Loss 2.817034                                        LR 0.000004    Time 0.203515    
2023-04-17 15:47:45,877 - Epoch: [237][  500/  518]    Overall Loss 2.812416    Objective Loss 2.812416                                        LR 0.000004    Time 0.203386    
2023-04-17 15:47:49,392 - Epoch: [237][  518/  518]    Overall Loss 2.809776    Objective Loss 2.809776                                        LR 0.000004    Time 0.203104    
2023-04-17 15:47:49,477 - --- validate (epoch=237)-----------
2023-04-17 15:47:49,478 - 4952 samples (32 per mini-batch)
2023-04-17 15:48:33,639 - Epoch: [237][   50/  155]    Loss 3.040504    mAP 0.516933    
2023-04-17 15:49:17,315 - Epoch: [237][  100/  155]    Loss 3.056179    mAP 0.512646    
2023-04-17 15:50:02,245 - Epoch: [237][  150/  155]    Loss 3.067431    mAP 0.517170    
2023-04-17 15:50:06,190 - Epoch: [237][  155/  155]    Loss 3.072221    mAP 0.513913    
2023-04-17 15:50:06,267 - ==> mAP: 0.51391    Loss: 3.072

2023-04-17 15:50:06,271 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 15:50:06,271 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 15:50:06,309 - 

2023-04-17 15:50:06,309 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 15:50:17,054 - Epoch: [238][   50/  518]    Overall Loss 2.807058    Objective Loss 2.807058                                        LR 0.000004    Time 0.214837    
2023-04-17 15:50:27,187 - Epoch: [238][  100/  518]    Overall Loss 2.816208    Objective Loss 2.816208                                        LR 0.000004    Time 0.208739    
2023-04-17 15:50:37,257 - Epoch: [238][  150/  518]    Overall Loss 2.793051    Objective Loss 2.793051                                        LR 0.000004    Time 0.206277    
2023-04-17 15:50:47,360 - Epoch: [238][  200/  518]    Overall Loss 2.802974    Objective Loss 2.802974                                        LR 0.000004    Time 0.205217    
2023-04-17 15:50:57,453 - Epoch: [238][  250/  518]    Overall Loss 2.811174    Objective Loss 2.811174                                        LR 0.000004    Time 0.204539    
2023-04-17 15:51:07,512 - Epoch: [238][  300/  518]    Overall Loss 2.807429    Objective Loss 2.807429                                        LR 0.000004    Time 0.203975    
2023-04-17 15:51:17,573 - Epoch: [238][  350/  518]    Overall Loss 2.800892    Objective Loss 2.800892                                        LR 0.000004    Time 0.203577    
2023-04-17 15:51:27,637 - Epoch: [238][  400/  518]    Overall Loss 2.804733    Objective Loss 2.804733                                        LR 0.000004    Time 0.203286    
2023-04-17 15:51:37,719 - Epoch: [238][  450/  518]    Overall Loss 2.804523    Objective Loss 2.804523                                        LR 0.000004    Time 0.203100    
2023-04-17 15:51:47,984 - Epoch: [238][  500/  518]    Overall Loss 2.807706    Objective Loss 2.807706                                        LR 0.000004    Time 0.203316    
2023-04-17 15:51:51,542 - Epoch: [238][  518/  518]    Overall Loss 2.803919    Objective Loss 2.803919                                        LR 0.000004    Time 0.203119    
2023-04-17 15:51:51,621 - --- validate (epoch=238)-----------
2023-04-17 15:51:51,621 - 4952 samples (32 per mini-batch)
2023-04-17 15:52:37,263 - Epoch: [238][   50/  155]    Loss 3.088406    mAP 0.501351    
2023-04-17 15:53:21,029 - Epoch: [238][  100/  155]    Loss 3.072127    mAP 0.508455    
2023-04-17 15:54:06,545 - Epoch: [238][  150/  155]    Loss 3.072943    mAP 0.509046    
2023-04-17 15:54:10,638 - Epoch: [238][  155/  155]    Loss 3.071849    mAP 0.506737    
2023-04-17 15:54:10,716 - ==> mAP: 0.50674    Loss: 3.072

2023-04-17 15:54:10,720 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 15:54:10,720 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 15:54:10,758 - 

2023-04-17 15:54:10,759 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 15:54:21,538 - Epoch: [239][   50/  518]    Overall Loss 2.788853    Objective Loss 2.788853                                        LR 0.000004    Time 0.215531    
2023-04-17 15:54:31,661 - Epoch: [239][  100/  518]    Overall Loss 2.779515    Objective Loss 2.779515                                        LR 0.000004    Time 0.208982    
2023-04-17 15:54:41,783 - Epoch: [239][  150/  518]    Overall Loss 2.798471    Objective Loss 2.798471                                        LR 0.000004    Time 0.206789    
2023-04-17 15:54:51,909 - Epoch: [239][  200/  518]    Overall Loss 2.794252    Objective Loss 2.794252                                        LR 0.000004    Time 0.205712    
2023-04-17 15:55:01,990 - Epoch: [239][  250/  518]    Overall Loss 2.791575    Objective Loss 2.791575                                        LR 0.000004    Time 0.204890    
2023-04-17 15:55:12,051 - Epoch: [239][  300/  518]    Overall Loss 2.808831    Objective Loss 2.808831                                        LR 0.000004    Time 0.204274    
2023-04-17 15:55:22,113 - Epoch: [239][  350/  518]    Overall Loss 2.800126    Objective Loss 2.800126                                        LR 0.000004    Time 0.203835    
2023-04-17 15:55:32,314 - Epoch: [239][  400/  518]    Overall Loss 2.807228    Objective Loss 2.807228                                        LR 0.000004    Time 0.203854    
2023-04-17 15:55:42,322 - Epoch: [239][  450/  518]    Overall Loss 2.803125    Objective Loss 2.803125                                        LR 0.000004    Time 0.203440    
2023-04-17 15:55:52,434 - Epoch: [239][  500/  518]    Overall Loss 2.802243    Objective Loss 2.802243                                        LR 0.000004    Time 0.203317    
2023-04-17 15:55:55,930 - Epoch: [239][  518/  518]    Overall Loss 2.805374    Objective Loss 2.805374                                        LR 0.000004    Time 0.203000    
2023-04-17 15:55:56,010 - --- validate (epoch=239)-----------
2023-04-17 15:55:56,010 - 4952 samples (32 per mini-batch)
2023-04-17 15:56:41,820 - Epoch: [239][   50/  155]    Loss 3.068819    mAP 0.527290    
2023-04-17 15:57:24,601 - Epoch: [239][  100/  155]    Loss 3.055761    mAP 0.515149    
2023-04-17 15:58:07,744 - Epoch: [239][  150/  155]    Loss 3.071536    mAP 0.515325    
2023-04-17 15:58:11,479 - Epoch: [239][  155/  155]    Loss 3.069089    mAP 0.516272    
2023-04-17 15:58:11,556 - ==> mAP: 0.51627    Loss: 3.069

2023-04-17 15:58:11,559 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 15:58:11,559 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 15:58:11,596 - 

2023-04-17 15:58:11,596 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 15:58:22,441 - Epoch: [240][   50/  518]    Overall Loss 2.851095    Objective Loss 2.851095                                        LR 0.000004    Time 0.216859    
2023-04-17 15:58:32,503 - Epoch: [240][  100/  518]    Overall Loss 2.827185    Objective Loss 2.827185                                        LR 0.000004    Time 0.209031    
2023-04-17 15:58:42,570 - Epoch: [240][  150/  518]    Overall Loss 2.824440    Objective Loss 2.824440                                        LR 0.000004    Time 0.206456    
2023-04-17 15:58:52,687 - Epoch: [240][  200/  518]    Overall Loss 2.818358    Objective Loss 2.818358                                        LR 0.000004    Time 0.205419    
2023-04-17 15:59:02,744 - Epoch: [240][  250/  518]    Overall Loss 2.825800    Objective Loss 2.825800                                        LR 0.000004    Time 0.204559    
2023-04-17 15:59:12,779 - Epoch: [240][  300/  518]    Overall Loss 2.815080    Objective Loss 2.815080                                        LR 0.000004    Time 0.203910    
2023-04-17 15:59:22,863 - Epoch: [240][  350/  518]    Overall Loss 2.815533    Objective Loss 2.815533                                        LR 0.000004    Time 0.203586    
2023-04-17 15:59:33,010 - Epoch: [240][  400/  518]    Overall Loss 2.814277    Objective Loss 2.814277                                        LR 0.000004    Time 0.203502    
2023-04-17 15:59:43,112 - Epoch: [240][  450/  518]    Overall Loss 2.816454    Objective Loss 2.816454                                        LR 0.000004    Time 0.203335    
2023-04-17 15:59:53,227 - Epoch: [240][  500/  518]    Overall Loss 2.814540    Objective Loss 2.814540                                        LR 0.000004    Time 0.203229    
2023-04-17 15:59:56,715 - Epoch: [240][  518/  518]    Overall Loss 2.813775    Objective Loss 2.813775                                        LR 0.000004    Time 0.202899    
2023-04-17 15:59:56,795 - --- validate (epoch=240)-----------
2023-04-17 15:59:56,795 - 4952 samples (32 per mini-batch)
2023-04-17 16:00:42,556 - Epoch: [240][   50/  155]    Loss 3.061021    mAP 0.526928    
2023-04-17 16:01:28,298 - Epoch: [240][  100/  155]    Loss 3.068361    mAP 0.519144    
2023-04-17 16:02:14,425 - Epoch: [240][  150/  155]    Loss 3.067637    mAP 0.519207    
2023-04-17 16:02:19,068 - Epoch: [240][  155/  155]    Loss 3.070672    mAP 0.519030    
2023-04-17 16:02:19,146 - ==> mAP: 0.51903    Loss: 3.071

2023-04-17 16:02:19,150 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 16:02:19,150 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 16:02:19,186 - 

2023-04-17 16:02:19,186 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 16:02:30,124 - Epoch: [241][   50/  518]    Overall Loss 2.789912    Objective Loss 2.789912                                        LR 0.000004    Time 0.218695    
2023-04-17 16:02:40,303 - Epoch: [241][  100/  518]    Overall Loss 2.842085    Objective Loss 2.842085                                        LR 0.000004    Time 0.211121    
2023-04-17 16:02:50,300 - Epoch: [241][  150/  518]    Overall Loss 2.840349    Objective Loss 2.840349                                        LR 0.000004    Time 0.207388    
2023-04-17 16:03:00,438 - Epoch: [241][  200/  518]    Overall Loss 2.827531    Objective Loss 2.827531                                        LR 0.000004    Time 0.206220    
2023-04-17 16:03:10,554 - Epoch: [241][  250/  518]    Overall Loss 2.817601    Objective Loss 2.817601                                        LR 0.000004    Time 0.205437    
2023-04-17 16:03:20,606 - Epoch: [241][  300/  518]    Overall Loss 2.816375    Objective Loss 2.816375                                        LR 0.000004    Time 0.204697    
2023-04-17 16:03:30,732 - Epoch: [241][  350/  518]    Overall Loss 2.811311    Objective Loss 2.811311                                        LR 0.000004    Time 0.204382    
2023-04-17 16:03:40,941 - Epoch: [241][  400/  518]    Overall Loss 2.814478    Objective Loss 2.814478                                        LR 0.000004    Time 0.204352    
2023-04-17 16:03:51,086 - Epoch: [241][  450/  518]    Overall Loss 2.812268    Objective Loss 2.812268                                        LR 0.000004    Time 0.204188    
2023-04-17 16:04:01,305 - Epoch: [241][  500/  518]    Overall Loss 2.811002    Objective Loss 2.811002                                        LR 0.000004    Time 0.204204    
2023-04-17 16:04:04,832 - Epoch: [241][  518/  518]    Overall Loss 2.813808    Objective Loss 2.813808                                        LR 0.000004    Time 0.203916    
2023-04-17 16:04:04,912 - --- validate (epoch=241)-----------
2023-04-17 16:04:04,912 - 4952 samples (32 per mini-batch)
2023-04-17 16:04:49,323 - Epoch: [241][   50/  155]    Loss 3.040236    mAP 0.519930    
2023-04-17 16:05:36,064 - Epoch: [241][  100/  155]    Loss 3.054798    mAP 0.515771    
2023-04-17 16:06:20,344 - Epoch: [241][  150/  155]    Loss 3.069783    mAP 0.517370    
2023-04-17 16:06:24,102 - Epoch: [241][  155/  155]    Loss 3.063820    mAP 0.517080    
2023-04-17 16:06:24,180 - ==> mAP: 0.51708    Loss: 3.064

2023-04-17 16:06:24,184 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 16:06:24,184 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 16:06:24,220 - 

2023-04-17 16:06:24,220 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 16:06:35,161 - Epoch: [242][   50/  518]    Overall Loss 2.829824    Objective Loss 2.829824                                        LR 0.000004    Time 0.218765    
2023-04-17 16:06:45,267 - Epoch: [242][  100/  518]    Overall Loss 2.821107    Objective Loss 2.821107                                        LR 0.000004    Time 0.210423    
2023-04-17 16:06:55,325 - Epoch: [242][  150/  518]    Overall Loss 2.821054    Objective Loss 2.821054                                        LR 0.000004    Time 0.207327    
2023-04-17 16:07:05,494 - Epoch: [242][  200/  518]    Overall Loss 2.815487    Objective Loss 2.815487                                        LR 0.000004    Time 0.206330    
2023-04-17 16:07:15,579 - Epoch: [242][  250/  518]    Overall Loss 2.816062    Objective Loss 2.816062                                        LR 0.000004    Time 0.205400    
2023-04-17 16:07:25,642 - Epoch: [242][  300/  518]    Overall Loss 2.820452    Objective Loss 2.820452                                        LR 0.000004    Time 0.204704    
2023-04-17 16:07:35,760 - Epoch: [242][  350/  518]    Overall Loss 2.814470    Objective Loss 2.814470                                        LR 0.000004    Time 0.204366    
2023-04-17 16:07:45,925 - Epoch: [242][  400/  518]    Overall Loss 2.814102    Objective Loss 2.814102                                        LR 0.000004    Time 0.204228    
2023-04-17 16:07:55,979 - Epoch: [242][  450/  518]    Overall Loss 2.808002    Objective Loss 2.808002                                        LR 0.000004    Time 0.203874    
2023-04-17 16:08:06,062 - Epoch: [242][  500/  518]    Overall Loss 2.809248    Objective Loss 2.809248                                        LR 0.000004    Time 0.203651    
2023-04-17 16:08:09,548 - Epoch: [242][  518/  518]    Overall Loss 2.810944    Objective Loss 2.810944                                        LR 0.000004    Time 0.203304    
2023-04-17 16:08:09,628 - --- validate (epoch=242)-----------
2023-04-17 16:08:09,629 - 4952 samples (32 per mini-batch)
2023-04-17 16:08:54,067 - Epoch: [242][   50/  155]    Loss 3.081428    mAP 0.517101    
2023-04-17 16:09:37,825 - Epoch: [242][  100/  155]    Loss 3.075639    mAP 0.515953    
2023-04-17 16:10:22,564 - Epoch: [242][  150/  155]    Loss 3.068937    mAP 0.513554    
2023-04-17 16:10:26,880 - Epoch: [242][  155/  155]    Loss 3.067050    mAP 0.512618    
2023-04-17 16:10:26,960 - ==> mAP: 0.51262    Loss: 3.067

2023-04-17 16:10:26,965 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 16:10:26,965 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 16:10:27,001 - 

2023-04-17 16:10:27,001 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 16:10:37,969 - Epoch: [243][   50/  518]    Overall Loss 2.825955    Objective Loss 2.825955                                        LR 0.000004    Time 0.219293    
2023-04-17 16:10:48,083 - Epoch: [243][  100/  518]    Overall Loss 2.834757    Objective Loss 2.834757                                        LR 0.000004    Time 0.210770    
2023-04-17 16:10:58,153 - Epoch: [243][  150/  518]    Overall Loss 2.844860    Objective Loss 2.844860                                        LR 0.000004    Time 0.207640    
2023-04-17 16:11:08,249 - Epoch: [243][  200/  518]    Overall Loss 2.837565    Objective Loss 2.837565                                        LR 0.000004    Time 0.206200    
2023-04-17 16:11:18,407 - Epoch: [243][  250/  518]    Overall Loss 2.828856    Objective Loss 2.828856                                        LR 0.000004    Time 0.205586    
2023-04-17 16:11:28,602 - Epoch: [243][  300/  518]    Overall Loss 2.822783    Objective Loss 2.822783                                        LR 0.000004    Time 0.205299    
2023-04-17 16:11:38,672 - Epoch: [243][  350/  518]    Overall Loss 2.818281    Objective Loss 2.818281                                        LR 0.000004    Time 0.204739    
2023-04-17 16:11:48,808 - Epoch: [243][  400/  518]    Overall Loss 2.825017    Objective Loss 2.825017                                        LR 0.000004    Time 0.204482    
2023-04-17 16:11:58,880 - Epoch: [243][  450/  518]    Overall Loss 2.817456    Objective Loss 2.817456                                        LR 0.000004    Time 0.204142    
2023-04-17 16:12:09,012 - Epoch: [243][  500/  518]    Overall Loss 2.823095    Objective Loss 2.823095                                        LR 0.000004    Time 0.203989    
2023-04-17 16:12:12,523 - Epoch: [243][  518/  518]    Overall Loss 2.823187    Objective Loss 2.823187                                        LR 0.000004    Time 0.203676    
2023-04-17 16:12:12,603 - --- validate (epoch=243)-----------
2023-04-17 16:12:12,603 - 4952 samples (32 per mini-batch)
2023-04-17 16:12:56,438 - Epoch: [243][   50/  155]    Loss 3.077629    mAP 0.507209    
2023-04-17 16:13:40,742 - Epoch: [243][  100/  155]    Loss 3.064404    mAP 0.521634    
2023-04-17 16:14:27,050 - Epoch: [243][  150/  155]    Loss 3.069029    mAP 0.519614    
2023-04-17 16:14:31,358 - Epoch: [243][  155/  155]    Loss 3.071419    mAP 0.518525    
2023-04-17 16:14:31,436 - ==> mAP: 0.51853    Loss: 3.071

2023-04-17 16:14:31,439 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 16:14:31,440 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 16:14:31,477 - 

2023-04-17 16:14:31,477 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 16:14:42,375 - Epoch: [244][   50/  518]    Overall Loss 2.748097    Objective Loss 2.748097                                        LR 0.000004    Time 0.217893    
2023-04-17 16:14:52,445 - Epoch: [244][  100/  518]    Overall Loss 2.773661    Objective Loss 2.773661                                        LR 0.000004    Time 0.209630    
2023-04-17 16:15:02,578 - Epoch: [244][  150/  518]    Overall Loss 2.776391    Objective Loss 2.776391                                        LR 0.000004    Time 0.207298    
2023-04-17 16:15:12,697 - Epoch: [244][  200/  518]    Overall Loss 2.790279    Objective Loss 2.790279                                        LR 0.000004    Time 0.206061    
2023-04-17 16:15:22,750 - Epoch: [244][  250/  518]    Overall Loss 2.795681    Objective Loss 2.795681                                        LR 0.000004    Time 0.205055    
2023-04-17 16:15:32,841 - Epoch: [244][  300/  518]    Overall Loss 2.802986    Objective Loss 2.802986                                        LR 0.000004    Time 0.204511    
2023-04-17 16:15:42,942 - Epoch: [244][  350/  518]    Overall Loss 2.807192    Objective Loss 2.807192                                        LR 0.000004    Time 0.204151    
2023-04-17 16:15:53,061 - Epoch: [244][  400/  518]    Overall Loss 2.810195    Objective Loss 2.810195                                        LR 0.000004    Time 0.203925    
2023-04-17 16:16:03,180 - Epoch: [244][  450/  518]    Overall Loss 2.808938    Objective Loss 2.808938                                        LR 0.000004    Time 0.203751    
2023-04-17 16:16:13,407 - Epoch: [244][  500/  518]    Overall Loss 2.806145    Objective Loss 2.806145                                        LR 0.000004    Time 0.203826    
2023-04-17 16:16:16,928 - Epoch: [244][  518/  518]    Overall Loss 2.804874    Objective Loss 2.804874                                        LR 0.000004    Time 0.203540    
2023-04-17 16:16:17,009 - --- validate (epoch=244)-----------
2023-04-17 16:16:17,009 - 4952 samples (32 per mini-batch)
2023-04-17 16:17:02,808 - Epoch: [244][   50/  155]    Loss 3.095793    mAP 0.519778    
2023-04-17 16:17:47,877 - Epoch: [244][  100/  155]    Loss 3.073567    mAP 0.527991    
2023-04-17 16:18:32,998 - Epoch: [244][  150/  155]    Loss 3.065826    mAP 0.524835    
2023-04-17 16:18:36,897 - Epoch: [244][  155/  155]    Loss 3.065617    mAP 0.524345    
2023-04-17 16:18:36,971 - ==> mAP: 0.52434    Loss: 3.066

2023-04-17 16:18:36,975 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 16:18:36,975 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 16:18:37,011 - 

2023-04-17 16:18:37,011 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 16:18:47,820 - Epoch: [245][   50/  518]    Overall Loss 2.840027    Objective Loss 2.840027                                        LR 0.000004    Time 0.216116    
2023-04-17 16:18:57,924 - Epoch: [245][  100/  518]    Overall Loss 2.844137    Objective Loss 2.844137                                        LR 0.000004    Time 0.209085    
2023-04-17 16:19:08,104 - Epoch: [245][  150/  518]    Overall Loss 2.842396    Objective Loss 2.842396                                        LR 0.000004    Time 0.207245    
2023-04-17 16:19:18,251 - Epoch: [245][  200/  518]    Overall Loss 2.827007    Objective Loss 2.827007                                        LR 0.000004    Time 0.206164    
2023-04-17 16:19:28,332 - Epoch: [245][  250/  518]    Overall Loss 2.816786    Objective Loss 2.816786                                        LR 0.000004    Time 0.205246    
2023-04-17 16:19:38,436 - Epoch: [245][  300/  518]    Overall Loss 2.803589    Objective Loss 2.803589                                        LR 0.000004    Time 0.204715    
2023-04-17 16:19:48,533 - Epoch: [245][  350/  518]    Overall Loss 2.800415    Objective Loss 2.800415                                        LR 0.000004    Time 0.204312    
2023-04-17 16:19:58,584 - Epoch: [245][  400/  518]    Overall Loss 2.796929    Objective Loss 2.796929                                        LR 0.000004    Time 0.203898    
2023-04-17 16:20:08,718 - Epoch: [245][  450/  518]    Overall Loss 2.798296    Objective Loss 2.798296                                        LR 0.000004    Time 0.203759    
2023-04-17 16:20:18,787 - Epoch: [245][  500/  518]    Overall Loss 2.802713    Objective Loss 2.802713                                        LR 0.000004    Time 0.203518    
2023-04-17 16:20:22,292 - Epoch: [245][  518/  518]    Overall Loss 2.803639    Objective Loss 2.803639                                        LR 0.000004    Time 0.203212    
2023-04-17 16:20:22,374 - --- validate (epoch=245)-----------
2023-04-17 16:20:22,375 - 4952 samples (32 per mini-batch)
2023-04-17 16:21:08,152 - Epoch: [245][   50/  155]    Loss 3.058570    mAP 0.500673    
2023-04-17 16:21:51,202 - Epoch: [245][  100/  155]    Loss 3.057870    mAP 0.513861    
2023-04-17 16:22:35,194 - Epoch: [245][  150/  155]    Loss 3.065787    mAP 0.513293    
2023-04-17 16:22:39,699 - Epoch: [245][  155/  155]    Loss 3.069031    mAP 0.511884    
2023-04-17 16:22:39,779 - ==> mAP: 0.51188    Loss: 3.069

2023-04-17 16:22:39,783 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 16:22:39,783 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 16:22:39,819 - 

2023-04-17 16:22:39,819 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 16:22:50,652 - Epoch: [246][   50/  518]    Overall Loss 2.832870    Objective Loss 2.832870                                        LR 0.000004    Time 0.216590    
2023-04-17 16:23:00,776 - Epoch: [246][  100/  518]    Overall Loss 2.843831    Objective Loss 2.843831                                        LR 0.000004    Time 0.209519    
2023-04-17 16:23:10,901 - Epoch: [246][  150/  518]    Overall Loss 2.818363    Objective Loss 2.818363                                        LR 0.000004    Time 0.207171    
2023-04-17 16:23:21,003 - Epoch: [246][  200/  518]    Overall Loss 2.815776    Objective Loss 2.815776                                        LR 0.000004    Time 0.205883    
2023-04-17 16:23:31,047 - Epoch: [246][  250/  518]    Overall Loss 2.815472    Objective Loss 2.815472                                        LR 0.000004    Time 0.204874    
2023-04-17 16:23:41,114 - Epoch: [246][  300/  518]    Overall Loss 2.812044    Objective Loss 2.812044                                        LR 0.000004    Time 0.204280    
2023-04-17 16:23:51,234 - Epoch: [246][  350/  518]    Overall Loss 2.813757    Objective Loss 2.813757                                        LR 0.000004    Time 0.204008    
2023-04-17 16:24:01,432 - Epoch: [246][  400/  518]    Overall Loss 2.813865    Objective Loss 2.813865                                        LR 0.000004    Time 0.203997    
2023-04-17 16:24:11,508 - Epoch: [246][  450/  518]    Overall Loss 2.807597    Objective Loss 2.807597                                        LR 0.000004    Time 0.203718    
2023-04-17 16:24:21,629 - Epoch: [246][  500/  518]    Overall Loss 2.808995    Objective Loss 2.808995                                        LR 0.000004    Time 0.203585    
2023-04-17 16:24:25,140 - Epoch: [246][  518/  518]    Overall Loss 2.809562    Objective Loss 2.809562                                        LR 0.000004    Time 0.203288    
2023-04-17 16:24:25,220 - --- validate (epoch=246)-----------
2023-04-17 16:24:25,221 - 4952 samples (32 per mini-batch)
2023-04-17 16:25:10,955 - Epoch: [246][   50/  155]    Loss 3.068296    mAP 0.506965    
2023-04-17 16:25:55,574 - Epoch: [246][  100/  155]    Loss 3.060238    mAP 0.514444    
2023-04-17 16:26:41,138 - Epoch: [246][  150/  155]    Loss 3.069101    mAP 0.514969    
2023-04-17 16:26:45,312 - Epoch: [246][  155/  155]    Loss 3.069149    mAP 0.515326    
2023-04-17 16:26:45,386 - ==> mAP: 0.51533    Loss: 3.069

2023-04-17 16:26:45,390 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 16:26:45,390 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 16:26:45,427 - 

2023-04-17 16:26:45,427 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 16:26:56,289 - Epoch: [247][   50/  518]    Overall Loss 2.846140    Objective Loss 2.846140                                        LR 0.000004    Time 0.217172    
2023-04-17 16:27:06,357 - Epoch: [247][  100/  518]    Overall Loss 2.839415    Objective Loss 2.839415                                        LR 0.000004    Time 0.209250    
2023-04-17 16:27:16,407 - Epoch: [247][  150/  518]    Overall Loss 2.845674    Objective Loss 2.845674                                        LR 0.000004    Time 0.206493    
2023-04-17 16:27:26,439 - Epoch: [247][  200/  518]    Overall Loss 2.822181    Objective Loss 2.822181                                        LR 0.000004    Time 0.205021    
2023-04-17 16:27:36,580 - Epoch: [247][  250/  518]    Overall Loss 2.815200    Objective Loss 2.815200                                        LR 0.000004    Time 0.204576    
2023-04-17 16:27:46,611 - Epoch: [247][  300/  518]    Overall Loss 2.816528    Objective Loss 2.816528                                        LR 0.000004    Time 0.203911    
2023-04-17 16:27:56,683 - Epoch: [247][  350/  518]    Overall Loss 2.819238    Objective Loss 2.819238                                        LR 0.000004    Time 0.203554    
2023-04-17 16:28:06,769 - Epoch: [247][  400/  518]    Overall Loss 2.817111    Objective Loss 2.817111                                        LR 0.000004    Time 0.203321    
2023-04-17 16:28:16,865 - Epoch: [247][  450/  518]    Overall Loss 2.814390    Objective Loss 2.814390                                        LR 0.000004    Time 0.203160    
2023-04-17 16:28:26,962 - Epoch: [247][  500/  518]    Overall Loss 2.814381    Objective Loss 2.814381                                        LR 0.000004    Time 0.203036    
2023-04-17 16:28:30,531 - Epoch: [247][  518/  518]    Overall Loss 2.818353    Objective Loss 2.818353                                        LR 0.000004    Time 0.202870    
2023-04-17 16:28:30,611 - --- validate (epoch=247)-----------
2023-04-17 16:28:30,612 - 4952 samples (32 per mini-batch)
2023-04-17 16:29:18,038 - Epoch: [247][   50/  155]    Loss 3.116055    mAP 0.518536    
2023-04-17 16:30:03,173 - Epoch: [247][  100/  155]    Loss 3.077883    mAP 0.516772    
2023-04-17 16:30:47,637 - Epoch: [247][  150/  155]    Loss 3.065703    mAP 0.519112    
2023-04-17 16:30:52,049 - Epoch: [247][  155/  155]    Loss 3.072358    mAP 0.519132    
2023-04-17 16:30:52,123 - ==> mAP: 0.51913    Loss: 3.072

2023-04-17 16:30:52,127 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 16:30:52,127 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 16:30:52,163 - 

2023-04-17 16:30:52,164 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 16:31:02,939 - Epoch: [248][   50/  518]    Overall Loss 2.781133    Objective Loss 2.781133                                        LR 0.000004    Time 0.215463    
2023-04-17 16:31:13,057 - Epoch: [248][  100/  518]    Overall Loss 2.799700    Objective Loss 2.799700                                        LR 0.000004    Time 0.208892    
2023-04-17 16:31:23,224 - Epoch: [248][  150/  518]    Overall Loss 2.793975    Objective Loss 2.793975                                        LR 0.000004    Time 0.207027    
2023-04-17 16:31:33,309 - Epoch: [248][  200/  518]    Overall Loss 2.797318    Objective Loss 2.797318                                        LR 0.000004    Time 0.205690    
2023-04-17 16:31:43,360 - Epoch: [248][  250/  518]    Overall Loss 2.795593    Objective Loss 2.795593                                        LR 0.000004    Time 0.204750    
2023-04-17 16:31:53,365 - Epoch: [248][  300/  518]    Overall Loss 2.804935    Objective Loss 2.804935                                        LR 0.000004    Time 0.203971    
2023-04-17 16:32:03,403 - Epoch: [248][  350/  518]    Overall Loss 2.806639    Objective Loss 2.806639                                        LR 0.000004    Time 0.203507    
2023-04-17 16:32:13,437 - Epoch: [248][  400/  518]    Overall Loss 2.807937    Objective Loss 2.807937                                        LR 0.000004    Time 0.203148    
2023-04-17 16:32:23,525 - Epoch: [248][  450/  518]    Overall Loss 2.808482    Objective Loss 2.808482                                        LR 0.000004    Time 0.202991    
2023-04-17 16:32:33,671 - Epoch: [248][  500/  518]    Overall Loss 2.805465    Objective Loss 2.805465                                        LR 0.000004    Time 0.202982    
2023-04-17 16:32:37,207 - Epoch: [248][  518/  518]    Overall Loss 2.806155    Objective Loss 2.806155                                        LR 0.000004    Time 0.202754    
2023-04-17 16:32:37,288 - --- validate (epoch=248)-----------
2023-04-17 16:32:37,288 - 4952 samples (32 per mini-batch)
2023-04-17 16:33:25,347 - Epoch: [248][   50/  155]    Loss 3.054035    mAP 0.529855    
2023-04-17 16:34:10,414 - Epoch: [248][  100/  155]    Loss 3.049083    mAP 0.518919    
2023-04-17 16:34:54,796 - Epoch: [248][  150/  155]    Loss 3.062254    mAP 0.513634    
2023-04-17 16:34:59,196 - Epoch: [248][  155/  155]    Loss 3.066847    mAP 0.511968    
2023-04-17 16:34:59,273 - ==> mAP: 0.51197    Loss: 3.067

2023-04-17 16:34:59,278 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 16:34:59,278 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 16:34:59,314 - 

2023-04-17 16:34:59,314 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 16:35:10,341 - Epoch: [249][   50/  518]    Overall Loss 2.805221    Objective Loss 2.805221                                        LR 0.000004    Time 0.220476    
2023-04-17 16:35:20,476 - Epoch: [249][  100/  518]    Overall Loss 2.837987    Objective Loss 2.837987                                        LR 0.000004    Time 0.211578    
2023-04-17 16:35:30,583 - Epoch: [249][  150/  518]    Overall Loss 2.830880    Objective Loss 2.830880                                        LR 0.000004    Time 0.208419    
2023-04-17 16:35:40,728 - Epoch: [249][  200/  518]    Overall Loss 2.833706    Objective Loss 2.833706                                        LR 0.000004    Time 0.207030    
2023-04-17 16:35:50,891 - Epoch: [249][  250/  518]    Overall Loss 2.832823    Objective Loss 2.832823                                        LR 0.000004    Time 0.206270    
2023-04-17 16:36:00,970 - Epoch: [249][  300/  518]    Overall Loss 2.822012    Objective Loss 2.822012                                        LR 0.000004    Time 0.205485    
2023-04-17 16:36:11,063 - Epoch: [249][  350/  518]    Overall Loss 2.820769    Objective Loss 2.820769                                        LR 0.000004    Time 0.204962    
2023-04-17 16:36:21,140 - Epoch: [249][  400/  518]    Overall Loss 2.813521    Objective Loss 2.813521                                        LR 0.000004    Time 0.204530    
2023-04-17 16:36:31,211 - Epoch: [249][  450/  518]    Overall Loss 2.814048    Objective Loss 2.814048                                        LR 0.000004    Time 0.204183    
2023-04-17 16:36:41,285 - Epoch: [249][  500/  518]    Overall Loss 2.813632    Objective Loss 2.813632                                        LR 0.000004    Time 0.203908    
2023-04-17 16:36:44,798 - Epoch: [249][  518/  518]    Overall Loss 2.815801    Objective Loss 2.815801                                        LR 0.000004    Time 0.203603    
2023-04-17 16:36:44,877 - --- validate (epoch=249)-----------
2023-04-17 16:36:44,877 - 4952 samples (32 per mini-batch)
2023-04-17 16:37:28,265 - Epoch: [249][   50/  155]    Loss 3.052686    mAP 0.530833    
2023-04-17 16:38:12,452 - Epoch: [249][  100/  155]    Loss 3.062058    mAP 0.529117    
2023-04-17 16:38:56,386 - Epoch: [249][  150/  155]    Loss 3.072215    mAP 0.523716    
2023-04-17 16:39:00,431 - Epoch: [249][  155/  155]    Loss 3.070151    mAP 0.523962    
2023-04-17 16:39:00,510 - ==> mAP: 0.52396    Loss: 3.070

2023-04-17 16:39:00,515 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 16:39:00,515 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 16:39:00,551 - 

2023-04-17 16:39:00,551 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 16:39:11,389 - Epoch: [250][   50/  518]    Overall Loss 2.816472    Objective Loss 2.816472                                        LR 0.000001    Time 0.216694    
2023-04-17 16:39:21,539 - Epoch: [250][  100/  518]    Overall Loss 2.820296    Objective Loss 2.820296                                        LR 0.000001    Time 0.209838    
2023-04-17 16:39:31,613 - Epoch: [250][  150/  518]    Overall Loss 2.813031    Objective Loss 2.813031                                        LR 0.000001    Time 0.207038    
2023-04-17 16:39:41,723 - Epoch: [250][  200/  518]    Overall Loss 2.807398    Objective Loss 2.807398                                        LR 0.000001    Time 0.205822    
2023-04-17 16:39:51,828 - Epoch: [250][  250/  518]    Overall Loss 2.807930    Objective Loss 2.807930                                        LR 0.000001    Time 0.205074    
2023-04-17 16:40:01,891 - Epoch: [250][  300/  518]    Overall Loss 2.810595    Objective Loss 2.810595                                        LR 0.000001    Time 0.204430    
2023-04-17 16:40:12,028 - Epoch: [250][  350/  518]    Overall Loss 2.810132    Objective Loss 2.810132                                        LR 0.000001    Time 0.204185    
2023-04-17 16:40:22,164 - Epoch: [250][  400/  518]    Overall Loss 2.811912    Objective Loss 2.811912                                        LR 0.000001    Time 0.203999    
2023-04-17 16:40:32,228 - Epoch: [250][  450/  518]    Overall Loss 2.806695    Objective Loss 2.806695                                        LR 0.000001    Time 0.203693    
2023-04-17 16:40:42,336 - Epoch: [250][  500/  518]    Overall Loss 2.810720    Objective Loss 2.810720                                        LR 0.000001    Time 0.203537    
2023-04-17 16:40:45,919 - Epoch: [250][  518/  518]    Overall Loss 2.810668    Objective Loss 2.810668                                        LR 0.000001    Time 0.203380    
2023-04-17 16:40:45,999 - --- validate (epoch=250)-----------
2023-04-17 16:40:45,999 - 4952 samples (32 per mini-batch)
2023-04-17 16:41:31,191 - Epoch: [250][   50/  155]    Loss 3.087382    mAP 0.521695    
2023-04-17 16:42:15,779 - Epoch: [250][  100/  155]    Loss 3.078626    mAP 0.517036    
2023-04-17 16:42:59,592 - Epoch: [250][  150/  155]    Loss 3.072202    mAP 0.517924    
2023-04-17 16:43:04,075 - Epoch: [250][  155/  155]    Loss 3.073618    mAP 0.517224    
2023-04-17 16:43:04,151 - ==> mAP: 0.51722    Loss: 3.074

2023-04-17 16:43:04,155 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 16:43:04,155 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 16:43:04,191 - 

2023-04-17 16:43:04,191 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 16:43:15,088 - Epoch: [251][   50/  518]    Overall Loss 2.850572    Objective Loss 2.850572                                        LR 0.000001    Time 0.217882    
2023-04-17 16:43:25,224 - Epoch: [251][  100/  518]    Overall Loss 2.851084    Objective Loss 2.851084                                        LR 0.000001    Time 0.210283    
2023-04-17 16:43:35,335 - Epoch: [251][  150/  518]    Overall Loss 2.831970    Objective Loss 2.831970                                        LR 0.000001    Time 0.207583    
2023-04-17 16:43:45,412 - Epoch: [251][  200/  518]    Overall Loss 2.821854    Objective Loss 2.821854                                        LR 0.000001    Time 0.206067    
2023-04-17 16:43:55,548 - Epoch: [251][  250/  518]    Overall Loss 2.823163    Objective Loss 2.823163                                        LR 0.000001    Time 0.205391    
2023-04-17 16:44:05,643 - Epoch: [251][  300/  518]    Overall Loss 2.812959    Objective Loss 2.812959                                        LR 0.000001    Time 0.204803    
2023-04-17 16:44:15,762 - Epoch: [251][  350/  518]    Overall Loss 2.803468    Objective Loss 2.803468                                        LR 0.000001    Time 0.204454    
2023-04-17 16:44:25,941 - Epoch: [251][  400/  518]    Overall Loss 2.802081    Objective Loss 2.802081                                        LR 0.000001    Time 0.204339    
2023-04-17 16:44:36,047 - Epoch: [251][  450/  518]    Overall Loss 2.806135    Objective Loss 2.806135                                        LR 0.000001    Time 0.204090    
2023-04-17 16:44:46,135 - Epoch: [251][  500/  518]    Overall Loss 2.801408    Objective Loss 2.801408                                        LR 0.000001    Time 0.203854    
2023-04-17 16:44:49,655 - Epoch: [251][  518/  518]    Overall Loss 2.802255    Objective Loss 2.802255                                        LR 0.000001    Time 0.203565    
2023-04-17 16:44:49,735 - --- validate (epoch=251)-----------
2023-04-17 16:44:49,735 - 4952 samples (32 per mini-batch)
2023-04-17 16:45:33,732 - Epoch: [251][   50/  155]    Loss 3.038845    mAP 0.531195    
2023-04-17 16:46:18,697 - Epoch: [251][  100/  155]    Loss 3.061362    mAP 0.517761    
2023-04-17 16:47:03,103 - Epoch: [251][  150/  155]    Loss 3.075497    mAP 0.515427    
2023-04-17 16:47:06,893 - Epoch: [251][  155/  155]    Loss 3.070662    mAP 0.514421    
2023-04-17 16:47:06,972 - ==> mAP: 0.51442    Loss: 3.071

2023-04-17 16:47:06,975 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 16:47:06,975 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 16:47:07,011 - 

2023-04-17 16:47:07,012 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 16:47:17,862 - Epoch: [252][   50/  518]    Overall Loss 2.795665    Objective Loss 2.795665                                        LR 0.000001    Time 0.216947    
2023-04-17 16:47:27,949 - Epoch: [252][  100/  518]    Overall Loss 2.811738    Objective Loss 2.811738                                        LR 0.000001    Time 0.209336    
2023-04-17 16:47:37,983 - Epoch: [252][  150/  518]    Overall Loss 2.807823    Objective Loss 2.807823                                        LR 0.000001    Time 0.206438    
2023-04-17 16:47:48,072 - Epoch: [252][  200/  518]    Overall Loss 2.796132    Objective Loss 2.796132                                        LR 0.000001    Time 0.205265    
2023-04-17 16:47:58,188 - Epoch: [252][  250/  518]    Overall Loss 2.797731    Objective Loss 2.797731                                        LR 0.000001    Time 0.204668    
2023-04-17 16:48:08,302 - Epoch: [252][  300/  518]    Overall Loss 2.793643    Objective Loss 2.793643                                        LR 0.000001    Time 0.204266    
2023-04-17 16:48:18,362 - Epoch: [252][  350/  518]    Overall Loss 2.804113    Objective Loss 2.804113                                        LR 0.000001    Time 0.203825    
2023-04-17 16:48:28,429 - Epoch: [252][  400/  518]    Overall Loss 2.804478    Objective Loss 2.804478                                        LR 0.000001    Time 0.203509    
2023-04-17 16:48:38,496 - Epoch: [252][  450/  518]    Overall Loss 2.803227    Objective Loss 2.803227                                        LR 0.000001    Time 0.203264    
2023-04-17 16:48:48,641 - Epoch: [252][  500/  518]    Overall Loss 2.804169    Objective Loss 2.804169                                        LR 0.000001    Time 0.203225    
2023-04-17 16:48:52,158 - Epoch: [252][  518/  518]    Overall Loss 2.802665    Objective Loss 2.802665                                        LR 0.000001    Time 0.202952    
2023-04-17 16:48:52,238 - --- validate (epoch=252)-----------
2023-04-17 16:48:52,238 - 4952 samples (32 per mini-batch)
2023-04-17 16:49:36,657 - Epoch: [252][   50/  155]    Loss 3.087189    mAP 0.513133    
2023-04-17 16:50:22,788 - Epoch: [252][  100/  155]    Loss 3.076731    mAP 0.508673    
2023-04-17 16:51:08,276 - Epoch: [252][  150/  155]    Loss 3.072492    mAP 0.514915    
2023-04-17 16:51:12,194 - Epoch: [252][  155/  155]    Loss 3.068192    mAP 0.516304    
2023-04-17 16:51:12,270 - ==> mAP: 0.51630    Loss: 3.068

2023-04-17 16:51:12,274 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 16:51:12,274 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 16:51:12,310 - 

2023-04-17 16:51:12,310 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 16:51:23,151 - Epoch: [253][   50/  518]    Overall Loss 2.815645    Objective Loss 2.815645                                        LR 0.000001    Time 0.216775    
2023-04-17 16:51:33,211 - Epoch: [253][  100/  518]    Overall Loss 2.810742    Objective Loss 2.810742                                        LR 0.000001    Time 0.208966    
2023-04-17 16:51:43,265 - Epoch: [253][  150/  518]    Overall Loss 2.821499    Objective Loss 2.821499                                        LR 0.000001    Time 0.206329    
2023-04-17 16:51:53,328 - Epoch: [253][  200/  518]    Overall Loss 2.805740    Objective Loss 2.805740                                        LR 0.000001    Time 0.205051    
2023-04-17 16:52:03,480 - Epoch: [253][  250/  518]    Overall Loss 2.811875    Objective Loss 2.811875                                        LR 0.000001    Time 0.204644    
2023-04-17 16:52:13,476 - Epoch: [253][  300/  518]    Overall Loss 2.816288    Objective Loss 2.816288                                        LR 0.000001    Time 0.203853    
2023-04-17 16:52:23,535 - Epoch: [253][  350/  518]    Overall Loss 2.809289    Objective Loss 2.809289                                        LR 0.000001    Time 0.203465    
2023-04-17 16:52:33,717 - Epoch: [253][  400/  518]    Overall Loss 2.814502    Objective Loss 2.814502                                        LR 0.000001    Time 0.203483    
2023-04-17 16:52:43,703 - Epoch: [253][  450/  518]    Overall Loss 2.818794    Objective Loss 2.818794                                        LR 0.000001    Time 0.203061    
2023-04-17 16:52:53,885 - Epoch: [253][  500/  518]    Overall Loss 2.813633    Objective Loss 2.813633                                        LR 0.000001    Time 0.203116    
2023-04-17 16:52:57,375 - Epoch: [253][  518/  518]    Overall Loss 2.814642    Objective Loss 2.814642                                        LR 0.000001    Time 0.202796    
2023-04-17 16:52:57,453 - --- validate (epoch=253)-----------
2023-04-17 16:52:57,453 - 4952 samples (32 per mini-batch)
2023-04-17 16:53:41,744 - Epoch: [253][   50/  155]    Loss 3.084806    mAP 0.530991    
2023-04-17 16:54:27,418 - Epoch: [253][  100/  155]    Loss 3.074232    mAP 0.531056    
2023-04-17 16:55:10,520 - Epoch: [253][  150/  155]    Loss 3.067593    mAP 0.520559    
2023-04-17 16:55:14,218 - Epoch: [253][  155/  155]    Loss 3.065956    mAP 0.521474    
2023-04-17 16:55:14,291 - ==> mAP: 0.52147    Loss: 3.066

2023-04-17 16:55:14,295 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 16:55:14,295 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 16:55:14,331 - 

2023-04-17 16:55:14,331 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 16:55:25,211 - Epoch: [254][   50/  518]    Overall Loss 2.779990    Objective Loss 2.779990                                        LR 0.000001    Time 0.217534    
2023-04-17 16:55:35,295 - Epoch: [254][  100/  518]    Overall Loss 2.795952    Objective Loss 2.795952                                        LR 0.000001    Time 0.209593    
2023-04-17 16:55:45,359 - Epoch: [254][  150/  518]    Overall Loss 2.780336    Objective Loss 2.780336                                        LR 0.000001    Time 0.206810    
2023-04-17 16:55:55,485 - Epoch: [254][  200/  518]    Overall Loss 2.781709    Objective Loss 2.781709                                        LR 0.000001    Time 0.205729    
2023-04-17 16:56:05,582 - Epoch: [254][  250/  518]    Overall Loss 2.795559    Objective Loss 2.795559                                        LR 0.000001    Time 0.204966    
2023-04-17 16:56:15,725 - Epoch: [254][  300/  518]    Overall Loss 2.795542    Objective Loss 2.795542                                        LR 0.000001    Time 0.204611    
2023-04-17 16:56:25,879 - Epoch: [254][  350/  518]    Overall Loss 2.803065    Objective Loss 2.803065                                        LR 0.000001    Time 0.204387    
2023-04-17 16:56:36,023 - Epoch: [254][  400/  518]    Overall Loss 2.802760    Objective Loss 2.802760                                        LR 0.000001    Time 0.204194    
2023-04-17 16:56:46,055 - Epoch: [254][  450/  518]    Overall Loss 2.798301    Objective Loss 2.798301                                        LR 0.000001    Time 0.203797    
2023-04-17 16:56:56,127 - Epoch: [254][  500/  518]    Overall Loss 2.794401    Objective Loss 2.794401                                        LR 0.000001    Time 0.203558    
2023-04-17 16:56:59,659 - Epoch: [254][  518/  518]    Overall Loss 2.792156    Objective Loss 2.792156                                        LR 0.000001    Time 0.203301    
2023-04-17 16:56:59,738 - --- validate (epoch=254)-----------
2023-04-17 16:56:59,738 - 4952 samples (32 per mini-batch)
2023-04-17 16:57:45,534 - Epoch: [254][   50/  155]    Loss 3.070940    mAP 0.526032    
2023-04-17 16:58:30,470 - Epoch: [254][  100/  155]    Loss 3.091199    mAP 0.526322    
2023-04-17 16:59:14,915 - Epoch: [254][  150/  155]    Loss 3.072942    mAP 0.521817    
2023-04-17 16:59:19,072 - Epoch: [254][  155/  155]    Loss 3.071122    mAP 0.521556    
2023-04-17 16:59:19,152 - ==> mAP: 0.52156    Loss: 3.071

2023-04-17 16:59:19,155 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 16:59:19,155 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 16:59:19,191 - 

2023-04-17 16:59:19,191 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 16:59:30,208 - Epoch: [255][   50/  518]    Overall Loss 2.806516    Objective Loss 2.806516                                        LR 0.000001    Time 0.220272    
2023-04-17 16:59:40,327 - Epoch: [255][  100/  518]    Overall Loss 2.825956    Objective Loss 2.825956                                        LR 0.000001    Time 0.211313    
2023-04-17 16:59:50,394 - Epoch: [255][  150/  518]    Overall Loss 2.824420    Objective Loss 2.824420                                        LR 0.000001    Time 0.207976    
2023-04-17 17:00:00,454 - Epoch: [255][  200/  518]    Overall Loss 2.817837    Objective Loss 2.817837                                        LR 0.000001    Time 0.206273    
2023-04-17 17:00:10,578 - Epoch: [255][  250/  518]    Overall Loss 2.817389    Objective Loss 2.817389                                        LR 0.000001    Time 0.205511    
2023-04-17 17:00:20,688 - Epoch: [255][  300/  518]    Overall Loss 2.814998    Objective Loss 2.814998                                        LR 0.000001    Time 0.204953    
2023-04-17 17:00:30,811 - Epoch: [255][  350/  518]    Overall Loss 2.828380    Objective Loss 2.828380                                        LR 0.000001    Time 0.204593    
2023-04-17 17:00:40,931 - Epoch: [255][  400/  518]    Overall Loss 2.825277    Objective Loss 2.825277                                        LR 0.000001    Time 0.204314    
2023-04-17 17:00:51,028 - Epoch: [255][  450/  518]    Overall Loss 2.823157    Objective Loss 2.823157                                        LR 0.000001    Time 0.204047    
2023-04-17 17:01:01,125 - Epoch: [255][  500/  518]    Overall Loss 2.817467    Objective Loss 2.817467                                        LR 0.000001    Time 0.203834    
2023-04-17 17:01:04,663 - Epoch: [255][  518/  518]    Overall Loss 2.816096    Objective Loss 2.816096                                        LR 0.000001    Time 0.203581    
2023-04-17 17:01:04,742 - --- validate (epoch=255)-----------
2023-04-17 17:01:04,742 - 4952 samples (32 per mini-batch)
2023-04-17 17:01:51,899 - Epoch: [255][   50/  155]    Loss 3.024586    mAP 0.523976    
2023-04-17 17:02:38,622 - Epoch: [255][  100/  155]    Loss 3.068467    mAP 0.524473    
2023-04-17 17:03:24,239 - Epoch: [255][  150/  155]    Loss 3.069697    mAP 0.519770    
2023-04-17 17:03:28,919 - Epoch: [255][  155/  155]    Loss 3.071038    mAP 0.519281    
2023-04-17 17:03:28,997 - ==> mAP: 0.51928    Loss: 3.071

2023-04-17 17:03:29,001 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 17:03:29,001 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 17:03:29,037 - 

2023-04-17 17:03:29,037 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 17:03:39,938 - Epoch: [256][   50/  518]    Overall Loss 2.830353    Objective Loss 2.830353                                        LR 0.000001    Time 0.217967    
2023-04-17 17:03:50,041 - Epoch: [256][  100/  518]    Overall Loss 2.850157    Objective Loss 2.850157                                        LR 0.000001    Time 0.209998    
2023-04-17 17:04:00,019 - Epoch: [256][  150/  518]    Overall Loss 2.824066    Objective Loss 2.824066                                        LR 0.000001    Time 0.206504    
2023-04-17 17:04:10,093 - Epoch: [256][  200/  518]    Overall Loss 2.817038    Objective Loss 2.817038                                        LR 0.000001    Time 0.205243    
2023-04-17 17:04:20,224 - Epoch: [256][  250/  518]    Overall Loss 2.816608    Objective Loss 2.816608                                        LR 0.000001    Time 0.204711    
2023-04-17 17:04:30,304 - Epoch: [256][  300/  518]    Overall Loss 2.803173    Objective Loss 2.803173                                        LR 0.000001    Time 0.204189    
2023-04-17 17:04:40,332 - Epoch: [256][  350/  518]    Overall Loss 2.798341    Objective Loss 2.798341                                        LR 0.000001    Time 0.203665    
2023-04-17 17:04:50,436 - Epoch: [256][  400/  518]    Overall Loss 2.801022    Objective Loss 2.801022                                        LR 0.000001    Time 0.203464    
2023-04-17 17:05:00,454 - Epoch: [256][  450/  518]    Overall Loss 2.803772    Objective Loss 2.803772                                        LR 0.000001    Time 0.203115    
2023-04-17 17:05:10,591 - Epoch: [256][  500/  518]    Overall Loss 2.805186    Objective Loss 2.805186                                        LR 0.000001    Time 0.203073    
2023-04-17 17:05:14,080 - Epoch: [256][  518/  518]    Overall Loss 2.805700    Objective Loss 2.805700                                        LR 0.000001    Time 0.202753    
2023-04-17 17:05:14,163 - --- validate (epoch=256)-----------
2023-04-17 17:05:14,164 - 4952 samples (32 per mini-batch)
2023-04-17 17:05:58,825 - Epoch: [256][   50/  155]    Loss 3.020363    mAP 0.525369    
2023-04-17 17:06:43,784 - Epoch: [256][  100/  155]    Loss 3.060818    mAP 0.514964    
2023-04-17 17:07:28,486 - Epoch: [256][  150/  155]    Loss 3.064609    mAP 0.522085    
2023-04-17 17:07:32,698 - Epoch: [256][  155/  155]    Loss 3.064727    mAP 0.523425    
2023-04-17 17:07:32,779 - ==> mAP: 0.52343    Loss: 3.065

2023-04-17 17:07:32,783 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 17:07:32,783 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 17:07:32,818 - 

2023-04-17 17:07:32,818 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 17:07:43,587 - Epoch: [257][   50/  518]    Overall Loss 2.797068    Objective Loss 2.797068                                        LR 0.000001    Time 0.215316    
2023-04-17 17:07:53,679 - Epoch: [257][  100/  518]    Overall Loss 2.779867    Objective Loss 2.779867                                        LR 0.000001    Time 0.208563    
2023-04-17 17:08:03,770 - Epoch: [257][  150/  518]    Overall Loss 2.796161    Objective Loss 2.796161                                        LR 0.000001    Time 0.206307    
2023-04-17 17:08:13,895 - Epoch: [257][  200/  518]    Overall Loss 2.787397    Objective Loss 2.787397                                        LR 0.000001    Time 0.205348    
2023-04-17 17:08:24,022 - Epoch: [257][  250/  518]    Overall Loss 2.797478    Objective Loss 2.797478                                        LR 0.000001    Time 0.204780    
2023-04-17 17:08:34,118 - Epoch: [257][  300/  518]    Overall Loss 2.803988    Objective Loss 2.803988                                        LR 0.000001    Time 0.204297    
2023-04-17 17:08:44,194 - Epoch: [257][  350/  518]    Overall Loss 2.799036    Objective Loss 2.799036                                        LR 0.000001    Time 0.203897    
2023-04-17 17:08:54,304 - Epoch: [257][  400/  518]    Overall Loss 2.802358    Objective Loss 2.802358                                        LR 0.000001    Time 0.203682    
2023-04-17 17:09:04,374 - Epoch: [257][  450/  518]    Overall Loss 2.800177    Objective Loss 2.800177                                        LR 0.000001    Time 0.203424    
2023-04-17 17:09:14,498 - Epoch: [257][  500/  518]    Overall Loss 2.801689    Objective Loss 2.801689                                        LR 0.000001    Time 0.203326    
2023-04-17 17:09:18,027 - Epoch: [257][  518/  518]    Overall Loss 2.798532    Objective Loss 2.798532                                        LR 0.000001    Time 0.203072    
2023-04-17 17:09:18,109 - --- validate (epoch=257)-----------
2023-04-17 17:09:18,109 - 4952 samples (32 per mini-batch)
2023-04-17 17:10:03,484 - Epoch: [257][   50/  155]    Loss 3.100911    mAP 0.516774    
2023-04-17 17:10:50,216 - Epoch: [257][  100/  155]    Loss 3.082435    mAP 0.509842    
2023-04-17 17:11:34,467 - Epoch: [257][  150/  155]    Loss 3.061357    mAP 0.514697    
2023-04-17 17:11:38,890 - Epoch: [257][  155/  155]    Loss 3.063441    mAP 0.514522    
2023-04-17 17:11:38,966 - ==> mAP: 0.51452    Loss: 3.063

2023-04-17 17:11:38,970 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 17:11:38,970 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 17:11:39,007 - 

2023-04-17 17:11:39,007 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 17:11:49,907 - Epoch: [258][   50/  518]    Overall Loss 2.805510    Objective Loss 2.805510                                        LR 0.000001    Time 0.217951    
2023-04-17 17:11:59,950 - Epoch: [258][  100/  518]    Overall Loss 2.773059    Objective Loss 2.773059                                        LR 0.000001    Time 0.209385    
2023-04-17 17:12:10,095 - Epoch: [258][  150/  518]    Overall Loss 2.790310    Objective Loss 2.790310                                        LR 0.000001    Time 0.207214    
2023-04-17 17:12:20,168 - Epoch: [258][  200/  518]    Overall Loss 2.797323    Objective Loss 2.797323                                        LR 0.000001    Time 0.205769    
2023-04-17 17:12:30,349 - Epoch: [258][  250/  518]    Overall Loss 2.806717    Objective Loss 2.806717                                        LR 0.000001    Time 0.205333    
2023-04-17 17:12:40,520 - Epoch: [258][  300/  518]    Overall Loss 2.807634    Objective Loss 2.807634                                        LR 0.000001    Time 0.205010    
2023-04-17 17:12:50,651 - Epoch: [258][  350/  518]    Overall Loss 2.804457    Objective Loss 2.804457                                        LR 0.000001    Time 0.204662    
2023-04-17 17:13:00,777 - Epoch: [258][  400/  518]    Overall Loss 2.801986    Objective Loss 2.801986                                        LR 0.000001    Time 0.204391    
2023-04-17 17:13:10,906 - Epoch: [258][  450/  518]    Overall Loss 2.801285    Objective Loss 2.801285                                        LR 0.000001    Time 0.204186    
2023-04-17 17:13:20,979 - Epoch: [258][  500/  518]    Overall Loss 2.805351    Objective Loss 2.805351                                        LR 0.000001    Time 0.203911    
2023-04-17 17:13:24,492 - Epoch: [258][  518/  518]    Overall Loss 2.807860    Objective Loss 2.807860                                        LR 0.000001    Time 0.203606    
2023-04-17 17:13:24,572 - --- validate (epoch=258)-----------
2023-04-17 17:13:24,572 - 4952 samples (32 per mini-batch)
2023-04-17 17:14:09,628 - Epoch: [258][   50/  155]    Loss 3.039680    mAP 0.532647    
2023-04-17 17:14:53,079 - Epoch: [258][  100/  155]    Loss 3.052510    mAP 0.521347    
2023-04-17 17:15:38,934 - Epoch: [258][  150/  155]    Loss 3.062764    mAP 0.521272    
2023-04-17 17:15:43,239 - Epoch: [258][  155/  155]    Loss 3.059151    mAP 0.521329    
2023-04-17 17:15:43,317 - ==> mAP: 0.52133    Loss: 3.059

2023-04-17 17:15:43,321 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 17:15:43,321 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 17:15:43,357 - 

2023-04-17 17:15:43,357 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 17:15:54,273 - Epoch: [259][   50/  518]    Overall Loss 2.779246    Objective Loss 2.779246                                        LR 0.000001    Time 0.218252    
2023-04-17 17:16:04,345 - Epoch: [259][  100/  518]    Overall Loss 2.803944    Objective Loss 2.803944                                        LR 0.000001    Time 0.209838    
2023-04-17 17:16:14,433 - Epoch: [259][  150/  518]    Overall Loss 2.811638    Objective Loss 2.811638                                        LR 0.000001    Time 0.207134    
2023-04-17 17:16:24,541 - Epoch: [259][  200/  518]    Overall Loss 2.809656    Objective Loss 2.809656                                        LR 0.000001    Time 0.205879    
2023-04-17 17:16:34,632 - Epoch: [259][  250/  518]    Overall Loss 2.807109    Objective Loss 2.807109                                        LR 0.000001    Time 0.205064    
2023-04-17 17:16:44,698 - Epoch: [259][  300/  518]    Overall Loss 2.805309    Objective Loss 2.805309                                        LR 0.000001    Time 0.204433    
2023-04-17 17:16:54,738 - Epoch: [259][  350/  518]    Overall Loss 2.799823    Objective Loss 2.799823                                        LR 0.000001    Time 0.203911    
2023-04-17 17:17:04,804 - Epoch: [259][  400/  518]    Overall Loss 2.802995    Objective Loss 2.802995                                        LR 0.000001    Time 0.203582    
2023-04-17 17:17:14,845 - Epoch: [259][  450/  518]    Overall Loss 2.799993    Objective Loss 2.799993                                        LR 0.000001    Time 0.203272    
2023-04-17 17:17:24,912 - Epoch: [259][  500/  518]    Overall Loss 2.796002    Objective Loss 2.796002                                        LR 0.000001    Time 0.203076    
2023-04-17 17:17:28,422 - Epoch: [259][  518/  518]    Overall Loss 2.797321    Objective Loss 2.797321                                        LR 0.000001    Time 0.202794    
2023-04-17 17:17:28,499 - --- validate (epoch=259)-----------
2023-04-17 17:17:28,500 - 4952 samples (32 per mini-batch)
2023-04-17 17:18:14,526 - Epoch: [259][   50/  155]    Loss 3.052755    mAP 0.528894    
2023-04-17 17:18:59,568 - Epoch: [259][  100/  155]    Loss 3.058899    mAP 0.524324    
2023-04-17 17:19:44,023 - Epoch: [259][  150/  155]    Loss 3.065717    mAP 0.519266    
2023-04-17 17:19:47,996 - Epoch: [259][  155/  155]    Loss 3.067052    mAP 0.516368    
2023-04-17 17:19:48,070 - ==> mAP: 0.51637    Loss: 3.067

2023-04-17 17:19:48,074 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 17:19:48,074 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 17:19:48,111 - 

2023-04-17 17:19:48,111 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 17:19:58,951 - Epoch: [260][   50/  518]    Overall Loss 2.837746    Objective Loss 2.837746                                        LR 0.000001    Time 0.216757    
2023-04-17 17:20:09,007 - Epoch: [260][  100/  518]    Overall Loss 2.832801    Objective Loss 2.832801                                        LR 0.000001    Time 0.208924    
2023-04-17 17:20:19,097 - Epoch: [260][  150/  518]    Overall Loss 2.824781    Objective Loss 2.824781                                        LR 0.000001    Time 0.206539    
2023-04-17 17:20:29,143 - Epoch: [260][  200/  518]    Overall Loss 2.830762    Objective Loss 2.830762                                        LR 0.000001    Time 0.205125    
2023-04-17 17:20:39,239 - Epoch: [260][  250/  518]    Overall Loss 2.824570    Objective Loss 2.824570                                        LR 0.000001    Time 0.204478    
2023-04-17 17:20:49,310 - Epoch: [260][  300/  518]    Overall Loss 2.812666    Objective Loss 2.812666                                        LR 0.000001    Time 0.203961    
2023-04-17 17:20:59,436 - Epoch: [260][  350/  518]    Overall Loss 2.809070    Objective Loss 2.809070                                        LR 0.000001    Time 0.203752    
2023-04-17 17:21:09,565 - Epoch: [260][  400/  518]    Overall Loss 2.805074    Objective Loss 2.805074                                        LR 0.000001    Time 0.203602    
2023-04-17 17:21:19,808 - Epoch: [260][  450/  518]    Overall Loss 2.805588    Objective Loss 2.805588                                        LR 0.000001    Time 0.203738    
2023-04-17 17:21:29,846 - Epoch: [260][  500/  518]    Overall Loss 2.806906    Objective Loss 2.806906                                        LR 0.000001    Time 0.203438    
2023-04-17 17:21:33,367 - Epoch: [260][  518/  518]    Overall Loss 2.804822    Objective Loss 2.804822                                        LR 0.000001    Time 0.203164    
2023-04-17 17:21:33,446 - --- validate (epoch=260)-----------
2023-04-17 17:21:33,447 - 4952 samples (32 per mini-batch)
2023-04-17 17:22:19,108 - Epoch: [260][   50/  155]    Loss 3.103532    mAP 0.520214    
2023-04-17 17:23:03,157 - Epoch: [260][  100/  155]    Loss 3.078467    mAP 0.524556    
2023-04-17 17:23:49,039 - Epoch: [260][  150/  155]    Loss 3.072278    mAP 0.521160    
2023-04-17 17:23:53,072 - Epoch: [260][  155/  155]    Loss 3.068328    mAP 0.520609    
2023-04-17 17:23:53,148 - ==> mAP: 0.52061    Loss: 3.068

2023-04-17 17:23:53,152 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 17:23:53,152 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 17:23:53,188 - 

2023-04-17 17:23:53,188 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 17:24:04,111 - Epoch: [261][   50/  518]    Overall Loss 2.787271    Objective Loss 2.787271                                        LR 0.000001    Time 0.218402    
2023-04-17 17:24:14,184 - Epoch: [261][  100/  518]    Overall Loss 2.790932    Objective Loss 2.790932                                        LR 0.000001    Time 0.209912    
2023-04-17 17:24:24,284 - Epoch: [261][  150/  518]    Overall Loss 2.793391    Objective Loss 2.793391                                        LR 0.000001    Time 0.207267    
2023-04-17 17:24:34,412 - Epoch: [261][  200/  518]    Overall Loss 2.792837    Objective Loss 2.792837                                        LR 0.000001    Time 0.206081    
2023-04-17 17:24:44,485 - Epoch: [261][  250/  518]    Overall Loss 2.811076    Objective Loss 2.811076                                        LR 0.000001    Time 0.205153    
2023-04-17 17:24:54,563 - Epoch: [261][  300/  518]    Overall Loss 2.804750    Objective Loss 2.804750                                        LR 0.000001    Time 0.204549    
2023-04-17 17:25:04,611 - Epoch: [261][  350/  518]    Overall Loss 2.806474    Objective Loss 2.806474                                        LR 0.000001    Time 0.204030    
2023-04-17 17:25:14,763 - Epoch: [261][  400/  518]    Overall Loss 2.804692    Objective Loss 2.804692                                        LR 0.000001    Time 0.203903    
2023-04-17 17:25:24,865 - Epoch: [261][  450/  518]    Overall Loss 2.801690    Objective Loss 2.801690                                        LR 0.000001    Time 0.203692    
2023-04-17 17:25:34,895 - Epoch: [261][  500/  518]    Overall Loss 2.807123    Objective Loss 2.807123                                        LR 0.000001    Time 0.203381    
2023-04-17 17:25:38,447 - Epoch: [261][  518/  518]    Overall Loss 2.807804    Objective Loss 2.807804                                        LR 0.000001    Time 0.203170    
2023-04-17 17:25:38,527 - --- validate (epoch=261)-----------
2023-04-17 17:25:38,528 - 4952 samples (32 per mini-batch)
2023-04-17 17:26:23,508 - Epoch: [261][   50/  155]    Loss 3.047629    mAP 0.516482    
2023-04-17 17:27:08,146 - Epoch: [261][  100/  155]    Loss 3.072324    mAP 0.511709    
2023-04-17 17:27:53,467 - Epoch: [261][  150/  155]    Loss 3.064646    mAP 0.516414    
2023-04-17 17:27:57,531 - Epoch: [261][  155/  155]    Loss 3.064677    mAP 0.515662    
2023-04-17 17:27:57,608 - ==> mAP: 0.51566    Loss: 3.065

2023-04-17 17:27:57,612 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 17:27:57,612 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 17:27:57,648 - 

2023-04-17 17:27:57,648 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 17:28:08,624 - Epoch: [262][   50/  518]    Overall Loss 2.806733    Objective Loss 2.806733                                        LR 0.000001    Time 0.219460    
2023-04-17 17:28:18,811 - Epoch: [262][  100/  518]    Overall Loss 2.822691    Objective Loss 2.822691                                        LR 0.000001    Time 0.211582    
2023-04-17 17:28:28,903 - Epoch: [262][  150/  518]    Overall Loss 2.824997    Objective Loss 2.824997                                        LR 0.000001    Time 0.208327    
2023-04-17 17:28:38,994 - Epoch: [262][  200/  518]    Overall Loss 2.810418    Objective Loss 2.810418                                        LR 0.000001    Time 0.206692    
2023-04-17 17:28:49,084 - Epoch: [262][  250/  518]    Overall Loss 2.799519    Objective Loss 2.799519                                        LR 0.000001    Time 0.205706    
2023-04-17 17:28:59,144 - Epoch: [262][  300/  518]    Overall Loss 2.802651    Objective Loss 2.802651                                        LR 0.000001    Time 0.204950    
2023-04-17 17:29:09,287 - Epoch: [262][  350/  518]    Overall Loss 2.804148    Objective Loss 2.804148                                        LR 0.000001    Time 0.204648    
2023-04-17 17:29:19,342 - Epoch: [262][  400/  518]    Overall Loss 2.805413    Objective Loss 2.805413                                        LR 0.000001    Time 0.204199    
2023-04-17 17:29:29,465 - Epoch: [262][  450/  518]    Overall Loss 2.800931    Objective Loss 2.800931                                        LR 0.000001    Time 0.204003    
2023-04-17 17:29:39,510 - Epoch: [262][  500/  518]    Overall Loss 2.804845    Objective Loss 2.804845                                        LR 0.000001    Time 0.203690    
2023-04-17 17:29:43,010 - Epoch: [262][  518/  518]    Overall Loss 2.805082    Objective Loss 2.805082                                        LR 0.000001    Time 0.203368    
2023-04-17 17:29:43,087 - --- validate (epoch=262)-----------
2023-04-17 17:29:43,087 - 4952 samples (32 per mini-batch)
2023-04-17 17:30:30,270 - Epoch: [262][   50/  155]    Loss 3.050451    mAP 0.511930    
2023-04-17 17:31:16,964 - Epoch: [262][  100/  155]    Loss 3.076777    mAP 0.514222    
2023-04-17 17:32:03,049 - Epoch: [262][  150/  155]    Loss 3.063261    mAP 0.520942    
2023-04-17 17:32:07,329 - Epoch: [262][  155/  155]    Loss 3.062282    mAP 0.522018    
2023-04-17 17:32:07,411 - ==> mAP: 0.52202    Loss: 3.062

2023-04-17 17:32:07,415 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 17:32:07,415 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 17:32:07,450 - 

2023-04-17 17:32:07,451 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 17:32:18,467 - Epoch: [263][   50/  518]    Overall Loss 2.794096    Objective Loss 2.794096                                        LR 0.000001    Time 0.220279    
2023-04-17 17:32:28,544 - Epoch: [263][  100/  518]    Overall Loss 2.813054    Objective Loss 2.813054                                        LR 0.000001    Time 0.210888    
2023-04-17 17:32:38,747 - Epoch: [263][  150/  518]    Overall Loss 2.812169    Objective Loss 2.812169                                        LR 0.000001    Time 0.208602    
2023-04-17 17:32:48,836 - Epoch: [263][  200/  518]    Overall Loss 2.816048    Objective Loss 2.816048                                        LR 0.000001    Time 0.206888    
2023-04-17 17:32:58,975 - Epoch: [263][  250/  518]    Overall Loss 2.821036    Objective Loss 2.821036                                        LR 0.000001    Time 0.206059    
2023-04-17 17:33:09,020 - Epoch: [263][  300/  518]    Overall Loss 2.818538    Objective Loss 2.818538                                        LR 0.000001    Time 0.205196    
2023-04-17 17:33:19,199 - Epoch: [263][  350/  518]    Overall Loss 2.815866    Objective Loss 2.815866                                        LR 0.000001    Time 0.204962    
2023-04-17 17:33:29,282 - Epoch: [263][  400/  518]    Overall Loss 2.819213    Objective Loss 2.819213                                        LR 0.000001    Time 0.204543    
2023-04-17 17:33:39,363 - Epoch: [263][  450/  518]    Overall Loss 2.814692    Objective Loss 2.814692                                        LR 0.000001    Time 0.204217    
2023-04-17 17:33:49,463 - Epoch: [263][  500/  518]    Overall Loss 2.812873    Objective Loss 2.812873                                        LR 0.000001    Time 0.203991    
2023-04-17 17:33:53,005 - Epoch: [263][  518/  518]    Overall Loss 2.812068    Objective Loss 2.812068                                        LR 0.000001    Time 0.203741    
2023-04-17 17:33:53,088 - --- validate (epoch=263)-----------
2023-04-17 17:33:53,088 - 4952 samples (32 per mini-batch)
2023-04-17 17:34:35,598 - Epoch: [263][   50/  155]    Loss 3.078704    mAP 0.528015    
2023-04-17 17:35:19,134 - Epoch: [263][  100/  155]    Loss 3.064054    mAP 0.524084    
2023-04-17 17:36:01,966 - Epoch: [263][  150/  155]    Loss 3.061171    mAP 0.521877    
2023-04-17 17:36:06,585 - Epoch: [263][  155/  155]    Loss 3.063046    mAP 0.521385    
2023-04-17 17:36:06,661 - ==> mAP: 0.52138    Loss: 3.063

2023-04-17 17:36:06,665 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 17:36:06,665 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 17:36:06,702 - 

2023-04-17 17:36:06,702 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 17:36:17,541 - Epoch: [264][   50/  518]    Overall Loss 2.814824    Objective Loss 2.814824                                        LR 0.000001    Time 0.216727    
2023-04-17 17:36:27,610 - Epoch: [264][  100/  518]    Overall Loss 2.814508    Objective Loss 2.814508                                        LR 0.000001    Time 0.209031    
2023-04-17 17:36:37,697 - Epoch: [264][  150/  518]    Overall Loss 2.792793    Objective Loss 2.792793                                        LR 0.000001    Time 0.206596    
2023-04-17 17:36:47,802 - Epoch: [264][  200/  518]    Overall Loss 2.793091    Objective Loss 2.793091                                        LR 0.000001    Time 0.205463    
2023-04-17 17:36:57,863 - Epoch: [264][  250/  518]    Overall Loss 2.795208    Objective Loss 2.795208                                        LR 0.000001    Time 0.204609    
2023-04-17 17:37:08,014 - Epoch: [264][  300/  518]    Overall Loss 2.796923    Objective Loss 2.796923                                        LR 0.000001    Time 0.204338    
2023-04-17 17:37:18,182 - Epoch: [264][  350/  518]    Overall Loss 2.793725    Objective Loss 2.793725                                        LR 0.000001    Time 0.204194    
2023-04-17 17:37:28,248 - Epoch: [264][  400/  518]    Overall Loss 2.805876    Objective Loss 2.805876                                        LR 0.000001    Time 0.203831    
2023-04-17 17:37:38,330 - Epoch: [264][  450/  518]    Overall Loss 2.805670    Objective Loss 2.805670                                        LR 0.000001    Time 0.203585    
2023-04-17 17:37:48,439 - Epoch: [264][  500/  518]    Overall Loss 2.805989    Objective Loss 2.805989                                        LR 0.000001    Time 0.203441    
2023-04-17 17:37:51,889 - Epoch: [264][  518/  518]    Overall Loss 2.804791    Objective Loss 2.804791                                        LR 0.000001    Time 0.203030    
2023-04-17 17:37:51,969 - --- validate (epoch=264)-----------
2023-04-17 17:37:51,969 - 4952 samples (32 per mini-batch)
2023-04-17 17:38:37,883 - Epoch: [264][   50/  155]    Loss 3.070730    mAP 0.501403    
2023-04-17 17:39:22,216 - Epoch: [264][  100/  155]    Loss 3.066741    mAP 0.511775    
2023-04-17 17:40:08,202 - Epoch: [264][  150/  155]    Loss 3.060793    mAP 0.515615    
2023-04-17 17:40:12,326 - Epoch: [264][  155/  155]    Loss 3.065958    mAP 0.516223    
2023-04-17 17:40:12,405 - ==> mAP: 0.51622    Loss: 3.066

2023-04-17 17:40:12,409 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 17:40:12,409 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 17:40:12,445 - 

2023-04-17 17:40:12,445 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 17:40:23,454 - Epoch: [265][   50/  518]    Overall Loss 2.782086    Objective Loss 2.782086                                        LR 0.000001    Time 0.220112    
2023-04-17 17:40:33,512 - Epoch: [265][  100/  518]    Overall Loss 2.795174    Objective Loss 2.795174                                        LR 0.000001    Time 0.210618    
2023-04-17 17:40:43,581 - Epoch: [265][  150/  518]    Overall Loss 2.798330    Objective Loss 2.798330                                        LR 0.000001    Time 0.207533    
2023-04-17 17:40:53,566 - Epoch: [265][  200/  518]    Overall Loss 2.790148    Objective Loss 2.790148                                        LR 0.000001    Time 0.205567    
2023-04-17 17:41:03,600 - Epoch: [265][  250/  518]    Overall Loss 2.797503    Objective Loss 2.797503                                        LR 0.000001    Time 0.204581    
2023-04-17 17:41:13,648 - Epoch: [265][  300/  518]    Overall Loss 2.798447    Objective Loss 2.798447                                        LR 0.000001    Time 0.203973    
2023-04-17 17:41:23,709 - Epoch: [265][  350/  518]    Overall Loss 2.798440    Objective Loss 2.798440                                        LR 0.000001    Time 0.203574    
2023-04-17 17:41:33,832 - Epoch: [265][  400/  518]    Overall Loss 2.795316    Objective Loss 2.795316                                        LR 0.000001    Time 0.203433    
2023-04-17 17:41:43,970 - Epoch: [265][  450/  518]    Overall Loss 2.796292    Objective Loss 2.796292                                        LR 0.000001    Time 0.203354    
2023-04-17 17:41:54,150 - Epoch: [265][  500/  518]    Overall Loss 2.801644    Objective Loss 2.801644                                        LR 0.000001    Time 0.203375    
2023-04-17 17:41:57,685 - Epoch: [265][  518/  518]    Overall Loss 2.803468    Objective Loss 2.803468                                        LR 0.000001    Time 0.203132    
2023-04-17 17:41:57,767 - --- validate (epoch=265)-----------
2023-04-17 17:41:57,767 - 4952 samples (32 per mini-batch)
2023-04-17 17:42:42,684 - Epoch: [265][   50/  155]    Loss 3.094569    mAP 0.500491    
2023-04-17 17:43:26,630 - Epoch: [265][  100/  155]    Loss 3.058134    mAP 0.505088    
2023-04-17 17:44:10,043 - Epoch: [265][  150/  155]    Loss 3.066242    mAP 0.507548    
2023-04-17 17:44:14,136 - Epoch: [265][  155/  155]    Loss 3.067108    mAP 0.508716    
2023-04-17 17:44:14,211 - ==> mAP: 0.50872    Loss: 3.067

2023-04-17 17:44:14,215 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 17:44:14,215 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 17:44:14,251 - 

2023-04-17 17:44:14,251 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 17:44:25,079 - Epoch: [266][   50/  518]    Overall Loss 2.810331    Objective Loss 2.810331                                        LR 0.000001    Time 0.216493    
2023-04-17 17:44:35,220 - Epoch: [266][  100/  518]    Overall Loss 2.779202    Objective Loss 2.779202                                        LR 0.000001    Time 0.209647    
2023-04-17 17:44:45,269 - Epoch: [266][  150/  518]    Overall Loss 2.795874    Objective Loss 2.795874                                        LR 0.000001    Time 0.206748    
2023-04-17 17:44:55,355 - Epoch: [266][  200/  518]    Overall Loss 2.785863    Objective Loss 2.785863                                        LR 0.000001    Time 0.205481    
2023-04-17 17:45:05,443 - Epoch: [266][  250/  518]    Overall Loss 2.794848    Objective Loss 2.794848                                        LR 0.000001    Time 0.204731    
2023-04-17 17:45:15,575 - Epoch: [266][  300/  518]    Overall Loss 2.802340    Objective Loss 2.802340                                        LR 0.000001    Time 0.204377    
2023-04-17 17:45:25,637 - Epoch: [266][  350/  518]    Overall Loss 2.798320    Objective Loss 2.798320                                        LR 0.000001    Time 0.203925    
2023-04-17 17:45:35,736 - Epoch: [266][  400/  518]    Overall Loss 2.798744    Objective Loss 2.798744                                        LR 0.000001    Time 0.203677    
2023-04-17 17:45:45,934 - Epoch: [266][  450/  518]    Overall Loss 2.795452    Objective Loss 2.795452                                        LR 0.000001    Time 0.203705    
2023-04-17 17:45:56,059 - Epoch: [266][  500/  518]    Overall Loss 2.794683    Objective Loss 2.794683                                        LR 0.000001    Time 0.203582    
2023-04-17 17:45:59,580 - Epoch: [266][  518/  518]    Overall Loss 2.796683    Objective Loss 2.796683                                        LR 0.000001    Time 0.203304    
2023-04-17 17:45:59,660 - --- validate (epoch=266)-----------
2023-04-17 17:45:59,661 - 4952 samples (32 per mini-batch)
2023-04-17 17:46:43,802 - Epoch: [266][   50/  155]    Loss 3.028381    mAP 0.549235    
2023-04-17 17:47:28,988 - Epoch: [266][  100/  155]    Loss 3.060598    mAP 0.525126    
2023-04-17 17:48:12,915 - Epoch: [266][  150/  155]    Loss 3.061754    mAP 0.519934    
2023-04-17 17:48:17,409 - Epoch: [266][  155/  155]    Loss 3.066666    mAP 0.518830    
2023-04-17 17:48:17,487 - ==> mAP: 0.51883    Loss: 3.067

2023-04-17 17:48:17,491 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 17:48:17,491 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 17:48:17,528 - 

2023-04-17 17:48:17,528 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 17:48:28,386 - Epoch: [267][   50/  518]    Overall Loss 2.795504    Objective Loss 2.795504                                        LR 0.000001    Time 0.217098    
2023-04-17 17:48:38,531 - Epoch: [267][  100/  518]    Overall Loss 2.805200    Objective Loss 2.805200                                        LR 0.000001    Time 0.209985    
2023-04-17 17:48:48,590 - Epoch: [267][  150/  518]    Overall Loss 2.817731    Objective Loss 2.817731                                        LR 0.000001    Time 0.207041    
2023-04-17 17:48:58,730 - Epoch: [267][  200/  518]    Overall Loss 2.820590    Objective Loss 2.820590                                        LR 0.000001    Time 0.205970    
2023-04-17 17:49:08,805 - Epoch: [267][  250/  518]    Overall Loss 2.823297    Objective Loss 2.823297                                        LR 0.000001    Time 0.205071    
2023-04-17 17:49:18,833 - Epoch: [267][  300/  518]    Overall Loss 2.821993    Objective Loss 2.821993                                        LR 0.000001    Time 0.204315    
2023-04-17 17:49:28,949 - Epoch: [267][  350/  518]    Overall Loss 2.819979    Objective Loss 2.819979                                        LR 0.000001    Time 0.204024    
2023-04-17 17:49:39,091 - Epoch: [267][  400/  518]    Overall Loss 2.814956    Objective Loss 2.814956                                        LR 0.000001    Time 0.203873    
2023-04-17 17:49:49,194 - Epoch: [267][  450/  518]    Overall Loss 2.810828    Objective Loss 2.810828                                        LR 0.000001    Time 0.203669    
2023-04-17 17:49:59,325 - Epoch: [267][  500/  518]    Overall Loss 2.813393    Objective Loss 2.813393                                        LR 0.000001    Time 0.203560    
2023-04-17 17:50:02,852 - Epoch: [267][  518/  518]    Overall Loss 2.817310    Objective Loss 2.817310                                        LR 0.000001    Time 0.203295    
2023-04-17 17:50:02,934 - --- validate (epoch=267)-----------
2023-04-17 17:50:02,935 - 4952 samples (32 per mini-batch)
2023-04-17 17:50:48,314 - Epoch: [267][   50/  155]    Loss 3.053431    mAP 0.521247    
2023-04-17 17:51:32,075 - Epoch: [267][  100/  155]    Loss 3.071324    mAP 0.519623    
2023-04-17 17:52:16,949 - Epoch: [267][  150/  155]    Loss 3.071708    mAP 0.517031    
2023-04-17 17:52:20,929 - Epoch: [267][  155/  155]    Loss 3.071292    mAP 0.515917    
2023-04-17 17:52:21,010 - ==> mAP: 0.51592    Loss: 3.071

2023-04-17 17:52:21,014 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 17:52:21,014 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 17:52:21,071 - 

2023-04-17 17:52:21,071 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 17:52:31,985 - Epoch: [268][   50/  518]    Overall Loss 2.820069    Objective Loss 2.820069                                        LR 0.000001    Time 0.218208    
2023-04-17 17:52:42,137 - Epoch: [268][  100/  518]    Overall Loss 2.826466    Objective Loss 2.826466                                        LR 0.000001    Time 0.210613    
2023-04-17 17:52:52,302 - Epoch: [268][  150/  518]    Overall Loss 2.820300    Objective Loss 2.820300                                        LR 0.000001    Time 0.208162    
2023-04-17 17:53:02,453 - Epoch: [268][  200/  518]    Overall Loss 2.809466    Objective Loss 2.809466                                        LR 0.000001    Time 0.206869    
2023-04-17 17:53:12,677 - Epoch: [268][  250/  518]    Overall Loss 2.818653    Objective Loss 2.818653                                        LR 0.000001    Time 0.206385    
2023-04-17 17:53:22,812 - Epoch: [268][  300/  518]    Overall Loss 2.819311    Objective Loss 2.819311                                        LR 0.000001    Time 0.205766    
2023-04-17 17:53:32,819 - Epoch: [268][  350/  518]    Overall Loss 2.820454    Objective Loss 2.820454                                        LR 0.000001    Time 0.204959    
2023-04-17 17:53:42,997 - Epoch: [268][  400/  518]    Overall Loss 2.824655    Objective Loss 2.824655                                        LR 0.000001    Time 0.204780    
2023-04-17 17:53:53,037 - Epoch: [268][  450/  518]    Overall Loss 2.823943    Objective Loss 2.823943                                        LR 0.000001    Time 0.204334    
2023-04-17 17:54:03,133 - Epoch: [268][  500/  518]    Overall Loss 2.817107    Objective Loss 2.817107                                        LR 0.000001    Time 0.204090    
2023-04-17 17:54:06,609 - Epoch: [268][  518/  518]    Overall Loss 2.813694    Objective Loss 2.813694                                        LR 0.000001    Time 0.203706    
2023-04-17 17:54:06,690 - --- validate (epoch=268)-----------
2023-04-17 17:54:06,691 - 4952 samples (32 per mini-batch)
2023-04-17 17:54:50,779 - Epoch: [268][   50/  155]    Loss 3.073553    mAP 0.523364    
2023-04-17 17:55:35,747 - Epoch: [268][  100/  155]    Loss 3.071258    mAP 0.526689    
2023-04-17 17:56:19,260 - Epoch: [268][  150/  155]    Loss 3.068479    mAP 0.517897    
2023-04-17 17:56:23,229 - Epoch: [268][  155/  155]    Loss 3.066470    mAP 0.517951    
2023-04-17 17:56:23,305 - ==> mAP: 0.51795    Loss: 3.066

2023-04-17 17:56:23,309 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 17:56:23,309 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 17:56:23,345 - 

2023-04-17 17:56:23,345 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 17:56:34,274 - Epoch: [269][   50/  518]    Overall Loss 2.819546    Objective Loss 2.819546                                        LR 0.000001    Time 0.218524    
2023-04-17 17:56:44,423 - Epoch: [269][  100/  518]    Overall Loss 2.806502    Objective Loss 2.806502                                        LR 0.000001    Time 0.210733    
2023-04-17 17:56:54,474 - Epoch: [269][  150/  518]    Overall Loss 2.810898    Objective Loss 2.810898                                        LR 0.000001    Time 0.207484    
2023-04-17 17:57:04,610 - Epoch: [269][  200/  518]    Overall Loss 2.809795    Objective Loss 2.809795                                        LR 0.000001    Time 0.206287    
2023-04-17 17:57:14,742 - Epoch: [269][  250/  518]    Overall Loss 2.806242    Objective Loss 2.806242                                        LR 0.000001    Time 0.205553    
2023-04-17 17:57:24,907 - Epoch: [269][  300/  518]    Overall Loss 2.801336    Objective Loss 2.801336                                        LR 0.000001    Time 0.205172    
2023-04-17 17:57:34,979 - Epoch: [269][  350/  518]    Overall Loss 2.790307    Objective Loss 2.790307                                        LR 0.000001    Time 0.204635    
2023-04-17 17:57:45,109 - Epoch: [269][  400/  518]    Overall Loss 2.790977    Objective Loss 2.790977                                        LR 0.000001    Time 0.204375    
2023-04-17 17:57:55,346 - Epoch: [269][  450/  518]    Overall Loss 2.800919    Objective Loss 2.800919                                        LR 0.000001    Time 0.204414    
2023-04-17 17:58:05,426 - Epoch: [269][  500/  518]    Overall Loss 2.808385    Objective Loss 2.808385                                        LR 0.000001    Time 0.204129    
2023-04-17 17:58:08,981 - Epoch: [269][  518/  518]    Overall Loss 2.805409    Objective Loss 2.805409                                        LR 0.000001    Time 0.203897    
2023-04-17 17:58:09,062 - --- validate (epoch=269)-----------
2023-04-17 17:58:09,062 - 4952 samples (32 per mini-batch)
2023-04-17 17:58:54,607 - Epoch: [269][   50/  155]    Loss 3.076968    mAP 0.516373    
2023-04-17 17:59:41,121 - Epoch: [269][  100/  155]    Loss 3.066855    mAP 0.526925    
2023-04-17 18:00:28,884 - Epoch: [269][  150/  155]    Loss 3.065469    mAP 0.526061    
2023-04-17 18:00:33,260 - Epoch: [269][  155/  155]    Loss 3.063392    mAP 0.527911    
2023-04-17 18:00:33,333 - ==> mAP: 0.52791    Loss: 3.063

2023-04-17 18:00:33,338 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 18:00:33,338 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 18:00:33,374 - 

2023-04-17 18:00:33,374 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 18:00:44,181 - Epoch: [270][   50/  518]    Overall Loss 2.856186    Objective Loss 2.856186                                        LR 0.000001    Time 0.216075    
2023-04-17 18:00:54,267 - Epoch: [270][  100/  518]    Overall Loss 2.815270    Objective Loss 2.815270                                        LR 0.000001    Time 0.208888    
2023-04-17 18:01:04,379 - Epoch: [270][  150/  518]    Overall Loss 2.816048    Objective Loss 2.816048                                        LR 0.000001    Time 0.206657    
2023-04-17 18:01:14,529 - Epoch: [270][  200/  518]    Overall Loss 2.815892    Objective Loss 2.815892                                        LR 0.000001    Time 0.205738    
2023-04-17 18:01:24,535 - Epoch: [270][  250/  518]    Overall Loss 2.797707    Objective Loss 2.797707                                        LR 0.000001    Time 0.204608    
2023-04-17 18:01:34,625 - Epoch: [270][  300/  518]    Overall Loss 2.800369    Objective Loss 2.800369                                        LR 0.000001    Time 0.204136    
2023-04-17 18:01:44,796 - Epoch: [270][  350/  518]    Overall Loss 2.799396    Objective Loss 2.799396                                        LR 0.000001    Time 0.204027    
2023-04-17 18:01:54,995 - Epoch: [270][  400/  518]    Overall Loss 2.802839    Objective Loss 2.802839                                        LR 0.000001    Time 0.204017    
2023-04-17 18:02:05,173 - Epoch: [270][  450/  518]    Overall Loss 2.800482    Objective Loss 2.800482                                        LR 0.000001    Time 0.203963    
2023-04-17 18:02:15,214 - Epoch: [270][  500/  518]    Overall Loss 2.802399    Objective Loss 2.802399                                        LR 0.000001    Time 0.203647    
2023-04-17 18:02:18,740 - Epoch: [270][  518/  518]    Overall Loss 2.802479    Objective Loss 2.802479                                        LR 0.000001    Time 0.203376    
2023-04-17 18:02:18,820 - --- validate (epoch=270)-----------
2023-04-17 18:02:18,820 - 4952 samples (32 per mini-batch)
2023-04-17 18:03:03,307 - Epoch: [270][   50/  155]    Loss 3.088830    mAP 0.530683    
2023-04-17 18:03:47,543 - Epoch: [270][  100/  155]    Loss 3.064573    mAP 0.523280    
2023-04-17 18:04:30,213 - Epoch: [270][  150/  155]    Loss 3.063963    mAP 0.524010    
2023-04-17 18:04:34,994 - Epoch: [270][  155/  155]    Loss 3.062803    mAP 0.523841    
2023-04-17 18:04:35,073 - ==> mAP: 0.52384    Loss: 3.063

2023-04-17 18:04:35,077 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 18:04:35,077 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 18:04:35,113 - 

2023-04-17 18:04:35,113 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 18:04:45,843 - Epoch: [271][   50/  518]    Overall Loss 2.780208    Objective Loss 2.780208                                        LR 0.000001    Time 0.214544    
2023-04-17 18:04:55,916 - Epoch: [271][  100/  518]    Overall Loss 2.792810    Objective Loss 2.792810                                        LR 0.000001    Time 0.207988    
2023-04-17 18:05:06,002 - Epoch: [271][  150/  518]    Overall Loss 2.808311    Objective Loss 2.808311                                        LR 0.000001    Time 0.205886    
2023-04-17 18:05:16,058 - Epoch: [271][  200/  518]    Overall Loss 2.805429    Objective Loss 2.805429                                        LR 0.000001    Time 0.204689    
2023-04-17 18:05:26,184 - Epoch: [271][  250/  518]    Overall Loss 2.811843    Objective Loss 2.811843                                        LR 0.000001    Time 0.204249    
2023-04-17 18:05:36,250 - Epoch: [271][  300/  518]    Overall Loss 2.812306    Objective Loss 2.812306                                        LR 0.000001    Time 0.203755    
2023-04-17 18:05:46,368 - Epoch: [271][  350/  518]    Overall Loss 2.812915    Objective Loss 2.812915                                        LR 0.000001    Time 0.203552    
2023-04-17 18:05:56,459 - Epoch: [271][  400/  518]    Overall Loss 2.808989    Objective Loss 2.808989                                        LR 0.000001    Time 0.203331    
2023-04-17 18:06:06,565 - Epoch: [271][  450/  518]    Overall Loss 2.815902    Objective Loss 2.815902                                        LR 0.000001    Time 0.203193    
2023-04-17 18:06:16,655 - Epoch: [271][  500/  518]    Overall Loss 2.811801    Objective Loss 2.811801                                        LR 0.000001    Time 0.203051    
2023-04-17 18:06:20,163 - Epoch: [271][  518/  518]    Overall Loss 2.812474    Objective Loss 2.812474                                        LR 0.000001    Time 0.202766    
2023-04-17 18:06:20,243 - --- validate (epoch=271)-----------
2023-04-17 18:06:20,244 - 4952 samples (32 per mini-batch)
2023-04-17 18:07:04,286 - Epoch: [271][   50/  155]    Loss 3.055258    mAP 0.521999    
2023-04-17 18:07:48,951 - Epoch: [271][  100/  155]    Loss 3.050657    mAP 0.519981    
2023-04-17 18:08:31,929 - Epoch: [271][  150/  155]    Loss 3.066177    mAP 0.519224    
2023-04-17 18:08:35,842 - Epoch: [271][  155/  155]    Loss 3.067871    mAP 0.518883    
2023-04-17 18:08:35,918 - ==> mAP: 0.51888    Loss: 3.068

2023-04-17 18:08:35,922 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 18:08:35,923 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 18:08:35,959 - 

2023-04-17 18:08:35,960 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 18:08:46,831 - Epoch: [272][   50/  518]    Overall Loss 2.803419    Objective Loss 2.803419                                        LR 0.000001    Time 0.217374    
2023-04-17 18:08:56,959 - Epoch: [272][  100/  518]    Overall Loss 2.806766    Objective Loss 2.806766                                        LR 0.000001    Time 0.209952    
2023-04-17 18:09:06,969 - Epoch: [272][  150/  518]    Overall Loss 2.794331    Objective Loss 2.794331                                        LR 0.000001    Time 0.206692    
2023-04-17 18:09:17,115 - Epoch: [272][  200/  518]    Overall Loss 2.794424    Objective Loss 2.794424                                        LR 0.000001    Time 0.205741    
2023-04-17 18:09:27,236 - Epoch: [272][  250/  518]    Overall Loss 2.795594    Objective Loss 2.795594                                        LR 0.000001    Time 0.205072    
2023-04-17 18:09:37,383 - Epoch: [272][  300/  518]    Overall Loss 2.802285    Objective Loss 2.802285                                        LR 0.000001    Time 0.204709    
2023-04-17 18:09:47,598 - Epoch: [272][  350/  518]    Overall Loss 2.803517    Objective Loss 2.803517                                        LR 0.000001    Time 0.204647    
2023-04-17 18:09:57,675 - Epoch: [272][  400/  518]    Overall Loss 2.802040    Objective Loss 2.802040                                        LR 0.000001    Time 0.204254    
2023-04-17 18:10:07,867 - Epoch: [272][  450/  518]    Overall Loss 2.803818    Objective Loss 2.803818                                        LR 0.000001    Time 0.204205    
2023-04-17 18:10:17,925 - Epoch: [272][  500/  518]    Overall Loss 2.797507    Objective Loss 2.797507                                        LR 0.000001    Time 0.203899    
2023-04-17 18:10:21,453 - Epoch: [272][  518/  518]    Overall Loss 2.801677    Objective Loss 2.801677                                        LR 0.000001    Time 0.203623    
2023-04-17 18:10:21,536 - --- validate (epoch=272)-----------
2023-04-17 18:10:21,536 - 4952 samples (32 per mini-batch)
2023-04-17 18:11:05,606 - Epoch: [272][   50/  155]    Loss 3.054773    mAP 0.519482    
2023-04-17 18:11:50,118 - Epoch: [272][  100/  155]    Loss 3.063428    mAP 0.522065    
2023-04-17 18:12:35,279 - Epoch: [272][  150/  155]    Loss 3.067148    mAP 0.521223    
2023-04-17 18:12:39,175 - Epoch: [272][  155/  155]    Loss 3.069244    mAP 0.518914    
2023-04-17 18:12:39,255 - ==> mAP: 0.51891    Loss: 3.069

2023-04-17 18:12:39,259 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 18:12:39,259 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 18:12:39,295 - 

2023-04-17 18:12:39,295 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 18:12:50,155 - Epoch: [273][   50/  518]    Overall Loss 2.817044    Objective Loss 2.817044                                        LR 0.000001    Time 0.217139    
2023-04-17 18:13:00,286 - Epoch: [273][  100/  518]    Overall Loss 2.795436    Objective Loss 2.795436                                        LR 0.000001    Time 0.209865    
2023-04-17 18:13:10,404 - Epoch: [273][  150/  518]    Overall Loss 2.805824    Objective Loss 2.805824                                        LR 0.000001    Time 0.207353    
2023-04-17 18:13:20,435 - Epoch: [273][  200/  518]    Overall Loss 2.796911    Objective Loss 2.796911                                        LR 0.000001    Time 0.205660    
2023-04-17 18:13:30,601 - Epoch: [273][  250/  518]    Overall Loss 2.800766    Objective Loss 2.800766                                        LR 0.000001    Time 0.205188    
2023-04-17 18:13:40,657 - Epoch: [273][  300/  518]    Overall Loss 2.794548    Objective Loss 2.794548                                        LR 0.000001    Time 0.204506    
2023-04-17 18:13:50,689 - Epoch: [273][  350/  518]    Overall Loss 2.786143    Objective Loss 2.786143                                        LR 0.000001    Time 0.203948    
2023-04-17 18:14:00,757 - Epoch: [273][  400/  518]    Overall Loss 2.790694    Objective Loss 2.790694                                        LR 0.000001    Time 0.203619    
2023-04-17 18:14:10,815 - Epoch: [273][  450/  518]    Overall Loss 2.787983    Objective Loss 2.787983                                        LR 0.000001    Time 0.203343    
2023-04-17 18:14:20,858 - Epoch: [273][  500/  518]    Overall Loss 2.795199    Objective Loss 2.795199                                        LR 0.000001    Time 0.203093    
2023-04-17 18:14:24,356 - Epoch: [273][  518/  518]    Overall Loss 2.797626    Objective Loss 2.797626                                        LR 0.000001    Time 0.202788    
2023-04-17 18:14:24,439 - --- validate (epoch=273)-----------
2023-04-17 18:14:24,439 - 4952 samples (32 per mini-batch)
2023-04-17 18:15:10,761 - Epoch: [273][   50/  155]    Loss 3.076776    mAP 0.514134    
2023-04-17 18:15:54,970 - Epoch: [273][  100/  155]    Loss 3.060506    mAP 0.518248    
2023-04-17 18:16:40,742 - Epoch: [273][  150/  155]    Loss 3.061994    mAP 0.511174    
2023-04-17 18:16:45,013 - Epoch: [273][  155/  155]    Loss 3.061496    mAP 0.510556    
2023-04-17 18:16:45,087 - ==> mAP: 0.51056    Loss: 3.061

2023-04-17 18:16:45,091 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 18:16:45,091 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 18:16:45,127 - 

2023-04-17 18:16:45,127 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 18:16:56,103 - Epoch: [274][   50/  518]    Overall Loss 2.785326    Objective Loss 2.785326                                        LR 0.000001    Time 0.219467    
2023-04-17 18:17:06,156 - Epoch: [274][  100/  518]    Overall Loss 2.765104    Objective Loss 2.765104                                        LR 0.000001    Time 0.210249    
2023-04-17 18:17:16,289 - Epoch: [274][  150/  518]    Overall Loss 2.786273    Objective Loss 2.786273                                        LR 0.000001    Time 0.207709    
2023-04-17 18:17:26,358 - Epoch: [274][  200/  518]    Overall Loss 2.794794    Objective Loss 2.794794                                        LR 0.000001    Time 0.206119    
2023-04-17 18:17:36,466 - Epoch: [274][  250/  518]    Overall Loss 2.795373    Objective Loss 2.795373                                        LR 0.000001    Time 0.205320    
2023-04-17 18:17:46,608 - Epoch: [274][  300/  518]    Overall Loss 2.799429    Objective Loss 2.799429                                        LR 0.000001    Time 0.204903    
2023-04-17 18:17:56,778 - Epoch: [274][  350/  518]    Overall Loss 2.803672    Objective Loss 2.803672                                        LR 0.000001    Time 0.204684    
2023-04-17 18:18:06,900 - Epoch: [274][  400/  518]    Overall Loss 2.806249    Objective Loss 2.806249                                        LR 0.000001    Time 0.204398    
2023-04-17 18:18:16,901 - Epoch: [274][  450/  518]    Overall Loss 2.806479    Objective Loss 2.806479                                        LR 0.000001    Time 0.203908    
2023-04-17 18:18:27,026 - Epoch: [274][  500/  518]    Overall Loss 2.808926    Objective Loss 2.808926                                        LR 0.000001    Time 0.203766    
2023-04-17 18:18:30,557 - Epoch: [274][  518/  518]    Overall Loss 2.808472    Objective Loss 2.808472                                        LR 0.000001    Time 0.203501    
2023-04-17 18:18:30,637 - --- validate (epoch=274)-----------
2023-04-17 18:18:30,637 - 4952 samples (32 per mini-batch)
2023-04-17 18:19:16,019 - Epoch: [274][   50/  155]    Loss 3.133346    mAP 0.521835    
2023-04-17 18:20:01,392 - Epoch: [274][  100/  155]    Loss 3.095731    mAP 0.522740    
2023-04-17 18:20:47,163 - Epoch: [274][  150/  155]    Loss 3.066896    mAP 0.519224    
2023-04-17 18:20:51,501 - Epoch: [274][  155/  155]    Loss 3.066378    mAP 0.517237    
2023-04-17 18:20:51,581 - ==> mAP: 0.51724    Loss: 3.066

2023-04-17 18:20:51,585 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 18:20:51,585 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 18:20:51,621 - 

2023-04-17 18:20:51,621 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 18:21:02,479 - Epoch: [275][   50/  518]    Overall Loss 2.788818    Objective Loss 2.788818                                        LR 0.000001    Time 0.217102    
2023-04-17 18:21:12,502 - Epoch: [275][  100/  518]    Overall Loss 2.787748    Objective Loss 2.787748                                        LR 0.000001    Time 0.208767    
2023-04-17 18:21:22,670 - Epoch: [275][  150/  518]    Overall Loss 2.797591    Objective Loss 2.797591                                        LR 0.000001    Time 0.206951    
2023-04-17 18:21:32,794 - Epoch: [275][  200/  518]    Overall Loss 2.797894    Objective Loss 2.797894                                        LR 0.000001    Time 0.205825    
2023-04-17 18:21:42,915 - Epoch: [275][  250/  518]    Overall Loss 2.802932    Objective Loss 2.802932                                        LR 0.000001    Time 0.205138    
2023-04-17 18:21:53,023 - Epoch: [275][  300/  518]    Overall Loss 2.806316    Objective Loss 2.806316                                        LR 0.000001    Time 0.204639    
2023-04-17 18:22:03,176 - Epoch: [275][  350/  518]    Overall Loss 2.808714    Objective Loss 2.808714                                        LR 0.000001    Time 0.204408    
2023-04-17 18:22:13,304 - Epoch: [275][  400/  518]    Overall Loss 2.807234    Objective Loss 2.807234                                        LR 0.000001    Time 0.204173    
2023-04-17 18:22:23,382 - Epoch: [275][  450/  518]    Overall Loss 2.807268    Objective Loss 2.807268                                        LR 0.000001    Time 0.203879    
2023-04-17 18:22:33,480 - Epoch: [275][  500/  518]    Overall Loss 2.801081    Objective Loss 2.801081                                        LR 0.000001    Time 0.203684    
2023-04-17 18:22:36,981 - Epoch: [275][  518/  518]    Overall Loss 2.801092    Objective Loss 2.801092                                        LR 0.000001    Time 0.203364    
2023-04-17 18:22:37,061 - --- validate (epoch=275)-----------
2023-04-17 18:22:37,062 - 4952 samples (32 per mini-batch)
2023-04-17 18:23:25,336 - Epoch: [275][   50/  155]    Loss 3.076457    mAP 0.517743    
2023-04-17 18:24:11,827 - Epoch: [275][  100/  155]    Loss 3.077018    mAP 0.520864    
2023-04-17 18:24:57,874 - Epoch: [275][  150/  155]    Loss 3.061542    mAP 0.516797    
2023-04-17 18:25:02,391 - Epoch: [275][  155/  155]    Loss 3.064016    mAP 0.514881    
2023-04-17 18:25:02,472 - ==> mAP: 0.51488    Loss: 3.064

2023-04-17 18:25:02,475 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 18:25:02,475 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 18:25:02,511 - 

2023-04-17 18:25:02,511 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 18:25:13,398 - Epoch: [276][   50/  518]    Overall Loss 2.822068    Objective Loss 2.822068                                        LR 0.000001    Time 0.217672    
2023-04-17 18:25:23,459 - Epoch: [276][  100/  518]    Overall Loss 2.813244    Objective Loss 2.813244                                        LR 0.000001    Time 0.209432    
2023-04-17 18:25:33,558 - Epoch: [276][  150/  518]    Overall Loss 2.809327    Objective Loss 2.809327                                        LR 0.000001    Time 0.206940    
2023-04-17 18:25:43,679 - Epoch: [276][  200/  518]    Overall Loss 2.802411    Objective Loss 2.802411                                        LR 0.000001    Time 0.205799    
2023-04-17 18:25:53,698 - Epoch: [276][  250/  518]    Overall Loss 2.811096    Objective Loss 2.811096                                        LR 0.000001    Time 0.204709    
2023-04-17 18:26:03,727 - Epoch: [276][  300/  518]    Overall Loss 2.798131    Objective Loss 2.798131                                        LR 0.000001    Time 0.204018    
2023-04-17 18:26:13,828 - Epoch: [276][  350/  518]    Overall Loss 2.797948    Objective Loss 2.797948                                        LR 0.000001    Time 0.203727    
2023-04-17 18:26:24,011 - Epoch: [276][  400/  518]    Overall Loss 2.795397    Objective Loss 2.795397                                        LR 0.000001    Time 0.203715    
2023-04-17 18:26:34,128 - Epoch: [276][  450/  518]    Overall Loss 2.798704    Objective Loss 2.798704                                        LR 0.000001    Time 0.203559    
2023-04-17 18:26:44,196 - Epoch: [276][  500/  518]    Overall Loss 2.804012    Objective Loss 2.804012                                        LR 0.000001    Time 0.203337    
2023-04-17 18:26:47,728 - Epoch: [276][  518/  518]    Overall Loss 2.806858    Objective Loss 2.806858                                        LR 0.000001    Time 0.203087    
2023-04-17 18:26:47,810 - --- validate (epoch=276)-----------
2023-04-17 18:26:47,811 - 4952 samples (32 per mini-batch)
2023-04-17 18:27:30,824 - Epoch: [276][   50/  155]    Loss 3.048012    mAP 0.514538    
2023-04-17 18:28:14,536 - Epoch: [276][  100/  155]    Loss 3.079096    mAP 0.517930    
2023-04-17 18:28:56,997 - Epoch: [276][  150/  155]    Loss 3.066784    mAP 0.513039    
2023-04-17 18:29:01,056 - Epoch: [276][  155/  155]    Loss 3.069905    mAP 0.512118    
2023-04-17 18:29:01,129 - ==> mAP: 0.51212    Loss: 3.070

2023-04-17 18:29:01,134 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 18:29:01,134 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 18:29:01,171 - 

2023-04-17 18:29:01,171 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 18:29:12,218 - Epoch: [277][   50/  518]    Overall Loss 2.840773    Objective Loss 2.840773                                        LR 0.000001    Time 0.220884    
2023-04-17 18:29:22,392 - Epoch: [277][  100/  518]    Overall Loss 2.803883    Objective Loss 2.803883                                        LR 0.000001    Time 0.212167    
2023-04-17 18:29:32,516 - Epoch: [277][  150/  518]    Overall Loss 2.817914    Objective Loss 2.817914                                        LR 0.000001    Time 0.208929    
2023-04-17 18:29:42,570 - Epoch: [277][  200/  518]    Overall Loss 2.824158    Objective Loss 2.824158                                        LR 0.000001    Time 0.206956    
2023-04-17 18:29:52,635 - Epoch: [277][  250/  518]    Overall Loss 2.820543    Objective Loss 2.820543                                        LR 0.000001    Time 0.205819    
2023-04-17 18:30:02,721 - Epoch: [277][  300/  518]    Overall Loss 2.814678    Objective Loss 2.814678                                        LR 0.000001    Time 0.205131    
2023-04-17 18:30:12,835 - Epoch: [277][  350/  518]    Overall Loss 2.816696    Objective Loss 2.816696                                        LR 0.000001    Time 0.204719    
2023-04-17 18:30:22,935 - Epoch: [277][  400/  518]    Overall Loss 2.813537    Objective Loss 2.813537                                        LR 0.000001    Time 0.204376    
2023-04-17 18:30:33,007 - Epoch: [277][  450/  518]    Overall Loss 2.815951    Objective Loss 2.815951                                        LR 0.000001    Time 0.204047    
2023-04-17 18:30:43,112 - Epoch: [277][  500/  518]    Overall Loss 2.813781    Objective Loss 2.813781                                        LR 0.000001    Time 0.203849    
2023-04-17 18:30:46,616 - Epoch: [277][  518/  518]    Overall Loss 2.813753    Objective Loss 2.813753                                        LR 0.000001    Time 0.203529    
2023-04-17 18:30:46,698 - --- validate (epoch=277)-----------
2023-04-17 18:30:46,698 - 4952 samples (32 per mini-batch)
2023-04-17 18:31:32,970 - Epoch: [277][   50/  155]    Loss 3.098127    mAP 0.504053    
2023-04-17 18:32:18,533 - Epoch: [277][  100/  155]    Loss 3.079764    mAP 0.509539    
2023-04-17 18:33:00,727 - Epoch: [277][  150/  155]    Loss 3.076567    mAP 0.515043    
2023-04-17 18:33:04,364 - Epoch: [277][  155/  155]    Loss 3.071368    mAP 0.515642    
2023-04-17 18:33:04,440 - ==> mAP: 0.51564    Loss: 3.071

2023-04-17 18:33:04,445 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 18:33:04,445 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 18:33:04,482 - 

2023-04-17 18:33:04,482 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 18:33:15,490 - Epoch: [278][   50/  518]    Overall Loss 2.828104    Objective Loss 2.828104                                        LR 0.000001    Time 0.220105    
2023-04-17 18:33:25,578 - Epoch: [278][  100/  518]    Overall Loss 2.809964    Objective Loss 2.809964                                        LR 0.000001    Time 0.210908    
2023-04-17 18:33:35,614 - Epoch: [278][  150/  518]    Overall Loss 2.811037    Objective Loss 2.811037                                        LR 0.000001    Time 0.207502    
2023-04-17 18:33:45,705 - Epoch: [278][  200/  518]    Overall Loss 2.796480    Objective Loss 2.796480                                        LR 0.000001    Time 0.206074    
2023-04-17 18:33:55,784 - Epoch: [278][  250/  518]    Overall Loss 2.802355    Objective Loss 2.802355                                        LR 0.000001    Time 0.205172    
2023-04-17 18:34:05,835 - Epoch: [278][  300/  518]    Overall Loss 2.803687    Objective Loss 2.803687                                        LR 0.000001    Time 0.204473    
2023-04-17 18:34:15,922 - Epoch: [278][  350/  518]    Overall Loss 2.808556    Objective Loss 2.808556                                        LR 0.000001    Time 0.204080    
2023-04-17 18:34:25,938 - Epoch: [278][  400/  518]    Overall Loss 2.807293    Objective Loss 2.807293                                        LR 0.000001    Time 0.203604    
2023-04-17 18:34:36,012 - Epoch: [278][  450/  518]    Overall Loss 2.810189    Objective Loss 2.810189                                        LR 0.000001    Time 0.203366    
2023-04-17 18:34:46,129 - Epoch: [278][  500/  518]    Overall Loss 2.806679    Objective Loss 2.806679                                        LR 0.000001    Time 0.203260    
2023-04-17 18:34:49,605 - Epoch: [278][  518/  518]    Overall Loss 2.803860    Objective Loss 2.803860                                        LR 0.000001    Time 0.202907    
2023-04-17 18:34:49,687 - --- validate (epoch=278)-----------
2023-04-17 18:34:49,687 - 4952 samples (32 per mini-batch)
2023-04-17 18:35:32,562 - Epoch: [278][   50/  155]    Loss 3.023223    mAP 0.525309    
2023-04-17 18:36:18,375 - Epoch: [278][  100/  155]    Loss 3.078111    mAP 0.512458    
2023-04-17 18:37:02,787 - Epoch: [278][  150/  155]    Loss 3.061979    mAP 0.514933    
2023-04-17 18:37:06,888 - Epoch: [278][  155/  155]    Loss 3.062795    mAP 0.515723    
2023-04-17 18:37:06,966 - ==> mAP: 0.51572    Loss: 3.063

2023-04-17 18:37:06,970 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 18:37:06,970 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 18:37:07,006 - 

2023-04-17 18:37:07,006 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 18:37:17,860 - Epoch: [279][   50/  518]    Overall Loss 2.755725    Objective Loss 2.755725                                        LR 0.000001    Time 0.217015    
2023-04-17 18:37:27,882 - Epoch: [279][  100/  518]    Overall Loss 2.762410    Objective Loss 2.762410                                        LR 0.000001    Time 0.208714    
2023-04-17 18:37:37,980 - Epoch: [279][  150/  518]    Overall Loss 2.779322    Objective Loss 2.779322                                        LR 0.000001    Time 0.206452    
2023-04-17 18:37:48,115 - Epoch: [279][  200/  518]    Overall Loss 2.798881    Objective Loss 2.798881                                        LR 0.000001    Time 0.205505    
2023-04-17 18:37:58,156 - Epoch: [279][  250/  518]    Overall Loss 2.809723    Objective Loss 2.809723                                        LR 0.000001    Time 0.204564    
2023-04-17 18:38:08,274 - Epoch: [279][  300/  518]    Overall Loss 2.807575    Objective Loss 2.807575                                        LR 0.000001    Time 0.204192    
2023-04-17 18:38:18,355 - Epoch: [279][  350/  518]    Overall Loss 2.804935    Objective Loss 2.804935                                        LR 0.000001    Time 0.203821    
2023-04-17 18:38:28,476 - Epoch: [279][  400/  518]    Overall Loss 2.808764    Objective Loss 2.808764                                        LR 0.000001    Time 0.203641    
2023-04-17 18:38:38,528 - Epoch: [279][  450/  518]    Overall Loss 2.812088    Objective Loss 2.812088                                        LR 0.000001    Time 0.203350    
2023-04-17 18:38:48,756 - Epoch: [279][  500/  518]    Overall Loss 2.808113    Objective Loss 2.808113                                        LR 0.000001    Time 0.203467    
2023-04-17 18:38:52,284 - Epoch: [279][  518/  518]    Overall Loss 2.808256    Objective Loss 2.808256                                        LR 0.000001    Time 0.203206    
2023-04-17 18:38:52,364 - --- validate (epoch=279)-----------
2023-04-17 18:38:52,364 - 4952 samples (32 per mini-batch)
2023-04-17 18:39:37,018 - Epoch: [279][   50/  155]    Loss 3.054440    mAP 0.506862    
2023-04-17 18:40:23,461 - Epoch: [279][  100/  155]    Loss 3.074602    mAP 0.513582    
2023-04-17 18:41:08,728 - Epoch: [279][  150/  155]    Loss 3.067221    mAP 0.515895    
2023-04-17 18:41:13,338 - Epoch: [279][  155/  155]    Loss 3.067826    mAP 0.515102    
2023-04-17 18:41:13,417 - ==> mAP: 0.51510    Loss: 3.068

2023-04-17 18:41:13,421 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 18:41:13,421 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 18:41:13,458 - 

2023-04-17 18:41:13,458 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 18:41:24,318 - Epoch: [280][   50/  518]    Overall Loss 2.808225    Objective Loss 2.808225                                        LR 0.000001    Time 0.217142    
2023-04-17 18:41:34,446 - Epoch: [280][  100/  518]    Overall Loss 2.814853    Objective Loss 2.814853                                        LR 0.000001    Time 0.209839    
2023-04-17 18:41:44,564 - Epoch: [280][  150/  518]    Overall Loss 2.802546    Objective Loss 2.802546                                        LR 0.000001    Time 0.207334    
2023-04-17 18:41:54,736 - Epoch: [280][  200/  518]    Overall Loss 2.801495    Objective Loss 2.801495                                        LR 0.000001    Time 0.206350    
2023-04-17 18:42:04,914 - Epoch: [280][  250/  518]    Overall Loss 2.799824    Objective Loss 2.799824                                        LR 0.000001    Time 0.205789    
2023-04-17 18:42:15,041 - Epoch: [280][  300/  518]    Overall Loss 2.802963    Objective Loss 2.802963                                        LR 0.000001    Time 0.205242    
2023-04-17 18:42:25,141 - Epoch: [280][  350/  518]    Overall Loss 2.804602    Objective Loss 2.804602                                        LR 0.000001    Time 0.204773    
2023-04-17 18:42:35,321 - Epoch: [280][  400/  518]    Overall Loss 2.803736    Objective Loss 2.803736                                        LR 0.000001    Time 0.204622    
2023-04-17 18:42:45,527 - Epoch: [280][  450/  518]    Overall Loss 2.800492    Objective Loss 2.800492                                        LR 0.000001    Time 0.204563    
2023-04-17 18:42:55,706 - Epoch: [280][  500/  518]    Overall Loss 2.798761    Objective Loss 2.798761                                        LR 0.000001    Time 0.204462    
2023-04-17 18:42:59,228 - Epoch: [280][  518/  518]    Overall Loss 2.796755    Objective Loss 2.796755                                        LR 0.000001    Time 0.204155    
2023-04-17 18:42:59,309 - --- validate (epoch=280)-----------
2023-04-17 18:42:59,310 - 4952 samples (32 per mini-batch)
2023-04-17 18:43:43,804 - Epoch: [280][   50/  155]    Loss 3.075684    mAP 0.515867    
2023-04-17 18:44:28,688 - Epoch: [280][  100/  155]    Loss 3.062753    mAP 0.510996    
2023-04-17 18:45:15,300 - Epoch: [280][  150/  155]    Loss 3.067741    mAP 0.511156    
2023-04-17 18:45:19,592 - Epoch: [280][  155/  155]    Loss 3.065426    mAP 0.512569    
2023-04-17 18:45:19,671 - ==> mAP: 0.51257    Loss: 3.065

2023-04-17 18:45:19,675 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 18:45:19,675 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 18:45:19,711 - 

2023-04-17 18:45:19,711 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 18:45:30,531 - Epoch: [281][   50/  518]    Overall Loss 2.787925    Objective Loss 2.787925                                        LR 0.000001    Time 0.216350    
2023-04-17 18:45:40,659 - Epoch: [281][  100/  518]    Overall Loss 2.788118    Objective Loss 2.788118                                        LR 0.000001    Time 0.209434    
2023-04-17 18:45:50,659 - Epoch: [281][  150/  518]    Overall Loss 2.785976    Objective Loss 2.785976                                        LR 0.000001    Time 0.206280    
2023-04-17 18:46:00,851 - Epoch: [281][  200/  518]    Overall Loss 2.782172    Objective Loss 2.782172                                        LR 0.000001    Time 0.205659    
2023-04-17 18:46:10,991 - Epoch: [281][  250/  518]    Overall Loss 2.791138    Objective Loss 2.791138                                        LR 0.000001    Time 0.205082    
2023-04-17 18:46:21,066 - Epoch: [281][  300/  518]    Overall Loss 2.793366    Objective Loss 2.793366                                        LR 0.000001    Time 0.204481    
2023-04-17 18:46:31,107 - Epoch: [281][  350/  518]    Overall Loss 2.785954    Objective Loss 2.785954                                        LR 0.000001    Time 0.203953    
2023-04-17 18:46:41,105 - Epoch: [281][  400/  518]    Overall Loss 2.791111    Objective Loss 2.791111                                        LR 0.000001    Time 0.203451    
2023-04-17 18:46:51,231 - Epoch: [281][  450/  518]    Overall Loss 2.797416    Objective Loss 2.797416                                        LR 0.000001    Time 0.203344    
2023-04-17 18:47:01,343 - Epoch: [281][  500/  518]    Overall Loss 2.797509    Objective Loss 2.797509                                        LR 0.000001    Time 0.203231    
2023-04-17 18:47:04,895 - Epoch: [281][  518/  518]    Overall Loss 2.803081    Objective Loss 2.803081                                        LR 0.000001    Time 0.203024    
2023-04-17 18:47:04,974 - --- validate (epoch=281)-----------
2023-04-17 18:47:04,974 - 4952 samples (32 per mini-batch)
2023-04-17 18:47:49,244 - Epoch: [281][   50/  155]    Loss 3.057276    mAP 0.504179    
2023-04-17 18:48:34,788 - Epoch: [281][  100/  155]    Loss 3.067248    mAP 0.511934    
2023-04-17 18:49:19,021 - Epoch: [281][  150/  155]    Loss 3.067084    mAP 0.507610    
2023-04-17 18:49:23,031 - Epoch: [281][  155/  155]    Loss 3.065816    mAP 0.507297    
2023-04-17 18:49:23,141 - ==> mAP: 0.50730    Loss: 3.066

2023-04-17 18:49:23,145 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 18:49:23,145 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 18:49:23,181 - 

2023-04-17 18:49:23,181 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 18:49:34,252 - Epoch: [282][   50/  518]    Overall Loss 2.881888    Objective Loss 2.881888                                        LR 0.000001    Time 0.221368    
2023-04-17 18:49:44,354 - Epoch: [282][  100/  518]    Overall Loss 2.839916    Objective Loss 2.839916                                        LR 0.000001    Time 0.211689    
2023-04-17 18:49:54,479 - Epoch: [282][  150/  518]    Overall Loss 2.837713    Objective Loss 2.837713                                        LR 0.000001    Time 0.208617    
2023-04-17 18:50:04,688 - Epoch: [282][  200/  518]    Overall Loss 2.810195    Objective Loss 2.810195                                        LR 0.000001    Time 0.207500    
2023-04-17 18:50:14,796 - Epoch: [282][  250/  518]    Overall Loss 2.830792    Objective Loss 2.830792                                        LR 0.000001    Time 0.206423    
2023-04-17 18:50:24,969 - Epoch: [282][  300/  518]    Overall Loss 2.824722    Objective Loss 2.824722                                        LR 0.000001    Time 0.205926    
2023-04-17 18:50:35,146 - Epoch: [282][  350/  518]    Overall Loss 2.820542    Objective Loss 2.820542                                        LR 0.000001    Time 0.205580    
2023-04-17 18:50:45,236 - Epoch: [282][  400/  518]    Overall Loss 2.814121    Objective Loss 2.814121                                        LR 0.000001    Time 0.205103    
2023-04-17 18:50:55,256 - Epoch: [282][  450/  518]    Overall Loss 2.812228    Objective Loss 2.812228                                        LR 0.000001    Time 0.204577    
2023-04-17 18:51:05,396 - Epoch: [282][  500/  518]    Overall Loss 2.811086    Objective Loss 2.811086                                        LR 0.000001    Time 0.204396    
2023-04-17 18:51:08,914 - Epoch: [282][  518/  518]    Overall Loss 2.815927    Objective Loss 2.815927                                        LR 0.000001    Time 0.204084    
2023-04-17 18:51:08,997 - --- validate (epoch=282)-----------
2023-04-17 18:51:08,997 - 4952 samples (32 per mini-batch)
2023-04-17 18:51:53,360 - Epoch: [282][   50/  155]    Loss 3.057058    mAP 0.541452    
2023-04-17 18:52:37,322 - Epoch: [282][  100/  155]    Loss 3.061892    mAP 0.528303    
2023-04-17 18:53:21,038 - Epoch: [282][  150/  155]    Loss 3.070580    mAP 0.517497    
2023-04-17 18:53:24,960 - Epoch: [282][  155/  155]    Loss 3.071250    mAP 0.516435    
2023-04-17 18:53:25,030 - ==> mAP: 0.51643    Loss: 3.071

2023-04-17 18:53:25,034 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 18:53:25,035 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 18:53:25,071 - 

2023-04-17 18:53:25,072 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 18:53:35,921 - Epoch: [283][   50/  518]    Overall Loss 2.785589    Objective Loss 2.785589                                        LR 0.000001    Time 0.216928    
2023-04-17 18:53:46,074 - Epoch: [283][  100/  518]    Overall Loss 2.787705    Objective Loss 2.787705                                        LR 0.000001    Time 0.209977    
2023-04-17 18:53:56,227 - Epoch: [283][  150/  518]    Overall Loss 2.774222    Objective Loss 2.774222                                        LR 0.000001    Time 0.207664    
2023-04-17 18:54:06,411 - Epoch: [283][  200/  518]    Overall Loss 2.788004    Objective Loss 2.788004                                        LR 0.000001    Time 0.206661    
2023-04-17 18:54:16,528 - Epoch: [283][  250/  518]    Overall Loss 2.801820    Objective Loss 2.801820                                        LR 0.000001    Time 0.205792    
2023-04-17 18:54:26,656 - Epoch: [283][  300/  518]    Overall Loss 2.796557    Objective Loss 2.796557                                        LR 0.000001    Time 0.205246    
2023-04-17 18:54:36,723 - Epoch: [283][  350/  518]    Overall Loss 2.799321    Objective Loss 2.799321                                        LR 0.000001    Time 0.204683    
2023-04-17 18:54:46,819 - Epoch: [283][  400/  518]    Overall Loss 2.802835    Objective Loss 2.802835                                        LR 0.000001    Time 0.204334    
2023-04-17 18:54:57,007 - Epoch: [283][  450/  518]    Overall Loss 2.803596    Objective Loss 2.803596                                        LR 0.000001    Time 0.204267    
2023-04-17 18:55:07,100 - Epoch: [283][  500/  518]    Overall Loss 2.799528    Objective Loss 2.799528                                        LR 0.000001    Time 0.204024    
2023-04-17 18:55:10,613 - Epoch: [283][  518/  518]    Overall Loss 2.797524    Objective Loss 2.797524                                        LR 0.000001    Time 0.203714    
2023-04-17 18:55:10,694 - --- validate (epoch=283)-----------
2023-04-17 18:55:10,694 - 4952 samples (32 per mini-batch)
2023-04-17 18:55:53,771 - Epoch: [283][   50/  155]    Loss 3.097001    mAP 0.516449    
2023-04-17 18:56:38,518 - Epoch: [283][  100/  155]    Loss 3.070022    mAP 0.513741    
2023-04-17 18:57:23,423 - Epoch: [283][  150/  155]    Loss 3.066885    mAP 0.519807    
2023-04-17 18:57:27,316 - Epoch: [283][  155/  155]    Loss 3.062806    mAP 0.519700    
2023-04-17 18:57:27,392 - ==> mAP: 0.51970    Loss: 3.063

2023-04-17 18:57:27,397 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 18:57:27,397 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 18:57:27,434 - 

2023-04-17 18:57:27,434 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 18:57:38,328 - Epoch: [284][   50/  518]    Overall Loss 2.813714    Objective Loss 2.813714                                        LR 0.000001    Time 0.217830    
2023-04-17 18:57:48,483 - Epoch: [284][  100/  518]    Overall Loss 2.846310    Objective Loss 2.846310                                        LR 0.000001    Time 0.210443    
2023-04-17 18:57:58,569 - Epoch: [284][  150/  518]    Overall Loss 2.821845    Objective Loss 2.821845                                        LR 0.000001    Time 0.207529    
2023-04-17 18:58:08,632 - Epoch: [284][  200/  518]    Overall Loss 2.822847    Objective Loss 2.822847                                        LR 0.000001    Time 0.205953    
2023-04-17 18:58:18,779 - Epoch: [284][  250/  518]    Overall Loss 2.817796    Objective Loss 2.817796                                        LR 0.000001    Time 0.205345    
2023-04-17 18:58:28,819 - Epoch: [284][  300/  518]    Overall Loss 2.811015    Objective Loss 2.811015                                        LR 0.000001    Time 0.204584    
2023-04-17 18:58:38,851 - Epoch: [284][  350/  518]    Overall Loss 2.815821    Objective Loss 2.815821                                        LR 0.000001    Time 0.204015    
2023-04-17 18:58:48,901 - Epoch: [284][  400/  518]    Overall Loss 2.808971    Objective Loss 2.808971                                        LR 0.000001    Time 0.203634    
2023-04-17 18:58:59,032 - Epoch: [284][  450/  518]    Overall Loss 2.805704    Objective Loss 2.805704                                        LR 0.000001    Time 0.203518    
2023-04-17 18:59:09,166 - Epoch: [284][  500/  518]    Overall Loss 2.803252    Objective Loss 2.803252                                        LR 0.000001    Time 0.203432    
2023-04-17 18:59:12,658 - Epoch: [284][  518/  518]    Overall Loss 2.801615    Objective Loss 2.801615                                        LR 0.000001    Time 0.203103    
2023-04-17 18:59:12,739 - --- validate (epoch=284)-----------
2023-04-17 18:59:12,740 - 4952 samples (32 per mini-batch)
2023-04-17 18:59:58,880 - Epoch: [284][   50/  155]    Loss 3.071992    mAP 0.505181    
2023-04-17 19:00:43,202 - Epoch: [284][  100/  155]    Loss 3.076674    mAP 0.506808    
2023-04-17 19:01:25,785 - Epoch: [284][  150/  155]    Loss 3.071865    mAP 0.520636    
2023-04-17 19:01:29,869 - Epoch: [284][  155/  155]    Loss 3.068649    mAP 0.520932    
2023-04-17 19:01:29,948 - ==> mAP: 0.52093    Loss: 3.069

2023-04-17 19:01:29,953 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 19:01:29,953 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 19:01:29,988 - 

2023-04-17 19:01:29,989 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 19:01:40,957 - Epoch: [285][   50/  518]    Overall Loss 2.797748    Objective Loss 2.797748                                        LR 0.000001    Time 0.219322    
2023-04-17 19:01:50,964 - Epoch: [285][  100/  518]    Overall Loss 2.801184    Objective Loss 2.801184                                        LR 0.000001    Time 0.209710    
2023-04-17 19:02:01,088 - Epoch: [285][  150/  518]    Overall Loss 2.797510    Objective Loss 2.797510                                        LR 0.000001    Time 0.207289    
2023-04-17 19:02:11,209 - Epoch: [285][  200/  518]    Overall Loss 2.798573    Objective Loss 2.798573                                        LR 0.000001    Time 0.206066    
2023-04-17 19:02:21,344 - Epoch: [285][  250/  518]    Overall Loss 2.792100    Objective Loss 2.792100                                        LR 0.000001    Time 0.205386    
2023-04-17 19:02:31,368 - Epoch: [285][  300/  518]    Overall Loss 2.796418    Objective Loss 2.796418                                        LR 0.000001    Time 0.204563    
2023-04-17 19:02:41,473 - Epoch: [285][  350/  518]    Overall Loss 2.793135    Objective Loss 2.793135                                        LR 0.000001    Time 0.204206    
2023-04-17 19:02:51,611 - Epoch: [285][  400/  518]    Overall Loss 2.795805    Objective Loss 2.795805                                        LR 0.000001    Time 0.204022    
2023-04-17 19:03:01,806 - Epoch: [285][  450/  518]    Overall Loss 2.795473    Objective Loss 2.795473                                        LR 0.000001    Time 0.204006    
2023-04-17 19:03:11,890 - Epoch: [285][  500/  518]    Overall Loss 2.794053    Objective Loss 2.794053                                        LR 0.000001    Time 0.203768    
2023-04-17 19:03:15,381 - Epoch: [285][  518/  518]    Overall Loss 2.795252    Objective Loss 2.795252                                        LR 0.000001    Time 0.203427    
2023-04-17 19:03:15,462 - --- validate (epoch=285)-----------
2023-04-17 19:03:15,462 - 4952 samples (32 per mini-batch)
2023-04-17 19:04:01,407 - Epoch: [285][   50/  155]    Loss 3.078377    mAP 0.507092    
2023-04-17 19:04:44,570 - Epoch: [285][  100/  155]    Loss 3.058020    mAP 0.515600    
2023-04-17 19:05:30,001 - Epoch: [285][  150/  155]    Loss 3.066504    mAP 0.512640    
2023-04-17 19:05:34,316 - Epoch: [285][  155/  155]    Loss 3.066999    mAP 0.510072    
2023-04-17 19:05:34,393 - ==> mAP: 0.51007    Loss: 3.067

2023-04-17 19:05:34,398 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 19:05:34,398 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 19:05:34,435 - 

2023-04-17 19:05:34,435 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 19:05:45,342 - Epoch: [286][   50/  518]    Overall Loss 2.816401    Objective Loss 2.816401                                        LR 0.000001    Time 0.218083    
2023-04-17 19:05:55,423 - Epoch: [286][  100/  518]    Overall Loss 2.807467    Objective Loss 2.807467                                        LR 0.000001    Time 0.209833    
2023-04-17 19:06:05,549 - Epoch: [286][  150/  518]    Overall Loss 2.810037    Objective Loss 2.810037                                        LR 0.000001    Time 0.207383    
2023-04-17 19:06:15,691 - Epoch: [286][  200/  518]    Overall Loss 2.825004    Objective Loss 2.825004                                        LR 0.000001    Time 0.206244    
2023-04-17 19:06:25,756 - Epoch: [286][  250/  518]    Overall Loss 2.817296    Objective Loss 2.817296                                        LR 0.000001    Time 0.205248    
2023-04-17 19:06:35,797 - Epoch: [286][  300/  518]    Overall Loss 2.807317    Objective Loss 2.807317                                        LR 0.000001    Time 0.204504    
2023-04-17 19:06:45,908 - Epoch: [286][  350/  518]    Overall Loss 2.809074    Objective Loss 2.809074                                        LR 0.000001    Time 0.204172    
2023-04-17 19:06:56,015 - Epoch: [286][  400/  518]    Overall Loss 2.810064    Objective Loss 2.810064                                        LR 0.000001    Time 0.203915    
2023-04-17 19:07:06,145 - Epoch: [286][  450/  518]    Overall Loss 2.812345    Objective Loss 2.812345                                        LR 0.000001    Time 0.203766    
2023-04-17 19:07:16,227 - Epoch: [286][  500/  518]    Overall Loss 2.812042    Objective Loss 2.812042                                        LR 0.000001    Time 0.203551    
2023-04-17 19:07:19,695 - Epoch: [286][  518/  518]    Overall Loss 2.813074    Objective Loss 2.813074                                        LR 0.000001    Time 0.203171    
2023-04-17 19:07:19,777 - --- validate (epoch=286)-----------
2023-04-17 19:07:19,778 - 4952 samples (32 per mini-batch)
2023-04-17 19:08:03,903 - Epoch: [286][   50/  155]    Loss 3.058315    mAP 0.522795    
2023-04-17 19:08:47,377 - Epoch: [286][  100/  155]    Loss 3.048933    mAP 0.514760    
2023-04-17 19:09:32,874 - Epoch: [286][  150/  155]    Loss 3.062492    mAP 0.510357    
2023-04-17 19:09:37,133 - Epoch: [286][  155/  155]    Loss 3.063948    mAP 0.509584    
2023-04-17 19:09:37,211 - ==> mAP: 0.50958    Loss: 3.064

2023-04-17 19:09:37,215 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 19:09:37,215 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 19:09:37,251 - 

2023-04-17 19:09:37,251 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 19:09:48,054 - Epoch: [287][   50/  518]    Overall Loss 2.793290    Objective Loss 2.793290                                        LR 0.000001    Time 0.216007    
2023-04-17 19:09:58,189 - Epoch: [287][  100/  518]    Overall Loss 2.806174    Objective Loss 2.806174                                        LR 0.000001    Time 0.209335    
2023-04-17 19:10:08,343 - Epoch: [287][  150/  518]    Overall Loss 2.807290    Objective Loss 2.807290                                        LR 0.000001    Time 0.207241    
2023-04-17 19:10:18,423 - Epoch: [287][  200/  518]    Overall Loss 2.807071    Objective Loss 2.807071                                        LR 0.000001    Time 0.205823    
2023-04-17 19:10:28,609 - Epoch: [287][  250/  518]    Overall Loss 2.821182    Objective Loss 2.821182                                        LR 0.000001    Time 0.205395    
2023-04-17 19:10:38,695 - Epoch: [287][  300/  518]    Overall Loss 2.818916    Objective Loss 2.818916                                        LR 0.000001    Time 0.204778    
2023-04-17 19:10:48,737 - Epoch: [287][  350/  518]    Overall Loss 2.816052    Objective Loss 2.816052                                        LR 0.000001    Time 0.204210    
2023-04-17 19:10:58,824 - Epoch: [287][  400/  518]    Overall Loss 2.810703    Objective Loss 2.810703                                        LR 0.000001    Time 0.203898    
2023-04-17 19:11:08,970 - Epoch: [287][  450/  518]    Overall Loss 2.804529    Objective Loss 2.804529                                        LR 0.000001    Time 0.203787    
2023-04-17 19:11:19,091 - Epoch: [287][  500/  518]    Overall Loss 2.808034    Objective Loss 2.808034                                        LR 0.000001    Time 0.203646    
2023-04-17 19:11:22,594 - Epoch: [287][  518/  518]    Overall Loss 2.809841    Objective Loss 2.809841                                        LR 0.000001    Time 0.203332    
2023-04-17 19:11:22,675 - --- validate (epoch=287)-----------
2023-04-17 19:11:22,675 - 4952 samples (32 per mini-batch)
2023-04-17 19:12:07,460 - Epoch: [287][   50/  155]    Loss 3.072812    mAP 0.509792    
2023-04-17 19:12:51,214 - Epoch: [287][  100/  155]    Loss 3.055582    mAP 0.515403    
2023-04-17 19:13:35,838 - Epoch: [287][  150/  155]    Loss 3.069810    mAP 0.517466    
2023-04-17 19:13:40,250 - Epoch: [287][  155/  155]    Loss 3.068075    mAP 0.517744    
2023-04-17 19:13:40,330 - ==> mAP: 0.51774    Loss: 3.068

2023-04-17 19:13:40,333 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 19:13:40,334 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 19:13:40,370 - 

2023-04-17 19:13:40,370 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 19:13:51,319 - Epoch: [288][   50/  518]    Overall Loss 2.838794    Objective Loss 2.838794                                        LR 0.000001    Time 0.218918    
2023-04-17 19:14:01,419 - Epoch: [288][  100/  518]    Overall Loss 2.799206    Objective Loss 2.799206                                        LR 0.000001    Time 0.210450    
2023-04-17 19:14:11,543 - Epoch: [288][  150/  518]    Overall Loss 2.786255    Objective Loss 2.786255                                        LR 0.000001    Time 0.207783    
2023-04-17 19:14:21,634 - Epoch: [288][  200/  518]    Overall Loss 2.782789    Objective Loss 2.782789                                        LR 0.000001    Time 0.206284    
2023-04-17 19:14:31,755 - Epoch: [288][  250/  518]    Overall Loss 2.790954    Objective Loss 2.790954                                        LR 0.000001    Time 0.205504    
2023-04-17 19:14:41,907 - Epoch: [288][  300/  518]    Overall Loss 2.791995    Objective Loss 2.791995                                        LR 0.000001    Time 0.205087    
2023-04-17 19:14:51,943 - Epoch: [288][  350/  518]    Overall Loss 2.795466    Objective Loss 2.795466                                        LR 0.000001    Time 0.204459    
2023-04-17 19:15:02,092 - Epoch: [288][  400/  518]    Overall Loss 2.792771    Objective Loss 2.792771                                        LR 0.000001    Time 0.204272    
2023-04-17 19:15:12,274 - Epoch: [288][  450/  518]    Overall Loss 2.795301    Objective Loss 2.795301                                        LR 0.000001    Time 0.204198    
2023-04-17 19:15:22,430 - Epoch: [288][  500/  518]    Overall Loss 2.802967    Objective Loss 2.802967                                        LR 0.000001    Time 0.204087    
2023-04-17 19:15:25,916 - Epoch: [288][  518/  518]    Overall Loss 2.804242    Objective Loss 2.804242                                        LR 0.000001    Time 0.203723    
2023-04-17 19:15:25,995 - --- validate (epoch=288)-----------
2023-04-17 19:15:25,996 - 4952 samples (32 per mini-batch)
2023-04-17 19:16:11,083 - Epoch: [288][   50/  155]    Loss 3.097781    mAP 0.524084    
2023-04-17 19:16:56,155 - Epoch: [288][  100/  155]    Loss 3.100729    mAP 0.514758    
2023-04-17 19:17:40,027 - Epoch: [288][  150/  155]    Loss 3.072190    mAP 0.521026    
2023-04-17 19:17:44,183 - Epoch: [288][  155/  155]    Loss 3.067902    mAP 0.520096    
2023-04-17 19:17:44,261 - ==> mAP: 0.52010    Loss: 3.068

2023-04-17 19:17:44,265 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 19:17:44,265 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 19:17:44,301 - 

2023-04-17 19:17:44,302 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 19:17:55,052 - Epoch: [289][   50/  518]    Overall Loss 2.777534    Objective Loss 2.777534                                        LR 0.000001    Time 0.214948    
2023-04-17 19:18:05,189 - Epoch: [289][  100/  518]    Overall Loss 2.784906    Objective Loss 2.784906                                        LR 0.000001    Time 0.208827    
2023-04-17 19:18:15,348 - Epoch: [289][  150/  518]    Overall Loss 2.803683    Objective Loss 2.803683                                        LR 0.000001    Time 0.206937    
2023-04-17 19:18:25,455 - Epoch: [289][  200/  518]    Overall Loss 2.804874    Objective Loss 2.804874                                        LR 0.000001    Time 0.205729    
2023-04-17 19:18:35,549 - Epoch: [289][  250/  518]    Overall Loss 2.811390    Objective Loss 2.811390                                        LR 0.000001    Time 0.204954    
2023-04-17 19:18:45,591 - Epoch: [289][  300/  518]    Overall Loss 2.819945    Objective Loss 2.819945                                        LR 0.000001    Time 0.204263    
2023-04-17 19:18:55,637 - Epoch: [289][  350/  518]    Overall Loss 2.819063    Objective Loss 2.819063                                        LR 0.000001    Time 0.203782    
2023-04-17 19:19:05,655 - Epoch: [289][  400/  518]    Overall Loss 2.812011    Objective Loss 2.812011                                        LR 0.000001    Time 0.203349    
2023-04-17 19:19:15,649 - Epoch: [289][  450/  518]    Overall Loss 2.810160    Objective Loss 2.810160                                        LR 0.000001    Time 0.202960    
2023-04-17 19:19:25,800 - Epoch: [289][  500/  518]    Overall Loss 2.806666    Objective Loss 2.806666                                        LR 0.000001    Time 0.202963    
2023-04-17 19:19:29,304 - Epoch: [289][  518/  518]    Overall Loss 2.804735    Objective Loss 2.804735                                        LR 0.000001    Time 0.202675    
2023-04-17 19:19:29,384 - --- validate (epoch=289)-----------
2023-04-17 19:19:29,384 - 4952 samples (32 per mini-batch)
2023-04-17 19:20:15,675 - Epoch: [289][   50/  155]    Loss 3.053294    mAP 0.511586    
2023-04-17 19:21:01,610 - Epoch: [289][  100/  155]    Loss 3.063288    mAP 0.526062    
2023-04-17 19:21:47,364 - Epoch: [289][  150/  155]    Loss 3.065265    mAP 0.515948    
2023-04-17 19:21:51,949 - Epoch: [289][  155/  155]    Loss 3.061725    mAP 0.515180    
2023-04-17 19:21:52,043 - ==> mAP: 0.51518    Loss: 3.062

2023-04-17 19:21:52,047 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 19:21:52,047 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 19:21:52,083 - 

2023-04-17 19:21:52,083 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 19:22:02,977 - Epoch: [290][   50/  518]    Overall Loss 2.788620    Objective Loss 2.788620                                        LR 0.000001    Time 0.217825    
2023-04-17 19:22:12,984 - Epoch: [290][  100/  518]    Overall Loss 2.789660    Objective Loss 2.789660                                        LR 0.000001    Time 0.208967    
2023-04-17 19:22:23,111 - Epoch: [290][  150/  518]    Overall Loss 2.788558    Objective Loss 2.788558                                        LR 0.000001    Time 0.206814    
2023-04-17 19:22:33,275 - Epoch: [290][  200/  518]    Overall Loss 2.797560    Objective Loss 2.797560                                        LR 0.000001    Time 0.205923    
2023-04-17 19:22:43,393 - Epoch: [290][  250/  518]    Overall Loss 2.807411    Objective Loss 2.807411                                        LR 0.000001    Time 0.205201    
2023-04-17 19:22:53,485 - Epoch: [290][  300/  518]    Overall Loss 2.803300    Objective Loss 2.803300                                        LR 0.000001    Time 0.204638    
2023-04-17 19:23:03,640 - Epoch: [290][  350/  518]    Overall Loss 2.804565    Objective Loss 2.804565                                        LR 0.000001    Time 0.204413    
2023-04-17 19:23:13,725 - Epoch: [290][  400/  518]    Overall Loss 2.809132    Objective Loss 2.809132                                        LR 0.000001    Time 0.204069    
2023-04-17 19:23:23,798 - Epoch: [290][  450/  518]    Overall Loss 2.806273    Objective Loss 2.806273                                        LR 0.000001    Time 0.203776    
2023-04-17 19:23:33,907 - Epoch: [290][  500/  518]    Overall Loss 2.800645    Objective Loss 2.800645                                        LR 0.000001    Time 0.203613    
2023-04-17 19:23:37,449 - Epoch: [290][  518/  518]    Overall Loss 2.805188    Objective Loss 2.805188                                        LR 0.000001    Time 0.203375    
2023-04-17 19:23:37,530 - --- validate (epoch=290)-----------
2023-04-17 19:23:37,530 - 4952 samples (32 per mini-batch)
2023-04-17 19:24:23,482 - Epoch: [290][   50/  155]    Loss 3.072682    mAP 0.497886    
2023-04-17 19:25:06,702 - Epoch: [290][  100/  155]    Loss 3.061667    mAP 0.514869    
2023-04-17 19:25:50,913 - Epoch: [290][  150/  155]    Loss 3.069474    mAP 0.517206    
2023-04-17 19:25:55,468 - Epoch: [290][  155/  155]    Loss 3.071211    mAP 0.515894    
2023-04-17 19:25:55,546 - ==> mAP: 0.51589    Loss: 3.071

2023-04-17 19:25:55,550 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 19:25:55,550 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 19:25:55,586 - 

2023-04-17 19:25:55,586 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 19:26:06,449 - Epoch: [291][   50/  518]    Overall Loss 2.793837    Objective Loss 2.793837                                        LR 0.000001    Time 0.217190    
2023-04-17 19:26:16,525 - Epoch: [291][  100/  518]    Overall Loss 2.812998    Objective Loss 2.812998                                        LR 0.000001    Time 0.209346    
2023-04-17 19:26:26,680 - Epoch: [291][  150/  518]    Overall Loss 2.816129    Objective Loss 2.816129                                        LR 0.000001    Time 0.207250    
2023-04-17 19:26:36,824 - Epoch: [291][  200/  518]    Overall Loss 2.812469    Objective Loss 2.812469                                        LR 0.000001    Time 0.206151    
2023-04-17 19:26:46,861 - Epoch: [291][  250/  518]    Overall Loss 2.804262    Objective Loss 2.804262                                        LR 0.000001    Time 0.205062    
2023-04-17 19:26:56,975 - Epoch: [291][  300/  518]    Overall Loss 2.804169    Objective Loss 2.804169                                        LR 0.000001    Time 0.204594    
2023-04-17 19:27:07,032 - Epoch: [291][  350/  518]    Overall Loss 2.806719    Objective Loss 2.806719                                        LR 0.000001    Time 0.204096    
2023-04-17 19:27:17,223 - Epoch: [291][  400/  518]    Overall Loss 2.801996    Objective Loss 2.801996                                        LR 0.000001    Time 0.204056    
2023-04-17 19:27:27,295 - Epoch: [291][  450/  518]    Overall Loss 2.802725    Objective Loss 2.802725                                        LR 0.000001    Time 0.203763    
2023-04-17 19:27:37,328 - Epoch: [291][  500/  518]    Overall Loss 2.800075    Objective Loss 2.800075                                        LR 0.000001    Time 0.203450    
2023-04-17 19:27:40,896 - Epoch: [291][  518/  518]    Overall Loss 2.802484    Objective Loss 2.802484                                        LR 0.000001    Time 0.203266    
2023-04-17 19:27:40,976 - --- validate (epoch=291)-----------
2023-04-17 19:27:40,976 - 4952 samples (32 per mini-batch)
2023-04-17 19:28:24,292 - Epoch: [291][   50/  155]    Loss 3.070323    mAP 0.518668    
2023-04-17 19:29:07,792 - Epoch: [291][  100/  155]    Loss 3.080964    mAP 0.516363    
2023-04-17 19:29:53,946 - Epoch: [291][  150/  155]    Loss 3.071111    mAP 0.515366    
2023-04-17 19:29:58,314 - Epoch: [291][  155/  155]    Loss 3.070239    mAP 0.516220    
2023-04-17 19:29:58,390 - ==> mAP: 0.51622    Loss: 3.070

2023-04-17 19:29:58,394 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 19:29:58,394 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 19:29:58,431 - 

2023-04-17 19:29:58,431 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 19:30:09,199 - Epoch: [292][   50/  518]    Overall Loss 2.815861    Objective Loss 2.815861                                        LR 0.000001    Time 0.215313    
2023-04-17 19:30:19,307 - Epoch: [292][  100/  518]    Overall Loss 2.839804    Objective Loss 2.839804                                        LR 0.000001    Time 0.208716    
2023-04-17 19:30:29,440 - Epoch: [292][  150/  518]    Overall Loss 2.812882    Objective Loss 2.812882                                        LR 0.000001    Time 0.206693    
2023-04-17 19:30:39,559 - Epoch: [292][  200/  518]    Overall Loss 2.805692    Objective Loss 2.805692                                        LR 0.000001    Time 0.205606    
2023-04-17 19:30:49,627 - Epoch: [292][  250/  518]    Overall Loss 2.807724    Objective Loss 2.807724                                        LR 0.000001    Time 0.204749    
2023-04-17 19:30:59,721 - Epoch: [292][  300/  518]    Overall Loss 2.808835    Objective Loss 2.808835                                        LR 0.000001    Time 0.204265    
2023-04-17 19:31:09,811 - Epoch: [292][  350/  518]    Overall Loss 2.809891    Objective Loss 2.809891                                        LR 0.000001    Time 0.203910    
2023-04-17 19:31:19,846 - Epoch: [292][  400/  518]    Overall Loss 2.808693    Objective Loss 2.808693                                        LR 0.000001    Time 0.203504    
2023-04-17 19:31:29,932 - Epoch: [292][  450/  518]    Overall Loss 2.802369    Objective Loss 2.802369                                        LR 0.000001    Time 0.203304    
2023-04-17 19:31:40,057 - Epoch: [292][  500/  518]    Overall Loss 2.803828    Objective Loss 2.803828                                        LR 0.000001    Time 0.203220    
2023-04-17 19:31:43,611 - Epoch: [292][  518/  518]    Overall Loss 2.803869    Objective Loss 2.803869                                        LR 0.000001    Time 0.203019    
2023-04-17 19:31:43,692 - --- validate (epoch=292)-----------
2023-04-17 19:31:43,693 - 4952 samples (32 per mini-batch)
2023-04-17 19:32:27,516 - Epoch: [292][   50/  155]    Loss 3.026564    mAP 0.520340    
2023-04-17 19:33:11,635 - Epoch: [292][  100/  155]    Loss 3.059946    mAP 0.515042    
2023-04-17 19:33:56,404 - Epoch: [292][  150/  155]    Loss 3.070978    mAP 0.515975    
2023-04-17 19:34:00,909 - Epoch: [292][  155/  155]    Loss 3.069425    mAP 0.515057    
2023-04-17 19:34:00,985 - ==> mAP: 0.51506    Loss: 3.069

2023-04-17 19:34:00,990 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 19:34:00,990 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 19:34:01,027 - 

2023-04-17 19:34:01,027 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 19:34:11,820 - Epoch: [293][   50/  518]    Overall Loss 2.814725    Objective Loss 2.814725                                        LR 0.000001    Time 0.215810    
2023-04-17 19:34:21,914 - Epoch: [293][  100/  518]    Overall Loss 2.775803    Objective Loss 2.775803                                        LR 0.000001    Time 0.208822    
2023-04-17 19:34:31,992 - Epoch: [293][  150/  518]    Overall Loss 2.787388    Objective Loss 2.787388                                        LR 0.000001    Time 0.206397    
2023-04-17 19:34:42,078 - Epoch: [293][  200/  518]    Overall Loss 2.796467    Objective Loss 2.796467                                        LR 0.000001    Time 0.205216    
2023-04-17 19:34:52,200 - Epoch: [293][  250/  518]    Overall Loss 2.797272    Objective Loss 2.797272                                        LR 0.000001    Time 0.204657    
2023-04-17 19:35:02,308 - Epoch: [293][  300/  518]    Overall Loss 2.804922    Objective Loss 2.804922                                        LR 0.000001    Time 0.204234    
2023-04-17 19:35:12,366 - Epoch: [293][  350/  518]    Overall Loss 2.802051    Objective Loss 2.802051                                        LR 0.000001    Time 0.203790    
2023-04-17 19:35:22,423 - Epoch: [293][  400/  518]    Overall Loss 2.811364    Objective Loss 2.811364                                        LR 0.000001    Time 0.203457    
2023-04-17 19:35:32,504 - Epoch: [293][  450/  518]    Overall Loss 2.811900    Objective Loss 2.811900                                        LR 0.000001    Time 0.203248    
2023-04-17 19:35:42,627 - Epoch: [293][  500/  518]    Overall Loss 2.808288    Objective Loss 2.808288                                        LR 0.000001    Time 0.203167    
2023-04-17 19:35:46,145 - Epoch: [293][  518/  518]    Overall Loss 2.809638    Objective Loss 2.809638                                        LR 0.000001    Time 0.202897    
2023-04-17 19:35:46,223 - --- validate (epoch=293)-----------
2023-04-17 19:35:46,224 - 4952 samples (32 per mini-batch)
2023-04-17 19:36:30,846 - Epoch: [293][   50/  155]    Loss 3.073336    mAP 0.519646    
2023-04-17 19:37:14,577 - Epoch: [293][  100/  155]    Loss 3.090806    mAP 0.507288    
2023-04-17 19:37:57,794 - Epoch: [293][  150/  155]    Loss 3.066352    mAP 0.514033    
2023-04-17 19:38:01,724 - Epoch: [293][  155/  155]    Loss 3.064915    mAP 0.512909    
2023-04-17 19:38:01,805 - ==> mAP: 0.51291    Loss: 3.065

2023-04-17 19:38:01,809 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 19:38:01,809 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 19:38:01,846 - 

2023-04-17 19:38:01,846 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 19:38:12,607 - Epoch: [294][   50/  518]    Overall Loss 2.803841    Objective Loss 2.803841                                        LR 0.000001    Time 0.215165    
2023-04-17 19:38:22,761 - Epoch: [294][  100/  518]    Overall Loss 2.809855    Objective Loss 2.809855                                        LR 0.000001    Time 0.209107    
2023-04-17 19:38:32,803 - Epoch: [294][  150/  518]    Overall Loss 2.813265    Objective Loss 2.813265                                        LR 0.000001    Time 0.206341    
2023-04-17 19:38:42,871 - Epoch: [294][  200/  518]    Overall Loss 2.813106    Objective Loss 2.813106                                        LR 0.000001    Time 0.205089    
2023-04-17 19:38:53,028 - Epoch: [294][  250/  518]    Overall Loss 2.819649    Objective Loss 2.819649                                        LR 0.000001    Time 0.204693    
2023-04-17 19:39:03,172 - Epoch: [294][  300/  518]    Overall Loss 2.820816    Objective Loss 2.820816                                        LR 0.000001    Time 0.204387    
2023-04-17 19:39:13,237 - Epoch: [294][  350/  518]    Overall Loss 2.818000    Objective Loss 2.818000                                        LR 0.000001    Time 0.203942    
2023-04-17 19:39:23,385 - Epoch: [294][  400/  518]    Overall Loss 2.825073    Objective Loss 2.825073                                        LR 0.000001    Time 0.203815    
2023-04-17 19:39:33,465 - Epoch: [294][  450/  518]    Overall Loss 2.819423    Objective Loss 2.819423                                        LR 0.000001    Time 0.203566    
2023-04-17 19:39:43,565 - Epoch: [294][  500/  518]    Overall Loss 2.814188    Objective Loss 2.814188                                        LR 0.000001    Time 0.203406    
2023-04-17 19:39:47,107 - Epoch: [294][  518/  518]    Overall Loss 2.813525    Objective Loss 2.813525                                        LR 0.000001    Time 0.203174    
2023-04-17 19:39:47,190 - --- validate (epoch=294)-----------
2023-04-17 19:39:47,190 - 4952 samples (32 per mini-batch)
2023-04-17 19:40:32,389 - Epoch: [294][   50/  155]    Loss 3.121460    mAP 0.518009    
2023-04-17 19:41:17,538 - Epoch: [294][  100/  155]    Loss 3.098264    mAP 0.514757    
2023-04-17 19:42:03,534 - Epoch: [294][  150/  155]    Loss 3.063264    mAP 0.519871    
2023-04-17 19:42:08,042 - Epoch: [294][  155/  155]    Loss 3.065295    mAP 0.518621    
2023-04-17 19:42:08,121 - ==> mAP: 0.51862    Loss: 3.065

2023-04-17 19:42:08,125 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 19:42:08,125 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 19:42:08,162 - 

2023-04-17 19:42:08,162 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 19:42:18,952 - Epoch: [295][   50/  518]    Overall Loss 2.779565    Objective Loss 2.779565                                        LR 0.000001    Time 0.215752    
2023-04-17 19:42:29,071 - Epoch: [295][  100/  518]    Overall Loss 2.776032    Objective Loss 2.776032                                        LR 0.000001    Time 0.209055    
2023-04-17 19:42:39,220 - Epoch: [295][  150/  518]    Overall Loss 2.787340    Objective Loss 2.787340                                        LR 0.000001    Time 0.207018    
2023-04-17 19:42:49,323 - Epoch: [295][  200/  518]    Overall Loss 2.780930    Objective Loss 2.780930                                        LR 0.000001    Time 0.205772    
2023-04-17 19:42:59,409 - Epoch: [295][  250/  518]    Overall Loss 2.787763    Objective Loss 2.787763                                        LR 0.000001    Time 0.204955    
2023-04-17 19:43:09,442 - Epoch: [295][  300/  518]    Overall Loss 2.786367    Objective Loss 2.786367                                        LR 0.000001    Time 0.204234    
2023-04-17 19:43:19,489 - Epoch: [295][  350/  518]    Overall Loss 2.791488    Objective Loss 2.791488                                        LR 0.000001    Time 0.203759    
2023-04-17 19:43:29,671 - Epoch: [295][  400/  518]    Overall Loss 2.792042    Objective Loss 2.792042                                        LR 0.000001    Time 0.203739    
2023-04-17 19:43:39,769 - Epoch: [295][  450/  518]    Overall Loss 2.789562    Objective Loss 2.789562                                        LR 0.000001    Time 0.203538    
2023-04-17 19:43:49,849 - Epoch: [295][  500/  518]    Overall Loss 2.789474    Objective Loss 2.789474                                        LR 0.000001    Time 0.203342    
2023-04-17 19:43:53,363 - Epoch: [295][  518/  518]    Overall Loss 2.792213    Objective Loss 2.792213                                        LR 0.000001    Time 0.203058    
2023-04-17 19:43:53,444 - --- validate (epoch=295)-----------
2023-04-17 19:43:53,444 - 4952 samples (32 per mini-batch)
2023-04-17 19:44:36,339 - Epoch: [295][   50/  155]    Loss 3.070072    mAP 0.538910    
2023-04-17 19:45:20,917 - Epoch: [295][  100/  155]    Loss 3.068108    mAP 0.520566    
2023-04-17 19:46:03,778 - Epoch: [295][  150/  155]    Loss 3.064336    mAP 0.524334    
2023-04-17 19:46:08,306 - Epoch: [295][  155/  155]    Loss 3.066753    mAP 0.523384    
2023-04-17 19:46:08,383 - ==> mAP: 0.52338    Loss: 3.067

2023-04-17 19:46:08,387 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 19:46:08,387 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 19:46:08,423 - 

2023-04-17 19:46:08,424 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 19:46:19,407 - Epoch: [296][   50/  518]    Overall Loss 2.785097    Objective Loss 2.785097                                        LR 0.000001    Time 0.219607    
2023-04-17 19:46:29,469 - Epoch: [296][  100/  518]    Overall Loss 2.792258    Objective Loss 2.792258                                        LR 0.000001    Time 0.210410    
2023-04-17 19:46:39,575 - Epoch: [296][  150/  518]    Overall Loss 2.793472    Objective Loss 2.793472                                        LR 0.000001    Time 0.207635    
2023-04-17 19:46:49,660 - Epoch: [296][  200/  518]    Overall Loss 2.801563    Objective Loss 2.801563                                        LR 0.000001    Time 0.206143    
2023-04-17 19:46:59,791 - Epoch: [296][  250/  518]    Overall Loss 2.812523    Objective Loss 2.812523                                        LR 0.000001    Time 0.205433    
2023-04-17 19:47:09,936 - Epoch: [296][  300/  518]    Overall Loss 2.813472    Objective Loss 2.813472                                        LR 0.000001    Time 0.205007    
2023-04-17 19:47:20,093 - Epoch: [296][  350/  518]    Overall Loss 2.802501    Objective Loss 2.802501                                        LR 0.000001    Time 0.204735    
2023-04-17 19:47:30,171 - Epoch: [296][  400/  518]    Overall Loss 2.804742    Objective Loss 2.804742                                        LR 0.000001    Time 0.204334    
2023-04-17 19:47:40,129 - Epoch: [296][  450/  518]    Overall Loss 2.803250    Objective Loss 2.803250                                        LR 0.000001    Time 0.203756    
2023-04-17 19:47:50,218 - Epoch: [296][  500/  518]    Overall Loss 2.806114    Objective Loss 2.806114                                        LR 0.000001    Time 0.203556    
2023-04-17 19:47:53,715 - Epoch: [296][  518/  518]    Overall Loss 2.808697    Objective Loss 2.808697                                        LR 0.000001    Time 0.203232    
2023-04-17 19:47:53,798 - --- validate (epoch=296)-----------
2023-04-17 19:47:53,798 - 4952 samples (32 per mini-batch)
2023-04-17 19:48:38,927 - Epoch: [296][   50/  155]    Loss 3.032236    mAP 0.540147    
2023-04-17 19:49:24,762 - Epoch: [296][  100/  155]    Loss 3.042375    mAP 0.524324    
2023-04-17 19:50:08,927 - Epoch: [296][  150/  155]    Loss 3.062937    mAP 0.516702    
2023-04-17 19:50:13,154 - Epoch: [296][  155/  155]    Loss 3.063542    mAP 0.517888    
2023-04-17 19:50:13,233 - ==> mAP: 0.51789    Loss: 3.064

2023-04-17 19:50:13,237 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 19:50:13,237 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 19:50:13,274 - 

2023-04-17 19:50:13,274 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 19:50:24,028 - Epoch: [297][   50/  518]    Overall Loss 2.796880    Objective Loss 2.796880                                        LR 0.000001    Time 0.215038    
2023-04-17 19:50:34,063 - Epoch: [297][  100/  518]    Overall Loss 2.809140    Objective Loss 2.809140                                        LR 0.000001    Time 0.207853    
2023-04-17 19:50:44,150 - Epoch: [297][  150/  518]    Overall Loss 2.814260    Objective Loss 2.814260                                        LR 0.000001    Time 0.205804    
2023-04-17 19:50:54,214 - Epoch: [297][  200/  518]    Overall Loss 2.814128    Objective Loss 2.814128                                        LR 0.000001    Time 0.204665    
2023-04-17 19:51:04,395 - Epoch: [297][  250/  518]    Overall Loss 2.808264    Objective Loss 2.808264                                        LR 0.000001    Time 0.204449    
2023-04-17 19:51:14,473 - Epoch: [297][  300/  518]    Overall Loss 2.817095    Objective Loss 2.817095                                        LR 0.000001    Time 0.203963    
2023-04-17 19:51:24,656 - Epoch: [297][  350/  518]    Overall Loss 2.803127    Objective Loss 2.803127                                        LR 0.000001    Time 0.203914    
2023-04-17 19:51:34,761 - Epoch: [297][  400/  518]    Overall Loss 2.801198    Objective Loss 2.801198                                        LR 0.000001    Time 0.203684    
2023-04-17 19:51:44,834 - Epoch: [297][  450/  518]    Overall Loss 2.803597    Objective Loss 2.803597                                        LR 0.000001    Time 0.203433    
2023-04-17 19:51:54,928 - Epoch: [297][  500/  518]    Overall Loss 2.802949    Objective Loss 2.802949                                        LR 0.000001    Time 0.203275    
2023-04-17 19:51:58,438 - Epoch: [297][  518/  518]    Overall Loss 2.804228    Objective Loss 2.804228                                        LR 0.000001    Time 0.202986    
2023-04-17 19:51:58,519 - --- validate (epoch=297)-----------
2023-04-17 19:51:58,520 - 4952 samples (32 per mini-batch)
2023-04-17 19:52:43,605 - Epoch: [297][   50/  155]    Loss 3.063360    mAP 0.515492    
2023-04-17 19:53:28,850 - Epoch: [297][  100/  155]    Loss 3.073755    mAP 0.521588    
2023-04-17 19:54:12,711 - Epoch: [297][  150/  155]    Loss 3.060540    mAP 0.527350    
2023-04-17 19:54:17,212 - Epoch: [297][  155/  155]    Loss 3.064489    mAP 0.525013    
2023-04-17 19:54:17,291 - ==> mAP: 0.52501    Loss: 3.064

2023-04-17 19:54:17,295 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 19:54:17,295 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 19:54:17,332 - 

2023-04-17 19:54:17,332 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 19:54:28,226 - Epoch: [298][   50/  518]    Overall Loss 2.776414    Objective Loss 2.776414                                        LR 0.000001    Time 0.217819    
2023-04-17 19:54:38,337 - Epoch: [298][  100/  518]    Overall Loss 2.788203    Objective Loss 2.788203                                        LR 0.000001    Time 0.210003    
2023-04-17 19:54:48,479 - Epoch: [298][  150/  518]    Overall Loss 2.779748    Objective Loss 2.779748                                        LR 0.000001    Time 0.207606    
2023-04-17 19:54:58,526 - Epoch: [298][  200/  518]    Overall Loss 2.788906    Objective Loss 2.788906                                        LR 0.000001    Time 0.205931    
2023-04-17 19:55:08,668 - Epoch: [298][  250/  518]    Overall Loss 2.795500    Objective Loss 2.795500                                        LR 0.000001    Time 0.205309    
2023-04-17 19:55:18,775 - Epoch: [298][  300/  518]    Overall Loss 2.801552    Objective Loss 2.801552                                        LR 0.000001    Time 0.204774    
2023-04-17 19:55:28,841 - Epoch: [298][  350/  518]    Overall Loss 2.796087    Objective Loss 2.796087                                        LR 0.000001    Time 0.204277    
2023-04-17 19:55:38,989 - Epoch: [298][  400/  518]    Overall Loss 2.801814    Objective Loss 2.801814                                        LR 0.000001    Time 0.204109    
2023-04-17 19:55:49,067 - Epoch: [298][  450/  518]    Overall Loss 2.802820    Objective Loss 2.802820                                        LR 0.000001    Time 0.203823    
2023-04-17 19:55:59,206 - Epoch: [298][  500/  518]    Overall Loss 2.803374    Objective Loss 2.803374                                        LR 0.000001    Time 0.203715    
2023-04-17 19:56:02,718 - Epoch: [298][  518/  518]    Overall Loss 2.804655    Objective Loss 2.804655                                        LR 0.000001    Time 0.203415    
2023-04-17 19:56:02,800 - --- validate (epoch=298)-----------
2023-04-17 19:56:02,801 - 4952 samples (32 per mini-batch)
2023-04-17 19:56:47,013 - Epoch: [298][   50/  155]    Loss 3.072942    mAP 0.519802    
2023-04-17 19:57:31,477 - Epoch: [298][  100/  155]    Loss 3.070207    mAP 0.519848    
2023-04-17 19:58:15,620 - Epoch: [298][  150/  155]    Loss 3.057487    mAP 0.524152    
2023-04-17 19:58:20,433 - Epoch: [298][  155/  155]    Loss 3.063531    mAP 0.523215    
2023-04-17 19:58:20,511 - ==> mAP: 0.52321    Loss: 3.064

2023-04-17 19:58:20,515 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 19:58:20,515 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 19:58:20,554 - 

2023-04-17 19:58:20,554 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 19:58:31,476 - Epoch: [299][   50/  518]    Overall Loss 2.841884    Objective Loss 2.841884                                        LR 0.000001    Time 0.218390    
2023-04-17 19:58:41,510 - Epoch: [299][  100/  518]    Overall Loss 2.843531    Objective Loss 2.843531                                        LR 0.000001    Time 0.209510    
2023-04-17 19:58:51,562 - Epoch: [299][  150/  518]    Overall Loss 2.830358    Objective Loss 2.830358                                        LR 0.000001    Time 0.206677    
2023-04-17 19:59:01,575 - Epoch: [299][  200/  518]    Overall Loss 2.836669    Objective Loss 2.836669                                        LR 0.000001    Time 0.205068    
2023-04-17 19:59:11,709 - Epoch: [299][  250/  518]    Overall Loss 2.830485    Objective Loss 2.830485                                        LR 0.000001    Time 0.204583    
2023-04-17 19:59:21,878 - Epoch: [299][  300/  518]    Overall Loss 2.818803    Objective Loss 2.818803                                        LR 0.000001    Time 0.204376    
2023-04-17 19:59:31,946 - Epoch: [299][  350/  518]    Overall Loss 2.811988    Objective Loss 2.811988                                        LR 0.000001    Time 0.203941    
2023-04-17 19:59:42,015 - Epoch: [299][  400/  518]    Overall Loss 2.808503    Objective Loss 2.808503                                        LR 0.000001    Time 0.203618    
2023-04-17 19:59:52,212 - Epoch: [299][  450/  518]    Overall Loss 2.814829    Objective Loss 2.814829                                        LR 0.000001    Time 0.203651    
2023-04-17 20:00:02,302 - Epoch: [299][  500/  518]    Overall Loss 2.812378    Objective Loss 2.812378                                        LR 0.000001    Time 0.203461    
2023-04-17 20:00:05,842 - Epoch: [299][  518/  518]    Overall Loss 2.813757    Objective Loss 2.813757                                        LR 0.000001    Time 0.203225    
2023-04-17 20:00:05,922 - --- validate (epoch=299)-----------
2023-04-17 20:00:05,922 - 4952 samples (32 per mini-batch)
2023-04-17 20:00:50,484 - Epoch: [299][   50/  155]    Loss 3.034664    mAP 0.514780    
2023-04-17 20:01:35,261 - Epoch: [299][  100/  155]    Loss 3.065789    mAP 0.517573    
2023-04-17 20:02:19,326 - Epoch: [299][  150/  155]    Loss 3.070667    mAP 0.513013    
2023-04-17 20:02:23,118 - Epoch: [299][  155/  155]    Loss 3.073473    mAP 0.514000    
2023-04-17 20:02:23,197 - ==> mAP: 0.51400    Loss: 3.073

2023-04-17 20:02:23,201 - ==> Best [mAP: 0.528215   vloss: 3.072769   Sparsity:0.00   Params: 2177088 on epoch: 215]
2023-04-17 20:02:23,201 - Saving checkpoint to: logs/2023.04.16-224243/checkpoint.pth.tar
2023-04-17 20:02:23,283 - 

2023-04-17 20:02:23,283 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 20:02:34,663 - Epoch: [300][   50/  518]    Overall Loss 3.670458    Objective Loss 3.670458                                        LR 0.000001    Time 0.227554    
2023-04-17 20:02:45,324 - Epoch: [300][  100/  518]    Overall Loss 3.497140    Objective Loss 3.497140                                        LR 0.000001    Time 0.220373    
2023-04-17 20:02:55,989 - Epoch: [300][  150/  518]    Overall Loss 3.408388    Objective Loss 3.408388                                        LR 0.000001    Time 0.218002    
2023-04-17 20:03:06,628 - Epoch: [300][  200/  518]    Overall Loss 3.360057    Objective Loss 3.360057                                        LR 0.000001    Time 0.216691    
2023-04-17 20:03:17,329 - Epoch: [300][  250/  518]    Overall Loss 3.322034    Objective Loss 3.322034                                        LR 0.000001    Time 0.216149    
2023-04-17 20:03:27,985 - Epoch: [300][  300/  518]    Overall Loss 3.287404    Objective Loss 3.287404                                        LR 0.000001    Time 0.215639    
2023-04-17 20:03:38,644 - Epoch: [300][  350/  518]    Overall Loss 3.262044    Objective Loss 3.262044                                        LR 0.000001    Time 0.215283    
2023-04-17 20:03:49,295 - Epoch: [300][  400/  518]    Overall Loss 3.250827    Objective Loss 3.250827                                        LR 0.000001    Time 0.214997    
2023-04-17 20:04:00,037 - Epoch: [300][  450/  518]    Overall Loss 3.236065    Objective Loss 3.236065                                        LR 0.000001    Time 0.214977    
2023-04-17 20:04:10,714 - Epoch: [300][  500/  518]    Overall Loss 3.226212    Objective Loss 3.226212                                        LR 0.000001    Time 0.214829    
2023-04-17 20:04:14,436 - Epoch: [300][  518/  518]    Overall Loss 3.223448    Objective Loss 3.223448                                        LR 0.000001    Time 0.214548    
2023-04-17 20:04:14,516 - --- validate (epoch=300)-----------
2023-04-17 20:04:14,517 - 4952 samples (32 per mini-batch)
2023-04-17 20:04:57,985 - Epoch: [300][   50/  155]    Loss 3.220039    mAP 0.523770    
2023-04-17 20:05:41,025 - Epoch: [300][  100/  155]    Loss 3.217582    mAP 0.515247    
2023-04-17 20:06:24,753 - Epoch: [300][  150/  155]    Loss 3.225443    mAP 0.515682    
2023-04-17 20:06:28,813 - Epoch: [300][  155/  155]    Loss 3.219850    mAP 0.516867    
2023-04-17 20:06:28,894 - ==> mAP: 0.51687    Loss: 3.220

2023-04-17 20:06:28,898 - ==> Best [mAP: 0.516867   vloss: 3.219850   Sparsity:0.00   Params: 2177088 on epoch: 300]
2023-04-17 20:06:28,898 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-17 20:06:28,934 - 

2023-04-17 20:06:28,934 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 20:06:40,475 - Epoch: [301][   50/  518]    Overall Loss 3.098425    Objective Loss 3.098425                                        LR 0.000001    Time 0.230754    
2023-04-17 20:06:51,108 - Epoch: [301][  100/  518]    Overall Loss 3.059196    Objective Loss 3.059196                                        LR 0.000001    Time 0.221693    
2023-04-17 20:07:01,812 - Epoch: [301][  150/  518]    Overall Loss 3.054252    Objective Loss 3.054252                                        LR 0.000001    Time 0.219146    
2023-04-17 20:07:12,482 - Epoch: [301][  200/  518]    Overall Loss 3.057747    Objective Loss 3.057747                                        LR 0.000001    Time 0.217700    
2023-04-17 20:07:23,215 - Epoch: [301][  250/  518]    Overall Loss 3.051387    Objective Loss 3.051387                                        LR 0.000001    Time 0.217089    
2023-04-17 20:07:34,025 - Epoch: [301][  300/  518]    Overall Loss 3.047136    Objective Loss 3.047136                                        LR 0.000001    Time 0.216934    
2023-04-17 20:07:44,677 - Epoch: [301][  350/  518]    Overall Loss 3.039295    Objective Loss 3.039295                                        LR 0.000001    Time 0.216374    
2023-04-17 20:07:55,399 - Epoch: [301][  400/  518]    Overall Loss 3.033231    Objective Loss 3.033231                                        LR 0.000001    Time 0.216129    
2023-04-17 20:08:06,060 - Epoch: [301][  450/  518]    Overall Loss 3.030627    Objective Loss 3.030627                                        LR 0.000001    Time 0.215802    
2023-04-17 20:08:16,764 - Epoch: [301][  500/  518]    Overall Loss 3.026317    Objective Loss 3.026317                                        LR 0.000001    Time 0.215626    
2023-04-17 20:08:20,466 - Epoch: [301][  518/  518]    Overall Loss 3.025214    Objective Loss 3.025214                                        LR 0.000001    Time 0.215280    
2023-04-17 20:08:20,550 - --- validate (epoch=301)-----------
2023-04-17 20:08:20,550 - 4952 samples (32 per mini-batch)
2023-04-17 20:09:03,163 - Epoch: [301][   50/  155]    Loss 3.165933    mAP 0.498063    
2023-04-17 20:09:45,208 - Epoch: [301][  100/  155]    Loss 3.148165    mAP 0.498135    
2023-04-17 20:10:29,854 - Epoch: [301][  150/  155]    Loss 3.156099    mAP 0.502522    
2023-04-17 20:10:33,708 - Epoch: [301][  155/  155]    Loss 3.159435    mAP 0.503206    
2023-04-17 20:10:33,781 - ==> mAP: 0.50321    Loss: 3.159

2023-04-17 20:10:33,785 - ==> Best [mAP: 0.516867   vloss: 3.219850   Sparsity:0.00   Params: 2177088 on epoch: 300]
2023-04-17 20:10:33,786 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-17 20:10:33,819 - 

2023-04-17 20:10:33,819 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 20:10:45,501 - Epoch: [302][   50/  518]    Overall Loss 3.016684    Objective Loss 3.016684                                        LR 0.000001    Time 0.233570    
2023-04-17 20:10:56,258 - Epoch: [302][  100/  518]    Overall Loss 3.023606    Objective Loss 3.023606                                        LR 0.000001    Time 0.224347    
2023-04-17 20:11:06,998 - Epoch: [302][  150/  518]    Overall Loss 3.015758    Objective Loss 3.015758                                        LR 0.000001    Time 0.221152    
2023-04-17 20:11:17,752 - Epoch: [302][  200/  518]    Overall Loss 3.011371    Objective Loss 3.011371                                        LR 0.000001    Time 0.219625    
2023-04-17 20:11:28,483 - Epoch: [302][  250/  518]    Overall Loss 3.000697    Objective Loss 3.000697                                        LR 0.000001    Time 0.218619    
2023-04-17 20:11:39,236 - Epoch: [302][  300/  518]    Overall Loss 3.001456    Objective Loss 3.001456                                        LR 0.000001    Time 0.218020    
2023-04-17 20:11:49,927 - Epoch: [302][  350/  518]    Overall Loss 2.998471    Objective Loss 2.998471                                        LR 0.000001    Time 0.217416    
2023-04-17 20:12:00,622 - Epoch: [302][  400/  518]    Overall Loss 2.996240    Objective Loss 2.996240                                        LR 0.000001    Time 0.216973    
2023-04-17 20:12:11,345 - Epoch: [302][  450/  518]    Overall Loss 2.990851    Objective Loss 2.990851                                        LR 0.000001    Time 0.216691    
2023-04-17 20:12:22,063 - Epoch: [302][  500/  518]    Overall Loss 2.988030    Objective Loss 2.988030                                        LR 0.000001    Time 0.216455    
2023-04-17 20:12:25,809 - Epoch: [302][  518/  518]    Overall Loss 2.985198    Objective Loss 2.985198                                        LR 0.000001    Time 0.216163    
2023-04-17 20:12:25,890 - --- validate (epoch=302)-----------
2023-04-17 20:12:25,891 - 4952 samples (32 per mini-batch)
2023-04-17 20:13:06,204 - Epoch: [302][   50/  155]    Loss 3.163819    mAP 0.512297    
2023-04-17 20:13:45,933 - Epoch: [302][  100/  155]    Loss 3.150100    mAP 0.512929    
2023-04-17 20:14:26,176 - Epoch: [302][  150/  155]    Loss 3.134615    mAP 0.518046    
2023-04-17 20:14:30,570 - Epoch: [302][  155/  155]    Loss 3.136797    mAP 0.517911    
2023-04-17 20:14:30,649 - ==> mAP: 0.51791    Loss: 3.137

2023-04-17 20:14:30,653 - ==> Best [mAP: 0.517911   vloss: 3.136797   Sparsity:0.00   Params: 2177088 on epoch: 302]
2023-04-17 20:14:30,653 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-17 20:14:30,703 - 

2023-04-17 20:14:30,704 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 20:14:42,293 - Epoch: [303][   50/  518]    Overall Loss 2.968981    Objective Loss 2.968981                                        LR 0.000001    Time 0.231736    
2023-04-17 20:14:52,982 - Epoch: [303][  100/  518]    Overall Loss 2.989129    Objective Loss 2.989129                                        LR 0.000001    Time 0.222737    
2023-04-17 20:15:03,619 - Epoch: [303][  150/  518]    Overall Loss 2.973597    Objective Loss 2.973597                                        LR 0.000001    Time 0.219398    
2023-04-17 20:15:14,300 - Epoch: [303][  200/  518]    Overall Loss 2.960084    Objective Loss 2.960084                                        LR 0.000001    Time 0.217948    
2023-04-17 20:15:25,094 - Epoch: [303][  250/  518]    Overall Loss 2.964897    Objective Loss 2.964897                                        LR 0.000001    Time 0.217526    
2023-04-17 20:15:35,815 - Epoch: [303][  300/  518]    Overall Loss 2.968603    Objective Loss 2.968603                                        LR 0.000001    Time 0.217005    
2023-04-17 20:15:46,485 - Epoch: [303][  350/  518]    Overall Loss 2.970239    Objective Loss 2.970239                                        LR 0.000001    Time 0.216484    
2023-04-17 20:15:57,230 - Epoch: [303][  400/  518]    Overall Loss 2.971621    Objective Loss 2.971621                                        LR 0.000001    Time 0.216283    
2023-04-17 20:16:07,942 - Epoch: [303][  450/  518]    Overall Loss 2.968234    Objective Loss 2.968234                                        LR 0.000001    Time 0.216052    
2023-04-17 20:16:18,634 - Epoch: [303][  500/  518]    Overall Loss 2.967970    Objective Loss 2.967970                                        LR 0.000001    Time 0.215829    
2023-04-17 20:16:22,372 - Epoch: [303][  518/  518]    Overall Loss 2.967091    Objective Loss 2.967091                                        LR 0.000001    Time 0.215544    
2023-04-17 20:16:22,453 - --- validate (epoch=303)-----------
2023-04-17 20:16:22,453 - 4952 samples (32 per mini-batch)
2023-04-17 20:17:08,190 - Epoch: [303][   50/  155]    Loss 3.134063    mAP 0.527597    
2023-04-17 20:17:50,912 - Epoch: [303][  100/  155]    Loss 3.112613    mAP 0.517979    
2023-04-17 20:18:33,341 - Epoch: [303][  150/  155]    Loss 3.113763    mAP 0.521481    
2023-04-17 20:18:37,108 - Epoch: [303][  155/  155]    Loss 3.110322    mAP 0.522494    
2023-04-17 20:18:37,188 - ==> mAP: 0.52249    Loss: 3.110

2023-04-17 20:18:37,191 - ==> Best [mAP: 0.522494   vloss: 3.110322   Sparsity:0.00   Params: 2177088 on epoch: 303]
2023-04-17 20:18:37,191 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-17 20:18:37,240 - 

2023-04-17 20:18:37,240 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 20:18:48,756 - Epoch: [304][   50/  518]    Overall Loss 2.916895    Objective Loss 2.916895                                        LR 0.000001    Time 0.230266    
2023-04-17 20:18:59,426 - Epoch: [304][  100/  518]    Overall Loss 2.943223    Objective Loss 2.943223                                        LR 0.000001    Time 0.221815    
2023-04-17 20:19:10,053 - Epoch: [304][  150/  518]    Overall Loss 2.936541    Objective Loss 2.936541                                        LR 0.000001    Time 0.218713    
2023-04-17 20:19:20,801 - Epoch: [304][  200/  518]    Overall Loss 2.928122    Objective Loss 2.928122                                        LR 0.000001    Time 0.217769    
2023-04-17 20:19:31,518 - Epoch: [304][  250/  518]    Overall Loss 2.937799    Objective Loss 2.937799                                        LR 0.000001    Time 0.217079    
2023-04-17 20:19:42,250 - Epoch: [304][  300/  518]    Overall Loss 2.937521    Objective Loss 2.937521                                        LR 0.000001    Time 0.216666    
2023-04-17 20:19:52,967 - Epoch: [304][  350/  518]    Overall Loss 2.939343    Objective Loss 2.939343                                        LR 0.000001    Time 0.216330    
2023-04-17 20:20:03,659 - Epoch: [304][  400/  518]    Overall Loss 2.941190    Objective Loss 2.941190                                        LR 0.000001    Time 0.216014    
2023-04-17 20:20:14,416 - Epoch: [304][  450/  518]    Overall Loss 2.949497    Objective Loss 2.949497                                        LR 0.000001    Time 0.215914    
2023-04-17 20:20:25,111 - Epoch: [304][  500/  518]    Overall Loss 2.955163    Objective Loss 2.955163                                        LR 0.000001    Time 0.215710    
2023-04-17 20:20:28,844 - Epoch: [304][  518/  518]    Overall Loss 2.952385    Objective Loss 2.952385                                        LR 0.000001    Time 0.215418    
2023-04-17 20:20:28,925 - --- validate (epoch=304)-----------
2023-04-17 20:20:28,925 - 4952 samples (32 per mini-batch)
2023-04-17 20:21:10,245 - Epoch: [304][   50/  155]    Loss 3.127630    mAP 0.504639    
2023-04-17 20:21:50,921 - Epoch: [304][  100/  155]    Loss 3.095549    mAP 0.523356    
2023-04-17 20:22:33,083 - Epoch: [304][  150/  155]    Loss 3.092020    mAP 0.525290    
2023-04-17 20:22:36,852 - Epoch: [304][  155/  155]    Loss 3.097290    mAP 0.524372    
2023-04-17 20:22:36,932 - ==> mAP: 0.52437    Loss: 3.097

2023-04-17 20:22:36,935 - ==> Best [mAP: 0.524372   vloss: 3.097290   Sparsity:0.00   Params: 2177088 on epoch: 304]
2023-04-17 20:22:36,935 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-17 20:22:36,984 - 

2023-04-17 20:22:36,984 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 20:22:48,557 - Epoch: [305][   50/  518]    Overall Loss 2.895696    Objective Loss 2.895696                                        LR 0.000001    Time 0.231407    
2023-04-17 20:22:59,295 - Epoch: [305][  100/  518]    Overall Loss 2.920230    Objective Loss 2.920230                                        LR 0.000001    Time 0.223064    
2023-04-17 20:23:10,007 - Epoch: [305][  150/  518]    Overall Loss 2.935545    Objective Loss 2.935545                                        LR 0.000001    Time 0.220113    
2023-04-17 20:23:20,697 - Epoch: [305][  200/  518]    Overall Loss 2.936612    Objective Loss 2.936612                                        LR 0.000001    Time 0.218530    
2023-04-17 20:23:31,386 - Epoch: [305][  250/  518]    Overall Loss 2.944161    Objective Loss 2.944161                                        LR 0.000001    Time 0.217571    
2023-04-17 20:23:42,163 - Epoch: [305][  300/  518]    Overall Loss 2.942905    Objective Loss 2.942905                                        LR 0.000001    Time 0.217228    
2023-04-17 20:23:52,891 - Epoch: [305][  350/  518]    Overall Loss 2.945781    Objective Loss 2.945781                                        LR 0.000001    Time 0.216844    
2023-04-17 20:24:03,659 - Epoch: [305][  400/  518]    Overall Loss 2.937864    Objective Loss 2.937864                                        LR 0.000001    Time 0.216655    
2023-04-17 20:24:14,343 - Epoch: [305][  450/  518]    Overall Loss 2.935201    Objective Loss 2.935201                                        LR 0.000001    Time 0.216320    
2023-04-17 20:24:25,138 - Epoch: [305][  500/  518]    Overall Loss 2.939758    Objective Loss 2.939758                                        LR 0.000001    Time 0.216276    
2023-04-17 20:24:28,865 - Epoch: [305][  518/  518]    Overall Loss 2.941883    Objective Loss 2.941883                                        LR 0.000001    Time 0.215953    
2023-04-17 20:24:28,945 - --- validate (epoch=305)-----------
2023-04-17 20:24:28,946 - 4952 samples (32 per mini-batch)
2023-04-17 20:25:10,309 - Epoch: [305][   50/  155]    Loss 3.110985    mAP 0.515633    
2023-04-17 20:25:52,971 - Epoch: [305][  100/  155]    Loss 3.094315    mAP 0.521226    
2023-04-17 20:26:34,007 - Epoch: [305][  150/  155]    Loss 3.087216    mAP 0.517759    
2023-04-17 20:26:38,083 - Epoch: [305][  155/  155]    Loss 3.089564    mAP 0.516555    
2023-04-17 20:26:38,161 - ==> mAP: 0.51656    Loss: 3.090

2023-04-17 20:26:38,165 - ==> Best [mAP: 0.524372   vloss: 3.097290   Sparsity:0.00   Params: 2177088 on epoch: 304]
2023-04-17 20:26:38,165 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-17 20:26:38,199 - 

2023-04-17 20:26:38,199 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 20:26:49,833 - Epoch: [306][   50/  518]    Overall Loss 2.939565    Objective Loss 2.939565                                        LR 0.000001    Time 0.232623    
2023-04-17 20:27:00,460 - Epoch: [306][  100/  518]    Overall Loss 2.943627    Objective Loss 2.943627                                        LR 0.000001    Time 0.222564    
2023-04-17 20:27:11,172 - Epoch: [306][  150/  518]    Overall Loss 2.942169    Objective Loss 2.942169                                        LR 0.000001    Time 0.219782    
2023-04-17 20:27:21,910 - Epoch: [306][  200/  518]    Overall Loss 2.947512    Objective Loss 2.947512                                        LR 0.000001    Time 0.218516    
2023-04-17 20:27:32,638 - Epoch: [306][  250/  518]    Overall Loss 2.948345    Objective Loss 2.948345                                        LR 0.000001    Time 0.217721    
2023-04-17 20:27:43,424 - Epoch: [306][  300/  518]    Overall Loss 2.942251    Objective Loss 2.942251                                        LR 0.000001    Time 0.217381    
2023-04-17 20:27:54,116 - Epoch: [306][  350/  518]    Overall Loss 2.948226    Objective Loss 2.948226                                        LR 0.000001    Time 0.216870    
2023-04-17 20:28:04,852 - Epoch: [306][  400/  518]    Overall Loss 2.947864    Objective Loss 2.947864                                        LR 0.000001    Time 0.216597    
2023-04-17 20:28:15,637 - Epoch: [306][  450/  518]    Overall Loss 2.946350    Objective Loss 2.946350                                        LR 0.000001    Time 0.216495    
2023-04-17 20:28:26,336 - Epoch: [306][  500/  518]    Overall Loss 2.942979    Objective Loss 2.942979                                        LR 0.000001    Time 0.216241    
2023-04-17 20:28:30,062 - Epoch: [306][  518/  518]    Overall Loss 2.942960    Objective Loss 2.942960                                        LR 0.000001    Time 0.215919    
2023-04-17 20:28:30,142 - --- validate (epoch=306)-----------
2023-04-17 20:28:30,142 - 4952 samples (32 per mini-batch)
2023-04-17 20:29:13,061 - Epoch: [306][   50/  155]    Loss 3.096381    mAP 0.521594    
2023-04-17 20:29:56,028 - Epoch: [306][  100/  155]    Loss 3.088609    mAP 0.522587    
2023-04-17 20:30:38,767 - Epoch: [306][  150/  155]    Loss 3.081427    mAP 0.530030    
2023-04-17 20:30:42,810 - Epoch: [306][  155/  155]    Loss 3.078836    mAP 0.529620    
2023-04-17 20:30:42,890 - ==> mAP: 0.52962    Loss: 3.079

2023-04-17 20:30:42,894 - ==> Best [mAP: 0.529620   vloss: 3.078836   Sparsity:0.00   Params: 2177088 on epoch: 306]
2023-04-17 20:30:42,894 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-17 20:30:42,943 - 

2023-04-17 20:30:42,944 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 20:30:54,634 - Epoch: [307][   50/  518]    Overall Loss 2.943454    Objective Loss 2.943454                                        LR 0.000001    Time 0.233762    
2023-04-17 20:31:05,353 - Epoch: [307][  100/  518]    Overall Loss 2.913490    Objective Loss 2.913490                                        LR 0.000001    Time 0.224051    
2023-04-17 20:31:16,071 - Epoch: [307][  150/  518]    Overall Loss 2.906849    Objective Loss 2.906849                                        LR 0.000001    Time 0.220811    
2023-04-17 20:31:26,865 - Epoch: [307][  200/  518]    Overall Loss 2.908105    Objective Loss 2.908105                                        LR 0.000001    Time 0.219572    
2023-04-17 20:31:37,524 - Epoch: [307][  250/  518]    Overall Loss 2.919874    Objective Loss 2.919874                                        LR 0.000001    Time 0.218288    
2023-04-17 20:31:48,337 - Epoch: [307][  300/  518]    Overall Loss 2.918340    Objective Loss 2.918340                                        LR 0.000001    Time 0.217942    
2023-04-17 20:31:59,053 - Epoch: [307][  350/  518]    Overall Loss 2.918929    Objective Loss 2.918929                                        LR 0.000001    Time 0.217422    
2023-04-17 20:32:09,812 - Epoch: [307][  400/  518]    Overall Loss 2.918360    Objective Loss 2.918360                                        LR 0.000001    Time 0.217137    
2023-04-17 20:32:20,563 - Epoch: [307][  450/  518]    Overall Loss 2.917110    Objective Loss 2.917110                                        LR 0.000001    Time 0.216899    
2023-04-17 20:32:31,294 - Epoch: [307][  500/  518]    Overall Loss 2.918840    Objective Loss 2.918840                                        LR 0.000001    Time 0.216669    
2023-04-17 20:32:35,037 - Epoch: [307][  518/  518]    Overall Loss 2.920106    Objective Loss 2.920106                                        LR 0.000001    Time 0.216364    
2023-04-17 20:32:35,114 - --- validate (epoch=307)-----------
2023-04-17 20:32:35,114 - 4952 samples (32 per mini-batch)
2023-04-17 20:33:17,315 - Epoch: [307][   50/  155]    Loss 3.095977    mAP 0.519165    
2023-04-17 20:34:00,861 - Epoch: [307][  100/  155]    Loss 3.092112    mAP 0.523278    
2023-04-17 20:34:42,857 - Epoch: [307][  150/  155]    Loss 3.072936    mAP 0.526646    
2023-04-17 20:34:46,955 - Epoch: [307][  155/  155]    Loss 3.070730    mAP 0.527351    
2023-04-17 20:34:47,030 - ==> mAP: 0.52735    Loss: 3.071

2023-04-17 20:34:47,034 - ==> Best [mAP: 0.529620   vloss: 3.078836   Sparsity:0.00   Params: 2177088 on epoch: 306]
2023-04-17 20:34:47,034 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-17 20:34:47,068 - 

2023-04-17 20:34:47,068 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 20:34:58,608 - Epoch: [308][   50/  518]    Overall Loss 2.920076    Objective Loss 2.920076                                        LR 0.000001    Time 0.230752    
2023-04-17 20:35:09,339 - Epoch: [308][  100/  518]    Overall Loss 2.931058    Objective Loss 2.931058                                        LR 0.000001    Time 0.222669    
2023-04-17 20:35:20,007 - Epoch: [308][  150/  518]    Overall Loss 2.916759    Objective Loss 2.916759                                        LR 0.000001    Time 0.219558    
2023-04-17 20:35:30,684 - Epoch: [308][  200/  518]    Overall Loss 2.911241    Objective Loss 2.911241                                        LR 0.000001    Time 0.218043    
2023-04-17 20:35:41,382 - Epoch: [308][  250/  518]    Overall Loss 2.914122    Objective Loss 2.914122                                        LR 0.000001    Time 0.217223    
2023-04-17 20:35:52,107 - Epoch: [308][  300/  518]    Overall Loss 2.917042    Objective Loss 2.917042                                        LR 0.000001    Time 0.216764    
2023-04-17 20:36:02,876 - Epoch: [308][  350/  518]    Overall Loss 2.913818    Objective Loss 2.913818                                        LR 0.000001    Time 0.216561    
2023-04-17 20:36:13,541 - Epoch: [308][  400/  518]    Overall Loss 2.911284    Objective Loss 2.911284                                        LR 0.000001    Time 0.216150    
2023-04-17 20:36:24,227 - Epoch: [308][  450/  518]    Overall Loss 2.908905    Objective Loss 2.908905                                        LR 0.000001    Time 0.215876    
2023-04-17 20:36:34,899 - Epoch: [308][  500/  518]    Overall Loss 2.903453    Objective Loss 2.903453                                        LR 0.000001    Time 0.215629    
2023-04-17 20:36:38,597 - Epoch: [308][  518/  518]    Overall Loss 2.903405    Objective Loss 2.903405                                        LR 0.000001    Time 0.215276    
2023-04-17 20:36:38,678 - --- validate (epoch=308)-----------
2023-04-17 20:36:38,678 - 4952 samples (32 per mini-batch)
2023-04-17 20:37:19,998 - Epoch: [308][   50/  155]    Loss 3.082033    mAP 0.507016    
2023-04-17 20:38:02,115 - Epoch: [308][  100/  155]    Loss 3.053576    mAP 0.520540    
2023-04-17 20:38:43,492 - Epoch: [308][  150/  155]    Loss 3.060770    mAP 0.516856    
2023-04-17 20:38:47,154 - Epoch: [308][  155/  155]    Loss 3.064416    mAP 0.516489    
2023-04-17 20:38:47,235 - ==> mAP: 0.51649    Loss: 3.064

2023-04-17 20:38:47,239 - ==> Best [mAP: 0.529620   vloss: 3.078836   Sparsity:0.00   Params: 2177088 on epoch: 306]
2023-04-17 20:38:47,239 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-17 20:38:47,272 - 

2023-04-17 20:38:47,273 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 20:38:58,818 - Epoch: [309][   50/  518]    Overall Loss 2.950357    Objective Loss 2.950357                                        LR 0.000001    Time 0.230851    
2023-04-17 20:39:09,574 - Epoch: [309][  100/  518]    Overall Loss 2.949273    Objective Loss 2.949273                                        LR 0.000001    Time 0.222976    
2023-04-17 20:39:20,288 - Epoch: [309][  150/  518]    Overall Loss 2.932445    Objective Loss 2.932445                                        LR 0.000001    Time 0.220068    
2023-04-17 20:39:30,987 - Epoch: [309][  200/  518]    Overall Loss 2.924957    Objective Loss 2.924957                                        LR 0.000001    Time 0.218536    
2023-04-17 20:39:41,804 - Epoch: [309][  250/  518]    Overall Loss 2.913331    Objective Loss 2.913331                                        LR 0.000001    Time 0.218090    
2023-04-17 20:39:52,528 - Epoch: [309][  300/  518]    Overall Loss 2.921485    Objective Loss 2.921485                                        LR 0.000001    Time 0.217485    
2023-04-17 20:40:03,181 - Epoch: [309][  350/  518]    Overall Loss 2.911739    Objective Loss 2.911739                                        LR 0.000001    Time 0.216848    
2023-04-17 20:40:13,903 - Epoch: [309][  400/  518]    Overall Loss 2.912449    Objective Loss 2.912449                                        LR 0.000001    Time 0.216544    
2023-04-17 20:40:24,544 - Epoch: [309][  450/  518]    Overall Loss 2.911820    Objective Loss 2.911820                                        LR 0.000001    Time 0.216126    
2023-04-17 20:40:35,310 - Epoch: [309][  500/  518]    Overall Loss 2.911991    Objective Loss 2.911991                                        LR 0.000001    Time 0.216042    
2023-04-17 20:40:38,965 - Epoch: [309][  518/  518]    Overall Loss 2.911109    Objective Loss 2.911109                                        LR 0.000001    Time 0.215590    
2023-04-17 20:40:39,045 - --- validate (epoch=309)-----------
2023-04-17 20:40:39,045 - 4952 samples (32 per mini-batch)
2023-04-17 20:41:20,049 - Epoch: [309][   50/  155]    Loss 3.042481    mAP 0.521787    
2023-04-17 20:42:01,555 - Epoch: [309][  100/  155]    Loss 3.079282    mAP 0.518834    
2023-04-17 20:42:42,787 - Epoch: [309][  150/  155]    Loss 3.058730    mAP 0.524707    
2023-04-17 20:42:46,654 - Epoch: [309][  155/  155]    Loss 3.064389    mAP 0.525350    
2023-04-17 20:42:46,727 - ==> mAP: 0.52535    Loss: 3.064

2023-04-17 20:42:46,731 - ==> Best [mAP: 0.529620   vloss: 3.078836   Sparsity:0.00   Params: 2177088 on epoch: 306]
2023-04-17 20:42:46,731 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-17 20:42:46,765 - 

2023-04-17 20:42:46,765 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 20:42:58,262 - Epoch: [310][   50/  518]    Overall Loss 2.922829    Objective Loss 2.922829                                        LR 0.000001    Time 0.229880    
2023-04-17 20:43:09,026 - Epoch: [310][  100/  518]    Overall Loss 2.915941    Objective Loss 2.915941                                        LR 0.000001    Time 0.222563    
2023-04-17 20:43:19,764 - Epoch: [310][  150/  518]    Overall Loss 2.896400    Objective Loss 2.896400                                        LR 0.000001    Time 0.219957    
2023-04-17 20:43:30,447 - Epoch: [310][  200/  518]    Overall Loss 2.900738    Objective Loss 2.900738                                        LR 0.000001    Time 0.218372    
2023-04-17 20:43:41,170 - Epoch: [310][  250/  518]    Overall Loss 2.906186    Objective Loss 2.906186                                        LR 0.000001    Time 0.217585    
2023-04-17 20:43:51,960 - Epoch: [310][  300/  518]    Overall Loss 2.902233    Objective Loss 2.902233                                        LR 0.000001    Time 0.217283    
2023-04-17 20:44:02,676 - Epoch: [310][  350/  518]    Overall Loss 2.907572    Objective Loss 2.907572                                        LR 0.000001    Time 0.216854    
2023-04-17 20:44:13,306 - Epoch: [310][  400/  518]    Overall Loss 2.905172    Objective Loss 2.905172                                        LR 0.000001    Time 0.216320    
2023-04-17 20:44:24,037 - Epoch: [310][  450/  518]    Overall Loss 2.905330    Objective Loss 2.905330                                        LR 0.000001    Time 0.216127    
2023-04-17 20:44:34,747 - Epoch: [310][  500/  518]    Overall Loss 2.906258    Objective Loss 2.906258                                        LR 0.000001    Time 0.215930    
2023-04-17 20:44:38,482 - Epoch: [310][  518/  518]    Overall Loss 2.906207    Objective Loss 2.906207                                        LR 0.000001    Time 0.215637    
2023-04-17 20:44:38,563 - --- validate (epoch=310)-----------
2023-04-17 20:44:38,563 - 4952 samples (32 per mini-batch)
2023-04-17 20:45:21,242 - Epoch: [310][   50/  155]    Loss 3.053049    mAP 0.514775    
2023-04-17 20:46:02,551 - Epoch: [310][  100/  155]    Loss 3.048265    mAP 0.515514    
2023-04-17 20:46:45,079 - Epoch: [310][  150/  155]    Loss 3.057962    mAP 0.510254    
2023-04-17 20:46:49,011 - Epoch: [310][  155/  155]    Loss 3.060387    mAP 0.508359    
2023-04-17 20:46:49,091 - ==> mAP: 0.50836    Loss: 3.060

2023-04-17 20:46:49,095 - ==> Best [mAP: 0.529620   vloss: 3.078836   Sparsity:0.00   Params: 2177088 on epoch: 306]
2023-04-17 20:46:49,095 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-17 20:46:49,129 - 

2023-04-17 20:46:49,129 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 20:47:00,656 - Epoch: [311][   50/  518]    Overall Loss 2.864032    Objective Loss 2.864032                                        LR 0.000001    Time 0.230474    
2023-04-17 20:47:11,414 - Epoch: [311][  100/  518]    Overall Loss 2.879958    Objective Loss 2.879958                                        LR 0.000001    Time 0.222803    
2023-04-17 20:47:22,089 - Epoch: [311][  150/  518]    Overall Loss 2.888838    Objective Loss 2.888838                                        LR 0.000001    Time 0.219689    
2023-04-17 20:47:32,747 - Epoch: [311][  200/  518]    Overall Loss 2.898246    Objective Loss 2.898246                                        LR 0.000001    Time 0.218054    
2023-04-17 20:47:43,455 - Epoch: [311][  250/  518]    Overall Loss 2.908473    Objective Loss 2.908473                                        LR 0.000001    Time 0.217267    
2023-04-17 20:47:54,148 - Epoch: [311][  300/  518]    Overall Loss 2.912012    Objective Loss 2.912012                                        LR 0.000001    Time 0.216693    
2023-04-17 20:48:04,791 - Epoch: [311][  350/  518]    Overall Loss 2.901791    Objective Loss 2.901791                                        LR 0.000001    Time 0.216141    
2023-04-17 20:48:15,476 - Epoch: [311][  400/  518]    Overall Loss 2.901077    Objective Loss 2.901077                                        LR 0.000001    Time 0.215834    
2023-04-17 20:48:26,174 - Epoch: [311][  450/  518]    Overall Loss 2.903258    Objective Loss 2.903258                                        LR 0.000001    Time 0.215621    
2023-04-17 20:48:36,903 - Epoch: [311][  500/  518]    Overall Loss 2.902490    Objective Loss 2.902490                                        LR 0.000001    Time 0.215514    
2023-04-17 20:48:40,605 - Epoch: [311][  518/  518]    Overall Loss 2.901662    Objective Loss 2.901662                                        LR 0.000001    Time 0.215172    
2023-04-17 20:48:40,684 - --- validate (epoch=311)-----------
2023-04-17 20:48:40,685 - 4952 samples (32 per mini-batch)
2023-04-17 20:49:21,731 - Epoch: [311][   50/  155]    Loss 3.065330    mAP 0.521543    
2023-04-17 20:50:03,358 - Epoch: [311][  100/  155]    Loss 3.055367    mAP 0.526384    
2023-04-17 20:50:42,907 - Epoch: [311][  150/  155]    Loss 3.061613    mAP 0.526612    
2023-04-17 20:50:46,474 - Epoch: [311][  155/  155]    Loss 3.057542    mAP 0.524906    
2023-04-17 20:50:46,554 - ==> mAP: 0.52491    Loss: 3.058

2023-04-17 20:50:46,557 - ==> Best [mAP: 0.529620   vloss: 3.078836   Sparsity:0.00   Params: 2177088 on epoch: 306]
2023-04-17 20:50:46,557 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-17 20:50:46,592 - 

2023-04-17 20:50:46,592 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 20:50:58,261 - Epoch: [312][   50/  518]    Overall Loss 2.935007    Objective Loss 2.935007                                        LR 0.000001    Time 0.233326    
2023-04-17 20:51:09,004 - Epoch: [312][  100/  518]    Overall Loss 2.928381    Objective Loss 2.928381                                        LR 0.000001    Time 0.224084    
2023-04-17 20:51:19,749 - Epoch: [312][  150/  518]    Overall Loss 2.916846    Objective Loss 2.916846                                        LR 0.000001    Time 0.221011    
2023-04-17 20:51:30,493 - Epoch: [312][  200/  518]    Overall Loss 2.911984    Objective Loss 2.911984                                        LR 0.000001    Time 0.219470    
2023-04-17 20:51:41,227 - Epoch: [312][  250/  518]    Overall Loss 2.897519    Objective Loss 2.897519                                        LR 0.000001    Time 0.218508    
2023-04-17 20:51:51,925 - Epoch: [312][  300/  518]    Overall Loss 2.896465    Objective Loss 2.896465                                        LR 0.000001    Time 0.217744    
2023-04-17 20:52:02,672 - Epoch: [312][  350/  518]    Overall Loss 2.898849    Objective Loss 2.898849                                        LR 0.000001    Time 0.217338    
2023-04-17 20:52:13,445 - Epoch: [312][  400/  518]    Overall Loss 2.898265    Objective Loss 2.898265                                        LR 0.000001    Time 0.217101    
2023-04-17 20:52:24,145 - Epoch: [312][  450/  518]    Overall Loss 2.900492    Objective Loss 2.900492                                        LR 0.000001    Time 0.216751    
2023-04-17 20:52:34,872 - Epoch: [312][  500/  518]    Overall Loss 2.900483    Objective Loss 2.900483                                        LR 0.000001    Time 0.216527    
2023-04-17 20:52:38,623 - Epoch: [312][  518/  518]    Overall Loss 2.900035    Objective Loss 2.900035                                        LR 0.000001    Time 0.216244    
2023-04-17 20:52:38,703 - --- validate (epoch=312)-----------
2023-04-17 20:52:38,704 - 4952 samples (32 per mini-batch)
2023-04-17 20:53:22,742 - Epoch: [312][   50/  155]    Loss 3.053106    mAP 0.538793    
2023-04-17 20:54:04,586 - Epoch: [312][  100/  155]    Loss 3.051210    mAP 0.529761    
2023-04-17 20:54:46,484 - Epoch: [312][  150/  155]    Loss 3.057857    mAP 0.524911    
2023-04-17 20:54:50,048 - Epoch: [312][  155/  155]    Loss 3.056354    mAP 0.526313    
2023-04-17 20:54:50,124 - ==> mAP: 0.52631    Loss: 3.056

2023-04-17 20:54:50,127 - ==> Best [mAP: 0.529620   vloss: 3.078836   Sparsity:0.00   Params: 2177088 on epoch: 306]
2023-04-17 20:54:50,127 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-17 20:54:50,162 - 

2023-04-17 20:54:50,162 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 20:55:01,822 - Epoch: [313][   50/  518]    Overall Loss 2.908140    Objective Loss 2.908140                                        LR 0.000001    Time 0.233135    
2023-04-17 20:55:12,497 - Epoch: [313][  100/  518]    Overall Loss 2.904010    Objective Loss 2.904010                                        LR 0.000001    Time 0.223303    
2023-04-17 20:55:23,141 - Epoch: [313][  150/  518]    Overall Loss 2.917007    Objective Loss 2.917007                                        LR 0.000001    Time 0.219824    
2023-04-17 20:55:33,832 - Epoch: [313][  200/  518]    Overall Loss 2.905333    Objective Loss 2.905333                                        LR 0.000001    Time 0.218315    
2023-04-17 20:55:44,486 - Epoch: [313][  250/  518]    Overall Loss 2.902311    Objective Loss 2.902311                                        LR 0.000001    Time 0.217258    
2023-04-17 20:55:55,192 - Epoch: [313][  300/  518]    Overall Loss 2.899492    Objective Loss 2.899492                                        LR 0.000001    Time 0.216732    
2023-04-17 20:56:05,944 - Epoch: [313][  350/  518]    Overall Loss 2.902355    Objective Loss 2.902355                                        LR 0.000001    Time 0.216486    
2023-04-17 20:56:16,595 - Epoch: [313][  400/  518]    Overall Loss 2.896515    Objective Loss 2.896515                                        LR 0.000001    Time 0.216048    
2023-04-17 20:56:27,334 - Epoch: [313][  450/  518]    Overall Loss 2.887620    Objective Loss 2.887620                                        LR 0.000001    Time 0.215906    
2023-04-17 20:56:38,095 - Epoch: [313][  500/  518]    Overall Loss 2.886502    Objective Loss 2.886502                                        LR 0.000001    Time 0.215832    
2023-04-17 20:56:41,839 - Epoch: [313][  518/  518]    Overall Loss 2.886081    Objective Loss 2.886081                                        LR 0.000001    Time 0.215561    
2023-04-17 20:56:41,920 - --- validate (epoch=313)-----------
2023-04-17 20:56:41,920 - 4952 samples (32 per mini-batch)
2023-04-17 20:57:24,872 - Epoch: [313][   50/  155]    Loss 3.089392    mAP 0.521403    
2023-04-17 20:58:06,071 - Epoch: [313][  100/  155]    Loss 3.062253    mAP 0.520882    
2023-04-17 20:58:46,645 - Epoch: [313][  150/  155]    Loss 3.052514    mAP 0.516841    
2023-04-17 20:58:50,646 - Epoch: [313][  155/  155]    Loss 3.051748    mAP 0.517174    
2023-04-17 20:58:50,724 - ==> mAP: 0.51717    Loss: 3.052

2023-04-17 20:58:50,727 - ==> Best [mAP: 0.529620   vloss: 3.078836   Sparsity:0.00   Params: 2177088 on epoch: 306]
2023-04-17 20:58:50,727 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-17 20:58:50,761 - 

2023-04-17 20:58:50,762 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 20:59:02,372 - Epoch: [314][   50/  518]    Overall Loss 2.887153    Objective Loss 2.887153                                        LR 0.000001    Time 0.232154    
2023-04-17 20:59:13,070 - Epoch: [314][  100/  518]    Overall Loss 2.892507    Objective Loss 2.892507                                        LR 0.000001    Time 0.223039    
2023-04-17 20:59:23,739 - Epoch: [314][  150/  518]    Overall Loss 2.903352    Objective Loss 2.903352                                        LR 0.000001    Time 0.219809    
2023-04-17 20:59:34,429 - Epoch: [314][  200/  518]    Overall Loss 2.915017    Objective Loss 2.915017                                        LR 0.000001    Time 0.218302    
2023-04-17 20:59:45,162 - Epoch: [314][  250/  518]    Overall Loss 2.895577    Objective Loss 2.895577                                        LR 0.000001    Time 0.217567    
2023-04-17 20:59:55,881 - Epoch: [314][  300/  518]    Overall Loss 2.891305    Objective Loss 2.891305                                        LR 0.000001    Time 0.217033    
2023-04-17 21:00:06,590 - Epoch: [314][  350/  518]    Overall Loss 2.888370    Objective Loss 2.888370                                        LR 0.000001    Time 0.216620    
2023-04-17 21:00:17,324 - Epoch: [314][  400/  518]    Overall Loss 2.889144    Objective Loss 2.889144                                        LR 0.000001    Time 0.216375    
2023-04-17 21:00:28,032 - Epoch: [314][  450/  518]    Overall Loss 2.886726    Objective Loss 2.886726                                        LR 0.000001    Time 0.216125    
2023-04-17 21:00:38,754 - Epoch: [314][  500/  518]    Overall Loss 2.884633    Objective Loss 2.884633                                        LR 0.000001    Time 0.215954    
2023-04-17 21:00:42,472 - Epoch: [314][  518/  518]    Overall Loss 2.883675    Objective Loss 2.883675                                        LR 0.000001    Time 0.215625    
2023-04-17 21:00:42,553 - --- validate (epoch=314)-----------
2023-04-17 21:00:42,554 - 4952 samples (32 per mini-batch)
2023-04-17 21:01:23,935 - Epoch: [314][   50/  155]    Loss 3.043823    mAP 0.511725    
2023-04-17 21:02:04,574 - Epoch: [314][  100/  155]    Loss 3.052474    mAP 0.519348    
2023-04-17 21:02:46,569 - Epoch: [314][  150/  155]    Loss 3.049650    mAP 0.518686    
2023-04-17 21:02:50,119 - Epoch: [314][  155/  155]    Loss 3.046241    mAP 0.520179    
2023-04-17 21:02:50,196 - ==> mAP: 0.52018    Loss: 3.046

2023-04-17 21:02:50,200 - ==> Best [mAP: 0.529620   vloss: 3.078836   Sparsity:0.00   Params: 2177088 on epoch: 306]
2023-04-17 21:02:50,200 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-17 21:02:50,234 - 

2023-04-17 21:02:50,234 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 21:03:01,840 - Epoch: [315][   50/  518]    Overall Loss 2.925302    Objective Loss 2.925302                                        LR 0.000001    Time 0.232068    
2023-04-17 21:03:12,544 - Epoch: [315][  100/  518]    Overall Loss 2.903891    Objective Loss 2.903891                                        LR 0.000001    Time 0.223058    
2023-04-17 21:03:23,228 - Epoch: [315][  150/  518]    Overall Loss 2.884677    Objective Loss 2.884677                                        LR 0.000001    Time 0.219919    
2023-04-17 21:03:33,907 - Epoch: [315][  200/  518]    Overall Loss 2.880277    Objective Loss 2.880277                                        LR 0.000001    Time 0.218328    
2023-04-17 21:03:44,607 - Epoch: [315][  250/  518]    Overall Loss 2.886460    Objective Loss 2.886460                                        LR 0.000001    Time 0.217456    
2023-04-17 21:03:55,340 - Epoch: [315][  300/  518]    Overall Loss 2.888425    Objective Loss 2.888425                                        LR 0.000001    Time 0.216986    
2023-04-17 21:04:06,165 - Epoch: [315][  350/  518]    Overall Loss 2.889473    Objective Loss 2.889473                                        LR 0.000001    Time 0.216911    
2023-04-17 21:04:16,847 - Epoch: [315][  400/  518]    Overall Loss 2.890133    Objective Loss 2.890133                                        LR 0.000001    Time 0.216500    
2023-04-17 21:04:27,564 - Epoch: [315][  450/  518]    Overall Loss 2.884950    Objective Loss 2.884950                                        LR 0.000001    Time 0.216256    
2023-04-17 21:04:38,247 - Epoch: [315][  500/  518]    Overall Loss 2.888398    Objective Loss 2.888398                                        LR 0.000001    Time 0.215994    
2023-04-17 21:04:41,952 - Epoch: [315][  518/  518]    Overall Loss 2.890489    Objective Loss 2.890489                                        LR 0.000001    Time 0.215640    
2023-04-17 21:04:42,034 - --- validate (epoch=315)-----------
2023-04-17 21:04:42,034 - 4952 samples (32 per mini-batch)
2023-04-17 21:05:24,403 - Epoch: [315][   50/  155]    Loss 3.034838    mAP 0.546518    
2023-04-17 21:06:05,753 - Epoch: [315][  100/  155]    Loss 3.032604    mAP 0.531824    
2023-04-17 21:06:45,500 - Epoch: [315][  150/  155]    Loss 3.043458    mAP 0.530437    
2023-04-17 21:06:49,461 - Epoch: [315][  155/  155]    Loss 3.046708    mAP 0.529132    
2023-04-17 21:06:49,532 - ==> mAP: 0.52913    Loss: 3.047

2023-04-17 21:06:49,536 - ==> Best [mAP: 0.529620   vloss: 3.078836   Sparsity:0.00   Params: 2177088 on epoch: 306]
2023-04-17 21:06:49,536 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-17 21:06:49,571 - 

2023-04-17 21:06:49,571 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 21:07:01,040 - Epoch: [316][   50/  518]    Overall Loss 2.845277    Objective Loss 2.845277                                        LR 0.000001    Time 0.229338    
2023-04-17 21:07:11,783 - Epoch: [316][  100/  518]    Overall Loss 2.844113    Objective Loss 2.844113                                        LR 0.000001    Time 0.222080    
2023-04-17 21:07:22,508 - Epoch: [316][  150/  518]    Overall Loss 2.841164    Objective Loss 2.841164                                        LR 0.000001    Time 0.219545    
2023-04-17 21:07:33,120 - Epoch: [316][  200/  518]    Overall Loss 2.840853    Objective Loss 2.840853                                        LR 0.000001    Time 0.217710    
2023-04-17 21:07:43,785 - Epoch: [316][  250/  518]    Overall Loss 2.846153    Objective Loss 2.846153                                        LR 0.000001    Time 0.216822    
2023-04-17 21:07:54,522 - Epoch: [316][  300/  518]    Overall Loss 2.854867    Objective Loss 2.854867                                        LR 0.000001    Time 0.216469    
2023-04-17 21:08:05,224 - Epoch: [316][  350/  518]    Overall Loss 2.856084    Objective Loss 2.856084                                        LR 0.000001    Time 0.216119    
2023-04-17 21:08:15,870 - Epoch: [316][  400/  518]    Overall Loss 2.857365    Objective Loss 2.857365                                        LR 0.000001    Time 0.215715    
2023-04-17 21:08:26,604 - Epoch: [316][  450/  518]    Overall Loss 2.862235    Objective Loss 2.862235                                        LR 0.000001    Time 0.215596    
2023-04-17 21:08:37,236 - Epoch: [316][  500/  518]    Overall Loss 2.863659    Objective Loss 2.863659                                        LR 0.000001    Time 0.215297    
2023-04-17 21:08:40,935 - Epoch: [316][  518/  518]    Overall Loss 2.861672    Objective Loss 2.861672                                        LR 0.000001    Time 0.214957    
2023-04-17 21:08:41,016 - --- validate (epoch=316)-----------
2023-04-17 21:08:41,016 - 4952 samples (32 per mini-batch)
2023-04-17 21:09:22,269 - Epoch: [316][   50/  155]    Loss 3.004167    mAP 0.526941    
2023-04-17 21:10:05,890 - Epoch: [316][  100/  155]    Loss 3.043079    mAP 0.530854    
2023-04-17 21:10:47,041 - Epoch: [316][  150/  155]    Loss 3.043469    mAP 0.527163    
2023-04-17 21:10:51,300 - Epoch: [316][  155/  155]    Loss 3.041346    mAP 0.528881    
2023-04-17 21:10:51,380 - ==> mAP: 0.52888    Loss: 3.041

2023-04-17 21:10:51,384 - ==> Best [mAP: 0.529620   vloss: 3.078836   Sparsity:0.00   Params: 2177088 on epoch: 306]
2023-04-17 21:10:51,384 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-17 21:10:51,420 - 

2023-04-17 21:10:51,420 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 21:11:02,987 - Epoch: [317][   50/  518]    Overall Loss 2.900618    Objective Loss 2.900618                                        LR 0.000001    Time 0.231301    
2023-04-17 21:11:13,659 - Epoch: [317][  100/  518]    Overall Loss 2.916345    Objective Loss 2.916345                                        LR 0.000001    Time 0.222346    
2023-04-17 21:11:24,359 - Epoch: [317][  150/  518]    Overall Loss 2.901391    Objective Loss 2.901391                                        LR 0.000001    Time 0.219558    
2023-04-17 21:11:35,089 - Epoch: [317][  200/  518]    Overall Loss 2.905318    Objective Loss 2.905318                                        LR 0.000001    Time 0.218308    
2023-04-17 21:11:45,805 - Epoch: [317][  250/  518]    Overall Loss 2.906555    Objective Loss 2.906555                                        LR 0.000001    Time 0.217505    
2023-04-17 21:11:56,436 - Epoch: [317][  300/  518]    Overall Loss 2.904834    Objective Loss 2.904834                                        LR 0.000001    Time 0.216688    
2023-04-17 21:12:07,127 - Epoch: [317][  350/  518]    Overall Loss 2.899007    Objective Loss 2.899007                                        LR 0.000001    Time 0.216272    
2023-04-17 21:12:17,879 - Epoch: [317][  400/  518]    Overall Loss 2.898144    Objective Loss 2.898144                                        LR 0.000001    Time 0.216115    
2023-04-17 21:12:28,571 - Epoch: [317][  450/  518]    Overall Loss 2.889833    Objective Loss 2.889833                                        LR 0.000001    Time 0.215859    
2023-04-17 21:12:39,276 - Epoch: [317][  500/  518]    Overall Loss 2.893362    Objective Loss 2.893362                                        LR 0.000001    Time 0.215680    
2023-04-17 21:12:43,025 - Epoch: [317][  518/  518]    Overall Loss 2.890988    Objective Loss 2.890988                                        LR 0.000001    Time 0.215421    
2023-04-17 21:12:43,104 - --- validate (epoch=317)-----------
2023-04-17 21:12:43,104 - 4952 samples (32 per mini-batch)
2023-04-17 21:13:26,427 - Epoch: [317][   50/  155]    Loss 3.093794    mAP 0.521105    
2023-04-17 21:14:08,202 - Epoch: [317][  100/  155]    Loss 3.049695    mAP 0.527717    
2023-04-17 21:14:49,104 - Epoch: [317][  150/  155]    Loss 3.038460    mAP 0.527596    
2023-04-17 21:14:53,114 - Epoch: [317][  155/  155]    Loss 3.039215    mAP 0.528093    
2023-04-17 21:14:53,191 - ==> mAP: 0.52809    Loss: 3.039

2023-04-17 21:14:53,195 - ==> Best [mAP: 0.529620   vloss: 3.078836   Sparsity:0.00   Params: 2177088 on epoch: 306]
2023-04-17 21:14:53,195 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-17 21:14:53,228 - 

2023-04-17 21:14:53,228 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 21:15:04,678 - Epoch: [318][   50/  518]    Overall Loss 2.804525    Objective Loss 2.804525                                        LR 0.000001    Time 0.228941    
2023-04-17 21:15:15,379 - Epoch: [318][  100/  518]    Overall Loss 2.809174    Objective Loss 2.809174                                        LR 0.000001    Time 0.221463    
2023-04-17 21:15:26,117 - Epoch: [318][  150/  518]    Overall Loss 2.837814    Objective Loss 2.837814                                        LR 0.000001    Time 0.219220    
2023-04-17 21:15:36,866 - Epoch: [318][  200/  518]    Overall Loss 2.858250    Objective Loss 2.858250                                        LR 0.000001    Time 0.218152    
2023-04-17 21:15:47,536 - Epoch: [318][  250/  518]    Overall Loss 2.863728    Objective Loss 2.863728                                        LR 0.000001    Time 0.217195    
2023-04-17 21:15:58,311 - Epoch: [318][  300/  518]    Overall Loss 2.876480    Objective Loss 2.876480                                        LR 0.000001    Time 0.216907    
2023-04-17 21:16:08,933 - Epoch: [318][  350/  518]    Overall Loss 2.876626    Objective Loss 2.876626                                        LR 0.000001    Time 0.216265    
2023-04-17 21:16:19,582 - Epoch: [318][  400/  518]    Overall Loss 2.881234    Objective Loss 2.881234                                        LR 0.000001    Time 0.215850    
2023-04-17 21:16:30,279 - Epoch: [318][  450/  518]    Overall Loss 2.882167    Objective Loss 2.882167                                        LR 0.000001    Time 0.215635    
2023-04-17 21:16:40,940 - Epoch: [318][  500/  518]    Overall Loss 2.880881    Objective Loss 2.880881                                        LR 0.000001    Time 0.215391    
2023-04-17 21:16:44,638 - Epoch: [318][  518/  518]    Overall Loss 2.881059    Objective Loss 2.881059                                        LR 0.000001    Time 0.215044    
2023-04-17 21:16:44,718 - --- validate (epoch=318)-----------
2023-04-17 21:16:44,718 - 4952 samples (32 per mini-batch)
2023-04-17 21:17:26,765 - Epoch: [318][   50/  155]    Loss 3.050421    mAP 0.534032    
2023-04-17 21:18:06,588 - Epoch: [318][  100/  155]    Loss 3.058195    mAP 0.521048    
2023-04-17 21:18:49,482 - Epoch: [318][  150/  155]    Loss 3.042693    mAP 0.524727    
2023-04-17 21:18:53,293 - Epoch: [318][  155/  155]    Loss 3.043306    mAP 0.522333    
2023-04-17 21:18:53,370 - ==> mAP: 0.52233    Loss: 3.043

2023-04-17 21:18:53,374 - ==> Best [mAP: 0.529620   vloss: 3.078836   Sparsity:0.00   Params: 2177088 on epoch: 306]
2023-04-17 21:18:53,374 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-17 21:18:53,408 - 

2023-04-17 21:18:53,408 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 21:19:05,080 - Epoch: [319][   50/  518]    Overall Loss 2.909498    Objective Loss 2.909498                                        LR 0.000001    Time 0.233376    
2023-04-17 21:19:15,720 - Epoch: [319][  100/  518]    Overall Loss 2.917832    Objective Loss 2.917832                                        LR 0.000001    Time 0.223073    
2023-04-17 21:19:26,371 - Epoch: [319][  150/  518]    Overall Loss 2.909447    Objective Loss 2.909447                                        LR 0.000001    Time 0.219711    
2023-04-17 21:19:37,056 - Epoch: [319][  200/  518]    Overall Loss 2.899939    Objective Loss 2.899939                                        LR 0.000001    Time 0.218203    
2023-04-17 21:19:47,827 - Epoch: [319][  250/  518]    Overall Loss 2.896546    Objective Loss 2.896546                                        LR 0.000001    Time 0.217640    
2023-04-17 21:19:58,579 - Epoch: [319][  300/  518]    Overall Loss 2.887315    Objective Loss 2.887315                                        LR 0.000001    Time 0.217203    
2023-04-17 21:20:09,202 - Epoch: [319][  350/  518]    Overall Loss 2.886389    Objective Loss 2.886389                                        LR 0.000001    Time 0.216520    
2023-04-17 21:20:19,894 - Epoch: [319][  400/  518]    Overall Loss 2.885207    Objective Loss 2.885207                                        LR 0.000001    Time 0.216180    
2023-04-17 21:20:30,624 - Epoch: [319][  450/  518]    Overall Loss 2.884965    Objective Loss 2.884965                                        LR 0.000001    Time 0.216003    
2023-04-17 21:20:41,338 - Epoch: [319][  500/  518]    Overall Loss 2.881855    Objective Loss 2.881855                                        LR 0.000001    Time 0.215827    
2023-04-17 21:20:45,029 - Epoch: [319][  518/  518]    Overall Loss 2.881625    Objective Loss 2.881625                                        LR 0.000001    Time 0.215451    
2023-04-17 21:20:45,107 - --- validate (epoch=319)-----------
2023-04-17 21:20:45,108 - 4952 samples (32 per mini-batch)
2023-04-17 21:21:25,561 - Epoch: [319][   50/  155]    Loss 3.021127    mAP 0.531070    
2023-04-17 21:22:06,264 - Epoch: [319][  100/  155]    Loss 3.038464    mAP 0.525136    
2023-04-17 21:22:48,965 - Epoch: [319][  150/  155]    Loss 3.044118    mAP 0.525547    
2023-04-17 21:22:52,703 - Epoch: [319][  155/  155]    Loss 3.044279    mAP 0.523575    
2023-04-17 21:22:52,781 - ==> mAP: 0.52358    Loss: 3.044

2023-04-17 21:22:52,785 - ==> Best [mAP: 0.529620   vloss: 3.078836   Sparsity:0.00   Params: 2177088 on epoch: 306]
2023-04-17 21:22:52,785 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-17 21:22:52,819 - 

2023-04-17 21:22:52,819 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 21:23:04,335 - Epoch: [320][   50/  518]    Overall Loss 2.831244    Objective Loss 2.831244                                        LR 0.000001    Time 0.230271    
2023-04-17 21:23:14,963 - Epoch: [320][  100/  518]    Overall Loss 2.848742    Objective Loss 2.848742                                        LR 0.000001    Time 0.221396    
2023-04-17 21:23:25,699 - Epoch: [320][  150/  518]    Overall Loss 2.875211    Objective Loss 2.875211                                        LR 0.000001    Time 0.219161    
2023-04-17 21:23:36,429 - Epoch: [320][  200/  518]    Overall Loss 2.870509    Objective Loss 2.870509                                        LR 0.000001    Time 0.218015    
2023-04-17 21:23:47,216 - Epoch: [320][  250/  518]    Overall Loss 2.869930    Objective Loss 2.869930                                        LR 0.000001    Time 0.217553    
2023-04-17 21:23:57,979 - Epoch: [320][  300/  518]    Overall Loss 2.876189    Objective Loss 2.876189                                        LR 0.000001    Time 0.217167    
2023-04-17 21:24:08,766 - Epoch: [320][  350/  518]    Overall Loss 2.870518    Objective Loss 2.870518                                        LR 0.000001    Time 0.216959    
2023-04-17 21:24:19,511 - Epoch: [320][  400/  518]    Overall Loss 2.875179    Objective Loss 2.875179                                        LR 0.000001    Time 0.216697    
2023-04-17 21:24:30,200 - Epoch: [320][  450/  518]    Overall Loss 2.880662    Objective Loss 2.880662                                        LR 0.000001    Time 0.216370    
2023-04-17 21:24:40,915 - Epoch: [320][  500/  518]    Overall Loss 2.878596    Objective Loss 2.878596                                        LR 0.000001    Time 0.216159    
2023-04-17 21:24:44,651 - Epoch: [320][  518/  518]    Overall Loss 2.879092    Objective Loss 2.879092                                        LR 0.000001    Time 0.215859    
2023-04-17 21:24:44,732 - --- validate (epoch=320)-----------
2023-04-17 21:24:44,732 - 4952 samples (32 per mini-batch)
2023-04-17 21:25:29,176 - Epoch: [320][   50/  155]    Loss 3.056840    mAP 0.525058    
2023-04-17 21:26:12,116 - Epoch: [320][  100/  155]    Loss 3.031486    mAP 0.524129    
2023-04-17 21:26:55,107 - Epoch: [320][  150/  155]    Loss 3.034938    mAP 0.524478    
2023-04-17 21:26:59,369 - Epoch: [320][  155/  155]    Loss 3.035291    mAP 0.522828    
2023-04-17 21:26:59,447 - ==> mAP: 0.52283    Loss: 3.035

2023-04-17 21:26:59,451 - ==> Best [mAP: 0.529620   vloss: 3.078836   Sparsity:0.00   Params: 2177088 on epoch: 306]
2023-04-17 21:26:59,451 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-17 21:26:59,485 - 

2023-04-17 21:26:59,486 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 21:27:11,029 - Epoch: [321][   50/  518]    Overall Loss 2.860332    Objective Loss 2.860332                                        LR 0.000001    Time 0.230824    
2023-04-17 21:27:21,797 - Epoch: [321][  100/  518]    Overall Loss 2.880351    Objective Loss 2.880351                                        LR 0.000001    Time 0.223074    
2023-04-17 21:27:32,482 - Epoch: [321][  150/  518]    Overall Loss 2.863022    Objective Loss 2.863022                                        LR 0.000001    Time 0.219942    
2023-04-17 21:27:43,215 - Epoch: [321][  200/  518]    Overall Loss 2.865914    Objective Loss 2.865914                                        LR 0.000001    Time 0.218609    
2023-04-17 21:27:53,919 - Epoch: [321][  250/  518]    Overall Loss 2.863132    Objective Loss 2.863132                                        LR 0.000001    Time 0.217699    
2023-04-17 21:28:04,590 - Epoch: [321][  300/  518]    Overall Loss 2.860640    Objective Loss 2.860640                                        LR 0.000001    Time 0.216980    
2023-04-17 21:28:15,330 - Epoch: [321][  350/  518]    Overall Loss 2.858334    Objective Loss 2.858334                                        LR 0.000001    Time 0.216665    
2023-04-17 21:28:26,000 - Epoch: [321][  400/  518]    Overall Loss 2.855315    Objective Loss 2.855315                                        LR 0.000001    Time 0.216253    
2023-04-17 21:28:36,657 - Epoch: [321][  450/  518]    Overall Loss 2.864520    Objective Loss 2.864520                                        LR 0.000001    Time 0.215904    
2023-04-17 21:28:47,297 - Epoch: [321][  500/  518]    Overall Loss 2.865701    Objective Loss 2.865701                                        LR 0.000001    Time 0.215591    
2023-04-17 21:28:51,085 - Epoch: [321][  518/  518]    Overall Loss 2.865688    Objective Loss 2.865688                                        LR 0.000001    Time 0.215410    
2023-04-17 21:28:51,165 - --- validate (epoch=321)-----------
2023-04-17 21:28:51,165 - 4952 samples (32 per mini-batch)
2023-04-17 21:29:34,069 - Epoch: [321][   50/  155]    Loss 3.042574    mAP 0.524054    
2023-04-17 21:30:16,616 - Epoch: [321][  100/  155]    Loss 3.045795    mAP 0.525074    
2023-04-17 21:30:58,374 - Epoch: [321][  150/  155]    Loss 3.034173    mAP 0.526018    
2023-04-17 21:31:03,021 - Epoch: [321][  155/  155]    Loss 3.033659    mAP 0.525645    
2023-04-17 21:31:03,098 - ==> mAP: 0.52564    Loss: 3.034

2023-04-17 21:31:03,102 - ==> Best [mAP: 0.529620   vloss: 3.078836   Sparsity:0.00   Params: 2177088 on epoch: 306]
2023-04-17 21:31:03,102 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-17 21:31:03,137 - 

2023-04-17 21:31:03,137 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 21:31:14,706 - Epoch: [322][   50/  518]    Overall Loss 2.909307    Objective Loss 2.909307                                        LR 0.000001    Time 0.231316    
2023-04-17 21:31:25,565 - Epoch: [322][  100/  518]    Overall Loss 2.877023    Objective Loss 2.877023                                        LR 0.000001    Time 0.224242    
2023-04-17 21:31:36,309 - Epoch: [322][  150/  518]    Overall Loss 2.851586    Objective Loss 2.851586                                        LR 0.000001    Time 0.221106    
2023-04-17 21:31:47,092 - Epoch: [322][  200/  518]    Overall Loss 2.850387    Objective Loss 2.850387                                        LR 0.000001    Time 0.219740    
2023-04-17 21:31:57,942 - Epoch: [322][  250/  518]    Overall Loss 2.855412    Objective Loss 2.855412                                        LR 0.000001    Time 0.219183    
2023-04-17 21:32:08,660 - Epoch: [322][  300/  518]    Overall Loss 2.854062    Objective Loss 2.854062                                        LR 0.000001    Time 0.218378    
2023-04-17 21:32:19,304 - Epoch: [322][  350/  518]    Overall Loss 2.849576    Objective Loss 2.849576                                        LR 0.000001    Time 0.217588    
2023-04-17 21:32:30,083 - Epoch: [322][  400/  518]    Overall Loss 2.849785    Objective Loss 2.849785                                        LR 0.000001    Time 0.217331    
2023-04-17 21:32:40,809 - Epoch: [322][  450/  518]    Overall Loss 2.852355    Objective Loss 2.852355                                        LR 0.000001    Time 0.217017    
2023-04-17 21:32:51,536 - Epoch: [322][  500/  518]    Overall Loss 2.853084    Objective Loss 2.853084                                        LR 0.000001    Time 0.216766    
2023-04-17 21:32:55,237 - Epoch: [322][  518/  518]    Overall Loss 2.851870    Objective Loss 2.851870                                        LR 0.000001    Time 0.216376    
2023-04-17 21:32:55,317 - --- validate (epoch=322)-----------
2023-04-17 21:32:55,317 - 4952 samples (32 per mini-batch)
2023-04-17 21:33:37,242 - Epoch: [322][   50/  155]    Loss 3.018029    mAP 0.539039    
2023-04-17 21:34:17,720 - Epoch: [322][  100/  155]    Loss 3.032187    mAP 0.524992    
2023-04-17 21:34:58,547 - Epoch: [322][  150/  155]    Loss 3.037435    mAP 0.522821    
2023-04-17 21:35:02,452 - Epoch: [322][  155/  155]    Loss 3.037044    mAP 0.521965    
2023-04-17 21:35:02,524 - ==> mAP: 0.52197    Loss: 3.037

2023-04-17 21:35:02,527 - ==> Best [mAP: 0.529620   vloss: 3.078836   Sparsity:0.00   Params: 2177088 on epoch: 306]
2023-04-17 21:35:02,527 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-17 21:35:02,561 - 

2023-04-17 21:35:02,562 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 21:35:14,021 - Epoch: [323][   50/  518]    Overall Loss 2.908936    Objective Loss 2.908936                                        LR 0.000001    Time 0.229133    
2023-04-17 21:35:24,731 - Epoch: [323][  100/  518]    Overall Loss 2.893299    Objective Loss 2.893299                                        LR 0.000001    Time 0.221650    
2023-04-17 21:35:35,461 - Epoch: [323][  150/  518]    Overall Loss 2.871314    Objective Loss 2.871314                                        LR 0.000001    Time 0.219288    
2023-04-17 21:35:46,179 - Epoch: [323][  200/  518]    Overall Loss 2.861030    Objective Loss 2.861030                                        LR 0.000001    Time 0.218049    
2023-04-17 21:35:56,929 - Epoch: [323][  250/  518]    Overall Loss 2.863008    Objective Loss 2.863008                                        LR 0.000001    Time 0.217434    
2023-04-17 21:36:07,650 - Epoch: [323][  300/  518]    Overall Loss 2.869565    Objective Loss 2.869565                                        LR 0.000001    Time 0.216928    
2023-04-17 21:36:18,401 - Epoch: [323][  350/  518]    Overall Loss 2.872304    Objective Loss 2.872304                                        LR 0.000001    Time 0.216649    
2023-04-17 21:36:29,202 - Epoch: [323][  400/  518]    Overall Loss 2.875214    Objective Loss 2.875214                                        LR 0.000001    Time 0.216568    
2023-04-17 21:36:39,980 - Epoch: [323][  450/  518]    Overall Loss 2.876282    Objective Loss 2.876282                                        LR 0.000001    Time 0.216453    
2023-04-17 21:36:50,734 - Epoch: [323][  500/  518]    Overall Loss 2.877461    Objective Loss 2.877461                                        LR 0.000001    Time 0.216313    
2023-04-17 21:36:54,497 - Epoch: [323][  518/  518]    Overall Loss 2.878146    Objective Loss 2.878146                                        LR 0.000001    Time 0.216060    
2023-04-17 21:36:54,577 - --- validate (epoch=323)-----------
2023-04-17 21:36:54,577 - 4952 samples (32 per mini-batch)
2023-04-17 21:37:36,714 - Epoch: [323][   50/  155]    Loss 3.035360    mAP 0.524780    
2023-04-17 21:38:18,090 - Epoch: [323][  100/  155]    Loss 3.042522    mAP 0.521455    
2023-04-17 21:39:00,122 - Epoch: [323][  150/  155]    Loss 3.038539    mAP 0.522922    
2023-04-17 21:39:04,469 - Epoch: [323][  155/  155]    Loss 3.036995    mAP 0.523718    
2023-04-17 21:39:04,546 - ==> mAP: 0.52372    Loss: 3.037

2023-04-17 21:39:04,550 - ==> Best [mAP: 0.529620   vloss: 3.078836   Sparsity:0.00   Params: 2177088 on epoch: 306]
2023-04-17 21:39:04,550 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-17 21:39:04,585 - 

2023-04-17 21:39:04,585 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 21:39:15,873 - Epoch: [324][   50/  518]    Overall Loss 2.908893    Objective Loss 2.908893                                        LR 0.000001    Time 0.225714    
2023-04-17 21:39:26,674 - Epoch: [324][  100/  518]    Overall Loss 2.885568    Objective Loss 2.885568                                        LR 0.000001    Time 0.220847    
2023-04-17 21:39:37,383 - Epoch: [324][  150/  518]    Overall Loss 2.884286    Objective Loss 2.884286                                        LR 0.000001    Time 0.218614    
2023-04-17 21:39:48,095 - Epoch: [324][  200/  518]    Overall Loss 2.866308    Objective Loss 2.866308                                        LR 0.000001    Time 0.217513    
2023-04-17 21:39:58,800 - Epoch: [324][  250/  518]    Overall Loss 2.868176    Objective Loss 2.868176                                        LR 0.000001    Time 0.216827    
2023-04-17 21:40:09,573 - Epoch: [324][  300/  518]    Overall Loss 2.864341    Objective Loss 2.864341                                        LR 0.000001    Time 0.216593    
2023-04-17 21:40:20,256 - Epoch: [324][  350/  518]    Overall Loss 2.857745    Objective Loss 2.857745                                        LR 0.000001    Time 0.216169    
2023-04-17 21:40:31,012 - Epoch: [324][  400/  518]    Overall Loss 2.858259    Objective Loss 2.858259                                        LR 0.000001    Time 0.216035    
2023-04-17 21:40:41,749 - Epoch: [324][  450/  518]    Overall Loss 2.860310    Objective Loss 2.860310                                        LR 0.000001    Time 0.215887    
2023-04-17 21:40:52,379 - Epoch: [324][  500/  518]    Overall Loss 2.860085    Objective Loss 2.860085                                        LR 0.000001    Time 0.215556    
2023-04-17 21:40:56,090 - Epoch: [324][  518/  518]    Overall Loss 2.858335    Objective Loss 2.858335                                        LR 0.000001    Time 0.215229    
2023-04-17 21:40:56,172 - --- validate (epoch=324)-----------
2023-04-17 21:40:56,172 - 4952 samples (32 per mini-batch)
2023-04-17 21:41:37,837 - Epoch: [324][   50/  155]    Loss 3.063389    mAP 0.548922    
2023-04-17 21:42:20,567 - Epoch: [324][  100/  155]    Loss 3.053725    mAP 0.536019    
2023-04-17 21:43:02,580 - Epoch: [324][  150/  155]    Loss 3.037553    mAP 0.528514    
2023-04-17 21:43:06,827 - Epoch: [324][  155/  155]    Loss 3.036416    mAP 0.527423    
2023-04-17 21:43:06,906 - ==> mAP: 0.52742    Loss: 3.036

2023-04-17 21:43:06,910 - ==> Best [mAP: 0.529620   vloss: 3.078836   Sparsity:0.00   Params: 2177088 on epoch: 306]
2023-04-17 21:43:06,910 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-17 21:43:06,944 - 

2023-04-17 21:43:06,944 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 21:43:18,421 - Epoch: [325][   50/  518]    Overall Loss 2.874162    Objective Loss 2.874162                                        LR 0.000001    Time 0.229480    
2023-04-17 21:43:29,166 - Epoch: [325][  100/  518]    Overall Loss 2.876103    Objective Loss 2.876103                                        LR 0.000001    Time 0.222181    
2023-04-17 21:43:39,882 - Epoch: [325][  150/  518]    Overall Loss 2.857150    Objective Loss 2.857150                                        LR 0.000001    Time 0.219546    
2023-04-17 21:43:50,618 - Epoch: [325][  200/  518]    Overall Loss 2.861855    Objective Loss 2.861855                                        LR 0.000001    Time 0.218334    
2023-04-17 21:44:01,376 - Epoch: [325][  250/  518]    Overall Loss 2.866110    Objective Loss 2.866110                                        LR 0.000001    Time 0.217694    
2023-04-17 21:44:12,192 - Epoch: [325][  300/  518]    Overall Loss 2.859657    Objective Loss 2.859657                                        LR 0.000001    Time 0.217460    
2023-04-17 21:44:22,916 - Epoch: [325][  350/  518]    Overall Loss 2.860633    Objective Loss 2.860633                                        LR 0.000001    Time 0.217029    
2023-04-17 21:44:33,623 - Epoch: [325][  400/  518]    Overall Loss 2.860390    Objective Loss 2.860390                                        LR 0.000001    Time 0.216665    
2023-04-17 21:44:44,386 - Epoch: [325][  450/  518]    Overall Loss 2.860429    Objective Loss 2.860429                                        LR 0.000001    Time 0.216504    
2023-04-17 21:44:55,251 - Epoch: [325][  500/  518]    Overall Loss 2.860536    Objective Loss 2.860536                                        LR 0.000001    Time 0.216580    
2023-04-17 21:44:58,964 - Epoch: [325][  518/  518]    Overall Loss 2.859727    Objective Loss 2.859727                                        LR 0.000001    Time 0.216222    
2023-04-17 21:44:59,045 - --- validate (epoch=325)-----------
2023-04-17 21:44:59,046 - 4952 samples (32 per mini-batch)
2023-04-17 21:45:41,357 - Epoch: [325][   50/  155]    Loss 3.033340    mAP 0.516830    
2023-04-17 21:46:23,691 - Epoch: [325][  100/  155]    Loss 3.001603    mAP 0.527426    
2023-04-17 21:47:06,955 - Epoch: [325][  150/  155]    Loss 3.031784    mAP 0.519412    
2023-04-17 21:47:10,407 - Epoch: [325][  155/  155]    Loss 3.028529    mAP 0.520501    
2023-04-17 21:47:10,479 - ==> mAP: 0.52050    Loss: 3.029

2023-04-17 21:47:10,482 - ==> Best [mAP: 0.529620   vloss: 3.078836   Sparsity:0.00   Params: 2177088 on epoch: 306]
2023-04-17 21:47:10,483 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-17 21:47:10,518 - 

2023-04-17 21:47:10,518 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 21:47:22,001 - Epoch: [326][   50/  518]    Overall Loss 2.863989    Objective Loss 2.863989                                        LR 0.000001    Time 0.229589    
2023-04-17 21:47:32,779 - Epoch: [326][  100/  518]    Overall Loss 2.867823    Objective Loss 2.867823                                        LR 0.000001    Time 0.222559    
2023-04-17 21:47:43,473 - Epoch: [326][  150/  518]    Overall Loss 2.855809    Objective Loss 2.855809                                        LR 0.000001    Time 0.219660    
2023-04-17 21:47:54,262 - Epoch: [326][  200/  518]    Overall Loss 2.852392    Objective Loss 2.852392                                        LR 0.000001    Time 0.218682    
2023-04-17 21:48:05,114 - Epoch: [326][  250/  518]    Overall Loss 2.857403    Objective Loss 2.857403                                        LR 0.000001    Time 0.218346    
2023-04-17 21:48:15,889 - Epoch: [326][  300/  518]    Overall Loss 2.864362    Objective Loss 2.864362                                        LR 0.000001    Time 0.217866    
2023-04-17 21:48:26,675 - Epoch: [326][  350/  518]    Overall Loss 2.865724    Objective Loss 2.865724                                        LR 0.000001    Time 0.217556    
2023-04-17 21:48:37,507 - Epoch: [326][  400/  518]    Overall Loss 2.870046    Objective Loss 2.870046                                        LR 0.000001    Time 0.217438    
2023-04-17 21:48:48,286 - Epoch: [326][  450/  518]    Overall Loss 2.863964    Objective Loss 2.863964                                        LR 0.000001    Time 0.217228    
2023-04-17 21:48:59,140 - Epoch: [326][  500/  518]    Overall Loss 2.862817    Objective Loss 2.862817                                        LR 0.000001    Time 0.217210    
2023-04-17 21:49:02,871 - Epoch: [326][  518/  518]    Overall Loss 2.859275    Objective Loss 2.859275                                        LR 0.000001    Time 0.216865    
2023-04-17 21:49:02,952 - --- validate (epoch=326)-----------
2023-04-17 21:49:02,952 - 4952 samples (32 per mini-batch)
2023-04-17 21:49:43,723 - Epoch: [326][   50/  155]    Loss 3.012764    mAP 0.522943    
2023-04-17 21:50:25,283 - Epoch: [326][  100/  155]    Loss 3.028545    mAP 0.525685    
2023-04-17 21:51:07,829 - Epoch: [326][  150/  155]    Loss 3.038041    mAP 0.525008    
2023-04-17 21:51:12,005 - Epoch: [326][  155/  155]    Loss 3.036847    mAP 0.522774    
2023-04-17 21:51:12,081 - ==> mAP: 0.52277    Loss: 3.037

2023-04-17 21:51:12,084 - ==> Best [mAP: 0.529620   vloss: 3.078836   Sparsity:0.00   Params: 2177088 on epoch: 306]
2023-04-17 21:51:12,085 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-17 21:51:12,121 - 

2023-04-17 21:51:12,121 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 21:51:23,449 - Epoch: [327][   50/  518]    Overall Loss 2.856970    Objective Loss 2.856970                                        LR 0.000001    Time 0.226510    
2023-04-17 21:51:34,103 - Epoch: [327][  100/  518]    Overall Loss 2.837982    Objective Loss 2.837982                                        LR 0.000001    Time 0.219775    
2023-04-17 21:51:44,735 - Epoch: [327][  150/  518]    Overall Loss 2.864251    Objective Loss 2.864251                                        LR 0.000001    Time 0.217390    
2023-04-17 21:51:55,450 - Epoch: [327][  200/  518]    Overall Loss 2.866289    Objective Loss 2.866289                                        LR 0.000001    Time 0.216608    
2023-04-17 21:52:06,338 - Epoch: [327][  250/  518]    Overall Loss 2.856767    Objective Loss 2.856767                                        LR 0.000001    Time 0.216831    
2023-04-17 21:52:17,124 - Epoch: [327][  300/  518]    Overall Loss 2.859000    Objective Loss 2.859000                                        LR 0.000001    Time 0.216643    
2023-04-17 21:52:27,891 - Epoch: [327][  350/  518]    Overall Loss 2.854270    Objective Loss 2.854270                                        LR 0.000001    Time 0.216452    
2023-04-17 21:52:38,553 - Epoch: [327][  400/  518]    Overall Loss 2.856299    Objective Loss 2.856299                                        LR 0.000001    Time 0.216046    
2023-04-17 21:52:49,278 - Epoch: [327][  450/  518]    Overall Loss 2.855084    Objective Loss 2.855084                                        LR 0.000001    Time 0.215872    
2023-04-17 21:52:59,974 - Epoch: [327][  500/  518]    Overall Loss 2.859278    Objective Loss 2.859278                                        LR 0.000001    Time 0.215673    
2023-04-17 21:53:03,651 - Epoch: [327][  518/  518]    Overall Loss 2.861976    Objective Loss 2.861976                                        LR 0.000001    Time 0.215275    
2023-04-17 21:53:03,734 - --- validate (epoch=327)-----------
2023-04-17 21:53:03,735 - 4952 samples (32 per mini-batch)
2023-04-17 21:53:45,090 - Epoch: [327][   50/  155]    Loss 3.021351    mAP 0.525380    
2023-04-17 21:54:27,740 - Epoch: [327][  100/  155]    Loss 3.025532    mAP 0.514185    
2023-04-17 21:55:08,923 - Epoch: [327][  150/  155]    Loss 3.030020    mAP 0.519637    
2023-04-17 21:55:12,668 - Epoch: [327][  155/  155]    Loss 3.031481    mAP 0.520915    
2023-04-17 21:55:12,749 - ==> mAP: 0.52091    Loss: 3.031

2023-04-17 21:55:12,753 - ==> Best [mAP: 0.529620   vloss: 3.078836   Sparsity:0.00   Params: 2177088 on epoch: 306]
2023-04-17 21:55:12,753 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-17 21:55:12,789 - 

2023-04-17 21:55:12,789 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 21:55:24,438 - Epoch: [328][   50/  518]    Overall Loss 2.881270    Objective Loss 2.881270                                        LR 0.000001    Time 0.232912    
2023-04-17 21:55:35,275 - Epoch: [328][  100/  518]    Overall Loss 2.848978    Objective Loss 2.848978                                        LR 0.000001    Time 0.224816    
2023-04-17 21:55:46,166 - Epoch: [328][  150/  518]    Overall Loss 2.855833    Objective Loss 2.855833                                        LR 0.000001    Time 0.222474    
2023-04-17 21:55:56,927 - Epoch: [328][  200/  518]    Overall Loss 2.845910    Objective Loss 2.845910                                        LR 0.000001    Time 0.220651    
2023-04-17 21:56:07,694 - Epoch: [328][  250/  518]    Overall Loss 2.856296    Objective Loss 2.856296                                        LR 0.000001    Time 0.219584    
2023-04-17 21:56:18,562 - Epoch: [328][  300/  518]    Overall Loss 2.857004    Objective Loss 2.857004                                        LR 0.000001    Time 0.219206    
2023-04-17 21:56:29,413 - Epoch: [328][  350/  518]    Overall Loss 2.858365    Objective Loss 2.858365                                        LR 0.000001    Time 0.218891    
2023-04-17 21:56:40,291 - Epoch: [328][  400/  518]    Overall Loss 2.865386    Objective Loss 2.865386                                        LR 0.000001    Time 0.218720    
2023-04-17 21:56:51,096 - Epoch: [328][  450/  518]    Overall Loss 2.861802    Objective Loss 2.861802                                        LR 0.000001    Time 0.218426    
2023-04-17 21:57:02,000 - Epoch: [328][  500/  518]    Overall Loss 2.859484    Objective Loss 2.859484                                        LR 0.000001    Time 0.218389    
2023-04-17 21:57:05,788 - Epoch: [328][  518/  518]    Overall Loss 2.859058    Objective Loss 2.859058                                        LR 0.000001    Time 0.218112    
2023-04-17 21:57:05,868 - --- validate (epoch=328)-----------
2023-04-17 21:57:05,869 - 4952 samples (32 per mini-batch)
2023-04-17 21:57:49,204 - Epoch: [328][   50/  155]    Loss 3.026530    mAP 0.540669    
2023-04-17 21:58:30,619 - Epoch: [328][  100/  155]    Loss 3.052719    mAP 0.528178    
2023-04-17 21:59:11,588 - Epoch: [328][  150/  155]    Loss 3.029468    mAP 0.526130    
2023-04-17 21:59:15,028 - Epoch: [328][  155/  155]    Loss 3.028803    mAP 0.526280    
2023-04-17 21:59:15,106 - ==> mAP: 0.52628    Loss: 3.029

2023-04-17 21:59:15,110 - ==> Best [mAP: 0.529620   vloss: 3.078836   Sparsity:0.00   Params: 2177088 on epoch: 306]
2023-04-17 21:59:15,110 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-17 21:59:15,147 - 

2023-04-17 21:59:15,147 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 21:59:26,795 - Epoch: [329][   50/  518]    Overall Loss 2.819637    Objective Loss 2.819637                                        LR 0.000001    Time 0.232913    
2023-04-17 21:59:37,530 - Epoch: [329][  100/  518]    Overall Loss 2.841420    Objective Loss 2.841420                                        LR 0.000001    Time 0.223790    
2023-04-17 21:59:48,318 - Epoch: [329][  150/  518]    Overall Loss 2.865537    Objective Loss 2.865537                                        LR 0.000001    Time 0.221104    
2023-04-17 21:59:59,019 - Epoch: [329][  200/  518]    Overall Loss 2.859735    Objective Loss 2.859735                                        LR 0.000001    Time 0.219321    
2023-04-17 22:00:09,730 - Epoch: [329][  250/  518]    Overall Loss 2.861715    Objective Loss 2.861715                                        LR 0.000001    Time 0.218295    
2023-04-17 22:00:20,486 - Epoch: [329][  300/  518]    Overall Loss 2.860082    Objective Loss 2.860082                                        LR 0.000001    Time 0.217760    
2023-04-17 22:00:31,226 - Epoch: [329][  350/  518]    Overall Loss 2.860473    Objective Loss 2.860473                                        LR 0.000001    Time 0.217334    
2023-04-17 22:00:42,110 - Epoch: [329][  400/  518]    Overall Loss 2.859381    Objective Loss 2.859381                                        LR 0.000001    Time 0.217374    
2023-04-17 22:00:52,966 - Epoch: [329][  450/  518]    Overall Loss 2.860580    Objective Loss 2.860580                                        LR 0.000001    Time 0.217343    
2023-04-17 22:01:03,729 - Epoch: [329][  500/  518]    Overall Loss 2.855832    Objective Loss 2.855832                                        LR 0.000001    Time 0.217130    
2023-04-17 22:01:07,393 - Epoch: [329][  518/  518]    Overall Loss 2.856130    Objective Loss 2.856130                                        LR 0.000001    Time 0.216658    
2023-04-17 22:01:07,475 - --- validate (epoch=329)-----------
2023-04-17 22:01:07,475 - 4952 samples (32 per mini-batch)
2023-04-17 22:01:48,659 - Epoch: [329][   50/  155]    Loss 3.023088    mAP 0.531379    
2023-04-17 22:02:30,720 - Epoch: [329][  100/  155]    Loss 3.030590    mAP 0.521551    
2023-04-17 22:03:12,894 - Epoch: [329][  150/  155]    Loss 3.026650    mAP 0.524638    
2023-04-17 22:03:16,429 - Epoch: [329][  155/  155]    Loss 3.021920    mAP 0.525030    
2023-04-17 22:03:16,512 - ==> mAP: 0.52503    Loss: 3.022

2023-04-17 22:03:16,515 - ==> Best [mAP: 0.529620   vloss: 3.078836   Sparsity:0.00   Params: 2177088 on epoch: 306]
2023-04-17 22:03:16,515 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-17 22:03:16,551 - 

2023-04-17 22:03:16,551 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 22:03:28,134 - Epoch: [330][   50/  518]    Overall Loss 2.884041    Objective Loss 2.884041                                        LR 0.000001    Time 0.231589    
2023-04-17 22:03:38,834 - Epoch: [330][  100/  518]    Overall Loss 2.893365    Objective Loss 2.893365                                        LR 0.000001    Time 0.222778    
2023-04-17 22:03:49,586 - Epoch: [330][  150/  518]    Overall Loss 2.890045    Objective Loss 2.890045                                        LR 0.000001    Time 0.220189    
2023-04-17 22:04:00,311 - Epoch: [330][  200/  518]    Overall Loss 2.887541    Objective Loss 2.887541                                        LR 0.000001    Time 0.218758    
2023-04-17 22:04:11,045 - Epoch: [330][  250/  518]    Overall Loss 2.874885    Objective Loss 2.874885                                        LR 0.000001    Time 0.217937    
2023-04-17 22:04:21,758 - Epoch: [330][  300/  518]    Overall Loss 2.861335    Objective Loss 2.861335                                        LR 0.000001    Time 0.217321    
2023-04-17 22:04:32,480 - Epoch: [330][  350/  518]    Overall Loss 2.864336    Objective Loss 2.864336                                        LR 0.000001    Time 0.216904    
2023-04-17 22:04:43,199 - Epoch: [330][  400/  518]    Overall Loss 2.860463    Objective Loss 2.860463                                        LR 0.000001    Time 0.216585    
2023-04-17 22:04:53,801 - Epoch: [330][  450/  518]    Overall Loss 2.856226    Objective Loss 2.856226                                        LR 0.000001    Time 0.216077    
2023-04-17 22:05:04,585 - Epoch: [330][  500/  518]    Overall Loss 2.856128    Objective Loss 2.856128                                        LR 0.000001    Time 0.216033    
2023-04-17 22:05:08,341 - Epoch: [330][  518/  518]    Overall Loss 2.858392    Objective Loss 2.858392                                        LR 0.000001    Time 0.215778    
2023-04-17 22:05:08,422 - --- validate (epoch=330)-----------
2023-04-17 22:05:08,423 - 4952 samples (32 per mini-batch)
2023-04-17 22:05:50,585 - Epoch: [330][   50/  155]    Loss 3.048904    mAP 0.514422    
2023-04-17 22:06:31,486 - Epoch: [330][  100/  155]    Loss 3.042902    mAP 0.515736    
2023-04-17 22:07:13,067 - Epoch: [330][  150/  155]    Loss 3.026006    mAP 0.515878    
2023-04-17 22:07:17,363 - Epoch: [330][  155/  155]    Loss 3.025668    mAP 0.517620    
2023-04-17 22:07:17,435 - ==> mAP: 0.51762    Loss: 3.026

2023-04-17 22:07:17,438 - ==> Best [mAP: 0.529620   vloss: 3.078836   Sparsity:0.00   Params: 2177088 on epoch: 306]
2023-04-17 22:07:17,439 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-17 22:07:17,474 - 

2023-04-17 22:07:17,474 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 22:07:28,960 - Epoch: [331][   50/  518]    Overall Loss 2.891493    Objective Loss 2.891493                                        LR 0.000001    Time 0.229659    
2023-04-17 22:07:39,710 - Epoch: [331][  100/  518]    Overall Loss 2.884410    Objective Loss 2.884410                                        LR 0.000001    Time 0.222315    
2023-04-17 22:07:50,361 - Epoch: [331][  150/  518]    Overall Loss 2.861893    Objective Loss 2.861893                                        LR 0.000001    Time 0.219206    
2023-04-17 22:08:01,019 - Epoch: [331][  200/  518]    Overall Loss 2.873201    Objective Loss 2.873201                                        LR 0.000001    Time 0.217689    
2023-04-17 22:08:11,742 - Epoch: [331][  250/  518]    Overall Loss 2.869072    Objective Loss 2.869072                                        LR 0.000001    Time 0.217038    
2023-04-17 22:08:22,454 - Epoch: [331][  300/  518]    Overall Loss 2.860078    Objective Loss 2.860078                                        LR 0.000001    Time 0.216566    
2023-04-17 22:08:33,270 - Epoch: [331][  350/  518]    Overall Loss 2.853571    Objective Loss 2.853571                                        LR 0.000001    Time 0.216525    
2023-04-17 22:08:43,962 - Epoch: [331][  400/  518]    Overall Loss 2.856324    Objective Loss 2.856324                                        LR 0.000001    Time 0.216187    
2023-04-17 22:08:54,657 - Epoch: [331][  450/  518]    Overall Loss 2.854588    Objective Loss 2.854588                                        LR 0.000001    Time 0.215928    
2023-04-17 22:09:05,402 - Epoch: [331][  500/  518]    Overall Loss 2.855179    Objective Loss 2.855179                                        LR 0.000001    Time 0.215823    
2023-04-17 22:09:09,076 - Epoch: [331][  518/  518]    Overall Loss 2.853690    Objective Loss 2.853690                                        LR 0.000001    Time 0.215416    
2023-04-17 22:09:09,156 - --- validate (epoch=331)-----------
2023-04-17 22:09:09,157 - 4952 samples (32 per mini-batch)
2023-04-17 22:09:50,708 - Epoch: [331][   50/  155]    Loss 3.018479    mAP 0.524539    
2023-04-17 22:10:32,863 - Epoch: [331][  100/  155]    Loss 3.019238    mAP 0.521264    
2023-04-17 22:11:16,257 - Epoch: [331][  150/  155]    Loss 3.020808    mAP 0.524237    
2023-04-17 22:11:20,577 - Epoch: [331][  155/  155]    Loss 3.018841    mAP 0.523634    
2023-04-17 22:11:20,655 - ==> mAP: 0.52363    Loss: 3.019

2023-04-17 22:11:20,658 - ==> Best [mAP: 0.529620   vloss: 3.078836   Sparsity:0.00   Params: 2177088 on epoch: 306]
2023-04-17 22:11:20,658 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-17 22:11:20,694 - 

2023-04-17 22:11:20,694 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 22:11:32,307 - Epoch: [332][   50/  518]    Overall Loss 2.918346    Objective Loss 2.918346                                        LR 0.000001    Time 0.232215    
2023-04-17 22:11:43,049 - Epoch: [332][  100/  518]    Overall Loss 2.876068    Objective Loss 2.876068                                        LR 0.000001    Time 0.223505    
2023-04-17 22:11:53,948 - Epoch: [332][  150/  518]    Overall Loss 2.874436    Objective Loss 2.874436                                        LR 0.000001    Time 0.221657    
2023-04-17 22:12:04,806 - Epoch: [332][  200/  518]    Overall Loss 2.864464    Objective Loss 2.864464                                        LR 0.000001    Time 0.220524    
2023-04-17 22:12:15,516 - Epoch: [332][  250/  518]    Overall Loss 2.856986    Objective Loss 2.856986                                        LR 0.000001    Time 0.219253    
2023-04-17 22:12:26,231 - Epoch: [332][  300/  518]    Overall Loss 2.865612    Objective Loss 2.865612                                        LR 0.000001    Time 0.218423    
2023-04-17 22:12:37,201 - Epoch: [332][  350/  518]    Overall Loss 2.865675    Objective Loss 2.865675                                        LR 0.000001    Time 0.218558    
2023-04-17 22:12:48,165 - Epoch: [332][  400/  518]    Overall Loss 2.864785    Objective Loss 2.864785                                        LR 0.000001    Time 0.218644    
2023-04-17 22:12:58,951 - Epoch: [332][  450/  518]    Overall Loss 2.860411    Objective Loss 2.860411                                        LR 0.000001    Time 0.218315    
2023-04-17 22:13:09,747 - Epoch: [332][  500/  518]    Overall Loss 2.858324    Objective Loss 2.858324                                        LR 0.000001    Time 0.218073    
2023-04-17 22:13:13,588 - Epoch: [332][  518/  518]    Overall Loss 2.857624    Objective Loss 2.857624                                        LR 0.000001    Time 0.217910    
2023-04-17 22:13:13,672 - --- validate (epoch=332)-----------
2023-04-17 22:13:13,673 - 4952 samples (32 per mini-batch)
2023-04-17 22:13:57,073 - Epoch: [332][   50/  155]    Loss 3.024523    mAP 0.528775    
2023-04-17 22:14:37,363 - Epoch: [332][  100/  155]    Loss 3.007344    mAP 0.532820    
2023-04-17 22:15:19,645 - Epoch: [332][  150/  155]    Loss 3.023463    mAP 0.530262    
2023-04-17 22:15:23,736 - Epoch: [332][  155/  155]    Loss 3.024507    mAP 0.529515    
2023-04-17 22:15:23,815 - ==> mAP: 0.52952    Loss: 3.025

2023-04-17 22:15:23,819 - ==> Best [mAP: 0.529620   vloss: 3.078836   Sparsity:0.00   Params: 2177088 on epoch: 306]
2023-04-17 22:15:23,819 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-17 22:15:23,853 - 

2023-04-17 22:15:23,853 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 22:15:35,531 - Epoch: [333][   50/  518]    Overall Loss 2.908059    Objective Loss 2.908059                                        LR 0.000001    Time 0.233498    
2023-04-17 22:15:46,181 - Epoch: [333][  100/  518]    Overall Loss 2.854022    Objective Loss 2.854022                                        LR 0.000001    Time 0.223230    
2023-04-17 22:15:56,854 - Epoch: [333][  150/  518]    Overall Loss 2.857084    Objective Loss 2.857084                                        LR 0.000001    Time 0.219968    
2023-04-17 22:16:07,607 - Epoch: [333][  200/  518]    Overall Loss 2.849431    Objective Loss 2.849431                                        LR 0.000001    Time 0.218733    
2023-04-17 22:16:18,355 - Epoch: [333][  250/  518]    Overall Loss 2.852464    Objective Loss 2.852464                                        LR 0.000001    Time 0.217971    
2023-04-17 22:16:29,046 - Epoch: [333][  300/  518]    Overall Loss 2.852214    Objective Loss 2.852214                                        LR 0.000001    Time 0.217274    
2023-04-17 22:16:39,691 - Epoch: [333][  350/  518]    Overall Loss 2.857210    Objective Loss 2.857210                                        LR 0.000001    Time 0.216646    
2023-04-17 22:16:50,364 - Epoch: [333][  400/  518]    Overall Loss 2.859015    Objective Loss 2.859015                                        LR 0.000001    Time 0.216243    
2023-04-17 22:17:01,074 - Epoch: [333][  450/  518]    Overall Loss 2.859951    Objective Loss 2.859951                                        LR 0.000001    Time 0.216013    
2023-04-17 22:17:11,849 - Epoch: [333][  500/  518]    Overall Loss 2.860454    Objective Loss 2.860454                                        LR 0.000001    Time 0.215959    
2023-04-17 22:17:15,573 - Epoch: [333][  518/  518]    Overall Loss 2.858799    Objective Loss 2.858799                                        LR 0.000001    Time 0.215641    
2023-04-17 22:17:15,653 - --- validate (epoch=333)-----------
2023-04-17 22:17:15,653 - 4952 samples (32 per mini-batch)
2023-04-17 22:17:57,772 - Epoch: [333][   50/  155]    Loss 2.994433    mAP 0.542055    
2023-04-17 22:18:40,749 - Epoch: [333][  100/  155]    Loss 3.027317    mAP 0.525242    
2023-04-17 22:19:21,975 - Epoch: [333][  150/  155]    Loss 3.020558    mAP 0.526371    
2023-04-17 22:19:26,112 - Epoch: [333][  155/  155]    Loss 3.021715    mAP 0.524577    
2023-04-17 22:19:26,189 - ==> mAP: 0.52458    Loss: 3.022

2023-04-17 22:19:26,193 - ==> Best [mAP: 0.529620   vloss: 3.078836   Sparsity:0.00   Params: 2177088 on epoch: 306]
2023-04-17 22:19:26,193 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-17 22:19:26,230 - 

2023-04-17 22:19:26,230 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 22:19:37,849 - Epoch: [334][   50/  518]    Overall Loss 2.908993    Objective Loss 2.908993                                        LR 0.000001    Time 0.232322    
2023-04-17 22:19:48,639 - Epoch: [334][  100/  518]    Overall Loss 2.893449    Objective Loss 2.893449                                        LR 0.000001    Time 0.224051    
2023-04-17 22:19:59,412 - Epoch: [334][  150/  518]    Overall Loss 2.894824    Objective Loss 2.894824                                        LR 0.000001    Time 0.221180    
2023-04-17 22:20:10,162 - Epoch: [334][  200/  518]    Overall Loss 2.871871    Objective Loss 2.871871                                        LR 0.000001    Time 0.219627    
2023-04-17 22:20:20,966 - Epoch: [334][  250/  518]    Overall Loss 2.856762    Objective Loss 2.856762                                        LR 0.000001    Time 0.218908    
2023-04-17 22:20:31,800 - Epoch: [334][  300/  518]    Overall Loss 2.858701    Objective Loss 2.858701                                        LR 0.000001    Time 0.218532    
2023-04-17 22:20:42,511 - Epoch: [334][  350/  518]    Overall Loss 2.860567    Objective Loss 2.860567                                        LR 0.000001    Time 0.217913    
2023-04-17 22:20:53,229 - Epoch: [334][  400/  518]    Overall Loss 2.862251    Objective Loss 2.862251                                        LR 0.000001    Time 0.217464    
2023-04-17 22:21:03,942 - Epoch: [334][  450/  518]    Overall Loss 2.863378    Objective Loss 2.863378                                        LR 0.000001    Time 0.217105    
2023-04-17 22:21:14,767 - Epoch: [334][  500/  518]    Overall Loss 2.859777    Objective Loss 2.859777                                        LR 0.000001    Time 0.217042    
2023-04-17 22:21:18,489 - Epoch: [334][  518/  518]    Overall Loss 2.857549    Objective Loss 2.857549                                        LR 0.000001    Time 0.216685    
2023-04-17 22:21:18,570 - --- validate (epoch=334)-----------
2023-04-17 22:21:18,570 - 4952 samples (32 per mini-batch)
2023-04-17 22:21:58,448 - Epoch: [334][   50/  155]    Loss 3.012981    mAP 0.527158    
2023-04-17 22:22:39,903 - Epoch: [334][  100/  155]    Loss 3.008231    mAP 0.522474    
2023-04-17 22:23:21,557 - Epoch: [334][  150/  155]    Loss 3.029822    mAP 0.523424    
2023-04-17 22:23:25,274 - Epoch: [334][  155/  155]    Loss 3.030224    mAP 0.523158    
2023-04-17 22:23:25,352 - ==> mAP: 0.52316    Loss: 3.030

2023-04-17 22:23:25,355 - ==> Best [mAP: 0.529620   vloss: 3.078836   Sparsity:0.00   Params: 2177088 on epoch: 306]
2023-04-17 22:23:25,355 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-17 22:23:25,390 - 

2023-04-17 22:23:25,391 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 22:23:36,863 - Epoch: [335][   50/  518]    Overall Loss 2.832379    Objective Loss 2.832379                                        LR 0.000001    Time 0.229396    
2023-04-17 22:23:47,604 - Epoch: [335][  100/  518]    Overall Loss 2.832284    Objective Loss 2.832284                                        LR 0.000001    Time 0.222094    
2023-04-17 22:23:58,416 - Epoch: [335][  150/  518]    Overall Loss 2.854954    Objective Loss 2.854954                                        LR 0.000001    Time 0.220128    
2023-04-17 22:24:09,281 - Epoch: [335][  200/  518]    Overall Loss 2.861772    Objective Loss 2.861772                                        LR 0.000001    Time 0.219417    
2023-04-17 22:24:19,976 - Epoch: [335][  250/  518]    Overall Loss 2.864638    Objective Loss 2.864638                                        LR 0.000001    Time 0.218306    
2023-04-17 22:24:30,717 - Epoch: [335][  300/  518]    Overall Loss 2.854212    Objective Loss 2.854212                                        LR 0.000001    Time 0.217720    
2023-04-17 22:24:41,456 - Epoch: [335][  350/  518]    Overall Loss 2.852338    Objective Loss 2.852338                                        LR 0.000001    Time 0.217296    
2023-04-17 22:24:52,200 - Epoch: [335][  400/  518]    Overall Loss 2.847248    Objective Loss 2.847248                                        LR 0.000001    Time 0.216990    
2023-04-17 22:25:02,919 - Epoch: [335][  450/  518]    Overall Loss 2.846135    Objective Loss 2.846135                                        LR 0.000001    Time 0.216697    
2023-04-17 22:25:13,763 - Epoch: [335][  500/  518]    Overall Loss 2.848004    Objective Loss 2.848004                                        LR 0.000001    Time 0.216712    
2023-04-17 22:25:17,516 - Epoch: [335][  518/  518]    Overall Loss 2.850343    Objective Loss 2.850343                                        LR 0.000001    Time 0.216425    
2023-04-17 22:25:17,596 - --- validate (epoch=335)-----------
2023-04-17 22:25:17,596 - 4952 samples (32 per mini-batch)
2023-04-17 22:25:59,292 - Epoch: [335][   50/  155]    Loss 3.002619    mAP 0.528576    
2023-04-17 22:26:40,069 - Epoch: [335][  100/  155]    Loss 3.000722    mAP 0.529263    
2023-04-17 22:27:21,296 - Epoch: [335][  150/  155]    Loss 3.019933    mAP 0.530815    
2023-04-17 22:27:24,872 - Epoch: [335][  155/  155]    Loss 3.016302    mAP 0.533323    
2023-04-17 22:27:24,951 - ==> mAP: 0.53332    Loss: 3.016

2023-04-17 22:27:24,955 - ==> Best [mAP: 0.533323   vloss: 3.016302   Sparsity:0.00   Params: 2177088 on epoch: 335]
2023-04-17 22:27:24,955 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-17 22:27:25,006 - 

2023-04-17 22:27:25,006 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 22:27:36,482 - Epoch: [336][   50/  518]    Overall Loss 2.822383    Objective Loss 2.822383                                        LR 0.000001    Time 0.229462    
2023-04-17 22:27:47,254 - Epoch: [336][  100/  518]    Overall Loss 2.841110    Objective Loss 2.841110                                        LR 0.000001    Time 0.222441    
2023-04-17 22:27:58,014 - Epoch: [336][  150/  518]    Overall Loss 2.834330    Objective Loss 2.834330                                        LR 0.000001    Time 0.220013    
2023-04-17 22:28:08,774 - Epoch: [336][  200/  518]    Overall Loss 2.842683    Objective Loss 2.842683                                        LR 0.000001    Time 0.218802    
2023-04-17 22:28:19,792 - Epoch: [336][  250/  518]    Overall Loss 2.848185    Objective Loss 2.848185                                        LR 0.000001    Time 0.219107    
2023-04-17 22:28:30,455 - Epoch: [336][  300/  518]    Overall Loss 2.848542    Objective Loss 2.848542                                        LR 0.000001    Time 0.218127    
2023-04-17 22:28:41,178 - Epoch: [336][  350/  518]    Overall Loss 2.847046    Objective Loss 2.847046                                        LR 0.000001    Time 0.217599    
2023-04-17 22:28:51,863 - Epoch: [336][  400/  518]    Overall Loss 2.849908    Objective Loss 2.849908                                        LR 0.000001    Time 0.217108    
2023-04-17 22:29:02,600 - Epoch: [336][  450/  518]    Overall Loss 2.850681    Objective Loss 2.850681                                        LR 0.000001    Time 0.216841    
2023-04-17 22:29:13,275 - Epoch: [336][  500/  518]    Overall Loss 2.854555    Objective Loss 2.854555                                        LR 0.000001    Time 0.216505    
2023-04-17 22:29:16,999 - Epoch: [336][  518/  518]    Overall Loss 2.857802    Objective Loss 2.857802                                        LR 0.000001    Time 0.216169    
2023-04-17 22:29:17,079 - --- validate (epoch=336)-----------
2023-04-17 22:29:17,079 - 4952 samples (32 per mini-batch)
2023-04-17 22:30:01,358 - Epoch: [336][   50/  155]    Loss 2.990734    mAP 0.540512    
2023-04-17 22:30:43,178 - Epoch: [336][  100/  155]    Loss 3.018334    mAP 0.533860    
2023-04-17 22:31:26,109 - Epoch: [336][  150/  155]    Loss 3.019644    mAP 0.527908    
2023-04-17 22:31:30,178 - Epoch: [336][  155/  155]    Loss 3.019050    mAP 0.526335    
2023-04-17 22:31:30,265 - ==> mAP: 0.52634    Loss: 3.019

2023-04-17 22:31:30,269 - ==> Best [mAP: 0.533323   vloss: 3.016302   Sparsity:0.00   Params: 2177088 on epoch: 335]
2023-04-17 22:31:30,269 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-17 22:31:30,305 - 

2023-04-17 22:31:30,305 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 22:31:41,806 - Epoch: [337][   50/  518]    Overall Loss 2.833371    Objective Loss 2.833371                                        LR 0.000001    Time 0.229971    
2023-04-17 22:31:52,622 - Epoch: [337][  100/  518]    Overall Loss 2.831900    Objective Loss 2.831900                                        LR 0.000001    Time 0.223122    
2023-04-17 22:32:03,432 - Epoch: [337][  150/  518]    Overall Loss 2.853161    Objective Loss 2.853161                                        LR 0.000001    Time 0.220805    
2023-04-17 22:32:14,194 - Epoch: [337][  200/  518]    Overall Loss 2.847542    Objective Loss 2.847542                                        LR 0.000001    Time 0.219407    
2023-04-17 22:32:25,040 - Epoch: [337][  250/  518]    Overall Loss 2.854639    Objective Loss 2.854639                                        LR 0.000001    Time 0.218903    
2023-04-17 22:32:35,845 - Epoch: [337][  300/  518]    Overall Loss 2.858689    Objective Loss 2.858689                                        LR 0.000001    Time 0.218433    
2023-04-17 22:32:46,575 - Epoch: [337][  350/  518]    Overall Loss 2.851797    Objective Loss 2.851797                                        LR 0.000001    Time 0.217879    
2023-04-17 22:32:57,391 - Epoch: [337][  400/  518]    Overall Loss 2.856054    Objective Loss 2.856054                                        LR 0.000001    Time 0.217681    
2023-04-17 22:33:08,033 - Epoch: [337][  450/  518]    Overall Loss 2.859910    Objective Loss 2.859910                                        LR 0.000001    Time 0.217140    
2023-04-17 22:33:18,715 - Epoch: [337][  500/  518]    Overall Loss 2.855608    Objective Loss 2.855608                                        LR 0.000001    Time 0.216786    
2023-04-17 22:33:22,459 - Epoch: [337][  518/  518]    Overall Loss 2.855185    Objective Loss 2.855185                                        LR 0.000001    Time 0.216480    
2023-04-17 22:33:22,540 - --- validate (epoch=337)-----------
2023-04-17 22:33:22,540 - 4952 samples (32 per mini-batch)
2023-04-17 22:34:03,190 - Epoch: [337][   50/  155]    Loss 3.010171    mAP 0.517809    
2023-04-17 22:34:45,156 - Epoch: [337][  100/  155]    Loss 3.025475    mAP 0.517914    
2023-04-17 22:35:26,250 - Epoch: [337][  150/  155]    Loss 3.023284    mAP 0.517559    
2023-04-17 22:35:30,177 - Epoch: [337][  155/  155]    Loss 3.024225    mAP 0.516455    
2023-04-17 22:35:30,256 - ==> mAP: 0.51645    Loss: 3.024

2023-04-17 22:35:30,260 - ==> Best [mAP: 0.533323   vloss: 3.016302   Sparsity:0.00   Params: 2177088 on epoch: 335]
2023-04-17 22:35:30,260 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-17 22:35:30,295 - 

2023-04-17 22:35:30,296 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 22:35:41,757 - Epoch: [338][   50/  518]    Overall Loss 2.834787    Objective Loss 2.834787                                        LR 0.000001    Time 0.229172    
2023-04-17 22:35:52,583 - Epoch: [338][  100/  518]    Overall Loss 2.844041    Objective Loss 2.844041                                        LR 0.000001    Time 0.222834    
2023-04-17 22:36:03,314 - Epoch: [338][  150/  518]    Overall Loss 2.857832    Objective Loss 2.857832                                        LR 0.000001    Time 0.220083    
2023-04-17 22:36:14,075 - Epoch: [338][  200/  518]    Overall Loss 2.862411    Objective Loss 2.862411                                        LR 0.000001    Time 0.218861    
2023-04-17 22:36:24,939 - Epoch: [338][  250/  518]    Overall Loss 2.870337    Objective Loss 2.870337                                        LR 0.000001    Time 0.218538    
2023-04-17 22:36:35,676 - Epoch: [338][  300/  518]    Overall Loss 2.863305    Objective Loss 2.863305                                        LR 0.000001    Time 0.217901    
2023-04-17 22:36:46,437 - Epoch: [338][  350/  518]    Overall Loss 2.865100    Objective Loss 2.865100                                        LR 0.000001    Time 0.217513    
2023-04-17 22:36:57,125 - Epoch: [338][  400/  518]    Overall Loss 2.863872    Objective Loss 2.863872                                        LR 0.000001    Time 0.217041    
2023-04-17 22:37:07,780 - Epoch: [338][  450/  518]    Overall Loss 2.856114    Objective Loss 2.856114                                        LR 0.000001    Time 0.216599    
2023-04-17 22:37:18,608 - Epoch: [338][  500/  518]    Overall Loss 2.849906    Objective Loss 2.849906                                        LR 0.000001    Time 0.216593    
2023-04-17 22:37:22,371 - Epoch: [338][  518/  518]    Overall Loss 2.850256    Objective Loss 2.850256                                        LR 0.000001    Time 0.216329    
2023-04-17 22:37:22,449 - --- validate (epoch=338)-----------
2023-04-17 22:37:22,450 - 4952 samples (32 per mini-batch)
2023-04-17 22:38:03,935 - Epoch: [338][   50/  155]    Loss 2.999384    mAP 0.534913    
2023-04-17 22:38:46,066 - Epoch: [338][  100/  155]    Loss 3.012481    mAP 0.524620    
2023-04-17 22:39:27,521 - Epoch: [338][  150/  155]    Loss 3.027961    mAP 0.517091    
2023-04-17 22:39:31,312 - Epoch: [338][  155/  155]    Loss 3.026528    mAP 0.517541    
2023-04-17 22:39:31,391 - ==> mAP: 0.51754    Loss: 3.027

2023-04-17 22:39:31,394 - ==> Best [mAP: 0.533323   vloss: 3.016302   Sparsity:0.00   Params: 2177088 on epoch: 335]
2023-04-17 22:39:31,394 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-17 22:39:31,451 - 

2023-04-17 22:39:31,451 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 22:39:43,036 - Epoch: [339][   50/  518]    Overall Loss 2.860724    Objective Loss 2.860724                                        LR 0.000001    Time 0.231643    
2023-04-17 22:39:53,738 - Epoch: [339][  100/  518]    Overall Loss 2.845579    Objective Loss 2.845579                                        LR 0.000001    Time 0.222819    
2023-04-17 22:40:04,472 - Epoch: [339][  150/  518]    Overall Loss 2.832851    Objective Loss 2.832851                                        LR 0.000001    Time 0.220095    
2023-04-17 22:40:15,258 - Epoch: [339][  200/  518]    Overall Loss 2.839736    Objective Loss 2.839736                                        LR 0.000001    Time 0.218996    
2023-04-17 22:40:25,932 - Epoch: [339][  250/  518]    Overall Loss 2.829454    Objective Loss 2.829454                                        LR 0.000001    Time 0.217885    
2023-04-17 22:40:36,706 - Epoch: [339][  300/  518]    Overall Loss 2.835007    Objective Loss 2.835007                                        LR 0.000001    Time 0.217480    
2023-04-17 22:40:47,431 - Epoch: [339][  350/  518]    Overall Loss 2.838142    Objective Loss 2.838142                                        LR 0.000001    Time 0.217049    
2023-04-17 22:40:58,223 - Epoch: [339][  400/  518]    Overall Loss 2.840694    Objective Loss 2.840694                                        LR 0.000001    Time 0.216896    
2023-04-17 22:41:08,975 - Epoch: [339][  450/  518]    Overall Loss 2.840442    Objective Loss 2.840442                                        LR 0.000001    Time 0.216686    
2023-04-17 22:41:19,857 - Epoch: [339][  500/  518]    Overall Loss 2.840405    Objective Loss 2.840405                                        LR 0.000001    Time 0.216778    
2023-04-17 22:41:23,530 - Epoch: [339][  518/  518]    Overall Loss 2.838823    Objective Loss 2.838823                                        LR 0.000001    Time 0.216334    
2023-04-17 22:41:23,610 - --- validate (epoch=339)-----------
2023-04-17 22:41:23,610 - 4952 samples (32 per mini-batch)
2023-04-17 22:42:05,178 - Epoch: [339][   50/  155]    Loss 3.033414    mAP 0.522865    
2023-04-17 22:42:46,801 - Epoch: [339][  100/  155]    Loss 3.028135    mAP 0.525366    
2023-04-17 22:43:29,184 - Epoch: [339][  150/  155]    Loss 3.022688    mAP 0.525550    
2023-04-17 22:43:33,240 - Epoch: [339][  155/  155]    Loss 3.022252    mAP 0.525189    
2023-04-17 22:43:33,313 - ==> mAP: 0.52519    Loss: 3.022

2023-04-17 22:43:33,317 - ==> Best [mAP: 0.533323   vloss: 3.016302   Sparsity:0.00   Params: 2177088 on epoch: 335]
2023-04-17 22:43:33,317 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-17 22:43:33,352 - 

2023-04-17 22:43:33,353 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 22:43:44,998 - Epoch: [340][   50/  518]    Overall Loss 2.875100    Objective Loss 2.875100                                        LR 0.000001    Time 0.232861    
2023-04-17 22:43:55,683 - Epoch: [340][  100/  518]    Overall Loss 2.839088    Objective Loss 2.839088                                        LR 0.000001    Time 0.223260    
2023-04-17 22:44:06,327 - Epoch: [340][  150/  518]    Overall Loss 2.852438    Objective Loss 2.852438                                        LR 0.000001    Time 0.219794    
2023-04-17 22:44:17,045 - Epoch: [340][  200/  518]    Overall Loss 2.846894    Objective Loss 2.846894                                        LR 0.000001    Time 0.218428    
2023-04-17 22:44:27,743 - Epoch: [340][  250/  518]    Overall Loss 2.852528    Objective Loss 2.852528                                        LR 0.000001    Time 0.217527    
2023-04-17 22:44:38,499 - Epoch: [340][  300/  518]    Overall Loss 2.856953    Objective Loss 2.856953                                        LR 0.000001    Time 0.217120    
2023-04-17 22:44:49,203 - Epoch: [340][  350/  518]    Overall Loss 2.857647    Objective Loss 2.857647                                        LR 0.000001    Time 0.216682    
2023-04-17 22:44:59,891 - Epoch: [340][  400/  518]    Overall Loss 2.854559    Objective Loss 2.854559                                        LR 0.000001    Time 0.216313    
2023-04-17 22:45:10,553 - Epoch: [340][  450/  518]    Overall Loss 2.852445    Objective Loss 2.852445                                        LR 0.000001    Time 0.215968    
2023-04-17 22:45:21,366 - Epoch: [340][  500/  518]    Overall Loss 2.853581    Objective Loss 2.853581                                        LR 0.000001    Time 0.215995    
2023-04-17 22:45:25,058 - Epoch: [340][  518/  518]    Overall Loss 2.854520    Objective Loss 2.854520                                        LR 0.000001    Time 0.215615    
2023-04-17 22:45:25,140 - --- validate (epoch=340)-----------
2023-04-17 22:45:25,140 - 4952 samples (32 per mini-batch)
2023-04-17 22:46:06,466 - Epoch: [340][   50/  155]    Loss 3.005649    mAP 0.514253    
2023-04-17 22:46:50,200 - Epoch: [340][  100/  155]    Loss 3.010709    mAP 0.524137    
2023-04-17 22:47:32,004 - Epoch: [340][  150/  155]    Loss 3.019194    mAP 0.525674    
2023-04-17 22:47:36,009 - Epoch: [340][  155/  155]    Loss 3.016769    mAP 0.525440    
2023-04-17 22:47:36,090 - ==> mAP: 0.52544    Loss: 3.017

2023-04-17 22:47:36,094 - ==> Best [mAP: 0.533323   vloss: 3.016302   Sparsity:0.00   Params: 2177088 on epoch: 335]
2023-04-17 22:47:36,094 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-17 22:47:36,131 - 

2023-04-17 22:47:36,132 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 22:47:47,709 - Epoch: [341][   50/  518]    Overall Loss 2.856795    Objective Loss 2.856795                                        LR 0.000001    Time 0.231493    
2023-04-17 22:47:58,383 - Epoch: [341][  100/  518]    Overall Loss 2.835799    Objective Loss 2.835799                                        LR 0.000001    Time 0.222470    
2023-04-17 22:48:09,206 - Epoch: [341][  150/  518]    Overall Loss 2.846478    Objective Loss 2.846478                                        LR 0.000001    Time 0.220456    
2023-04-17 22:48:19,962 - Epoch: [341][  200/  518]    Overall Loss 2.848748    Objective Loss 2.848748                                        LR 0.000001    Time 0.219114    
2023-04-17 22:48:30,780 - Epoch: [341][  250/  518]    Overall Loss 2.845091    Objective Loss 2.845091                                        LR 0.000001    Time 0.218559    
2023-04-17 22:48:41,469 - Epoch: [341][  300/  518]    Overall Loss 2.842955    Objective Loss 2.842955                                        LR 0.000001    Time 0.217756    
2023-04-17 22:48:52,770 - Epoch: [341][  350/  518]    Overall Loss 2.846899    Objective Loss 2.846899                                        LR 0.000001    Time 0.218931    
2023-04-17 22:49:08,063 - Epoch: [341][  400/  518]    Overall Loss 2.849363    Objective Loss 2.849363                                        LR 0.000001    Time 0.229791    
2023-04-17 22:49:23,135 - Epoch: [341][  450/  518]    Overall Loss 2.845384    Objective Loss 2.845384                                        LR 0.000001    Time 0.237748    
2023-04-17 22:49:38,685 - Epoch: [341][  500/  518]    Overall Loss 2.852419    Objective Loss 2.852419                                        LR 0.000001    Time 0.245069    
2023-04-17 22:49:43,735 - Epoch: [341][  518/  518]    Overall Loss 2.849623    Objective Loss 2.849623                                        LR 0.000001    Time 0.246299    
2023-04-17 22:49:43,850 - --- validate (epoch=341)-----------
2023-04-17 22:49:43,850 - 4952 samples (32 per mini-batch)
2023-04-17 22:50:41,420 - Epoch: [341][   50/  155]    Loss 3.064380    mAP 0.504477    
2023-04-17 22:51:35,205 - Epoch: [341][  100/  155]    Loss 3.029451    mAP 0.521708    
2023-04-17 22:52:30,426 - Epoch: [341][  150/  155]    Loss 3.019333    mAP 0.528483    
2023-04-17 22:52:35,780 - Epoch: [341][  155/  155]    Loss 3.017262    mAP 0.529044    
2023-04-17 22:52:35,931 - ==> mAP: 0.52904    Loss: 3.017

2023-04-17 22:52:35,937 - ==> Best [mAP: 0.533323   vloss: 3.016302   Sparsity:0.00   Params: 2177088 on epoch: 335]
2023-04-17 22:52:35,937 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-17 22:52:36,003 - 

2023-04-17 22:52:36,004 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 22:52:52,646 - Epoch: [342][   50/  518]    Overall Loss 2.878748    Objective Loss 2.878748                                        LR 0.000001    Time 0.332745    
2023-04-17 22:53:07,853 - Epoch: [342][  100/  518]    Overall Loss 2.865358    Objective Loss 2.865358                                        LR 0.000001    Time 0.318412    
2023-04-17 22:53:23,645 - Epoch: [342][  150/  518]    Overall Loss 2.855610    Objective Loss 2.855610                                        LR 0.000001    Time 0.317542    
2023-04-17 22:53:39,474 - Epoch: [342][  200/  518]    Overall Loss 2.844950    Objective Loss 2.844950                                        LR 0.000001    Time 0.317286    
2023-04-17 22:53:55,014 - Epoch: [342][  250/  518]    Overall Loss 2.842764    Objective Loss 2.842764                                        LR 0.000001    Time 0.315978    
2023-04-17 22:54:10,358 - Epoch: [342][  300/  518]    Overall Loss 2.842744    Objective Loss 2.842744                                        LR 0.000001    Time 0.314452    
2023-04-17 22:54:26,405 - Epoch: [342][  350/  518]    Overall Loss 2.844267    Objective Loss 2.844267                                        LR 0.000001    Time 0.315371    
2023-04-17 22:54:41,427 - Epoch: [342][  400/  518]    Overall Loss 2.850957    Objective Loss 2.850957                                        LR 0.000001    Time 0.313495    
2023-04-17 22:54:57,243 - Epoch: [342][  450/  518]    Overall Loss 2.853323    Objective Loss 2.853323                                        LR 0.000001    Time 0.313804    
2023-04-17 22:55:12,897 - Epoch: [342][  500/  518]    Overall Loss 2.850034    Objective Loss 2.850034                                        LR 0.000001    Time 0.313726    
2023-04-17 22:55:18,326 - Epoch: [342][  518/  518]    Overall Loss 2.852410    Objective Loss 2.852410                                        LR 0.000001    Time 0.313302    
2023-04-17 22:55:18,427 - --- validate (epoch=342)-----------
2023-04-17 22:55:18,428 - 4952 samples (32 per mini-batch)
2023-04-17 22:56:11,610 - Epoch: [342][   50/  155]    Loss 3.042693    mAP 0.535124    
2023-04-17 22:57:08,625 - Epoch: [342][  100/  155]    Loss 3.035007    mAP 0.526722    
2023-04-17 22:58:04,093 - Epoch: [342][  150/  155]    Loss 3.019848    mAP 0.525298    
2023-04-17 22:58:09,100 - Epoch: [342][  155/  155]    Loss 3.020029    mAP 0.523134    
2023-04-17 22:58:09,206 - ==> mAP: 0.52313    Loss: 3.020

2023-04-17 22:58:09,212 - ==> Best [mAP: 0.533323   vloss: 3.016302   Sparsity:0.00   Params: 2177088 on epoch: 335]
2023-04-17 22:58:09,212 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-17 22:58:09,292 - 

2023-04-17 22:58:09,292 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 22:58:26,503 - Epoch: [343][   50/  518]    Overall Loss 2.864153    Objective Loss 2.864153                                        LR 0.000001    Time 0.344138    
2023-04-17 22:58:38,738 - Epoch: [343][  100/  518]    Overall Loss 2.860469    Objective Loss 2.860469                                        LR 0.000001    Time 0.294391    
2023-04-17 22:58:49,554 - Epoch: [343][  150/  518]    Overall Loss 2.852188    Objective Loss 2.852188                                        LR 0.000001    Time 0.268363    
2023-04-17 22:59:00,281 - Epoch: [343][  200/  518]    Overall Loss 2.853724    Objective Loss 2.853724                                        LR 0.000001    Time 0.254895    
2023-04-17 22:59:11,023 - Epoch: [343][  250/  518]    Overall Loss 2.851889    Objective Loss 2.851889                                        LR 0.000001    Time 0.246878    
2023-04-17 22:59:21,774 - Epoch: [343][  300/  518]    Overall Loss 2.847421    Objective Loss 2.847421                                        LR 0.000001    Time 0.241566    
2023-04-17 22:59:32,512 - Epoch: [343][  350/  518]    Overall Loss 2.845393    Objective Loss 2.845393                                        LR 0.000001    Time 0.237731    
2023-04-17 22:59:43,256 - Epoch: [343][  400/  518]    Overall Loss 2.843093    Objective Loss 2.843093                                        LR 0.000001    Time 0.234871    
2023-04-17 22:59:54,059 - Epoch: [343][  450/  518]    Overall Loss 2.843230    Objective Loss 2.843230                                        LR 0.000001    Time 0.232777    
2023-04-17 23:00:04,820 - Epoch: [343][  500/  518]    Overall Loss 2.842507    Objective Loss 2.842507                                        LR 0.000001    Time 0.231017    
2023-04-17 23:00:08,591 - Epoch: [343][  518/  518]    Overall Loss 2.844214    Objective Loss 2.844214                                        LR 0.000001    Time 0.230270    
2023-04-17 23:00:08,685 - --- validate (epoch=343)-----------
2023-04-17 23:00:08,686 - 4952 samples (32 per mini-batch)
2023-04-17 23:00:50,966 - Epoch: [343][   50/  155]    Loss 3.018476    mAP 0.512113    
2023-04-17 23:01:33,683 - Epoch: [343][  100/  155]    Loss 3.006580    mAP 0.519593    
2023-04-17 23:02:15,878 - Epoch: [343][  150/  155]    Loss 3.022349    mAP 0.521539    
2023-04-17 23:02:19,774 - Epoch: [343][  155/  155]    Loss 3.024632    mAP 0.520549    
2023-04-17 23:02:19,851 - ==> mAP: 0.52055    Loss: 3.025

2023-04-17 23:02:19,855 - ==> Best [mAP: 0.533323   vloss: 3.016302   Sparsity:0.00   Params: 2177088 on epoch: 335]
2023-04-17 23:02:19,855 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-17 23:02:19,891 - 

2023-04-17 23:02:19,891 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 23:02:31,507 - Epoch: [344][   50/  518]    Overall Loss 2.840120    Objective Loss 2.840120                                        LR 0.000001    Time 0.232268    
2023-04-17 23:02:42,158 - Epoch: [344][  100/  518]    Overall Loss 2.843743    Objective Loss 2.843743                                        LR 0.000001    Time 0.222631    
2023-04-17 23:02:52,863 - Epoch: [344][  150/  518]    Overall Loss 2.850335    Objective Loss 2.850335                                        LR 0.000001    Time 0.219776    
2023-04-17 23:03:03,600 - Epoch: [344][  200/  518]    Overall Loss 2.831924    Objective Loss 2.831924                                        LR 0.000001    Time 0.218505    
2023-04-17 23:03:14,368 - Epoch: [344][  250/  518]    Overall Loss 2.841225    Objective Loss 2.841225                                        LR 0.000001    Time 0.217870    
2023-04-17 23:03:25,171 - Epoch: [344][  300/  518]    Overall Loss 2.843459    Objective Loss 2.843459                                        LR 0.000001    Time 0.217563    
2023-04-17 23:03:35,899 - Epoch: [344][  350/  518]    Overall Loss 2.842636    Objective Loss 2.842636                                        LR 0.000001    Time 0.217130    
2023-04-17 23:03:46,596 - Epoch: [344][  400/  518]    Overall Loss 2.840042    Objective Loss 2.840042                                        LR 0.000001    Time 0.216729    
2023-04-17 23:03:57,338 - Epoch: [344][  450/  518]    Overall Loss 2.842544    Objective Loss 2.842544                                        LR 0.000001    Time 0.216514    
2023-04-17 23:04:08,149 - Epoch: [344][  500/  518]    Overall Loss 2.841535    Objective Loss 2.841535                                        LR 0.000001    Time 0.216483    
2023-04-17 23:04:11,861 - Epoch: [344][  518/  518]    Overall Loss 2.842956    Objective Loss 2.842956                                        LR 0.000001    Time 0.216126    
2023-04-17 23:04:11,943 - --- validate (epoch=344)-----------
2023-04-17 23:04:11,944 - 4952 samples (32 per mini-batch)
2023-04-17 23:04:55,334 - Epoch: [344][   50/  155]    Loss 3.010916    mAP 0.526223    
2023-04-17 23:05:37,653 - Epoch: [344][  100/  155]    Loss 3.006694    mAP 0.526067    
2023-04-17 23:06:20,316 - Epoch: [344][  150/  155]    Loss 3.020518    mAP 0.524124    
2023-04-17 23:06:24,281 - Epoch: [344][  155/  155]    Loss 3.018068    mAP 0.524991    
2023-04-17 23:06:24,360 - ==> mAP: 0.52499    Loss: 3.018

2023-04-17 23:06:24,363 - ==> Best [mAP: 0.533323   vloss: 3.016302   Sparsity:0.00   Params: 2177088 on epoch: 335]
2023-04-17 23:06:24,363 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-17 23:06:24,397 - 

2023-04-17 23:06:24,397 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 23:06:35,951 - Epoch: [345][   50/  518]    Overall Loss 2.836379    Objective Loss 2.836379                                        LR 0.000001    Time 0.231020    
2023-04-17 23:06:46,671 - Epoch: [345][  100/  518]    Overall Loss 2.879732    Objective Loss 2.879732                                        LR 0.000001    Time 0.222693    
2023-04-17 23:06:57,467 - Epoch: [345][  150/  518]    Overall Loss 2.866555    Objective Loss 2.866555                                        LR 0.000001    Time 0.220429    
2023-04-17 23:07:08,224 - Epoch: [345][  200/  518]    Overall Loss 2.851233    Objective Loss 2.851233                                        LR 0.000001    Time 0.219099    
2023-04-17 23:07:18,996 - Epoch: [345][  250/  518]    Overall Loss 2.841686    Objective Loss 2.841686                                        LR 0.000001    Time 0.218360    
2023-04-17 23:07:29,765 - Epoch: [345][  300/  518]    Overall Loss 2.847250    Objective Loss 2.847250                                        LR 0.000001    Time 0.217858    
2023-04-17 23:07:40,512 - Epoch: [345][  350/  518]    Overall Loss 2.844254    Objective Loss 2.844254                                        LR 0.000001    Time 0.217437    
2023-04-17 23:07:51,233 - Epoch: [345][  400/  518]    Overall Loss 2.844277    Objective Loss 2.844277                                        LR 0.000001    Time 0.217056    
2023-04-17 23:08:01,965 - Epoch: [345][  450/  518]    Overall Loss 2.846048    Objective Loss 2.846048                                        LR 0.000001    Time 0.216785    
2023-04-17 23:08:12,650 - Epoch: [345][  500/  518]    Overall Loss 2.842347    Objective Loss 2.842347                                        LR 0.000001    Time 0.216473    
2023-04-17 23:08:16,351 - Epoch: [345][  518/  518]    Overall Loss 2.841610    Objective Loss 2.841610                                        LR 0.000001    Time 0.216094    
2023-04-17 23:08:16,430 - --- validate (epoch=345)-----------
2023-04-17 23:08:16,431 - 4952 samples (32 per mini-batch)
2023-04-17 23:08:59,511 - Epoch: [345][   50/  155]    Loss 2.996195    mAP 0.551736    
2023-04-17 23:09:43,341 - Epoch: [345][  100/  155]    Loss 3.013784    mAP 0.529954    
2023-04-17 23:10:24,685 - Epoch: [345][  150/  155]    Loss 3.012885    mAP 0.523366    
2023-04-17 23:10:28,607 - Epoch: [345][  155/  155]    Loss 3.016784    mAP 0.521889    
2023-04-17 23:10:28,685 - ==> mAP: 0.52189    Loss: 3.017

2023-04-17 23:10:28,689 - ==> Best [mAP: 0.533323   vloss: 3.016302   Sparsity:0.00   Params: 2177088 on epoch: 335]
2023-04-17 23:10:28,689 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-17 23:10:28,723 - 

2023-04-17 23:10:28,723 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 23:10:40,260 - Epoch: [346][   50/  518]    Overall Loss 2.840686    Objective Loss 2.840686                                        LR 0.000001    Time 0.230674    
2023-04-17 23:10:51,025 - Epoch: [346][  100/  518]    Overall Loss 2.837785    Objective Loss 2.837785                                        LR 0.000001    Time 0.222977    
2023-04-17 23:11:01,813 - Epoch: [346][  150/  518]    Overall Loss 2.853853    Objective Loss 2.853853                                        LR 0.000001    Time 0.220559    
2023-04-17 23:11:12,589 - Epoch: [346][  200/  518]    Overall Loss 2.837613    Objective Loss 2.837613                                        LR 0.000001    Time 0.219290    
2023-04-17 23:11:23,287 - Epoch: [346][  250/  518]    Overall Loss 2.850978    Objective Loss 2.850978                                        LR 0.000001    Time 0.218219    
2023-04-17 23:11:34,159 - Epoch: [346][  300/  518]    Overall Loss 2.850765    Objective Loss 2.850765                                        LR 0.000001    Time 0.218085    
2023-04-17 23:11:44,829 - Epoch: [346][  350/  518]    Overall Loss 2.846355    Objective Loss 2.846355                                        LR 0.000001    Time 0.217411    
2023-04-17 23:11:55,689 - Epoch: [346][  400/  518]    Overall Loss 2.847248    Objective Loss 2.847248                                        LR 0.000001    Time 0.217381    
2023-04-17 23:12:06,422 - Epoch: [346][  450/  518]    Overall Loss 2.845761    Objective Loss 2.845761                                        LR 0.000001    Time 0.217075    
2023-04-17 23:12:17,224 - Epoch: [346][  500/  518]    Overall Loss 2.849209    Objective Loss 2.849209                                        LR 0.000001    Time 0.216970    
2023-04-17 23:12:20,883 - Epoch: [346][  518/  518]    Overall Loss 2.851409    Objective Loss 2.851409                                        LR 0.000001    Time 0.216491    
2023-04-17 23:12:20,963 - --- validate (epoch=346)-----------
2023-04-17 23:12:20,963 - 4952 samples (32 per mini-batch)
2023-04-17 23:13:02,411 - Epoch: [346][   50/  155]    Loss 3.000234    mAP 0.524775    
2023-04-17 23:13:43,583 - Epoch: [346][  100/  155]    Loss 3.028444    mAP 0.520220    
2023-04-17 23:14:25,243 - Epoch: [346][  150/  155]    Loss 3.026671    mAP 0.522418    
2023-04-17 23:14:29,630 - Epoch: [346][  155/  155]    Loss 3.027844    mAP 0.522357    
2023-04-17 23:14:29,710 - ==> mAP: 0.52236    Loss: 3.028

2023-04-17 23:14:29,714 - ==> Best [mAP: 0.533323   vloss: 3.016302   Sparsity:0.00   Params: 2177088 on epoch: 335]
2023-04-17 23:14:29,714 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-17 23:14:29,748 - 

2023-04-17 23:14:29,748 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 23:14:41,197 - Epoch: [347][   50/  518]    Overall Loss 2.816986    Objective Loss 2.816986                                        LR 0.000001    Time 0.228926    
2023-04-17 23:14:51,825 - Epoch: [347][  100/  518]    Overall Loss 2.847217    Objective Loss 2.847217                                        LR 0.000001    Time 0.220723    
2023-04-17 23:15:02,560 - Epoch: [347][  150/  518]    Overall Loss 2.848203    Objective Loss 2.848203                                        LR 0.000001    Time 0.218710    
2023-04-17 23:15:13,286 - Epoch: [347][  200/  518]    Overall Loss 2.845551    Objective Loss 2.845551                                        LR 0.000001    Time 0.217654    
2023-04-17 23:15:24,080 - Epoch: [347][  250/  518]    Overall Loss 2.854545    Objective Loss 2.854545                                        LR 0.000001    Time 0.217293    
2023-04-17 23:15:34,747 - Epoch: [347][  300/  518]    Overall Loss 2.858107    Objective Loss 2.858107                                        LR 0.000001    Time 0.216627    
2023-04-17 23:15:45,522 - Epoch: [347][  350/  518]    Overall Loss 2.857519    Objective Loss 2.857519                                        LR 0.000001    Time 0.216463    
2023-04-17 23:15:56,227 - Epoch: [347][  400/  518]    Overall Loss 2.856407    Objective Loss 2.856407                                        LR 0.000001    Time 0.216164    
2023-04-17 23:16:06,927 - Epoch: [347][  450/  518]    Overall Loss 2.854676    Objective Loss 2.854676                                        LR 0.000001    Time 0.215919    
2023-04-17 23:16:17,713 - Epoch: [347][  500/  518]    Overall Loss 2.857156    Objective Loss 2.857156                                        LR 0.000001    Time 0.215896    
2023-04-17 23:16:21,466 - Epoch: [347][  518/  518]    Overall Loss 2.857539    Objective Loss 2.857539                                        LR 0.000001    Time 0.215639    
2023-04-17 23:16:21,546 - --- validate (epoch=347)-----------
2023-04-17 23:16:21,547 - 4952 samples (32 per mini-batch)
2023-04-17 23:17:03,815 - Epoch: [347][   50/  155]    Loss 3.014713    mAP 0.535356    
2023-04-17 23:17:46,280 - Epoch: [347][  100/  155]    Loss 3.016384    mAP 0.527460    
2023-04-17 23:18:29,401 - Epoch: [347][  150/  155]    Loss 3.014518    mAP 0.529623    
2023-04-17 23:18:33,402 - Epoch: [347][  155/  155]    Loss 3.018022    mAP 0.527045    
2023-04-17 23:18:33,480 - ==> mAP: 0.52705    Loss: 3.018

2023-04-17 23:18:33,483 - ==> Best [mAP: 0.533323   vloss: 3.016302   Sparsity:0.00   Params: 2177088 on epoch: 335]
2023-04-17 23:18:33,484 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-17 23:18:33,520 - 

2023-04-17 23:18:33,521 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 23:18:44,997 - Epoch: [348][   50/  518]    Overall Loss 2.769034    Objective Loss 2.769034                                        LR 0.000001    Time 0.229473    
2023-04-17 23:18:55,744 - Epoch: [348][  100/  518]    Overall Loss 2.784061    Objective Loss 2.784061                                        LR 0.000001    Time 0.222189    
2023-04-17 23:19:06,431 - Epoch: [348][  150/  518]    Overall Loss 2.816542    Objective Loss 2.816542                                        LR 0.000001    Time 0.219365    
2023-04-17 23:19:17,163 - Epoch: [348][  200/  518]    Overall Loss 2.827505    Objective Loss 2.827505                                        LR 0.000001    Time 0.218177    
2023-04-17 23:19:27,898 - Epoch: [348][  250/  518]    Overall Loss 2.831189    Objective Loss 2.831189                                        LR 0.000001    Time 0.217475    
2023-04-17 23:19:38,554 - Epoch: [348][  300/  518]    Overall Loss 2.827348    Objective Loss 2.827348                                        LR 0.000001    Time 0.216744    
2023-04-17 23:19:49,247 - Epoch: [348][  350/  518]    Overall Loss 2.831303    Objective Loss 2.831303                                        LR 0.000001    Time 0.216328    
2023-04-17 23:19:59,872 - Epoch: [348][  400/  518]    Overall Loss 2.832234    Objective Loss 2.832234                                        LR 0.000001    Time 0.215845    
2023-04-17 23:20:10,477 - Epoch: [348][  450/  518]    Overall Loss 2.834387    Objective Loss 2.834387                                        LR 0.000001    Time 0.215424    
2023-04-17 23:20:21,126 - Epoch: [348][  500/  518]    Overall Loss 2.834911    Objective Loss 2.834911                                        LR 0.000001    Time 0.215178    
2023-04-17 23:20:24,798 - Epoch: [348][  518/  518]    Overall Loss 2.839746    Objective Loss 2.839746                                        LR 0.000001    Time 0.214789    
2023-04-17 23:20:24,879 - --- validate (epoch=348)-----------
2023-04-17 23:20:24,880 - 4952 samples (32 per mini-batch)
2023-04-17 23:21:07,688 - Epoch: [348][   50/  155]    Loss 3.006965    mAP 0.511147    
2023-04-17 23:21:49,208 - Epoch: [348][  100/  155]    Loss 2.986580    mAP 0.525141    
2023-04-17 23:22:31,676 - Epoch: [348][  150/  155]    Loss 3.009891    mAP 0.523593    
2023-04-17 23:22:36,170 - Epoch: [348][  155/  155]    Loss 3.011518    mAP 0.525451    
2023-04-17 23:22:36,249 - ==> mAP: 0.52545    Loss: 3.012

2023-04-17 23:22:36,254 - ==> Best [mAP: 0.533323   vloss: 3.016302   Sparsity:0.00   Params: 2177088 on epoch: 335]
2023-04-17 23:22:36,254 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-17 23:22:36,288 - 

2023-04-17 23:22:36,288 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 23:22:47,788 - Epoch: [349][   50/  518]    Overall Loss 2.836868    Objective Loss 2.836868                                        LR 0.000001    Time 0.229958    
2023-04-17 23:22:58,453 - Epoch: [349][  100/  518]    Overall Loss 2.856931    Objective Loss 2.856931                                        LR 0.000001    Time 0.221612    
2023-04-17 23:23:09,110 - Epoch: [349][  150/  518]    Overall Loss 2.845807    Objective Loss 2.845807                                        LR 0.000001    Time 0.218777    
2023-04-17 23:23:19,872 - Epoch: [349][  200/  518]    Overall Loss 2.855103    Objective Loss 2.855103                                        LR 0.000001    Time 0.217886    
2023-04-17 23:23:30,685 - Epoch: [349][  250/  518]    Overall Loss 2.852672    Objective Loss 2.852672                                        LR 0.000001    Time 0.217552    
2023-04-17 23:23:41,416 - Epoch: [349][  300/  518]    Overall Loss 2.846478    Objective Loss 2.846478                                        LR 0.000001    Time 0.217060    
2023-04-17 23:23:52,134 - Epoch: [349][  350/  518]    Overall Loss 2.852197    Objective Loss 2.852197                                        LR 0.000001    Time 0.216668    
2023-04-17 23:24:02,875 - Epoch: [349][  400/  518]    Overall Loss 2.849502    Objective Loss 2.849502                                        LR 0.000001    Time 0.216434    
2023-04-17 23:24:13,558 - Epoch: [349][  450/  518]    Overall Loss 2.848748    Objective Loss 2.848748                                        LR 0.000001    Time 0.216123    
2023-04-17 23:24:24,293 - Epoch: [349][  500/  518]    Overall Loss 2.848884    Objective Loss 2.848884                                        LR 0.000001    Time 0.215977    
2023-04-17 23:24:28,011 - Epoch: [349][  518/  518]    Overall Loss 2.851279    Objective Loss 2.851279                                        LR 0.000001    Time 0.215650    
2023-04-17 23:24:28,092 - --- validate (epoch=349)-----------
2023-04-17 23:24:28,092 - 4952 samples (32 per mini-batch)
2023-04-17 23:25:10,242 - Epoch: [349][   50/  155]    Loss 3.027754    mAP 0.523119    
2023-04-17 23:25:52,196 - Epoch: [349][  100/  155]    Loss 3.020623    mAP 0.529757    
2023-04-17 23:26:34,831 - Epoch: [349][  150/  155]    Loss 3.018302    mAP 0.525979    
2023-04-17 23:26:39,012 - Epoch: [349][  155/  155]    Loss 3.019570    mAP 0.526342    
2023-04-17 23:26:39,089 - ==> mAP: 0.52634    Loss: 3.020

2023-04-17 23:26:39,093 - ==> Best [mAP: 0.533323   vloss: 3.016302   Sparsity:0.00   Params: 2177088 on epoch: 335]
2023-04-17 23:26:39,093 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-17 23:26:39,127 - 

2023-04-17 23:26:39,127 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 23:26:50,667 - Epoch: [350][   50/  518]    Overall Loss 2.809410    Objective Loss 2.809410                                        LR 0.000001    Time 0.230727    
2023-04-17 23:27:01,414 - Epoch: [350][  100/  518]    Overall Loss 2.812665    Objective Loss 2.812665                                        LR 0.000001    Time 0.222820    
2023-04-17 23:27:12,130 - Epoch: [350][  150/  518]    Overall Loss 2.825882    Objective Loss 2.825882                                        LR 0.000001    Time 0.219977    
2023-04-17 23:27:22,895 - Epoch: [350][  200/  518]    Overall Loss 2.842102    Objective Loss 2.842102                                        LR 0.000001    Time 0.218803    
2023-04-17 23:27:33,582 - Epoch: [350][  250/  518]    Overall Loss 2.847504    Objective Loss 2.847504                                        LR 0.000001    Time 0.217782    
2023-04-17 23:27:44,397 - Epoch: [350][  300/  518]    Overall Loss 2.851471    Objective Loss 2.851471                                        LR 0.000001    Time 0.217530    
2023-04-17 23:27:55,157 - Epoch: [350][  350/  518]    Overall Loss 2.853359    Objective Loss 2.853359                                        LR 0.000001    Time 0.217193    
2023-04-17 23:28:05,927 - Epoch: [350][  400/  518]    Overall Loss 2.850967    Objective Loss 2.850967                                        LR 0.000001    Time 0.216967    
2023-04-17 23:28:16,667 - Epoch: [350][  450/  518]    Overall Loss 2.854212    Objective Loss 2.854212                                        LR 0.000001    Time 0.216722    
2023-04-17 23:28:27,413 - Epoch: [350][  500/  518]    Overall Loss 2.855465    Objective Loss 2.855465                                        LR 0.000001    Time 0.216538    
2023-04-17 23:28:31,137 - Epoch: [350][  518/  518]    Overall Loss 2.857402    Objective Loss 2.857402                                        LR 0.000001    Time 0.216201    
2023-04-17 23:28:31,218 - --- validate (epoch=350)-----------
2023-04-17 23:28:31,218 - 4952 samples (32 per mini-batch)
2023-04-17 23:29:12,962 - Epoch: [350][   50/  155]    Loss 2.983062    mAP 0.543913    
2023-04-17 23:29:56,572 - Epoch: [350][  100/  155]    Loss 3.024997    mAP 0.532980    
2023-04-17 23:30:39,673 - Epoch: [350][  150/  155]    Loss 3.016553    mAP 0.528185    
2023-04-17 23:30:43,342 - Epoch: [350][  155/  155]    Loss 3.014216    mAP 0.527555    
2023-04-17 23:30:43,422 - ==> mAP: 0.52756    Loss: 3.014

2023-04-17 23:30:43,426 - ==> Best [mAP: 0.533323   vloss: 3.016302   Sparsity:0.00   Params: 2177088 on epoch: 335]
2023-04-17 23:30:43,426 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-17 23:30:43,460 - 

2023-04-17 23:30:43,460 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 23:30:55,026 - Epoch: [351][   50/  518]    Overall Loss 2.850418    Objective Loss 2.850418                                        LR 0.000001    Time 0.231259    
2023-04-17 23:31:05,705 - Epoch: [351][  100/  518]    Overall Loss 2.849503    Objective Loss 2.849503                                        LR 0.000001    Time 0.222406    
2023-04-17 23:31:16,423 - Epoch: [351][  150/  518]    Overall Loss 2.847557    Objective Loss 2.847557                                        LR 0.000001    Time 0.219709    
2023-04-17 23:31:27,198 - Epoch: [351][  200/  518]    Overall Loss 2.839854    Objective Loss 2.839854                                        LR 0.000001    Time 0.218650    
2023-04-17 23:31:37,918 - Epoch: [351][  250/  518]    Overall Loss 2.855758    Objective Loss 2.855758                                        LR 0.000001    Time 0.217795    
2023-04-17 23:31:48,643 - Epoch: [351][  300/  518]    Overall Loss 2.856739    Objective Loss 2.856739                                        LR 0.000001    Time 0.217241    
2023-04-17 23:31:59,375 - Epoch: [351][  350/  518]    Overall Loss 2.852420    Objective Loss 2.852420                                        LR 0.000001    Time 0.216864    
2023-04-17 23:32:10,120 - Epoch: [351][  400/  518]    Overall Loss 2.844930    Objective Loss 2.844930                                        LR 0.000001    Time 0.216615    
2023-04-17 23:32:20,810 - Epoch: [351][  450/  518]    Overall Loss 2.851494    Objective Loss 2.851494                                        LR 0.000001    Time 0.216300    
2023-04-17 23:32:31,548 - Epoch: [351][  500/  518]    Overall Loss 2.851326    Objective Loss 2.851326                                        LR 0.000001    Time 0.216142    
2023-04-17 23:32:35,334 - Epoch: [351][  518/  518]    Overall Loss 2.851620    Objective Loss 2.851620                                        LR 0.000001    Time 0.215941    
2023-04-17 23:32:35,416 - --- validate (epoch=351)-----------
2023-04-17 23:32:35,416 - 4952 samples (32 per mini-batch)
2023-04-17 23:33:18,558 - Epoch: [351][   50/  155]    Loss 3.022040    mAP 0.530448    
2023-04-17 23:34:00,651 - Epoch: [351][  100/  155]    Loss 3.013067    mAP 0.523054    
2023-04-17 23:34:42,581 - Epoch: [351][  150/  155]    Loss 3.020694    mAP 0.521966    
2023-04-17 23:34:46,580 - Epoch: [351][  155/  155]    Loss 3.016861    mAP 0.523438    
2023-04-17 23:34:46,659 - ==> mAP: 0.52344    Loss: 3.017

2023-04-17 23:34:46,663 - ==> Best [mAP: 0.533323   vloss: 3.016302   Sparsity:0.00   Params: 2177088 on epoch: 335]
2023-04-17 23:34:46,663 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-17 23:34:46,716 - 

2023-04-17 23:34:46,717 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 23:34:58,181 - Epoch: [352][   50/  518]    Overall Loss 2.811034    Objective Loss 2.811034                                        LR 0.000001    Time 0.229217    
2023-04-17 23:35:08,809 - Epoch: [352][  100/  518]    Overall Loss 2.841121    Objective Loss 2.841121                                        LR 0.000001    Time 0.220873    
2023-04-17 23:35:19,600 - Epoch: [352][  150/  518]    Overall Loss 2.832982    Objective Loss 2.832982                                        LR 0.000001    Time 0.219181    
2023-04-17 23:35:30,362 - Epoch: [352][  200/  518]    Overall Loss 2.831553    Objective Loss 2.831553                                        LR 0.000001    Time 0.218188    
2023-04-17 23:35:41,159 - Epoch: [352][  250/  518]    Overall Loss 2.832957    Objective Loss 2.832957                                        LR 0.000001    Time 0.217733    
2023-04-17 23:35:51,979 - Epoch: [352][  300/  518]    Overall Loss 2.836419    Objective Loss 2.836419                                        LR 0.000001    Time 0.217506    
2023-04-17 23:36:02,755 - Epoch: [352][  350/  518]    Overall Loss 2.842612    Objective Loss 2.842612                                        LR 0.000001    Time 0.217217    
2023-04-17 23:36:13,518 - Epoch: [352][  400/  518]    Overall Loss 2.837785    Objective Loss 2.837785                                        LR 0.000001    Time 0.216968    
2023-04-17 23:36:24,232 - Epoch: [352][  450/  518]    Overall Loss 2.838248    Objective Loss 2.838248                                        LR 0.000001    Time 0.216667    
2023-04-17 23:36:34,898 - Epoch: [352][  500/  518]    Overall Loss 2.843085    Objective Loss 2.843085                                        LR 0.000001    Time 0.216329    
2023-04-17 23:36:38,631 - Epoch: [352][  518/  518]    Overall Loss 2.841884    Objective Loss 2.841884                                        LR 0.000001    Time 0.216018    
2023-04-17 23:36:38,714 - --- validate (epoch=352)-----------
2023-04-17 23:36:38,714 - 4952 samples (32 per mini-batch)
2023-04-17 23:37:20,482 - Epoch: [352][   50/  155]    Loss 3.022823    mAP 0.525872    
2023-04-17 23:38:02,704 - Epoch: [352][  100/  155]    Loss 3.035911    mAP 0.524092    
2023-04-17 23:38:44,789 - Epoch: [352][  150/  155]    Loss 3.018254    mAP 0.524391    
2023-04-17 23:38:48,444 - Epoch: [352][  155/  155]    Loss 3.013651    mAP 0.526026    
2023-04-17 23:38:48,521 - ==> mAP: 0.52603    Loss: 3.014

2023-04-17 23:38:48,525 - ==> Best [mAP: 0.533323   vloss: 3.016302   Sparsity:0.00   Params: 2177088 on epoch: 335]
2023-04-17 23:38:48,525 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-17 23:38:48,560 - 

2023-04-17 23:38:48,561 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 23:39:00,148 - Epoch: [353][   50/  518]    Overall Loss 2.837291    Objective Loss 2.837291                                        LR 0.000001    Time 0.231687    
2023-04-17 23:39:10,870 - Epoch: [353][  100/  518]    Overall Loss 2.839115    Objective Loss 2.839115                                        LR 0.000001    Time 0.223056    
2023-04-17 23:39:21,605 - Epoch: [353][  150/  518]    Overall Loss 2.844313    Objective Loss 2.844313                                        LR 0.000001    Time 0.220255    
2023-04-17 23:39:32,346 - Epoch: [353][  200/  518]    Overall Loss 2.835962    Objective Loss 2.835962                                        LR 0.000001    Time 0.218888    
2023-04-17 23:39:43,053 - Epoch: [353][  250/  518]    Overall Loss 2.847416    Objective Loss 2.847416                                        LR 0.000001    Time 0.217935    
2023-04-17 23:39:53,819 - Epoch: [353][  300/  518]    Overall Loss 2.848560    Objective Loss 2.848560                                        LR 0.000001    Time 0.217495    
2023-04-17 23:40:04,568 - Epoch: [353][  350/  518]    Overall Loss 2.844429    Objective Loss 2.844429                                        LR 0.000001    Time 0.217131    
2023-04-17 23:40:15,402 - Epoch: [353][  400/  518]    Overall Loss 2.841890    Objective Loss 2.841890                                        LR 0.000001    Time 0.217070    
2023-04-17 23:40:26,248 - Epoch: [353][  450/  518]    Overall Loss 2.848577    Objective Loss 2.848577                                        LR 0.000001    Time 0.217049    
2023-04-17 23:40:36,943 - Epoch: [353][  500/  518]    Overall Loss 2.846537    Objective Loss 2.846537                                        LR 0.000001    Time 0.216731    
2023-04-17 23:40:40,668 - Epoch: [353][  518/  518]    Overall Loss 2.847248    Objective Loss 2.847248                                        LR 0.000001    Time 0.216391    
2023-04-17 23:40:40,750 - --- validate (epoch=353)-----------
2023-04-17 23:40:40,750 - 4952 samples (32 per mini-batch)
2023-04-17 23:41:22,750 - Epoch: [353][   50/  155]    Loss 3.027459    mAP 0.537489    
2023-04-17 23:42:03,420 - Epoch: [353][  100/  155]    Loss 3.011200    mAP 0.530751    
2023-04-17 23:42:46,583 - Epoch: [353][  150/  155]    Loss 3.023055    mAP 0.534897    
2023-04-17 23:42:50,404 - Epoch: [353][  155/  155]    Loss 3.019388    mAP 0.532088    
2023-04-17 23:42:50,498 - ==> mAP: 0.53209    Loss: 3.019

2023-04-17 23:42:50,501 - ==> Best [mAP: 0.533323   vloss: 3.016302   Sparsity:0.00   Params: 2177088 on epoch: 335]
2023-04-17 23:42:50,502 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-17 23:42:50,536 - 

2023-04-17 23:42:50,536 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 23:43:02,296 - Epoch: [354][   50/  518]    Overall Loss 2.809265    Objective Loss 2.809265                                        LR 0.000001    Time 0.235146    
2023-04-17 23:43:13,017 - Epoch: [354][  100/  518]    Overall Loss 2.833936    Objective Loss 2.833936                                        LR 0.000001    Time 0.224769    
2023-04-17 23:43:23,626 - Epoch: [354][  150/  518]    Overall Loss 2.812845    Objective Loss 2.812845                                        LR 0.000001    Time 0.220563    
2023-04-17 23:43:34,388 - Epoch: [354][  200/  518]    Overall Loss 2.827720    Objective Loss 2.827720                                        LR 0.000001    Time 0.219225    
2023-04-17 23:43:45,082 - Epoch: [354][  250/  518]    Overall Loss 2.823898    Objective Loss 2.823898                                        LR 0.000001    Time 0.218148    
2023-04-17 23:43:55,815 - Epoch: [354][  300/  518]    Overall Loss 2.829964    Objective Loss 2.829964                                        LR 0.000001    Time 0.217563    
2023-04-17 23:44:06,566 - Epoch: [354][  350/  518]    Overall Loss 2.830128    Objective Loss 2.830128                                        LR 0.000001    Time 0.217194    
2023-04-17 23:44:17,311 - Epoch: [354][  400/  518]    Overall Loss 2.831547    Objective Loss 2.831547                                        LR 0.000001    Time 0.216903    
2023-04-17 23:44:28,063 - Epoch: [354][  450/  518]    Overall Loss 2.825444    Objective Loss 2.825444                                        LR 0.000001    Time 0.216695    
2023-04-17 23:44:38,774 - Epoch: [354][  500/  518]    Overall Loss 2.835752    Objective Loss 2.835752                                        LR 0.000001    Time 0.216443    
2023-04-17 23:44:42,510 - Epoch: [354][  518/  518]    Overall Loss 2.836769    Objective Loss 2.836769                                        LR 0.000001    Time 0.216134    
2023-04-17 23:44:42,591 - --- validate (epoch=354)-----------
2023-04-17 23:44:42,591 - 4952 samples (32 per mini-batch)
2023-04-17 23:45:25,642 - Epoch: [354][   50/  155]    Loss 3.014527    mAP 0.518735    
2023-04-17 23:46:06,070 - Epoch: [354][  100/  155]    Loss 3.001469    mAP 0.524974    
2023-04-17 23:46:48,225 - Epoch: [354][  150/  155]    Loss 3.007546    mAP 0.526545    
2023-04-17 23:46:52,038 - Epoch: [354][  155/  155]    Loss 3.013106    mAP 0.525864    
2023-04-17 23:46:52,116 - ==> mAP: 0.52586    Loss: 3.013

2023-04-17 23:46:52,119 - ==> Best [mAP: 0.533323   vloss: 3.016302   Sparsity:0.00   Params: 2177088 on epoch: 335]
2023-04-17 23:46:52,119 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-17 23:46:52,154 - 

2023-04-17 23:46:52,154 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 23:47:03,737 - Epoch: [355][   50/  518]    Overall Loss 2.853639    Objective Loss 2.853639                                        LR 0.000001    Time 0.231603    
2023-04-17 23:47:14,449 - Epoch: [355][  100/  518]    Overall Loss 2.849037    Objective Loss 2.849037                                        LR 0.000001    Time 0.222909    
2023-04-17 23:47:25,197 - Epoch: [355][  150/  518]    Overall Loss 2.862942    Objective Loss 2.862942                                        LR 0.000001    Time 0.220248    
2023-04-17 23:47:35,900 - Epoch: [355][  200/  518]    Overall Loss 2.851554    Objective Loss 2.851554                                        LR 0.000001    Time 0.218696    
2023-04-17 23:47:46,593 - Epoch: [355][  250/  518]    Overall Loss 2.849744    Objective Loss 2.849744                                        LR 0.000001    Time 0.217720    
2023-04-17 23:47:57,288 - Epoch: [355][  300/  518]    Overall Loss 2.849598    Objective Loss 2.849598                                        LR 0.000001    Time 0.217078    
2023-04-17 23:48:08,065 - Epoch: [355][  350/  518]    Overall Loss 2.853279    Objective Loss 2.853279                                        LR 0.000001    Time 0.216856    
2023-04-17 23:48:18,765 - Epoch: [355][  400/  518]    Overall Loss 2.852903    Objective Loss 2.852903                                        LR 0.000001    Time 0.216494    
2023-04-17 23:48:29,424 - Epoch: [355][  450/  518]    Overall Loss 2.853104    Objective Loss 2.853104                                        LR 0.000001    Time 0.216123    
2023-04-17 23:48:40,094 - Epoch: [355][  500/  518]    Overall Loss 2.851959    Objective Loss 2.851959                                        LR 0.000001    Time 0.215846    
2023-04-17 23:48:43,799 - Epoch: [355][  518/  518]    Overall Loss 2.852735    Objective Loss 2.852735                                        LR 0.000001    Time 0.215499    
2023-04-17 23:48:43,880 - --- validate (epoch=355)-----------
2023-04-17 23:48:43,880 - 4952 samples (32 per mini-batch)
2023-04-17 23:49:27,948 - Epoch: [355][   50/  155]    Loss 3.026886    mAP 0.527622    
2023-04-17 23:50:10,783 - Epoch: [355][  100/  155]    Loss 3.033162    mAP 0.529259    
2023-04-17 23:50:53,277 - Epoch: [355][  150/  155]    Loss 3.018018    mAP 0.534287    
2023-04-17 23:50:57,169 - Epoch: [355][  155/  155]    Loss 3.013999    mAP 0.533637    
2023-04-17 23:50:57,247 - ==> mAP: 0.53364    Loss: 3.014

2023-04-17 23:50:57,251 - ==> Best [mAP: 0.533637   vloss: 3.013999   Sparsity:0.00   Params: 2177088 on epoch: 355]
2023-04-17 23:50:57,251 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-17 23:50:57,300 - 

2023-04-17 23:50:57,300 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 23:51:08,891 - Epoch: [356][   50/  518]    Overall Loss 2.886481    Objective Loss 2.886481                                        LR 0.000001    Time 0.231760    
2023-04-17 23:51:19,708 - Epoch: [356][  100/  518]    Overall Loss 2.854803    Objective Loss 2.854803                                        LR 0.000001    Time 0.224039    
2023-04-17 23:51:30,461 - Epoch: [356][  150/  518]    Overall Loss 2.852609    Objective Loss 2.852609                                        LR 0.000001    Time 0.221038    
2023-04-17 23:51:41,259 - Epoch: [356][  200/  518]    Overall Loss 2.843528    Objective Loss 2.843528                                        LR 0.000001    Time 0.219760    
2023-04-17 23:51:52,061 - Epoch: [356][  250/  518]    Overall Loss 2.847613    Objective Loss 2.847613                                        LR 0.000001    Time 0.219011    
2023-04-17 23:52:02,825 - Epoch: [356][  300/  518]    Overall Loss 2.845763    Objective Loss 2.845763                                        LR 0.000001    Time 0.218382    
2023-04-17 23:52:13,607 - Epoch: [356][  350/  518]    Overall Loss 2.837111    Objective Loss 2.837111                                        LR 0.000001    Time 0.217985    
2023-04-17 23:52:24,378 - Epoch: [356][  400/  518]    Overall Loss 2.844228    Objective Loss 2.844228                                        LR 0.000001    Time 0.217662    
2023-04-17 23:52:35,068 - Epoch: [356][  450/  518]    Overall Loss 2.842631    Objective Loss 2.842631                                        LR 0.000001    Time 0.217228    
2023-04-17 23:52:45,769 - Epoch: [356][  500/  518]    Overall Loss 2.841466    Objective Loss 2.841466                                        LR 0.000001    Time 0.216906    
2023-04-17 23:52:49,485 - Epoch: [356][  518/  518]    Overall Loss 2.839528    Objective Loss 2.839528                                        LR 0.000001    Time 0.216541    
2023-04-17 23:52:49,566 - --- validate (epoch=356)-----------
2023-04-17 23:52:49,567 - 4952 samples (32 per mini-batch)
2023-04-17 23:53:32,707 - Epoch: [356][   50/  155]    Loss 3.029082    mAP 0.532370    
2023-04-17 23:54:14,457 - Epoch: [356][  100/  155]    Loss 3.020004    mAP 0.529966    
2023-04-17 23:54:56,177 - Epoch: [356][  150/  155]    Loss 3.011489    mAP 0.530104    
2023-04-17 23:54:59,906 - Epoch: [356][  155/  155]    Loss 3.013345    mAP 0.529693    
2023-04-17 23:54:59,983 - ==> mAP: 0.52969    Loss: 3.013

2023-04-17 23:54:59,986 - ==> Best [mAP: 0.533637   vloss: 3.013999   Sparsity:0.00   Params: 2177088 on epoch: 355]
2023-04-17 23:54:59,987 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-17 23:55:00,021 - 

2023-04-17 23:55:00,021 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 23:55:11,430 - Epoch: [357][   50/  518]    Overall Loss 2.901797    Objective Loss 2.901797                                        LR 0.000001    Time 0.228131    
2023-04-17 23:55:22,118 - Epoch: [357][  100/  518]    Overall Loss 2.869933    Objective Loss 2.869933                                        LR 0.000001    Time 0.220927    
2023-04-17 23:55:32,911 - Epoch: [357][  150/  518]    Overall Loss 2.850945    Objective Loss 2.850945                                        LR 0.000001    Time 0.219227    
2023-04-17 23:55:43,668 - Epoch: [357][  200/  518]    Overall Loss 2.847499    Objective Loss 2.847499                                        LR 0.000001    Time 0.218198    
2023-04-17 23:55:54,426 - Epoch: [357][  250/  518]    Overall Loss 2.851757    Objective Loss 2.851757                                        LR 0.000001    Time 0.217585    
2023-04-17 23:56:05,110 - Epoch: [357][  300/  518]    Overall Loss 2.850575    Objective Loss 2.850575                                        LR 0.000001    Time 0.216929    
2023-04-17 23:56:15,838 - Epoch: [357][  350/  518]    Overall Loss 2.842628    Objective Loss 2.842628                                        LR 0.000001    Time 0.216587    
2023-04-17 23:56:26,532 - Epoch: [357][  400/  518]    Overall Loss 2.841481    Objective Loss 2.841481                                        LR 0.000001    Time 0.216243    
2023-04-17 23:56:37,260 - Epoch: [357][  450/  518]    Overall Loss 2.843459    Objective Loss 2.843459                                        LR 0.000001    Time 0.216054    
2023-04-17 23:56:47,933 - Epoch: [357][  500/  518]    Overall Loss 2.843022    Objective Loss 2.843022                                        LR 0.000001    Time 0.215791    
2023-04-17 23:56:51,647 - Epoch: [357][  518/  518]    Overall Loss 2.843278    Objective Loss 2.843278                                        LR 0.000001    Time 0.215462    
2023-04-17 23:56:51,729 - --- validate (epoch=357)-----------
2023-04-17 23:56:51,730 - 4952 samples (32 per mini-batch)
2023-04-17 23:57:34,034 - Epoch: [357][   50/  155]    Loss 3.012492    mAP 0.533059    
2023-04-17 23:58:16,900 - Epoch: [357][  100/  155]    Loss 3.014709    mAP 0.537885    
2023-04-17 23:58:58,481 - Epoch: [357][  150/  155]    Loss 3.013482    mAP 0.530187    
2023-04-17 23:59:02,946 - Epoch: [357][  155/  155]    Loss 3.011463    mAP 0.530093    
2023-04-17 23:59:03,022 - ==> mAP: 0.53009    Loss: 3.011

2023-04-17 23:59:03,026 - ==> Best [mAP: 0.533637   vloss: 3.013999   Sparsity:0.00   Params: 2177088 on epoch: 355]
2023-04-17 23:59:03,026 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-17 23:59:03,060 - 

2023-04-17 23:59:03,060 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-17 23:59:14,739 - Epoch: [358][   50/  518]    Overall Loss 2.901261    Objective Loss 2.901261                                        LR 0.000001    Time 0.233525    
2023-04-17 23:59:25,364 - Epoch: [358][  100/  518]    Overall Loss 2.888945    Objective Loss 2.888945                                        LR 0.000001    Time 0.222993    
2023-04-17 23:59:36,016 - Epoch: [358][  150/  518]    Overall Loss 2.866935    Objective Loss 2.866935                                        LR 0.000001    Time 0.219664    
2023-04-17 23:59:46,743 - Epoch: [358][  200/  518]    Overall Loss 2.848691    Objective Loss 2.848691                                        LR 0.000001    Time 0.218376    
2023-04-17 23:59:57,477 - Epoch: [358][  250/  518]    Overall Loss 2.851919    Objective Loss 2.851919                                        LR 0.000001    Time 0.217630    
2023-04-18 00:00:08,165 - Epoch: [358][  300/  518]    Overall Loss 2.841591    Objective Loss 2.841591                                        LR 0.000001    Time 0.216979    
2023-04-18 00:00:18,864 - Epoch: [358][  350/  518]    Overall Loss 2.842427    Objective Loss 2.842427                                        LR 0.000001    Time 0.216548    
2023-04-18 00:00:29,536 - Epoch: [358][  400/  518]    Overall Loss 2.838598    Objective Loss 2.838598                                        LR 0.000001    Time 0.216155    
2023-04-18 00:00:40,296 - Epoch: [358][  450/  518]    Overall Loss 2.840882    Objective Loss 2.840882                                        LR 0.000001    Time 0.216045    
2023-04-18 00:00:51,016 - Epoch: [358][  500/  518]    Overall Loss 2.836137    Objective Loss 2.836137                                        LR 0.000001    Time 0.215878    
2023-04-18 00:00:54,722 - Epoch: [358][  518/  518]    Overall Loss 2.835490    Objective Loss 2.835490                                        LR 0.000001    Time 0.215529    
2023-04-18 00:00:54,803 - --- validate (epoch=358)-----------
2023-04-18 00:00:54,803 - 4952 samples (32 per mini-batch)
2023-04-18 00:01:37,112 - Epoch: [358][   50/  155]    Loss 3.035724    mAP 0.524509    
2023-04-18 00:02:19,543 - Epoch: [358][  100/  155]    Loss 3.016076    mAP 0.523381    
2023-04-18 00:03:02,577 - Epoch: [358][  150/  155]    Loss 3.010692    mAP 0.530819    
2023-04-18 00:03:06,444 - Epoch: [358][  155/  155]    Loss 3.013782    mAP 0.531422    
2023-04-18 00:03:06,524 - ==> mAP: 0.53142    Loss: 3.014

2023-04-18 00:03:06,527 - ==> Best [mAP: 0.533637   vloss: 3.013999   Sparsity:0.00   Params: 2177088 on epoch: 355]
2023-04-18 00:03:06,527 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-18 00:03:06,560 - 

2023-04-18 00:03:06,560 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-18 00:03:18,268 - Epoch: [359][   50/  518]    Overall Loss 2.880443    Objective Loss 2.880443                                        LR 0.000001    Time 0.234103    
2023-04-18 00:03:29,014 - Epoch: [359][  100/  518]    Overall Loss 2.874864    Objective Loss 2.874864                                        LR 0.000001    Time 0.224494    
2023-04-18 00:03:39,822 - Epoch: [359][  150/  518]    Overall Loss 2.862346    Objective Loss 2.862346                                        LR 0.000001    Time 0.221706    
2023-04-18 00:03:50,596 - Epoch: [359][  200/  518]    Overall Loss 2.858141    Objective Loss 2.858141                                        LR 0.000001    Time 0.220142    
2023-04-18 00:04:01,372 - Epoch: [359][  250/  518]    Overall Loss 2.851437    Objective Loss 2.851437                                        LR 0.000001    Time 0.219210    
2023-04-18 00:04:12,100 - Epoch: [359][  300/  518]    Overall Loss 2.839296    Objective Loss 2.839296                                        LR 0.000001    Time 0.218433    
2023-04-18 00:04:22,757 - Epoch: [359][  350/  518]    Overall Loss 2.842276    Objective Loss 2.842276                                        LR 0.000001    Time 0.217669    
2023-04-18 00:04:33,392 - Epoch: [359][  400/  518]    Overall Loss 2.846377    Objective Loss 2.846377                                        LR 0.000001    Time 0.217045    
2023-04-18 00:04:44,134 - Epoch: [359][  450/  518]    Overall Loss 2.845634    Objective Loss 2.845634                                        LR 0.000001    Time 0.216798    
2023-04-18 00:04:54,806 - Epoch: [359][  500/  518]    Overall Loss 2.846833    Objective Loss 2.846833                                        LR 0.000001    Time 0.216458    
2023-04-18 00:04:58,555 - Epoch: [359][  518/  518]    Overall Loss 2.846917    Objective Loss 2.846917                                        LR 0.000001    Time 0.216174    
2023-04-18 00:04:58,636 - --- validate (epoch=359)-----------
2023-04-18 00:04:58,636 - 4952 samples (32 per mini-batch)
2023-04-18 00:05:41,800 - Epoch: [359][   50/  155]    Loss 3.001405    mAP 0.517302    
2023-04-18 00:06:24,644 - Epoch: [359][  100/  155]    Loss 2.998232    mAP 0.521894    
2023-04-18 00:07:07,583 - Epoch: [359][  150/  155]    Loss 3.003955    mAP 0.522712    
2023-04-18 00:07:11,320 - Epoch: [359][  155/  155]    Loss 3.007742    mAP 0.520925    
2023-04-18 00:07:11,395 - ==> mAP: 0.52093    Loss: 3.008

2023-04-18 00:07:11,399 - ==> Best [mAP: 0.533637   vloss: 3.013999   Sparsity:0.00   Params: 2177088 on epoch: 355]
2023-04-18 00:07:11,399 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-18 00:07:11,432 - 

2023-04-18 00:07:11,432 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-18 00:07:22,919 - Epoch: [360][   50/  518]    Overall Loss 2.872292    Objective Loss 2.872292                                        LR 0.000001    Time 0.229671    
2023-04-18 00:07:33,684 - Epoch: [360][  100/  518]    Overall Loss 2.878460    Objective Loss 2.878460                                        LR 0.000001    Time 0.222474    
2023-04-18 00:07:44,514 - Epoch: [360][  150/  518]    Overall Loss 2.868950    Objective Loss 2.868950                                        LR 0.000001    Time 0.220509    
2023-04-18 00:07:55,296 - Epoch: [360][  200/  518]    Overall Loss 2.857727    Objective Loss 2.857727                                        LR 0.000001    Time 0.219281    
2023-04-18 00:08:06,038 - Epoch: [360][  250/  518]    Overall Loss 2.857799    Objective Loss 2.857799                                        LR 0.000001    Time 0.218389    
2023-04-18 00:08:16,743 - Epoch: [360][  300/  518]    Overall Loss 2.853899    Objective Loss 2.853899                                        LR 0.000001    Time 0.217668    
2023-04-18 00:08:27,582 - Epoch: [360][  350/  518]    Overall Loss 2.847244    Objective Loss 2.847244                                        LR 0.000001    Time 0.217536    
2023-04-18 00:08:38,307 - Epoch: [360][  400/  518]    Overall Loss 2.844863    Objective Loss 2.844863                                        LR 0.000001    Time 0.217154    
2023-04-18 00:08:48,961 - Epoch: [360][  450/  518]    Overall Loss 2.839419    Objective Loss 2.839419                                        LR 0.000001    Time 0.216697    
2023-04-18 00:08:59,567 - Epoch: [360][  500/  518]    Overall Loss 2.839008    Objective Loss 2.839008                                        LR 0.000001    Time 0.216236    
2023-04-18 00:09:03,328 - Epoch: [360][  518/  518]    Overall Loss 2.841723    Objective Loss 2.841723                                        LR 0.000001    Time 0.215983    
2023-04-18 00:09:03,405 - --- validate (epoch=360)-----------
2023-04-18 00:09:03,405 - 4952 samples (32 per mini-batch)
2023-04-18 00:09:48,303 - Epoch: [360][   50/  155]    Loss 3.018046    mAP 0.522191    
2023-04-18 00:10:30,176 - Epoch: [360][  100/  155]    Loss 3.004468    mAP 0.531282    
2023-04-18 00:11:14,627 - Epoch: [360][  150/  155]    Loss 3.013151    mAP 0.522643    
2023-04-18 00:11:18,007 - Epoch: [360][  155/  155]    Loss 3.016039    mAP 0.519606    
2023-04-18 00:11:18,085 - ==> mAP: 0.51961    Loss: 3.016

2023-04-18 00:11:18,089 - ==> Best [mAP: 0.533637   vloss: 3.013999   Sparsity:0.00   Params: 2177088 on epoch: 355]
2023-04-18 00:11:18,089 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-18 00:11:18,125 - 

2023-04-18 00:11:18,125 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-18 00:11:29,690 - Epoch: [361][   50/  518]    Overall Loss 2.832533    Objective Loss 2.832533                                        LR 0.000001    Time 0.231246    
2023-04-18 00:11:40,387 - Epoch: [361][  100/  518]    Overall Loss 2.816805    Objective Loss 2.816805                                        LR 0.000001    Time 0.222585    
2023-04-18 00:11:51,112 - Epoch: [361][  150/  518]    Overall Loss 2.838896    Objective Loss 2.838896                                        LR 0.000001    Time 0.219876    
2023-04-18 00:12:01,845 - Epoch: [361][  200/  518]    Overall Loss 2.839473    Objective Loss 2.839473                                        LR 0.000001    Time 0.218567    
2023-04-18 00:12:12,563 - Epoch: [361][  250/  518]    Overall Loss 2.829451    Objective Loss 2.829451                                        LR 0.000001    Time 0.217717    
2023-04-18 00:12:23,222 - Epoch: [361][  300/  518]    Overall Loss 2.840420    Objective Loss 2.840420                                        LR 0.000001    Time 0.216956    
2023-04-18 00:12:33,891 - Epoch: [361][  350/  518]    Overall Loss 2.831472    Objective Loss 2.831472                                        LR 0.000001    Time 0.216443    
2023-04-18 00:12:44,600 - Epoch: [361][  400/  518]    Overall Loss 2.828855    Objective Loss 2.828855                                        LR 0.000001    Time 0.216154    
2023-04-18 00:12:55,299 - Epoch: [361][  450/  518]    Overall Loss 2.833825    Objective Loss 2.833825                                        LR 0.000001    Time 0.215911    
2023-04-18 00:13:06,090 - Epoch: [361][  500/  518]    Overall Loss 2.836690    Objective Loss 2.836690                                        LR 0.000001    Time 0.215898    
2023-04-18 00:13:09,804 - Epoch: [361][  518/  518]    Overall Loss 2.833062    Objective Loss 2.833062                                        LR 0.000001    Time 0.215564    
2023-04-18 00:13:09,883 - --- validate (epoch=361)-----------
2023-04-18 00:13:09,884 - 4952 samples (32 per mini-batch)
2023-04-18 00:13:53,422 - Epoch: [361][   50/  155]    Loss 3.021518    mAP 0.507912    
2023-04-18 00:14:34,013 - Epoch: [361][  100/  155]    Loss 3.005784    mAP 0.523592    
2023-04-18 00:15:16,363 - Epoch: [361][  150/  155]    Loss 3.013449    mAP 0.517979    
2023-04-18 00:15:20,123 - Epoch: [361][  155/  155]    Loss 3.017763    mAP 0.516911    
2023-04-18 00:15:20,201 - ==> mAP: 0.51691    Loss: 3.018

2023-04-18 00:15:20,205 - ==> Best [mAP: 0.533637   vloss: 3.013999   Sparsity:0.00   Params: 2177088 on epoch: 355]
2023-04-18 00:15:20,205 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-18 00:15:20,240 - 

2023-04-18 00:15:20,240 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-18 00:15:31,712 - Epoch: [362][   50/  518]    Overall Loss 2.797403    Objective Loss 2.797403                                        LR 0.000001    Time 0.229394    
2023-04-18 00:15:42,467 - Epoch: [362][  100/  518]    Overall Loss 2.804535    Objective Loss 2.804535                                        LR 0.000001    Time 0.222232    
2023-04-18 00:15:53,185 - Epoch: [362][  150/  518]    Overall Loss 2.814715    Objective Loss 2.814715                                        LR 0.000001    Time 0.219596    
2023-04-18 00:16:04,007 - Epoch: [362][  200/  518]    Overall Loss 2.808013    Objective Loss 2.808013                                        LR 0.000001    Time 0.218798    
2023-04-18 00:16:14,694 - Epoch: [362][  250/  518]    Overall Loss 2.810640    Objective Loss 2.810640                                        LR 0.000001    Time 0.217783    
2023-04-18 00:16:25,446 - Epoch: [362][  300/  518]    Overall Loss 2.817426    Objective Loss 2.817426                                        LR 0.000001    Time 0.217320    
2023-04-18 00:16:36,081 - Epoch: [362][  350/  518]    Overall Loss 2.823786    Objective Loss 2.823786                                        LR 0.000001    Time 0.216655    
2023-04-18 00:16:46,815 - Epoch: [362][  400/  518]    Overall Loss 2.831290    Objective Loss 2.831290                                        LR 0.000001    Time 0.216405    
2023-04-18 00:16:57,581 - Epoch: [362][  450/  518]    Overall Loss 2.839304    Objective Loss 2.839304                                        LR 0.000001    Time 0.216281    
2023-04-18 00:17:08,340 - Epoch: [362][  500/  518]    Overall Loss 2.836176    Objective Loss 2.836176                                        LR 0.000001    Time 0.216168    
2023-04-18 00:17:12,108 - Epoch: [362][  518/  518]    Overall Loss 2.833330    Objective Loss 2.833330                                        LR 0.000001    Time 0.215930    
2023-04-18 00:17:12,189 - --- validate (epoch=362)-----------
2023-04-18 00:17:12,189 - 4952 samples (32 per mini-batch)
2023-04-18 00:17:55,487 - Epoch: [362][   50/  155]    Loss 3.059560    mAP 0.517441    
2023-04-18 00:18:37,785 - Epoch: [362][  100/  155]    Loss 3.013742    mAP 0.525686    
2023-04-18 00:19:19,672 - Epoch: [362][  150/  155]    Loss 3.011930    mAP 0.528433    
2023-04-18 00:19:23,688 - Epoch: [362][  155/  155]    Loss 3.010882    mAP 0.528786    
2023-04-18 00:19:23,766 - ==> mAP: 0.52879    Loss: 3.011

2023-04-18 00:19:23,770 - ==> Best [mAP: 0.533637   vloss: 3.013999   Sparsity:0.00   Params: 2177088 on epoch: 355]
2023-04-18 00:19:23,770 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-18 00:19:23,804 - 

2023-04-18 00:19:23,804 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-18 00:19:35,420 - Epoch: [363][   50/  518]    Overall Loss 2.838667    Objective Loss 2.838667                                        LR 0.000001    Time 0.232261    
2023-04-18 00:19:46,155 - Epoch: [363][  100/  518]    Overall Loss 2.842213    Objective Loss 2.842213                                        LR 0.000001    Time 0.223465    
2023-04-18 00:19:56,859 - Epoch: [363][  150/  518]    Overall Loss 2.846960    Objective Loss 2.846960                                        LR 0.000001    Time 0.220330    
2023-04-18 00:20:07,598 - Epoch: [363][  200/  518]    Overall Loss 2.842655    Objective Loss 2.842655                                        LR 0.000001    Time 0.218932    
2023-04-18 00:20:18,288 - Epoch: [363][  250/  518]    Overall Loss 2.839127    Objective Loss 2.839127                                        LR 0.000001    Time 0.217902    
2023-04-18 00:20:29,005 - Epoch: [363][  300/  518]    Overall Loss 2.826569    Objective Loss 2.826569                                        LR 0.000001    Time 0.217303    
2023-04-18 00:20:39,748 - Epoch: [363][  350/  518]    Overall Loss 2.830342    Objective Loss 2.830342                                        LR 0.000001    Time 0.216950    
2023-04-18 00:20:50,601 - Epoch: [363][  400/  518]    Overall Loss 2.824938    Objective Loss 2.824938                                        LR 0.000001    Time 0.216960    
2023-04-18 00:21:01,285 - Epoch: [363][  450/  518]    Overall Loss 2.823078    Objective Loss 2.823078                                        LR 0.000001    Time 0.216592    
2023-04-18 00:21:12,055 - Epoch: [363][  500/  518]    Overall Loss 2.828690    Objective Loss 2.828690                                        LR 0.000001    Time 0.216470    
2023-04-18 00:21:15,789 - Epoch: [363][  518/  518]    Overall Loss 2.828281    Objective Loss 2.828281                                        LR 0.000001    Time 0.216156    
2023-04-18 00:21:15,870 - --- validate (epoch=363)-----------
2023-04-18 00:21:15,870 - 4952 samples (32 per mini-batch)
2023-04-18 00:21:57,858 - Epoch: [363][   50/  155]    Loss 3.012789    mAP 0.513285    
2023-04-18 00:22:40,104 - Epoch: [363][  100/  155]    Loss 3.038225    mAP 0.510488    
2023-04-18 00:23:22,010 - Epoch: [363][  150/  155]    Loss 3.012543    mAP 0.526667    
2023-04-18 00:23:25,857 - Epoch: [363][  155/  155]    Loss 3.010804    mAP 0.525421    
2023-04-18 00:23:25,931 - ==> mAP: 0.52542    Loss: 3.011

2023-04-18 00:23:25,935 - ==> Best [mAP: 0.533637   vloss: 3.013999   Sparsity:0.00   Params: 2177088 on epoch: 355]
2023-04-18 00:23:25,935 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-18 00:23:25,969 - 

2023-04-18 00:23:25,969 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-18 00:23:37,563 - Epoch: [364][   50/  518]    Overall Loss 2.790547    Objective Loss 2.790547                                        LR 0.000001    Time 0.231833    
2023-04-18 00:23:48,199 - Epoch: [364][  100/  518]    Overall Loss 2.801335    Objective Loss 2.801335                                        LR 0.000001    Time 0.222263    
2023-04-18 00:23:58,907 - Epoch: [364][  150/  518]    Overall Loss 2.805621    Objective Loss 2.805621                                        LR 0.000001    Time 0.219553    
2023-04-18 00:24:09,641 - Epoch: [364][  200/  518]    Overall Loss 2.817420    Objective Loss 2.817420                                        LR 0.000001    Time 0.218326    
2023-04-18 00:24:20,396 - Epoch: [364][  250/  518]    Overall Loss 2.819130    Objective Loss 2.819130                                        LR 0.000001    Time 0.217675    
2023-04-18 00:24:31,082 - Epoch: [364][  300/  518]    Overall Loss 2.822866    Objective Loss 2.822866                                        LR 0.000001    Time 0.217010    
2023-04-18 00:24:41,746 - Epoch: [364][  350/  518]    Overall Loss 2.823704    Objective Loss 2.823704                                        LR 0.000001    Time 0.216473    
2023-04-18 00:24:52,397 - Epoch: [364][  400/  518]    Overall Loss 2.832869    Objective Loss 2.832869                                        LR 0.000001    Time 0.216037    
2023-04-18 00:25:03,114 - Epoch: [364][  450/  518]    Overall Loss 2.834311    Objective Loss 2.834311                                        LR 0.000001    Time 0.215846    
2023-04-18 00:25:13,820 - Epoch: [364][  500/  518]    Overall Loss 2.837195    Objective Loss 2.837195                                        LR 0.000001    Time 0.215670    
2023-04-18 00:25:17,529 - Epoch: [364][  518/  518]    Overall Loss 2.835833    Objective Loss 2.835833                                        LR 0.000001    Time 0.215335    
2023-04-18 00:25:17,610 - --- validate (epoch=364)-----------
2023-04-18 00:25:17,611 - 4952 samples (32 per mini-batch)
2023-04-18 00:26:00,732 - Epoch: [364][   50/  155]    Loss 2.979360    mAP 0.537938    
2023-04-18 00:26:43,575 - Epoch: [364][  100/  155]    Loss 3.010858    mAP 0.534845    
2023-04-18 00:27:26,381 - Epoch: [364][  150/  155]    Loss 3.003495    mAP 0.528686    
2023-04-18 00:27:30,831 - Epoch: [364][  155/  155]    Loss 3.003920    mAP 0.527336    
2023-04-18 00:27:30,909 - ==> mAP: 0.52734    Loss: 3.004

2023-04-18 00:27:30,913 - ==> Best [mAP: 0.533637   vloss: 3.013999   Sparsity:0.00   Params: 2177088 on epoch: 355]
2023-04-18 00:27:30,913 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-18 00:27:30,947 - 

2023-04-18 00:27:30,947 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-18 00:27:42,331 - Epoch: [365][   50/  518]    Overall Loss 2.866216    Objective Loss 2.866216                                        LR 0.000001    Time 0.227615    
2023-04-18 00:27:53,092 - Epoch: [365][  100/  518]    Overall Loss 2.861670    Objective Loss 2.861670                                        LR 0.000001    Time 0.221410    
2023-04-18 00:28:03,805 - Epoch: [365][  150/  518]    Overall Loss 2.835088    Objective Loss 2.835088                                        LR 0.000001    Time 0.219016    
2023-04-18 00:28:14,612 - Epoch: [365][  200/  518]    Overall Loss 2.840624    Objective Loss 2.840624                                        LR 0.000001    Time 0.218289    
2023-04-18 00:28:25,320 - Epoch: [365][  250/  518]    Overall Loss 2.840201    Objective Loss 2.840201                                        LR 0.000001    Time 0.217454    
2023-04-18 00:28:35,950 - Epoch: [365][  300/  518]    Overall Loss 2.841353    Objective Loss 2.841353                                        LR 0.000001    Time 0.216641    
2023-04-18 00:28:46,693 - Epoch: [365][  350/  518]    Overall Loss 2.840876    Objective Loss 2.840876                                        LR 0.000001    Time 0.216382    
2023-04-18 00:28:57,338 - Epoch: [365][  400/  518]    Overall Loss 2.844558    Objective Loss 2.844558                                        LR 0.000001    Time 0.215944    
2023-04-18 00:29:08,066 - Epoch: [365][  450/  518]    Overall Loss 2.840277    Objective Loss 2.840277                                        LR 0.000001    Time 0.215785    
2023-04-18 00:29:18,788 - Epoch: [365][  500/  518]    Overall Loss 2.841517    Objective Loss 2.841517                                        LR 0.000001    Time 0.215648    
2023-04-18 00:29:22,504 - Epoch: [365][  518/  518]    Overall Loss 2.843523    Objective Loss 2.843523                                        LR 0.000001    Time 0.215328    
2023-04-18 00:29:22,585 - --- validate (epoch=365)-----------
2023-04-18 00:29:22,586 - 4952 samples (32 per mini-batch)
2023-04-18 00:30:05,817 - Epoch: [365][   50/  155]    Loss 3.057214    mAP 0.530941    
2023-04-18 00:30:48,963 - Epoch: [365][  100/  155]    Loss 3.012235    mAP 0.538774    
2023-04-18 00:31:31,943 - Epoch: [365][  150/  155]    Loss 3.005255    mAP 0.534879    
2023-04-18 00:31:35,987 - Epoch: [365][  155/  155]    Loss 3.006499    mAP 0.534820    
2023-04-18 00:31:36,066 - ==> mAP: 0.53482    Loss: 3.006

2023-04-18 00:31:36,070 - ==> Best [mAP: 0.534820   vloss: 3.006499   Sparsity:0.00   Params: 2177088 on epoch: 365]
2023-04-18 00:31:36,070 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-18 00:31:36,120 - 

2023-04-18 00:31:36,121 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-18 00:31:47,758 - Epoch: [366][   50/  518]    Overall Loss 2.898240    Objective Loss 2.898240                                        LR 0.000001    Time 0.232698    
2023-04-18 00:31:58,547 - Epoch: [366][  100/  518]    Overall Loss 2.860169    Objective Loss 2.860169                                        LR 0.000001    Time 0.224225    
2023-04-18 00:32:09,339 - Epoch: [366][  150/  518]    Overall Loss 2.845036    Objective Loss 2.845036                                        LR 0.000001    Time 0.221415    
2023-04-18 00:32:20,072 - Epoch: [366][  200/  518]    Overall Loss 2.839549    Objective Loss 2.839549                                        LR 0.000001    Time 0.219721    
2023-04-18 00:32:30,714 - Epoch: [366][  250/  518]    Overall Loss 2.837132    Objective Loss 2.837132                                        LR 0.000001    Time 0.218340    
2023-04-18 00:32:41,449 - Epoch: [366][  300/  518]    Overall Loss 2.846405    Objective Loss 2.846405                                        LR 0.000001    Time 0.217726    
2023-04-18 00:32:52,245 - Epoch: [366][  350/  518]    Overall Loss 2.847456    Objective Loss 2.847456                                        LR 0.000001    Time 0.217465    
2023-04-18 00:33:02,979 - Epoch: [366][  400/  518]    Overall Loss 2.842507    Objective Loss 2.842507                                        LR 0.000001    Time 0.217113    
2023-04-18 00:33:13,780 - Epoch: [366][  450/  518]    Overall Loss 2.841667    Objective Loss 2.841667                                        LR 0.000001    Time 0.216988    
2023-04-18 00:33:24,537 - Epoch: [366][  500/  518]    Overall Loss 2.843481    Objective Loss 2.843481                                        LR 0.000001    Time 0.216800    
2023-04-18 00:33:28,264 - Epoch: [366][  518/  518]    Overall Loss 2.842517    Objective Loss 2.842517                                        LR 0.000001    Time 0.216461    
2023-04-18 00:33:28,343 - --- validate (epoch=366)-----------
2023-04-18 00:33:28,344 - 4952 samples (32 per mini-batch)
2023-04-18 00:34:12,459 - Epoch: [366][   50/  155]    Loss 2.994864    mAP 0.512213    
2023-04-18 00:34:54,562 - Epoch: [366][  100/  155]    Loss 3.020707    mAP 0.514396    
2023-04-18 00:35:35,865 - Epoch: [366][  150/  155]    Loss 3.008113    mAP 0.528822    
2023-04-18 00:35:39,762 - Epoch: [366][  155/  155]    Loss 3.003072    mAP 0.528603    
2023-04-18 00:35:39,835 - ==> mAP: 0.52860    Loss: 3.003

2023-04-18 00:35:39,839 - ==> Best [mAP: 0.534820   vloss: 3.006499   Sparsity:0.00   Params: 2177088 on epoch: 365]
2023-04-18 00:35:39,839 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-18 00:35:39,873 - 

2023-04-18 00:35:39,873 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-18 00:35:51,325 - Epoch: [367][   50/  518]    Overall Loss 2.894167    Objective Loss 2.894167                                        LR 0.000001    Time 0.228988    
2023-04-18 00:36:02,047 - Epoch: [367][  100/  518]    Overall Loss 2.890534    Objective Loss 2.890534                                        LR 0.000001    Time 0.221694    
2023-04-18 00:36:12,730 - Epoch: [367][  150/  518]    Overall Loss 2.847808    Objective Loss 2.847808                                        LR 0.000001    Time 0.219005    
2023-04-18 00:36:23,403 - Epoch: [367][  200/  518]    Overall Loss 2.847824    Objective Loss 2.847824                                        LR 0.000001    Time 0.217613    
2023-04-18 00:36:34,245 - Epoch: [367][  250/  518]    Overall Loss 2.846020    Objective Loss 2.846020                                        LR 0.000001    Time 0.217452    
2023-04-18 00:36:44,960 - Epoch: [367][  300/  518]    Overall Loss 2.850859    Objective Loss 2.850859                                        LR 0.000001    Time 0.216919    
2023-04-18 00:36:55,706 - Epoch: [367][  350/  518]    Overall Loss 2.848331    Objective Loss 2.848331                                        LR 0.000001    Time 0.216630    
2023-04-18 00:37:06,418 - Epoch: [367][  400/  518]    Overall Loss 2.843557    Objective Loss 2.843557                                        LR 0.000001    Time 0.216329    
2023-04-18 00:37:17,223 - Epoch: [367][  450/  518]    Overall Loss 2.844602    Objective Loss 2.844602                                        LR 0.000001    Time 0.216299    
2023-04-18 00:37:28,023 - Epoch: [367][  500/  518]    Overall Loss 2.844511    Objective Loss 2.844511                                        LR 0.000001    Time 0.216267    
2023-04-18 00:37:31,738 - Epoch: [367][  518/  518]    Overall Loss 2.845214    Objective Loss 2.845214                                        LR 0.000001    Time 0.215923    
2023-04-18 00:37:31,818 - --- validate (epoch=367)-----------
2023-04-18 00:37:31,818 - 4952 samples (32 per mini-batch)
2023-04-18 00:38:14,561 - Epoch: [367][   50/  155]    Loss 3.015932    mAP 0.530100    
2023-04-18 00:38:55,916 - Epoch: [367][  100/  155]    Loss 3.024828    mAP 0.527585    
2023-04-18 00:39:37,988 - Epoch: [367][  150/  155]    Loss 3.012237    mAP 0.525505    
2023-04-18 00:39:42,178 - Epoch: [367][  155/  155]    Loss 3.005214    mAP 0.528009    
2023-04-18 00:39:42,256 - ==> mAP: 0.52801    Loss: 3.005

2023-04-18 00:39:42,260 - ==> Best [mAP: 0.534820   vloss: 3.006499   Sparsity:0.00   Params: 2177088 on epoch: 365]
2023-04-18 00:39:42,260 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-18 00:39:42,294 - 

2023-04-18 00:39:42,295 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-18 00:39:53,745 - Epoch: [368][   50/  518]    Overall Loss 2.822041    Objective Loss 2.822041                                        LR 0.000001    Time 0.228948    
2023-04-18 00:40:04,572 - Epoch: [368][  100/  518]    Overall Loss 2.834438    Objective Loss 2.834438                                        LR 0.000001    Time 0.222729    
2023-04-18 00:40:15,239 - Epoch: [368][  150/  518]    Overall Loss 2.827744    Objective Loss 2.827744                                        LR 0.000001    Time 0.219588    
2023-04-18 00:40:25,950 - Epoch: [368][  200/  518]    Overall Loss 2.827882    Objective Loss 2.827882                                        LR 0.000001    Time 0.218241    
2023-04-18 00:40:36,652 - Epoch: [368][  250/  518]    Overall Loss 2.831657    Objective Loss 2.831657                                        LR 0.000001    Time 0.217393    
2023-04-18 00:40:47,398 - Epoch: [368][  300/  518]    Overall Loss 2.833553    Objective Loss 2.833553                                        LR 0.000001    Time 0.216977    
2023-04-18 00:40:58,056 - Epoch: [368][  350/  518]    Overall Loss 2.829088    Objective Loss 2.829088                                        LR 0.000001    Time 0.216428    
2023-04-18 00:41:08,807 - Epoch: [368][  400/  518]    Overall Loss 2.834043    Objective Loss 2.834043                                        LR 0.000001    Time 0.216248    
2023-04-18 00:41:19,544 - Epoch: [368][  450/  518]    Overall Loss 2.836019    Objective Loss 2.836019                                        LR 0.000001    Time 0.216076    
2023-04-18 00:41:30,317 - Epoch: [368][  500/  518]    Overall Loss 2.837147    Objective Loss 2.837147                                        LR 0.000001    Time 0.216011    
2023-04-18 00:41:34,011 - Epoch: [368][  518/  518]    Overall Loss 2.834132    Objective Loss 2.834132                                        LR 0.000001    Time 0.215636    
2023-04-18 00:41:34,092 - --- validate (epoch=368)-----------
2023-04-18 00:41:34,092 - 4952 samples (32 per mini-batch)
2023-04-18 00:42:17,709 - Epoch: [368][   50/  155]    Loss 3.007624    mAP 0.529177    
2023-04-18 00:43:01,057 - Epoch: [368][  100/  155]    Loss 3.005442    mAP 0.533932    
2023-04-18 00:43:42,788 - Epoch: [368][  150/  155]    Loss 3.005746    mAP 0.533399    
2023-04-18 00:43:46,455 - Epoch: [368][  155/  155]    Loss 3.006364    mAP 0.532754    
2023-04-18 00:43:46,533 - ==> mAP: 0.53275    Loss: 3.006

2023-04-18 00:43:46,537 - ==> Best [mAP: 0.534820   vloss: 3.006499   Sparsity:0.00   Params: 2177088 on epoch: 365]
2023-04-18 00:43:46,537 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-18 00:43:46,572 - 

2023-04-18 00:43:46,572 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-18 00:43:58,184 - Epoch: [369][   50/  518]    Overall Loss 2.817240    Objective Loss 2.817240                                        LR 0.000001    Time 0.232184    
2023-04-18 00:44:08,869 - Epoch: [369][  100/  518]    Overall Loss 2.802497    Objective Loss 2.802497                                        LR 0.000001    Time 0.222933    
2023-04-18 00:44:19,631 - Epoch: [369][  150/  518]    Overall Loss 2.802136    Objective Loss 2.802136                                        LR 0.000001    Time 0.220355    
2023-04-18 00:44:30,340 - Epoch: [369][  200/  518]    Overall Loss 2.819456    Objective Loss 2.819456                                        LR 0.000001    Time 0.218807    
2023-04-18 00:44:41,174 - Epoch: [369][  250/  518]    Overall Loss 2.828470    Objective Loss 2.828470                                        LR 0.000001    Time 0.218372    
2023-04-18 00:44:51,940 - Epoch: [369][  300/  518]    Overall Loss 2.821401    Objective Loss 2.821401                                        LR 0.000001    Time 0.217858    
2023-04-18 00:45:02,778 - Epoch: [369][  350/  518]    Overall Loss 2.827914    Objective Loss 2.827914                                        LR 0.000001    Time 0.217700    
2023-04-18 00:45:13,519 - Epoch: [369][  400/  518]    Overall Loss 2.830322    Objective Loss 2.830322                                        LR 0.000001    Time 0.217335    
2023-04-18 00:45:24,264 - Epoch: [369][  450/  518]    Overall Loss 2.834454    Objective Loss 2.834454                                        LR 0.000001    Time 0.217062    
2023-04-18 00:45:35,101 - Epoch: [369][  500/  518]    Overall Loss 2.833121    Objective Loss 2.833121                                        LR 0.000001    Time 0.217026    
2023-04-18 00:45:38,827 - Epoch: [369][  518/  518]    Overall Loss 2.835294    Objective Loss 2.835294                                        LR 0.000001    Time 0.216677    
2023-04-18 00:45:38,909 - --- validate (epoch=369)-----------
2023-04-18 00:45:38,909 - 4952 samples (32 per mini-batch)
2023-04-18 00:46:21,797 - Epoch: [369][   50/  155]    Loss 3.008891    mAP 0.542139    
2023-04-18 00:47:02,359 - Epoch: [369][  100/  155]    Loss 2.991710    mAP 0.533698    
2023-04-18 00:47:44,444 - Epoch: [369][  150/  155]    Loss 3.004941    mAP 0.526293    
2023-04-18 00:47:48,409 - Epoch: [369][  155/  155]    Loss 3.000183    mAP 0.525628    
2023-04-18 00:47:48,489 - ==> mAP: 0.52563    Loss: 3.000

2023-04-18 00:47:48,493 - ==> Best [mAP: 0.534820   vloss: 3.006499   Sparsity:0.00   Params: 2177088 on epoch: 365]
2023-04-18 00:47:48,493 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-18 00:47:48,595 - 

2023-04-18 00:47:48,595 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-18 00:48:00,235 - Epoch: [370][   50/  518]    Overall Loss 2.864720    Objective Loss 2.864720                                        LR 0.000001    Time 0.232739    
2023-04-18 00:48:11,048 - Epoch: [370][  100/  518]    Overall Loss 2.846325    Objective Loss 2.846325                                        LR 0.000001    Time 0.224484    
2023-04-18 00:48:21,729 - Epoch: [370][  150/  518]    Overall Loss 2.836522    Objective Loss 2.836522                                        LR 0.000001    Time 0.220854    
2023-04-18 00:48:32,445 - Epoch: [370][  200/  518]    Overall Loss 2.831315    Objective Loss 2.831315                                        LR 0.000001    Time 0.219211    
2023-04-18 00:48:43,234 - Epoch: [370][  250/  518]    Overall Loss 2.839461    Objective Loss 2.839461                                        LR 0.000001    Time 0.218519    
2023-04-18 00:48:53,887 - Epoch: [370][  300/  518]    Overall Loss 2.839949    Objective Loss 2.839949                                        LR 0.000001    Time 0.217605    
2023-04-18 00:49:04,625 - Epoch: [370][  350/  518]    Overall Loss 2.838610    Objective Loss 2.838610                                        LR 0.000001    Time 0.217193    
2023-04-18 00:49:15,386 - Epoch: [370][  400/  518]    Overall Loss 2.838752    Objective Loss 2.838752                                        LR 0.000001    Time 0.216944    
2023-04-18 00:49:26,171 - Epoch: [370][  450/  518]    Overall Loss 2.838759    Objective Loss 2.838759                                        LR 0.000001    Time 0.216803    
2023-04-18 00:49:36,986 - Epoch: [370][  500/  518]    Overall Loss 2.836993    Objective Loss 2.836993                                        LR 0.000001    Time 0.216748    
2023-04-18 00:49:40,722 - Epoch: [370][  518/  518]    Overall Loss 2.836990    Objective Loss 2.836990                                        LR 0.000001    Time 0.216429    
2023-04-18 00:49:40,806 - --- validate (epoch=370)-----------
2023-04-18 00:49:40,806 - 4952 samples (32 per mini-batch)
2023-04-18 00:50:22,898 - Epoch: [370][   50/  155]    Loss 3.035686    mAP 0.519811    
2023-04-18 00:51:04,496 - Epoch: [370][  100/  155]    Loss 3.016901    mAP 0.531281    
2023-04-18 00:51:47,014 - Epoch: [370][  150/  155]    Loss 3.011641    mAP 0.533755    
2023-04-18 00:51:51,059 - Epoch: [370][  155/  155]    Loss 3.008965    mAP 0.534009    
2023-04-18 00:51:51,135 - ==> mAP: 0.53401    Loss: 3.009

2023-04-18 00:51:51,139 - ==> Best [mAP: 0.534820   vloss: 3.006499   Sparsity:0.00   Params: 2177088 on epoch: 365]
2023-04-18 00:51:51,139 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-18 00:51:51,172 - 

2023-04-18 00:51:51,172 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-18 00:52:02,582 - Epoch: [371][   50/  518]    Overall Loss 2.854159    Objective Loss 2.854159                                        LR 0.000001    Time 0.228135    
2023-04-18 00:52:13,287 - Epoch: [371][  100/  518]    Overall Loss 2.844130    Objective Loss 2.844130                                        LR 0.000001    Time 0.221104    
2023-04-18 00:52:23,972 - Epoch: [371][  150/  518]    Overall Loss 2.844415    Objective Loss 2.844415                                        LR 0.000001    Time 0.218623    
2023-04-18 00:52:34,587 - Epoch: [371][  200/  518]    Overall Loss 2.842766    Objective Loss 2.842766                                        LR 0.000001    Time 0.217039    
2023-04-18 00:52:45,312 - Epoch: [371][  250/  518]    Overall Loss 2.833870    Objective Loss 2.833870                                        LR 0.000001    Time 0.216524    
2023-04-18 00:52:56,067 - Epoch: [371][  300/  518]    Overall Loss 2.838524    Objective Loss 2.838524                                        LR 0.000001    Time 0.216282    
2023-04-18 00:53:06,718 - Epoch: [371][  350/  518]    Overall Loss 2.835261    Objective Loss 2.835261                                        LR 0.000001    Time 0.215812    
2023-04-18 00:53:17,490 - Epoch: [371][  400/  518]    Overall Loss 2.841527    Objective Loss 2.841527                                        LR 0.000001    Time 0.215761    
2023-04-18 00:53:28,282 - Epoch: [371][  450/  518]    Overall Loss 2.840117    Objective Loss 2.840117                                        LR 0.000001    Time 0.215767    
2023-04-18 00:53:38,997 - Epoch: [371][  500/  518]    Overall Loss 2.837195    Objective Loss 2.837195                                        LR 0.000001    Time 0.215616    
2023-04-18 00:53:42,693 - Epoch: [371][  518/  518]    Overall Loss 2.831642    Objective Loss 2.831642                                        LR 0.000001    Time 0.215259    
2023-04-18 00:53:42,773 - --- validate (epoch=371)-----------
2023-04-18 00:53:42,773 - 4952 samples (32 per mini-batch)
2023-04-18 00:54:27,054 - Epoch: [371][   50/  155]    Loss 3.015778    mAP 0.528148    
2023-04-18 00:55:10,161 - Epoch: [371][  100/  155]    Loss 3.022801    mAP 0.526670    
2023-04-18 00:55:53,382 - Epoch: [371][  150/  155]    Loss 3.013703    mAP 0.526536    
2023-04-18 00:55:57,455 - Epoch: [371][  155/  155]    Loss 3.012421    mAP 0.526480    
2023-04-18 00:55:57,527 - ==> mAP: 0.52648    Loss: 3.012

2023-04-18 00:55:57,531 - ==> Best [mAP: 0.534820   vloss: 3.006499   Sparsity:0.00   Params: 2177088 on epoch: 365]
2023-04-18 00:55:57,531 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-18 00:55:57,565 - 

2023-04-18 00:55:57,565 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-18 00:56:09,040 - Epoch: [372][   50/  518]    Overall Loss 2.822670    Objective Loss 2.822670                                        LR 0.000001    Time 0.229453    
2023-04-18 00:56:19,704 - Epoch: [372][  100/  518]    Overall Loss 2.841059    Objective Loss 2.841059                                        LR 0.000001    Time 0.221346    
2023-04-18 00:56:30,371 - Epoch: [372][  150/  518]    Overall Loss 2.833631    Objective Loss 2.833631                                        LR 0.000001    Time 0.218666    
2023-04-18 00:56:41,029 - Epoch: [372][  200/  518]    Overall Loss 2.840431    Objective Loss 2.840431                                        LR 0.000001    Time 0.217285    
2023-04-18 00:56:51,774 - Epoch: [372][  250/  518]    Overall Loss 2.836754    Objective Loss 2.836754                                        LR 0.000001    Time 0.216800    
2023-04-18 00:57:02,518 - Epoch: [372][  300/  518]    Overall Loss 2.831736    Objective Loss 2.831736                                        LR 0.000001    Time 0.216476    
2023-04-18 00:57:13,275 - Epoch: [372][  350/  518]    Overall Loss 2.836552    Objective Loss 2.836552                                        LR 0.000001    Time 0.216280    
2023-04-18 00:57:23,919 - Epoch: [372][  400/  518]    Overall Loss 2.835511    Objective Loss 2.835511                                        LR 0.000001    Time 0.215853    
2023-04-18 00:57:34,698 - Epoch: [372][  450/  518]    Overall Loss 2.837832    Objective Loss 2.837832                                        LR 0.000001    Time 0.215819    
2023-04-18 00:57:45,454 - Epoch: [372][  500/  518]    Overall Loss 2.834633    Objective Loss 2.834633                                        LR 0.000001    Time 0.215745    
2023-04-18 00:57:49,180 - Epoch: [372][  518/  518]    Overall Loss 2.833704    Objective Loss 2.833704                                        LR 0.000001    Time 0.215440    
2023-04-18 00:57:49,259 - --- validate (epoch=372)-----------
2023-04-18 00:57:49,259 - 4952 samples (32 per mini-batch)
2023-04-18 00:58:31,186 - Epoch: [372][   50/  155]    Loss 3.033487    mAP 0.518485    
2023-04-18 00:59:12,002 - Epoch: [372][  100/  155]    Loss 2.992694    mAP 0.532831    
2023-04-18 00:59:52,708 - Epoch: [372][  150/  155]    Loss 3.005514    mAP 0.528731    
2023-04-18 00:59:56,675 - Epoch: [372][  155/  155]    Loss 3.010214    mAP 0.528529    
2023-04-18 00:59:56,747 - ==> mAP: 0.52853    Loss: 3.010

2023-04-18 00:59:56,751 - ==> Best [mAP: 0.534820   vloss: 3.006499   Sparsity:0.00   Params: 2177088 on epoch: 365]
2023-04-18 00:59:56,751 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-18 00:59:56,785 - 

2023-04-18 00:59:56,785 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-18 01:00:08,421 - Epoch: [373][   50/  518]    Overall Loss 2.845789    Objective Loss 2.845789                                        LR 0.000001    Time 0.232680    
2023-04-18 01:00:19,174 - Epoch: [373][  100/  518]    Overall Loss 2.811070    Objective Loss 2.811070                                        LR 0.000001    Time 0.223854    
2023-04-18 01:00:29,808 - Epoch: [373][  150/  518]    Overall Loss 2.815532    Objective Loss 2.815532                                        LR 0.000001    Time 0.220115    
2023-04-18 01:00:40,472 - Epoch: [373][  200/  518]    Overall Loss 2.821284    Objective Loss 2.821284                                        LR 0.000001    Time 0.218400    
2023-04-18 01:00:51,338 - Epoch: [373][  250/  518]    Overall Loss 2.824516    Objective Loss 2.824516                                        LR 0.000001    Time 0.218176    
2023-04-18 01:01:02,059 - Epoch: [373][  300/  518]    Overall Loss 2.831189    Objective Loss 2.831189                                        LR 0.000001    Time 0.217545    
2023-04-18 01:01:12,787 - Epoch: [373][  350/  518]    Overall Loss 2.831328    Objective Loss 2.831328                                        LR 0.000001    Time 0.217116    
2023-04-18 01:01:23,542 - Epoch: [373][  400/  518]    Overall Loss 2.833569    Objective Loss 2.833569                                        LR 0.000001    Time 0.216860    
2023-04-18 01:01:34,266 - Epoch: [373][  450/  518]    Overall Loss 2.836149    Objective Loss 2.836149                                        LR 0.000001    Time 0.216591    
2023-04-18 01:01:45,064 - Epoch: [373][  500/  518]    Overall Loss 2.841187    Objective Loss 2.841187                                        LR 0.000001    Time 0.216525    
2023-04-18 01:01:48,769 - Epoch: [373][  518/  518]    Overall Loss 2.840322    Objective Loss 2.840322                                        LR 0.000001    Time 0.216152    
2023-04-18 01:01:48,849 - --- validate (epoch=373)-----------
2023-04-18 01:01:48,849 - 4952 samples (32 per mini-batch)
2023-04-18 01:02:31,132 - Epoch: [373][   50/  155]    Loss 3.045600    mAP 0.531592    
2023-04-18 01:03:11,750 - Epoch: [373][  100/  155]    Loss 3.020937    mAP 0.525083    
2023-04-18 01:03:53,847 - Epoch: [373][  150/  155]    Loss 3.013096    mAP 0.528952    
2023-04-18 01:03:57,352 - Epoch: [373][  155/  155]    Loss 3.012308    mAP 0.529541    
2023-04-18 01:03:57,429 - ==> mAP: 0.52954    Loss: 3.012

2023-04-18 01:03:57,435 - ==> Best [mAP: 0.534820   vloss: 3.006499   Sparsity:0.00   Params: 2177088 on epoch: 365]
2023-04-18 01:03:57,435 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-18 01:03:57,469 - 

2023-04-18 01:03:57,469 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-18 01:04:09,032 - Epoch: [374][   50/  518]    Overall Loss 2.869675    Objective Loss 2.869675                                        LR 0.000001    Time 0.231207    
2023-04-18 01:04:19,821 - Epoch: [374][  100/  518]    Overall Loss 2.862860    Objective Loss 2.862860                                        LR 0.000001    Time 0.223475    
2023-04-18 01:04:30,609 - Epoch: [374][  150/  518]    Overall Loss 2.857052    Objective Loss 2.857052                                        LR 0.000001    Time 0.220896    
2023-04-18 01:04:41,397 - Epoch: [374][  200/  518]    Overall Loss 2.841131    Objective Loss 2.841131                                        LR 0.000001    Time 0.219605    
2023-04-18 01:04:52,144 - Epoch: [374][  250/  518]    Overall Loss 2.833399    Objective Loss 2.833399                                        LR 0.000001    Time 0.218665    
2023-04-18 01:05:02,852 - Epoch: [374][  300/  518]    Overall Loss 2.826012    Objective Loss 2.826012                                        LR 0.000001    Time 0.217908    
2023-04-18 01:05:13,667 - Epoch: [374][  350/  518]    Overall Loss 2.830625    Objective Loss 2.830625                                        LR 0.000001    Time 0.217674    
2023-04-18 01:05:24,390 - Epoch: [374][  400/  518]    Overall Loss 2.832997    Objective Loss 2.832997                                        LR 0.000001    Time 0.217270    
2023-04-18 01:05:35,071 - Epoch: [374][  450/  518]    Overall Loss 2.833292    Objective Loss 2.833292                                        LR 0.000001    Time 0.216860    
2023-04-18 01:05:45,834 - Epoch: [374][  500/  518]    Overall Loss 2.827821    Objective Loss 2.827821                                        LR 0.000001    Time 0.216697    
2023-04-18 01:05:49,541 - Epoch: [374][  518/  518]    Overall Loss 2.825588    Objective Loss 2.825588                                        LR 0.000001    Time 0.216322    
2023-04-18 01:05:49,622 - --- validate (epoch=374)-----------
2023-04-18 01:05:49,622 - 4952 samples (32 per mini-batch)
2023-04-18 01:06:31,808 - Epoch: [374][   50/  155]    Loss 3.020954    mAP 0.529973    
2023-04-18 01:07:14,076 - Epoch: [374][  100/  155]    Loss 3.018042    mAP 0.529173    
2023-04-18 01:07:55,275 - Epoch: [374][  150/  155]    Loss 3.004426    mAP 0.527821    
2023-04-18 01:07:58,907 - Epoch: [374][  155/  155]    Loss 3.004727    mAP 0.526985    
2023-04-18 01:07:58,987 - ==> mAP: 0.52699    Loss: 3.005

2023-04-18 01:07:58,991 - ==> Best [mAP: 0.534820   vloss: 3.006499   Sparsity:0.00   Params: 2177088 on epoch: 365]
2023-04-18 01:07:58,991 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-18 01:07:59,025 - 

2023-04-18 01:07:59,025 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-18 01:08:10,682 - Epoch: [375][   50/  518]    Overall Loss 2.839676    Objective Loss 2.839676                                        LR 0.000001    Time 0.233090    
2023-04-18 01:08:21,422 - Epoch: [375][  100/  518]    Overall Loss 2.816776    Objective Loss 2.816776                                        LR 0.000001    Time 0.223931    
2023-04-18 01:08:32,217 - Epoch: [375][  150/  518]    Overall Loss 2.830628    Objective Loss 2.830628                                        LR 0.000001    Time 0.221245    
2023-04-18 01:08:42,924 - Epoch: [375][  200/  518]    Overall Loss 2.824054    Objective Loss 2.824054                                        LR 0.000001    Time 0.219461    
2023-04-18 01:08:53,609 - Epoch: [375][  250/  518]    Overall Loss 2.825238    Objective Loss 2.825238                                        LR 0.000001    Time 0.218302    
2023-04-18 01:09:04,376 - Epoch: [375][  300/  518]    Overall Loss 2.819843    Objective Loss 2.819843                                        LR 0.000001    Time 0.217804    
2023-04-18 01:09:15,135 - Epoch: [375][  350/  518]    Overall Loss 2.823591    Objective Loss 2.823591                                        LR 0.000001    Time 0.217423    
2023-04-18 01:09:25,932 - Epoch: [375][  400/  518]    Overall Loss 2.824517    Objective Loss 2.824517                                        LR 0.000001    Time 0.217234    
2023-04-18 01:09:36,708 - Epoch: [375][  450/  518]    Overall Loss 2.824552    Objective Loss 2.824552                                        LR 0.000001    Time 0.217042    
2023-04-18 01:09:47,456 - Epoch: [375][  500/  518]    Overall Loss 2.827802    Objective Loss 2.827802                                        LR 0.000001    Time 0.216829    
2023-04-18 01:09:51,198 - Epoch: [375][  518/  518]    Overall Loss 2.827846    Objective Loss 2.827846                                        LR 0.000001    Time 0.216518    
2023-04-18 01:09:51,277 - --- validate (epoch=375)-----------
2023-04-18 01:09:51,277 - 4952 samples (32 per mini-batch)
2023-04-18 01:10:32,688 - Epoch: [375][   50/  155]    Loss 3.002374    mAP 0.535967    
2023-04-18 01:11:12,074 - Epoch: [375][  100/  155]    Loss 3.021634    mAP 0.530052    
2023-04-18 01:11:52,574 - Epoch: [375][  150/  155]    Loss 3.016945    mAP 0.529012    
2023-04-18 01:11:56,414 - Epoch: [375][  155/  155]    Loss 3.017469    mAP 0.528171    
2023-04-18 01:11:56,487 - ==> mAP: 0.52817    Loss: 3.017

2023-04-18 01:11:56,491 - ==> Best [mAP: 0.534820   vloss: 3.006499   Sparsity:0.00   Params: 2177088 on epoch: 365]
2023-04-18 01:11:56,491 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-18 01:11:56,525 - 

2023-04-18 01:11:56,525 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-18 01:12:08,080 - Epoch: [376][   50/  518]    Overall Loss 2.872458    Objective Loss 2.872458                                        LR 0.000001    Time 0.231033    
2023-04-18 01:12:18,720 - Epoch: [376][  100/  518]    Overall Loss 2.860247    Objective Loss 2.860247                                        LR 0.000001    Time 0.221907    
2023-04-18 01:12:29,392 - Epoch: [376][  150/  518]    Overall Loss 2.845057    Objective Loss 2.845057                                        LR 0.000001    Time 0.219072    
2023-04-18 01:12:40,083 - Epoch: [376][  200/  518]    Overall Loss 2.836996    Objective Loss 2.836996                                        LR 0.000001    Time 0.217751    
2023-04-18 01:12:50,784 - Epoch: [376][  250/  518]    Overall Loss 2.829660    Objective Loss 2.829660                                        LR 0.000001    Time 0.217000    
2023-04-18 01:13:01,573 - Epoch: [376][  300/  518]    Overall Loss 2.828605    Objective Loss 2.828605                                        LR 0.000001    Time 0.216791    
2023-04-18 01:13:12,240 - Epoch: [376][  350/  518]    Overall Loss 2.827368    Objective Loss 2.827368                                        LR 0.000001    Time 0.216294    
2023-04-18 01:13:23,021 - Epoch: [376][  400/  518]    Overall Loss 2.826576    Objective Loss 2.826576                                        LR 0.000001    Time 0.216207    
2023-04-18 01:13:33,678 - Epoch: [376][  450/  518]    Overall Loss 2.829387    Objective Loss 2.829387                                        LR 0.000001    Time 0.215861    
2023-04-18 01:13:44,461 - Epoch: [376][  500/  518]    Overall Loss 2.832071    Objective Loss 2.832071                                        LR 0.000001    Time 0.215838    
2023-04-18 01:13:48,200 - Epoch: [376][  518/  518]    Overall Loss 2.833367    Objective Loss 2.833367                                        LR 0.000001    Time 0.215555    
2023-04-18 01:13:48,280 - --- validate (epoch=376)-----------
2023-04-18 01:13:48,281 - 4952 samples (32 per mini-batch)
2023-04-18 01:14:31,259 - Epoch: [376][   50/  155]    Loss 3.036420    mAP 0.529721    
2023-04-18 01:15:14,015 - Epoch: [376][  100/  155]    Loss 3.014792    mAP 0.527874    
2023-04-18 01:15:56,139 - Epoch: [376][  150/  155]    Loss 3.012175    mAP 0.524273    
2023-04-18 01:16:00,085 - Epoch: [376][  155/  155]    Loss 3.012455    mAP 0.525898    
2023-04-18 01:16:00,163 - ==> mAP: 0.52590    Loss: 3.012

2023-04-18 01:16:00,167 - ==> Best [mAP: 0.534820   vloss: 3.006499   Sparsity:0.00   Params: 2177088 on epoch: 365]
2023-04-18 01:16:00,167 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-18 01:16:00,201 - 

2023-04-18 01:16:00,201 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-18 01:16:11,753 - Epoch: [377][   50/  518]    Overall Loss 2.831266    Objective Loss 2.831266                                        LR 0.000001    Time 0.230997    
2023-04-18 01:16:22,514 - Epoch: [377][  100/  518]    Overall Loss 2.829268    Objective Loss 2.829268                                        LR 0.000001    Time 0.223095    
2023-04-18 01:16:33,290 - Epoch: [377][  150/  518]    Overall Loss 2.834751    Objective Loss 2.834751                                        LR 0.000001    Time 0.220555    
2023-04-18 01:16:43,982 - Epoch: [377][  200/  518]    Overall Loss 2.815187    Objective Loss 2.815187                                        LR 0.000001    Time 0.218870    
2023-04-18 01:16:54,739 - Epoch: [377][  250/  518]    Overall Loss 2.821772    Objective Loss 2.821772                                        LR 0.000001    Time 0.218117    
2023-04-18 01:17:05,522 - Epoch: [377][  300/  518]    Overall Loss 2.825943    Objective Loss 2.825943                                        LR 0.000001    Time 0.217704    
2023-04-18 01:17:16,316 - Epoch: [377][  350/  518]    Overall Loss 2.826769    Objective Loss 2.826769                                        LR 0.000001    Time 0.217440    
2023-04-18 01:17:27,049 - Epoch: [377][  400/  518]    Overall Loss 2.829157    Objective Loss 2.829157                                        LR 0.000001    Time 0.217088    
2023-04-18 01:17:37,653 - Epoch: [377][  450/  518]    Overall Loss 2.826948    Objective Loss 2.826948                                        LR 0.000001    Time 0.216528    
2023-04-18 01:17:48,368 - Epoch: [377][  500/  518]    Overall Loss 2.830922    Objective Loss 2.830922                                        LR 0.000001    Time 0.216302    
2023-04-18 01:17:52,128 - Epoch: [377][  518/  518]    Overall Loss 2.829803    Objective Loss 2.829803                                        LR 0.000001    Time 0.216044    
2023-04-18 01:17:52,211 - --- validate (epoch=377)-----------
2023-04-18 01:17:52,212 - 4952 samples (32 per mini-batch)
2023-04-18 01:18:35,869 - Epoch: [377][   50/  155]    Loss 3.021313    mAP 0.530819    
2023-04-18 01:19:18,201 - Epoch: [377][  100/  155]    Loss 3.040458    mAP 0.522631    
2023-04-18 01:19:59,640 - Epoch: [377][  150/  155]    Loss 3.013110    mAP 0.526718    
2023-04-18 01:20:03,435 - Epoch: [377][  155/  155]    Loss 3.010918    mAP 0.527366    
2023-04-18 01:20:03,513 - ==> mAP: 0.52737    Loss: 3.011

2023-04-18 01:20:03,517 - ==> Best [mAP: 0.534820   vloss: 3.006499   Sparsity:0.00   Params: 2177088 on epoch: 365]
2023-04-18 01:20:03,517 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-18 01:20:03,551 - 

2023-04-18 01:20:03,551 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-18 01:20:15,083 - Epoch: [378][   50/  518]    Overall Loss 2.808615    Objective Loss 2.808615                                        LR 0.000001    Time 0.230580    
2023-04-18 01:20:25,904 - Epoch: [378][  100/  518]    Overall Loss 2.805104    Objective Loss 2.805104                                        LR 0.000001    Time 0.223486    
2023-04-18 01:20:36,800 - Epoch: [378][  150/  518]    Overall Loss 2.811388    Objective Loss 2.811388                                        LR 0.000001    Time 0.221622    
2023-04-18 01:20:47,648 - Epoch: [378][  200/  518]    Overall Loss 2.823351    Objective Loss 2.823351                                        LR 0.000001    Time 0.220446    
2023-04-18 01:20:58,277 - Epoch: [378][  250/  518]    Overall Loss 2.823595    Objective Loss 2.823595                                        LR 0.000001    Time 0.218866    
2023-04-18 01:21:09,019 - Epoch: [378][  300/  518]    Overall Loss 2.824286    Objective Loss 2.824286                                        LR 0.000001    Time 0.218191    
2023-04-18 01:21:19,835 - Epoch: [378][  350/  518]    Overall Loss 2.827688    Objective Loss 2.827688                                        LR 0.000001    Time 0.217918    
2023-04-18 01:21:30,540 - Epoch: [378][  400/  518]    Overall Loss 2.826775    Objective Loss 2.826775                                        LR 0.000001    Time 0.217439    
2023-04-18 01:21:41,199 - Epoch: [378][  450/  518]    Overall Loss 2.825517    Objective Loss 2.825517                                        LR 0.000001    Time 0.216961    
2023-04-18 01:21:51,922 - Epoch: [378][  500/  518]    Overall Loss 2.828958    Objective Loss 2.828958                                        LR 0.000001    Time 0.216709    
2023-04-18 01:21:55,656 - Epoch: [378][  518/  518]    Overall Loss 2.833019    Objective Loss 2.833019                                        LR 0.000001    Time 0.216386    
2023-04-18 01:21:55,737 - --- validate (epoch=378)-----------
2023-04-18 01:21:55,738 - 4952 samples (32 per mini-batch)
2023-04-18 01:22:40,792 - Epoch: [378][   50/  155]    Loss 3.029256    mAP 0.511122    
2023-04-18 01:23:24,596 - Epoch: [378][  100/  155]    Loss 3.026459    mAP 0.521056    
2023-04-18 01:24:06,787 - Epoch: [378][  150/  155]    Loss 3.002110    mAP 0.528171    
2023-04-18 01:24:11,118 - Epoch: [378][  155/  155]    Loss 3.000576    mAP 0.527555    
2023-04-18 01:24:11,194 - ==> mAP: 0.52756    Loss: 3.001

2023-04-18 01:24:11,197 - ==> Best [mAP: 0.534820   vloss: 3.006499   Sparsity:0.00   Params: 2177088 on epoch: 365]
2023-04-18 01:24:11,197 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-18 01:24:11,232 - 

2023-04-18 01:24:11,232 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-18 01:24:22,772 - Epoch: [379][   50/  518]    Overall Loss 2.816489    Objective Loss 2.816489                                        LR 0.000001    Time 0.230736    
2023-04-18 01:24:33,445 - Epoch: [379][  100/  518]    Overall Loss 2.826028    Objective Loss 2.826028                                        LR 0.000001    Time 0.222086    
2023-04-18 01:24:44,130 - Epoch: [379][  150/  518]    Overall Loss 2.827911    Objective Loss 2.827911                                        LR 0.000001    Time 0.219278    
2023-04-18 01:24:54,851 - Epoch: [379][  200/  518]    Overall Loss 2.832348    Objective Loss 2.832348                                        LR 0.000001    Time 0.218058    
2023-04-18 01:25:05,654 - Epoch: [379][  250/  518]    Overall Loss 2.826093    Objective Loss 2.826093                                        LR 0.000001    Time 0.217653    
2023-04-18 01:25:16,449 - Epoch: [379][  300/  518]    Overall Loss 2.833424    Objective Loss 2.833424                                        LR 0.000001    Time 0.217354    
2023-04-18 01:25:27,215 - Epoch: [379][  350/  518]    Overall Loss 2.836367    Objective Loss 2.836367                                        LR 0.000001    Time 0.217061    
2023-04-18 01:25:37,905 - Epoch: [379][  400/  518]    Overall Loss 2.835791    Objective Loss 2.835791                                        LR 0.000001    Time 0.216648    
2023-04-18 01:25:48,675 - Epoch: [379][  450/  518]    Overall Loss 2.834239    Objective Loss 2.834239                                        LR 0.000001    Time 0.216507    
2023-04-18 01:25:59,425 - Epoch: [379][  500/  518]    Overall Loss 2.838688    Objective Loss 2.838688                                        LR 0.000001    Time 0.216353    
2023-04-18 01:26:03,133 - Epoch: [379][  518/  518]    Overall Loss 2.837180    Objective Loss 2.837180                                        LR 0.000001    Time 0.215992    
2023-04-18 01:26:03,213 - --- validate (epoch=379)-----------
2023-04-18 01:26:03,213 - 4952 samples (32 per mini-batch)
2023-04-18 01:26:46,671 - Epoch: [379][   50/  155]    Loss 3.015972    mAP 0.544139    
2023-04-18 01:27:29,628 - Epoch: [379][  100/  155]    Loss 2.983444    mAP 0.536023    
2023-04-18 01:28:12,028 - Epoch: [379][  150/  155]    Loss 3.001074    mAP 0.533103    
2023-04-18 01:28:15,779 - Epoch: [379][  155/  155]    Loss 3.001474    mAP 0.533124    
2023-04-18 01:28:15,854 - ==> mAP: 0.53312    Loss: 3.001

2023-04-18 01:28:15,858 - ==> Best [mAP: 0.534820   vloss: 3.006499   Sparsity:0.00   Params: 2177088 on epoch: 365]
2023-04-18 01:28:15,858 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-18 01:28:15,891 - 

2023-04-18 01:28:15,891 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-18 01:28:27,563 - Epoch: [380][   50/  518]    Overall Loss 2.809643    Objective Loss 2.809643                                        LR 0.000001    Time 0.233382    
2023-04-18 01:28:38,337 - Epoch: [380][  100/  518]    Overall Loss 2.798994    Objective Loss 2.798994                                        LR 0.000001    Time 0.224421    
2023-04-18 01:28:49,067 - Epoch: [380][  150/  518]    Overall Loss 2.809415    Objective Loss 2.809415                                        LR 0.000001    Time 0.221137    
2023-04-18 01:28:59,814 - Epoch: [380][  200/  518]    Overall Loss 2.814002    Objective Loss 2.814002                                        LR 0.000001    Time 0.219579    
2023-04-18 01:29:10,429 - Epoch: [380][  250/  518]    Overall Loss 2.810194    Objective Loss 2.810194                                        LR 0.000001    Time 0.218118    
2023-04-18 01:29:21,196 - Epoch: [380][  300/  518]    Overall Loss 2.815845    Objective Loss 2.815845                                        LR 0.000001    Time 0.217650    
2023-04-18 01:29:31,931 - Epoch: [380][  350/  518]    Overall Loss 2.815424    Objective Loss 2.815424                                        LR 0.000001    Time 0.217224    
2023-04-18 01:29:42,658 - Epoch: [380][  400/  518]    Overall Loss 2.821510    Objective Loss 2.821510                                        LR 0.000001    Time 0.216884    
2023-04-18 01:29:53,436 - Epoch: [380][  450/  518]    Overall Loss 2.826296    Objective Loss 2.826296                                        LR 0.000001    Time 0.216735    
2023-04-18 01:30:04,184 - Epoch: [380][  500/  518]    Overall Loss 2.822043    Objective Loss 2.822043                                        LR 0.000001    Time 0.216553    
2023-04-18 01:30:07,897 - Epoch: [380][  518/  518]    Overall Loss 2.823420    Objective Loss 2.823420                                        LR 0.000001    Time 0.216195    
2023-04-18 01:30:07,976 - --- validate (epoch=380)-----------
2023-04-18 01:30:07,976 - 4952 samples (32 per mini-batch)
2023-04-18 01:30:49,610 - Epoch: [380][   50/  155]    Loss 3.064528    mAP 0.533396    
2023-04-18 01:31:31,424 - Epoch: [380][  100/  155]    Loss 3.017201    mAP 0.530991    
2023-04-18 01:32:11,077 - Epoch: [380][  150/  155]    Loss 3.014039    mAP 0.523502    
2023-04-18 01:32:15,136 - Epoch: [380][  155/  155]    Loss 3.010381    mAP 0.523733    
2023-04-18 01:32:15,213 - ==> mAP: 0.52373    Loss: 3.010

2023-04-18 01:32:15,217 - ==> Best [mAP: 0.534820   vloss: 3.006499   Sparsity:0.00   Params: 2177088 on epoch: 365]
2023-04-18 01:32:15,217 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-18 01:32:15,251 - 

2023-04-18 01:32:15,252 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-18 01:32:26,723 - Epoch: [381][   50/  518]    Overall Loss 2.864588    Objective Loss 2.864588                                        LR 0.000001    Time 0.229382    
2023-04-18 01:32:37,486 - Epoch: [381][  100/  518]    Overall Loss 2.843117    Objective Loss 2.843117                                        LR 0.000001    Time 0.222306    
2023-04-18 01:32:48,186 - Epoch: [381][  150/  518]    Overall Loss 2.834769    Objective Loss 2.834769                                        LR 0.000001    Time 0.219521    
2023-04-18 01:32:58,814 - Epoch: [381][  200/  518]    Overall Loss 2.823275    Objective Loss 2.823275                                        LR 0.000001    Time 0.217775    
2023-04-18 01:33:09,507 - Epoch: [381][  250/  518]    Overall Loss 2.818773    Objective Loss 2.818773                                        LR 0.000001    Time 0.216986    
2023-04-18 01:33:20,197 - Epoch: [381][  300/  518]    Overall Loss 2.823331    Objective Loss 2.823331                                        LR 0.000001    Time 0.216451    
2023-04-18 01:33:30,992 - Epoch: [381][  350/  518]    Overall Loss 2.823062    Objective Loss 2.823062                                        LR 0.000001    Time 0.216368    
2023-04-18 01:33:41,679 - Epoch: [381][  400/  518]    Overall Loss 2.818947    Objective Loss 2.818947                                        LR 0.000001    Time 0.216035    
2023-04-18 01:33:52,409 - Epoch: [381][  450/  518]    Overall Loss 2.822079    Objective Loss 2.822079                                        LR 0.000001    Time 0.215871    
2023-04-18 01:34:03,174 - Epoch: [381][  500/  518]    Overall Loss 2.823475    Objective Loss 2.823475                                        LR 0.000001    Time 0.215812    
2023-04-18 01:34:06,866 - Epoch: [381][  518/  518]    Overall Loss 2.823614    Objective Loss 2.823614                                        LR 0.000001    Time 0.215439    
2023-04-18 01:34:06,948 - --- validate (epoch=381)-----------
2023-04-18 01:34:06,948 - 4952 samples (32 per mini-batch)
2023-04-18 01:34:49,369 - Epoch: [381][   50/  155]    Loss 2.996993    mAP 0.533805    
2023-04-18 01:35:33,155 - Epoch: [381][  100/  155]    Loss 3.011832    mAP 0.525912    
2023-04-18 01:36:13,606 - Epoch: [381][  150/  155]    Loss 3.007318    mAP 0.532061    
2023-04-18 01:36:17,216 - Epoch: [381][  155/  155]    Loss 3.007365    mAP 0.530982    
2023-04-18 01:36:17,290 - ==> mAP: 0.53098    Loss: 3.007

2023-04-18 01:36:17,294 - ==> Best [mAP: 0.534820   vloss: 3.006499   Sparsity:0.00   Params: 2177088 on epoch: 365]
2023-04-18 01:36:17,294 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-18 01:36:17,348 - 

2023-04-18 01:36:17,348 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-18 01:36:28,913 - Epoch: [382][   50/  518]    Overall Loss 2.840569    Objective Loss 2.840569                                        LR 0.000001    Time 0.231226    
2023-04-18 01:36:39,519 - Epoch: [382][  100/  518]    Overall Loss 2.856933    Objective Loss 2.856933                                        LR 0.000001    Time 0.221663    
2023-04-18 01:36:50,233 - Epoch: [382][  150/  518]    Overall Loss 2.836384    Objective Loss 2.836384                                        LR 0.000001    Time 0.219186    
2023-04-18 01:37:01,192 - Epoch: [382][  200/  518]    Overall Loss 2.825573    Objective Loss 2.825573                                        LR 0.000001    Time 0.219178    
2023-04-18 01:37:11,945 - Epoch: [382][  250/  518]    Overall Loss 2.821302    Objective Loss 2.821302                                        LR 0.000001    Time 0.218348    
2023-04-18 01:37:22,703 - Epoch: [382][  300/  518]    Overall Loss 2.828029    Objective Loss 2.828029                                        LR 0.000001    Time 0.217814    
2023-04-18 01:37:33,367 - Epoch: [382][  350/  518]    Overall Loss 2.826730    Objective Loss 2.826730                                        LR 0.000001    Time 0.217159    
2023-04-18 01:37:44,097 - Epoch: [382][  400/  518]    Overall Loss 2.825535    Objective Loss 2.825535                                        LR 0.000001    Time 0.216836    
2023-04-18 01:37:54,831 - Epoch: [382][  450/  518]    Overall Loss 2.823273    Objective Loss 2.823273                                        LR 0.000001    Time 0.216593    
2023-04-18 01:38:05,601 - Epoch: [382][  500/  518]    Overall Loss 2.820557    Objective Loss 2.820557                                        LR 0.000001    Time 0.216472    
2023-04-18 01:38:09,337 - Epoch: [382][  518/  518]    Overall Loss 2.819728    Objective Loss 2.819728                                        LR 0.000001    Time 0.216160    
2023-04-18 01:38:09,417 - --- validate (epoch=382)-----------
2023-04-18 01:38:09,417 - 4952 samples (32 per mini-batch)
2023-04-18 01:38:51,894 - Epoch: [382][   50/  155]    Loss 2.997325    mAP 0.547358    
2023-04-18 01:39:33,804 - Epoch: [382][  100/  155]    Loss 3.011102    mAP 0.525725    
2023-04-18 01:40:15,200 - Epoch: [382][  150/  155]    Loss 3.003085    mAP 0.525819    
2023-04-18 01:40:19,202 - Epoch: [382][  155/  155]    Loss 3.001333    mAP 0.525214    
2023-04-18 01:40:19,284 - ==> mAP: 0.52521    Loss: 3.001

2023-04-18 01:40:19,288 - ==> Best [mAP: 0.534820   vloss: 3.006499   Sparsity:0.00   Params: 2177088 on epoch: 365]
2023-04-18 01:40:19,288 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-18 01:40:19,323 - 

2023-04-18 01:40:19,323 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-18 01:40:30,781 - Epoch: [383][   50/  518]    Overall Loss 2.855414    Objective Loss 2.855414                                        LR 0.000001    Time 0.229105    
2023-04-18 01:40:41,556 - Epoch: [383][  100/  518]    Overall Loss 2.809321    Objective Loss 2.809321                                        LR 0.000001    Time 0.222288    
2023-04-18 01:40:52,344 - Epoch: [383][  150/  518]    Overall Loss 2.802030    Objective Loss 2.802030                                        LR 0.000001    Time 0.220103    
2023-04-18 01:41:03,131 - Epoch: [383][  200/  518]    Overall Loss 2.805462    Objective Loss 2.805462                                        LR 0.000001    Time 0.219005    
2023-04-18 01:41:13,934 - Epoch: [383][  250/  518]    Overall Loss 2.818864    Objective Loss 2.818864                                        LR 0.000001    Time 0.218407    
2023-04-18 01:41:24,713 - Epoch: [383][  300/  518]    Overall Loss 2.828441    Objective Loss 2.828441                                        LR 0.000001    Time 0.217933    
2023-04-18 01:41:35,516 - Epoch: [383][  350/  518]    Overall Loss 2.827020    Objective Loss 2.827020                                        LR 0.000001    Time 0.217661    
2023-04-18 01:41:46,373 - Epoch: [383][  400/  518]    Overall Loss 2.832696    Objective Loss 2.832696                                        LR 0.000001    Time 0.217593    
2023-04-18 01:41:57,091 - Epoch: [383][  450/  518]    Overall Loss 2.827943    Objective Loss 2.827943                                        LR 0.000001    Time 0.217229    
2023-04-18 01:42:07,828 - Epoch: [383][  500/  518]    Overall Loss 2.831506    Objective Loss 2.831506                                        LR 0.000001    Time 0.216977    
2023-04-18 01:42:11,494 - Epoch: [383][  518/  518]    Overall Loss 2.830978    Objective Loss 2.830978                                        LR 0.000001    Time 0.216514    
2023-04-18 01:42:11,573 - --- validate (epoch=383)-----------
2023-04-18 01:42:11,574 - 4952 samples (32 per mini-batch)
2023-04-18 01:42:55,578 - Epoch: [383][   50/  155]    Loss 2.986109    mAP 0.555697    
2023-04-18 01:43:38,107 - Epoch: [383][  100/  155]    Loss 3.001631    mAP 0.543117    
2023-04-18 01:44:20,942 - Epoch: [383][  150/  155]    Loss 3.013218    mAP 0.530992    
2023-04-18 01:44:25,231 - Epoch: [383][  155/  155]    Loss 3.012539    mAP 0.531634    
2023-04-18 01:44:25,303 - ==> mAP: 0.53163    Loss: 3.013

2023-04-18 01:44:25,307 - ==> Best [mAP: 0.534820   vloss: 3.006499   Sparsity:0.00   Params: 2177088 on epoch: 365]
2023-04-18 01:44:25,307 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-18 01:44:25,341 - 

2023-04-18 01:44:25,341 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-18 01:44:36,965 - Epoch: [384][   50/  518]    Overall Loss 2.805461    Objective Loss 2.805461                                        LR 0.000001    Time 0.232430    
2023-04-18 01:44:47,656 - Epoch: [384][  100/  518]    Overall Loss 2.807273    Objective Loss 2.807273                                        LR 0.000001    Time 0.223110    
2023-04-18 01:44:58,490 - Epoch: [384][  150/  518]    Overall Loss 2.818520    Objective Loss 2.818520                                        LR 0.000001    Time 0.220958    
2023-04-18 01:45:09,159 - Epoch: [384][  200/  518]    Overall Loss 2.806466    Objective Loss 2.806466                                        LR 0.000001    Time 0.219052    
2023-04-18 01:45:19,813 - Epoch: [384][  250/  518]    Overall Loss 2.806769    Objective Loss 2.806769                                        LR 0.000001    Time 0.217852    
2023-04-18 01:45:30,576 - Epoch: [384][  300/  518]    Overall Loss 2.813181    Objective Loss 2.813181                                        LR 0.000001    Time 0.217415    
2023-04-18 01:45:41,306 - Epoch: [384][  350/  518]    Overall Loss 2.817379    Objective Loss 2.817379                                        LR 0.000001    Time 0.217009    
2023-04-18 01:45:52,052 - Epoch: [384][  400/  518]    Overall Loss 2.815785    Objective Loss 2.815785                                        LR 0.000001    Time 0.216745    
2023-04-18 01:46:02,710 - Epoch: [384][  450/  518]    Overall Loss 2.816885    Objective Loss 2.816885                                        LR 0.000001    Time 0.216344    
2023-04-18 01:46:13,460 - Epoch: [384][  500/  518]    Overall Loss 2.821804    Objective Loss 2.821804                                        LR 0.000001    Time 0.216206    
2023-04-18 01:46:17,191 - Epoch: [384][  518/  518]    Overall Loss 2.821273    Objective Loss 2.821273                                        LR 0.000001    Time 0.215895    
2023-04-18 01:46:17,272 - --- validate (epoch=384)-----------
2023-04-18 01:46:17,272 - 4952 samples (32 per mini-batch)
2023-04-18 01:47:00,458 - Epoch: [384][   50/  155]    Loss 3.041087    mAP 0.527865    
2023-04-18 01:47:42,978 - Epoch: [384][  100/  155]    Loss 3.018931    mAP 0.522233    
2023-04-18 01:48:23,936 - Epoch: [384][  150/  155]    Loss 3.006275    mAP 0.530090    
2023-04-18 01:48:28,022 - Epoch: [384][  155/  155]    Loss 3.004620    mAP 0.530316    
2023-04-18 01:48:28,101 - ==> mAP: 0.53032    Loss: 3.005

2023-04-18 01:48:28,105 - ==> Best [mAP: 0.534820   vloss: 3.006499   Sparsity:0.00   Params: 2177088 on epoch: 365]
2023-04-18 01:48:28,105 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-18 01:48:28,140 - 

2023-04-18 01:48:28,140 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-18 01:48:39,661 - Epoch: [385][   50/  518]    Overall Loss 2.858129    Objective Loss 2.858129                                        LR 0.000001    Time 0.230363    
2023-04-18 01:48:50,310 - Epoch: [385][  100/  518]    Overall Loss 2.836304    Objective Loss 2.836304                                        LR 0.000001    Time 0.221652    
2023-04-18 01:49:00,985 - Epoch: [385][  150/  518]    Overall Loss 2.826913    Objective Loss 2.826913                                        LR 0.000001    Time 0.218929    
2023-04-18 01:49:11,858 - Epoch: [385][  200/  518]    Overall Loss 2.830498    Objective Loss 2.830498                                        LR 0.000001    Time 0.218553    
2023-04-18 01:49:22,554 - Epoch: [385][  250/  518]    Overall Loss 2.816897    Objective Loss 2.816897                                        LR 0.000001    Time 0.217619    
2023-04-18 01:49:33,305 - Epoch: [385][  300/  518]    Overall Loss 2.825679    Objective Loss 2.825679                                        LR 0.000001    Time 0.217182    
2023-04-18 01:49:43,926 - Epoch: [385][  350/  518]    Overall Loss 2.826603    Objective Loss 2.826603                                        LR 0.000001    Time 0.216498    
2023-04-18 01:49:54,634 - Epoch: [385][  400/  518]    Overall Loss 2.828921    Objective Loss 2.828921                                        LR 0.000001    Time 0.216201    
2023-04-18 01:50:05,357 - Epoch: [385][  450/  518]    Overall Loss 2.825874    Objective Loss 2.825874                                        LR 0.000001    Time 0.216005    
2023-04-18 01:50:16,162 - Epoch: [385][  500/  518]    Overall Loss 2.827541    Objective Loss 2.827541                                        LR 0.000001    Time 0.216011    
2023-04-18 01:50:19,884 - Epoch: [385][  518/  518]    Overall Loss 2.828494    Objective Loss 2.828494                                        LR 0.000001    Time 0.215689    
2023-04-18 01:50:19,964 - --- validate (epoch=385)-----------
2023-04-18 01:50:19,964 - 4952 samples (32 per mini-batch)
2023-04-18 01:51:02,731 - Epoch: [385][   50/  155]    Loss 2.995195    mAP 0.528936    
2023-04-18 01:51:46,000 - Epoch: [385][  100/  155]    Loss 3.012231    mAP 0.533226    
2023-04-18 01:52:28,975 - Epoch: [385][  150/  155]    Loss 3.012192    mAP 0.529872    
2023-04-18 01:52:32,786 - Epoch: [385][  155/  155]    Loss 3.008796    mAP 0.528142    
2023-04-18 01:52:32,866 - ==> mAP: 0.52814    Loss: 3.009

2023-04-18 01:52:32,869 - ==> Best [mAP: 0.534820   vloss: 3.006499   Sparsity:0.00   Params: 2177088 on epoch: 365]
2023-04-18 01:52:32,869 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-18 01:52:32,903 - 

2023-04-18 01:52:32,904 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-18 01:52:44,356 - Epoch: [386][   50/  518]    Overall Loss 2.826158    Objective Loss 2.826158                                        LR 0.000001    Time 0.228992    
2023-04-18 01:52:55,113 - Epoch: [386][  100/  518]    Overall Loss 2.804904    Objective Loss 2.804904                                        LR 0.000001    Time 0.222047    
2023-04-18 01:53:05,906 - Epoch: [386][  150/  518]    Overall Loss 2.801152    Objective Loss 2.801152                                        LR 0.000001    Time 0.219977    
2023-04-18 01:53:16,630 - Epoch: [386][  200/  518]    Overall Loss 2.793460    Objective Loss 2.793460                                        LR 0.000001    Time 0.218596    
2023-04-18 01:53:27,473 - Epoch: [386][  250/  518]    Overall Loss 2.807320    Objective Loss 2.807320                                        LR 0.000001    Time 0.218240    
2023-04-18 01:53:38,256 - Epoch: [386][  300/  518]    Overall Loss 2.804683    Objective Loss 2.804683                                        LR 0.000001    Time 0.217806    
2023-04-18 01:53:49,037 - Epoch: [386][  350/  518]    Overall Loss 2.806672    Objective Loss 2.806672                                        LR 0.000001    Time 0.217489    
2023-04-18 01:53:59,733 - Epoch: [386][  400/  518]    Overall Loss 2.802988    Objective Loss 2.802988                                        LR 0.000001    Time 0.217041    
2023-04-18 01:54:10,476 - Epoch: [386][  450/  518]    Overall Loss 2.803990    Objective Loss 2.803990                                        LR 0.000001    Time 0.216795    
2023-04-18 01:54:21,199 - Epoch: [386][  500/  518]    Overall Loss 2.808157    Objective Loss 2.808157                                        LR 0.000001    Time 0.216558    
2023-04-18 01:54:24,977 - Epoch: [386][  518/  518]    Overall Loss 2.806925    Objective Loss 2.806925                                        LR 0.000001    Time 0.216324    
2023-04-18 01:54:25,056 - --- validate (epoch=386)-----------
2023-04-18 01:54:25,057 - 4952 samples (32 per mini-batch)
2023-04-18 01:55:07,706 - Epoch: [386][   50/  155]    Loss 2.980566    mAP 0.540495    
2023-04-18 01:55:50,155 - Epoch: [386][  100/  155]    Loss 2.972137    mAP 0.531088    
2023-04-18 01:56:33,177 - Epoch: [386][  150/  155]    Loss 3.006022    mAP 0.525299    
2023-04-18 01:56:37,121 - Epoch: [386][  155/  155]    Loss 3.008311    mAP 0.523602    
2023-04-18 01:56:37,200 - ==> mAP: 0.52360    Loss: 3.008

2023-04-18 01:56:37,204 - ==> Best [mAP: 0.534820   vloss: 3.006499   Sparsity:0.00   Params: 2177088 on epoch: 365]
2023-04-18 01:56:37,204 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-18 01:56:37,239 - 

2023-04-18 01:56:37,239 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-18 01:56:48,651 - Epoch: [387][   50/  518]    Overall Loss 2.762813    Objective Loss 2.762813                                        LR 0.000001    Time 0.228188    
2023-04-18 01:56:59,311 - Epoch: [387][  100/  518]    Overall Loss 2.797789    Objective Loss 2.797789                                        LR 0.000001    Time 0.220677    
2023-04-18 01:57:10,027 - Epoch: [387][  150/  518]    Overall Loss 2.803406    Objective Loss 2.803406                                        LR 0.000001    Time 0.218548    
2023-04-18 01:57:20,763 - Epoch: [387][  200/  518]    Overall Loss 2.815347    Objective Loss 2.815347                                        LR 0.000001    Time 0.217584    
2023-04-18 01:57:31,559 - Epoch: [387][  250/  518]    Overall Loss 2.818437    Objective Loss 2.818437                                        LR 0.000001    Time 0.217242    
2023-04-18 01:57:42,329 - Epoch: [387][  300/  518]    Overall Loss 2.823280    Objective Loss 2.823280                                        LR 0.000001    Time 0.216931    
2023-04-18 01:57:53,091 - Epoch: [387][  350/  518]    Overall Loss 2.823627    Objective Loss 2.823627                                        LR 0.000001    Time 0.216687    
2023-04-18 01:58:03,772 - Epoch: [387][  400/  518]    Overall Loss 2.825927    Objective Loss 2.825927                                        LR 0.000001    Time 0.216300    
2023-04-18 01:58:14,500 - Epoch: [387][  450/  518]    Overall Loss 2.822118    Objective Loss 2.822118                                        LR 0.000001    Time 0.216102    
2023-04-18 01:58:25,193 - Epoch: [387][  500/  518]    Overall Loss 2.826314    Objective Loss 2.826314                                        LR 0.000001    Time 0.215875    
2023-04-18 01:58:28,938 - Epoch: [387][  518/  518]    Overall Loss 2.826985    Objective Loss 2.826985                                        LR 0.000001    Time 0.215601    
2023-04-18 01:58:29,017 - --- validate (epoch=387)-----------
2023-04-18 01:58:29,018 - 4952 samples (32 per mini-batch)
2023-04-18 01:59:12,738 - Epoch: [387][   50/  155]    Loss 3.011223    mAP 0.529473    
2023-04-18 01:59:54,150 - Epoch: [387][  100/  155]    Loss 2.993125    mAP 0.524813    
2023-04-18 02:00:35,472 - Epoch: [387][  150/  155]    Loss 2.993250    mAP 0.529729    
2023-04-18 02:00:38,880 - Epoch: [387][  155/  155]    Loss 3.000130    mAP 0.529136    
2023-04-18 02:00:38,955 - ==> mAP: 0.52914    Loss: 3.000

2023-04-18 02:00:38,958 - ==> Best [mAP: 0.534820   vloss: 3.006499   Sparsity:0.00   Params: 2177088 on epoch: 365]
2023-04-18 02:00:38,959 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-18 02:00:38,992 - 

2023-04-18 02:00:38,993 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-18 02:00:50,421 - Epoch: [388][   50/  518]    Overall Loss 2.875526    Objective Loss 2.875526                                        LR 0.000001    Time 0.228507    
2023-04-18 02:01:01,073 - Epoch: [388][  100/  518]    Overall Loss 2.866286    Objective Loss 2.866286                                        LR 0.000001    Time 0.220764    
2023-04-18 02:01:11,838 - Epoch: [388][  150/  518]    Overall Loss 2.851332    Objective Loss 2.851332                                        LR 0.000001    Time 0.218932    
2023-04-18 02:01:22,504 - Epoch: [388][  200/  518]    Overall Loss 2.843384    Objective Loss 2.843384                                        LR 0.000001    Time 0.217519    
2023-04-18 02:01:33,294 - Epoch: [388][  250/  518]    Overall Loss 2.839990    Objective Loss 2.839990                                        LR 0.000001    Time 0.217170    
2023-04-18 02:01:44,033 - Epoch: [388][  300/  518]    Overall Loss 2.830364    Objective Loss 2.830364                                        LR 0.000001    Time 0.216766    
2023-04-18 02:01:54,771 - Epoch: [388][  350/  518]    Overall Loss 2.825293    Objective Loss 2.825293                                        LR 0.000001    Time 0.216477    
2023-04-18 02:02:05,456 - Epoch: [388][  400/  518]    Overall Loss 2.829615    Objective Loss 2.829615                                        LR 0.000001    Time 0.216126    
2023-04-18 02:02:16,230 - Epoch: [388][  450/  518]    Overall Loss 2.832100    Objective Loss 2.832100                                        LR 0.000001    Time 0.216050    
2023-04-18 02:02:26,974 - Epoch: [388][  500/  518]    Overall Loss 2.833161    Objective Loss 2.833161                                        LR 0.000001    Time 0.215929    
2023-04-18 02:02:30,700 - Epoch: [388][  518/  518]    Overall Loss 2.832593    Objective Loss 2.832593                                        LR 0.000001    Time 0.215618    
2023-04-18 02:02:30,778 - --- validate (epoch=388)-----------
2023-04-18 02:02:30,779 - 4952 samples (32 per mini-batch)
2023-04-18 02:03:11,369 - Epoch: [388][   50/  155]    Loss 2.978415    mAP 0.523310    
2023-04-18 02:03:54,204 - Epoch: [388][  100/  155]    Loss 2.994006    mAP 0.529901    
2023-04-18 02:04:36,204 - Epoch: [388][  150/  155]    Loss 3.011416    mAP 0.525103    
2023-04-18 02:04:40,002 - Epoch: [388][  155/  155]    Loss 3.010421    mAP 0.524688    
2023-04-18 02:04:40,077 - ==> mAP: 0.52469    Loss: 3.010

2023-04-18 02:04:40,080 - ==> Best [mAP: 0.534820   vloss: 3.006499   Sparsity:0.00   Params: 2177088 on epoch: 365]
2023-04-18 02:04:40,080 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-18 02:04:40,114 - 

2023-04-18 02:04:40,114 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-18 02:04:51,705 - Epoch: [389][   50/  518]    Overall Loss 2.759540    Objective Loss 2.759540                                        LR 0.000001    Time 0.231760    
2023-04-18 02:05:02,412 - Epoch: [389][  100/  518]    Overall Loss 2.770933    Objective Loss 2.770933                                        LR 0.000001    Time 0.222935    
2023-04-18 02:05:13,053 - Epoch: [389][  150/  518]    Overall Loss 2.791590    Objective Loss 2.791590                                        LR 0.000001    Time 0.219552    
2023-04-18 02:05:23,806 - Epoch: [389][  200/  518]    Overall Loss 2.804935    Objective Loss 2.804935                                        LR 0.000001    Time 0.218423    
2023-04-18 02:05:34,457 - Epoch: [389][  250/  518]    Overall Loss 2.818040    Objective Loss 2.818040                                        LR 0.000001    Time 0.217335    
2023-04-18 02:05:45,170 - Epoch: [389][  300/  518]    Overall Loss 2.828166    Objective Loss 2.828166                                        LR 0.000001    Time 0.216818    
2023-04-18 02:05:55,863 - Epoch: [389][  350/  518]    Overall Loss 2.828618    Objective Loss 2.828618                                        LR 0.000001    Time 0.216392    
2023-04-18 02:06:06,542 - Epoch: [389][  400/  518]    Overall Loss 2.833393    Objective Loss 2.833393                                        LR 0.000001    Time 0.216036    
2023-04-18 02:06:17,281 - Epoch: [389][  450/  518]    Overall Loss 2.832668    Objective Loss 2.832668                                        LR 0.000001    Time 0.215892    
2023-04-18 02:06:27,923 - Epoch: [389][  500/  518]    Overall Loss 2.830802    Objective Loss 2.830802                                        LR 0.000001    Time 0.215585    
2023-04-18 02:06:31,677 - Epoch: [389][  518/  518]    Overall Loss 2.829921    Objective Loss 2.829921                                        LR 0.000001    Time 0.215339    
2023-04-18 02:06:31,756 - --- validate (epoch=389)-----------
2023-04-18 02:06:31,756 - 4952 samples (32 per mini-batch)
2023-04-18 02:07:15,420 - Epoch: [389][   50/  155]    Loss 2.998158    mAP 0.521145    
2023-04-18 02:07:59,436 - Epoch: [389][  100/  155]    Loss 2.987156    mAP 0.534713    
2023-04-18 02:08:42,667 - Epoch: [389][  150/  155]    Loss 2.998187    mAP 0.531061    
2023-04-18 02:08:46,517 - Epoch: [389][  155/  155]    Loss 3.001360    mAP 0.530865    
2023-04-18 02:08:46,596 - ==> mAP: 0.53087    Loss: 3.001

2023-04-18 02:08:46,600 - ==> Best [mAP: 0.534820   vloss: 3.006499   Sparsity:0.00   Params: 2177088 on epoch: 365]
2023-04-18 02:08:46,600 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-18 02:08:46,634 - 

2023-04-18 02:08:46,634 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-18 02:08:58,115 - Epoch: [390][   50/  518]    Overall Loss 2.845944    Objective Loss 2.845944                                        LR 0.000001    Time 0.229568    
2023-04-18 02:09:08,887 - Epoch: [390][  100/  518]    Overall Loss 2.840644    Objective Loss 2.840644                                        LR 0.000001    Time 0.222489    
2023-04-18 02:09:19,691 - Epoch: [390][  150/  518]    Overall Loss 2.827097    Objective Loss 2.827097                                        LR 0.000001    Time 0.220339    
2023-04-18 02:09:30,417 - Epoch: [390][  200/  518]    Overall Loss 2.818231    Objective Loss 2.818231                                        LR 0.000001    Time 0.218879    
2023-04-18 02:09:41,188 - Epoch: [390][  250/  518]    Overall Loss 2.822195    Objective Loss 2.822195                                        LR 0.000001    Time 0.218182    
2023-04-18 02:09:51,929 - Epoch: [390][  300/  518]    Overall Loss 2.821096    Objective Loss 2.821096                                        LR 0.000001    Time 0.217617    
2023-04-18 02:10:02,684 - Epoch: [390][  350/  518]    Overall Loss 2.815663    Objective Loss 2.815663                                        LR 0.000001    Time 0.217252    
2023-04-18 02:10:13,407 - Epoch: [390][  400/  518]    Overall Loss 2.822560    Objective Loss 2.822560                                        LR 0.000001    Time 0.216898    
2023-04-18 02:10:24,066 - Epoch: [390][  450/  518]    Overall Loss 2.828662    Objective Loss 2.828662                                        LR 0.000001    Time 0.216483    
2023-04-18 02:10:34,686 - Epoch: [390][  500/  518]    Overall Loss 2.829502    Objective Loss 2.829502                                        LR 0.000001    Time 0.216071    
2023-04-18 02:10:38,393 - Epoch: [390][  518/  518]    Overall Loss 2.831569    Objective Loss 2.831569                                        LR 0.000001    Time 0.215718    
2023-04-18 02:10:38,474 - --- validate (epoch=390)-----------
2023-04-18 02:10:38,475 - 4952 samples (32 per mini-batch)
2023-04-18 02:11:19,590 - Epoch: [390][   50/  155]    Loss 3.064651    mAP 0.519810    
2023-04-18 02:11:59,922 - Epoch: [390][  100/  155]    Loss 3.047050    mAP 0.518775    
2023-04-18 02:12:40,637 - Epoch: [390][  150/  155]    Loss 3.007680    mAP 0.527472    
2023-04-18 02:12:44,455 - Epoch: [390][  155/  155]    Loss 3.006615    mAP 0.528897    
2023-04-18 02:12:44,534 - ==> mAP: 0.52890    Loss: 3.007

2023-04-18 02:12:44,538 - ==> Best [mAP: 0.534820   vloss: 3.006499   Sparsity:0.00   Params: 2177088 on epoch: 365]
2023-04-18 02:12:44,538 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-18 02:12:44,572 - 

2023-04-18 02:12:44,572 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-18 02:12:56,150 - Epoch: [391][   50/  518]    Overall Loss 2.798391    Objective Loss 2.798391                                        LR 0.000001    Time 0.231507    
2023-04-18 02:13:06,844 - Epoch: [391][  100/  518]    Overall Loss 2.820724    Objective Loss 2.820724                                        LR 0.000001    Time 0.222670    
2023-04-18 02:13:17,565 - Epoch: [391][  150/  518]    Overall Loss 2.817249    Objective Loss 2.817249                                        LR 0.000001    Time 0.219912    
2023-04-18 02:13:28,265 - Epoch: [391][  200/  518]    Overall Loss 2.815943    Objective Loss 2.815943                                        LR 0.000001    Time 0.218428    
2023-04-18 02:13:38,990 - Epoch: [391][  250/  518]    Overall Loss 2.817945    Objective Loss 2.817945                                        LR 0.000001    Time 0.217635    
2023-04-18 02:13:49,775 - Epoch: [391][  300/  518]    Overall Loss 2.827620    Objective Loss 2.827620                                        LR 0.000001    Time 0.217310    
2023-04-18 02:14:00,534 - Epoch: [391][  350/  518]    Overall Loss 2.823033    Objective Loss 2.823033                                        LR 0.000001    Time 0.217001    
2023-04-18 02:14:11,243 - Epoch: [391][  400/  518]    Overall Loss 2.822264    Objective Loss 2.822264                                        LR 0.000001    Time 0.216643    
2023-04-18 02:14:21,944 - Epoch: [391][  450/  518]    Overall Loss 2.825790    Objective Loss 2.825790                                        LR 0.000001    Time 0.216350    
2023-04-18 02:14:32,632 - Epoch: [391][  500/  518]    Overall Loss 2.825832    Objective Loss 2.825832                                        LR 0.000001    Time 0.216088    
2023-04-18 02:14:36,327 - Epoch: [391][  518/  518]    Overall Loss 2.825285    Objective Loss 2.825285                                        LR 0.000001    Time 0.215710    
2023-04-18 02:14:36,407 - --- validate (epoch=391)-----------
2023-04-18 02:14:36,407 - 4952 samples (32 per mini-batch)
2023-04-18 02:15:19,439 - Epoch: [391][   50/  155]    Loss 3.029275    mAP 0.521263    
2023-04-18 02:16:02,518 - Epoch: [391][  100/  155]    Loss 3.003926    mAP 0.538309    
2023-04-18 02:16:46,007 - Epoch: [391][  150/  155]    Loss 3.010750    mAP 0.528234    
2023-04-18 02:16:49,871 - Epoch: [391][  155/  155]    Loss 3.005233    mAP 0.527848    
2023-04-18 02:16:49,949 - ==> mAP: 0.52785    Loss: 3.005

2023-04-18 02:16:49,953 - ==> Best [mAP: 0.534820   vloss: 3.006499   Sparsity:0.00   Params: 2177088 on epoch: 365]
2023-04-18 02:16:49,953 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-18 02:16:49,989 - 

2023-04-18 02:16:49,989 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-18 02:17:01,482 - Epoch: [392][   50/  518]    Overall Loss 2.869205    Objective Loss 2.869205                                        LR 0.000001    Time 0.229807    
2023-04-18 02:17:12,237 - Epoch: [392][  100/  518]    Overall Loss 2.866357    Objective Loss 2.866357                                        LR 0.000001    Time 0.222441    
2023-04-18 02:17:22,963 - Epoch: [392][  150/  518]    Overall Loss 2.856066    Objective Loss 2.856066                                        LR 0.000001    Time 0.219788    
2023-04-18 02:17:33,849 - Epoch: [392][  200/  518]    Overall Loss 2.851557    Objective Loss 2.851557                                        LR 0.000001    Time 0.219265    
2023-04-18 02:17:44,525 - Epoch: [392][  250/  518]    Overall Loss 2.842087    Objective Loss 2.842087                                        LR 0.000001    Time 0.218108    
2023-04-18 02:17:55,289 - Epoch: [392][  300/  518]    Overall Loss 2.836249    Objective Loss 2.836249                                        LR 0.000001    Time 0.217634    
2023-04-18 02:18:06,035 - Epoch: [392][  350/  518]    Overall Loss 2.839202    Objective Loss 2.839202                                        LR 0.000001    Time 0.217240    
2023-04-18 02:18:16,780 - Epoch: [392][  400/  518]    Overall Loss 2.828061    Objective Loss 2.828061                                        LR 0.000001    Time 0.216946    
2023-04-18 02:18:27,439 - Epoch: [392][  450/  518]    Overall Loss 2.826188    Objective Loss 2.826188                                        LR 0.000001    Time 0.216522    
2023-04-18 02:18:38,109 - Epoch: [392][  500/  518]    Overall Loss 2.826061    Objective Loss 2.826061                                        LR 0.000001    Time 0.216209    
2023-04-18 02:18:41,853 - Epoch: [392][  518/  518]    Overall Loss 2.824736    Objective Loss 2.824736                                        LR 0.000001    Time 0.215922    
2023-04-18 02:18:41,937 - --- validate (epoch=392)-----------
2023-04-18 02:18:41,938 - 4952 samples (32 per mini-batch)
2023-04-18 02:19:24,601 - Epoch: [392][   50/  155]    Loss 3.030355    mAP 0.516543    
2023-04-18 02:20:07,110 - Epoch: [392][  100/  155]    Loss 3.010185    mAP 0.522625    
2023-04-18 02:20:48,932 - Epoch: [392][  150/  155]    Loss 3.002696    mAP 0.526840    
2023-04-18 02:20:52,760 - Epoch: [392][  155/  155]    Loss 3.002316    mAP 0.522388    
2023-04-18 02:20:52,835 - ==> mAP: 0.52239    Loss: 3.002

2023-04-18 02:20:52,839 - ==> Best [mAP: 0.534820   vloss: 3.006499   Sparsity:0.00   Params: 2177088 on epoch: 365]
2023-04-18 02:20:52,839 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-18 02:20:52,873 - 

2023-04-18 02:20:52,874 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-18 02:21:04,490 - Epoch: [393][   50/  518]    Overall Loss 2.818166    Objective Loss 2.818166                                        LR 0.000001    Time 0.232283    
2023-04-18 02:21:15,231 - Epoch: [393][  100/  518]    Overall Loss 2.848666    Objective Loss 2.848666                                        LR 0.000001    Time 0.223536    
2023-04-18 02:21:25,931 - Epoch: [393][  150/  518]    Overall Loss 2.836366    Objective Loss 2.836366                                        LR 0.000001    Time 0.220345    
2023-04-18 02:21:36,612 - Epoch: [393][  200/  518]    Overall Loss 2.830412    Objective Loss 2.830412                                        LR 0.000001    Time 0.218653    
2023-04-18 02:21:47,418 - Epoch: [393][  250/  518]    Overall Loss 2.813688    Objective Loss 2.813688                                        LR 0.000001    Time 0.218144    
2023-04-18 02:21:58,176 - Epoch: [393][  300/  518]    Overall Loss 2.816664    Objective Loss 2.816664                                        LR 0.000001    Time 0.217641    
2023-04-18 02:22:08,929 - Epoch: [393][  350/  518]    Overall Loss 2.821611    Objective Loss 2.821611                                        LR 0.000001    Time 0.217267    
2023-04-18 02:22:19,562 - Epoch: [393][  400/  518]    Overall Loss 2.818527    Objective Loss 2.818527                                        LR 0.000001    Time 0.216687    
2023-04-18 02:22:30,266 - Epoch: [393][  450/  518]    Overall Loss 2.825494    Objective Loss 2.825494                                        LR 0.000001    Time 0.216394    
2023-04-18 02:22:40,975 - Epoch: [393][  500/  518]    Overall Loss 2.820832    Objective Loss 2.820832                                        LR 0.000001    Time 0.216170    
2023-04-18 02:22:44,703 - Epoch: [393][  518/  518]    Overall Loss 2.820548    Objective Loss 2.820548                                        LR 0.000001    Time 0.215854    
2023-04-18 02:22:44,783 - --- validate (epoch=393)-----------
2023-04-18 02:22:44,783 - 4952 samples (32 per mini-batch)
2023-04-18 02:23:26,447 - Epoch: [393][   50/  155]    Loss 3.038738    mAP 0.502304    
2023-04-18 02:24:08,553 - Epoch: [393][  100/  155]    Loss 3.014205    mAP 0.517449    
2023-04-18 02:24:51,868 - Epoch: [393][  150/  155]    Loss 3.001617    mAP 0.519413    
2023-04-18 02:24:55,097 - Epoch: [393][  155/  155]    Loss 2.999631    mAP 0.519568    
2023-04-18 02:24:55,176 - ==> mAP: 0.51957    Loss: 3.000

2023-04-18 02:24:55,180 - ==> Best [mAP: 0.534820   vloss: 3.006499   Sparsity:0.00   Params: 2177088 on epoch: 365]
2023-04-18 02:24:55,180 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-18 02:24:55,214 - 

2023-04-18 02:24:55,215 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-18 02:25:06,913 - Epoch: [394][   50/  518]    Overall Loss 2.819128    Objective Loss 2.819128                                        LR 0.000001    Time 0.233914    
2023-04-18 02:25:17,655 - Epoch: [394][  100/  518]    Overall Loss 2.832597    Objective Loss 2.832597                                        LR 0.000001    Time 0.224364    
2023-04-18 02:25:28,288 - Epoch: [394][  150/  518]    Overall Loss 2.822554    Objective Loss 2.822554                                        LR 0.000001    Time 0.220450    
2023-04-18 02:25:38,907 - Epoch: [394][  200/  518]    Overall Loss 2.824097    Objective Loss 2.824097                                        LR 0.000001    Time 0.218429    
2023-04-18 02:25:49,614 - Epoch: [394][  250/  518]    Overall Loss 2.830415    Objective Loss 2.830415                                        LR 0.000001    Time 0.217562    
2023-04-18 02:26:00,282 - Epoch: [394][  300/  518]    Overall Loss 2.832668    Objective Loss 2.832668                                        LR 0.000001    Time 0.216856    
2023-04-18 02:26:10,998 - Epoch: [394][  350/  518]    Overall Loss 2.830724    Objective Loss 2.830724                                        LR 0.000001    Time 0.216492    
2023-04-18 02:26:21,647 - Epoch: [394][  400/  518]    Overall Loss 2.825478    Objective Loss 2.825478                                        LR 0.000001    Time 0.216049    
2023-04-18 02:26:32,340 - Epoch: [394][  450/  518]    Overall Loss 2.827977    Objective Loss 2.827977                                        LR 0.000001    Time 0.215803    
2023-04-18 02:26:43,113 - Epoch: [394][  500/  518]    Overall Loss 2.826660    Objective Loss 2.826660                                        LR 0.000001    Time 0.215764    
2023-04-18 02:26:46,786 - Epoch: [394][  518/  518]    Overall Loss 2.825074    Objective Loss 2.825074                                        LR 0.000001    Time 0.215356    
2023-04-18 02:26:46,865 - --- validate (epoch=394)-----------
2023-04-18 02:26:46,866 - 4952 samples (32 per mini-batch)
2023-04-18 02:27:28,649 - Epoch: [394][   50/  155]    Loss 2.995018    mAP 0.529948    
2023-04-18 02:28:10,372 - Epoch: [394][  100/  155]    Loss 3.008741    mAP 0.526544    
2023-04-18 02:28:52,196 - Epoch: [394][  150/  155]    Loss 3.005165    mAP 0.527358    
2023-04-18 02:28:56,396 - Epoch: [394][  155/  155]    Loss 3.006553    mAP 0.526961    
2023-04-18 02:28:56,470 - ==> mAP: 0.52696    Loss: 3.007

2023-04-18 02:28:56,474 - ==> Best [mAP: 0.534820   vloss: 3.006499   Sparsity:0.00   Params: 2177088 on epoch: 365]
2023-04-18 02:28:56,474 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-18 02:28:56,508 - 

2023-04-18 02:28:56,509 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-18 02:29:08,066 - Epoch: [395][   50/  518]    Overall Loss 2.812573    Objective Loss 2.812573                                        LR 0.000001    Time 0.231101    
2023-04-18 02:29:18,717 - Epoch: [395][  100/  518]    Overall Loss 2.820450    Objective Loss 2.820450                                        LR 0.000001    Time 0.222041    
2023-04-18 02:29:29,372 - Epoch: [395][  150/  518]    Overall Loss 2.812680    Objective Loss 2.812680                                        LR 0.000001    Time 0.219049    
2023-04-18 02:29:40,025 - Epoch: [395][  200/  518]    Overall Loss 2.820616    Objective Loss 2.820616                                        LR 0.000001    Time 0.217545    
2023-04-18 02:29:50,798 - Epoch: [395][  250/  518]    Overall Loss 2.812703    Objective Loss 2.812703                                        LR 0.000001    Time 0.217125    
2023-04-18 02:30:01,544 - Epoch: [395][  300/  518]    Overall Loss 2.815813    Objective Loss 2.815813                                        LR 0.000001    Time 0.216752    
2023-04-18 02:30:12,233 - Epoch: [395][  350/  518]    Overall Loss 2.817112    Objective Loss 2.817112                                        LR 0.000001    Time 0.216324    
2023-04-18 02:30:22,911 - Epoch: [395][  400/  518]    Overall Loss 2.819882    Objective Loss 2.819882                                        LR 0.000001    Time 0.215974    
2023-04-18 02:30:33,660 - Epoch: [395][  450/  518]    Overall Loss 2.821741    Objective Loss 2.821741                                        LR 0.000001    Time 0.215860    
2023-04-18 02:30:44,340 - Epoch: [395][  500/  518]    Overall Loss 2.817833    Objective Loss 2.817833                                        LR 0.000001    Time 0.215631    
2023-04-18 02:30:48,005 - Epoch: [395][  518/  518]    Overall Loss 2.817879    Objective Loss 2.817879                                        LR 0.000001    Time 0.215213    
2023-04-18 02:30:48,084 - --- validate (epoch=395)-----------
2023-04-18 02:30:48,084 - 4952 samples (32 per mini-batch)
2023-04-18 02:31:29,629 - Epoch: [395][   50/  155]    Loss 3.024868    mAP 0.530364    
2023-04-18 02:32:10,416 - Epoch: [395][  100/  155]    Loss 3.011341    mAP 0.534338    
2023-04-18 02:32:51,395 - Epoch: [395][  150/  155]    Loss 2.998242    mAP 0.535386    
2023-04-18 02:32:55,649 - Epoch: [395][  155/  155]    Loss 2.998958    mAP 0.535118    
2023-04-18 02:32:55,734 - ==> mAP: 0.53512    Loss: 2.999

2023-04-18 02:32:55,739 - ==> Best [mAP: 0.535118   vloss: 2.998958   Sparsity:0.00   Params: 2177088 on epoch: 395]
2023-04-18 02:32:55,739 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-18 02:32:55,788 - 

2023-04-18 02:32:55,788 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-18 02:33:07,461 - Epoch: [396][   50/  518]    Overall Loss 2.859264    Objective Loss 2.859264                                        LR 0.000001    Time 0.233412    
2023-04-18 02:33:18,187 - Epoch: [396][  100/  518]    Overall Loss 2.852687    Objective Loss 2.852687                                        LR 0.000001    Time 0.223944    
2023-04-18 02:33:28,864 - Epoch: [396][  150/  518]    Overall Loss 2.853098    Objective Loss 2.853098                                        LR 0.000001    Time 0.220469    
2023-04-18 02:33:39,510 - Epoch: [396][  200/  518]    Overall Loss 2.847631    Objective Loss 2.847631                                        LR 0.000001    Time 0.218576    
2023-04-18 02:33:50,227 - Epoch: [396][  250/  518]    Overall Loss 2.845575    Objective Loss 2.845575                                        LR 0.000001    Time 0.217722    
2023-04-18 02:34:00,911 - Epoch: [396][  300/  518]    Overall Loss 2.847148    Objective Loss 2.847148                                        LR 0.000001    Time 0.217044    
2023-04-18 02:34:11,678 - Epoch: [396][  350/  518]    Overall Loss 2.849311    Objective Loss 2.849311                                        LR 0.000001    Time 0.216794    
2023-04-18 02:34:22,496 - Epoch: [396][  400/  518]    Overall Loss 2.845300    Objective Loss 2.845300                                        LR 0.000001    Time 0.216736    
2023-04-18 02:34:33,066 - Epoch: [396][  450/  518]    Overall Loss 2.835916    Objective Loss 2.835916                                        LR 0.000001    Time 0.216140    
2023-04-18 02:34:43,783 - Epoch: [396][  500/  518]    Overall Loss 2.830960    Objective Loss 2.830960                                        LR 0.000001    Time 0.215957    
2023-04-18 02:34:47,481 - Epoch: [396][  518/  518]    Overall Loss 2.833602    Objective Loss 2.833602                                        LR 0.000001    Time 0.215592    
2023-04-18 02:34:47,562 - --- validate (epoch=396)-----------
2023-04-18 02:34:47,562 - 4952 samples (32 per mini-batch)
2023-04-18 02:35:30,717 - Epoch: [396][   50/  155]    Loss 3.047419    mAP 0.518064    
2023-04-18 02:36:13,075 - Epoch: [396][  100/  155]    Loss 3.019125    mAP 0.518009    
2023-04-18 02:36:55,064 - Epoch: [396][  150/  155]    Loss 3.006554    mAP 0.525105    
2023-04-18 02:36:59,415 - Epoch: [396][  155/  155]    Loss 3.006498    mAP 0.523045    
2023-04-18 02:36:59,518 - ==> mAP: 0.52304    Loss: 3.006

2023-04-18 02:36:59,522 - ==> Best [mAP: 0.535118   vloss: 2.998958   Sparsity:0.00   Params: 2177088 on epoch: 395]
2023-04-18 02:36:59,522 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-18 02:36:59,556 - 

2023-04-18 02:36:59,556 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-18 02:37:10,846 - Epoch: [397][   50/  518]    Overall Loss 2.843666    Objective Loss 2.843666                                        LR 0.000001    Time 0.225748    
2023-04-18 02:37:21,519 - Epoch: [397][  100/  518]    Overall Loss 2.845455    Objective Loss 2.845455                                        LR 0.000001    Time 0.219592    
2023-04-18 02:37:32,165 - Epoch: [397][  150/  518]    Overall Loss 2.845207    Objective Loss 2.845207                                        LR 0.000001    Time 0.217358    
2023-04-18 02:37:42,901 - Epoch: [397][  200/  518]    Overall Loss 2.845346    Objective Loss 2.845346                                        LR 0.000001    Time 0.216688    
2023-04-18 02:37:53,585 - Epoch: [397][  250/  518]    Overall Loss 2.837018    Objective Loss 2.837018                                        LR 0.000001    Time 0.216080    
2023-04-18 02:38:04,342 - Epoch: [397][  300/  518]    Overall Loss 2.832118    Objective Loss 2.832118                                        LR 0.000001    Time 0.215921    
2023-04-18 02:38:15,068 - Epoch: [397][  350/  518]    Overall Loss 2.829132    Objective Loss 2.829132                                        LR 0.000001    Time 0.215717    
2023-04-18 02:38:25,759 - Epoch: [397][  400/  518]    Overall Loss 2.823974    Objective Loss 2.823974                                        LR 0.000001    Time 0.215474    
2023-04-18 02:38:36,503 - Epoch: [397][  450/  518]    Overall Loss 2.822862    Objective Loss 2.822862                                        LR 0.000001    Time 0.215404    
2023-04-18 02:38:47,225 - Epoch: [397][  500/  518]    Overall Loss 2.823255    Objective Loss 2.823255                                        LR 0.000001    Time 0.215306    
2023-04-18 02:38:50,893 - Epoch: [397][  518/  518]    Overall Loss 2.821810    Objective Loss 2.821810                                        LR 0.000001    Time 0.214904    
2023-04-18 02:38:50,975 - --- validate (epoch=397)-----------
2023-04-18 02:38:50,976 - 4952 samples (32 per mini-batch)
2023-04-18 02:39:34,556 - Epoch: [397][   50/  155]    Loss 3.005583    mAP 0.526267    
2023-04-18 02:40:18,810 - Epoch: [397][  100/  155]    Loss 3.007035    mAP 0.522532    
2023-04-18 02:41:00,657 - Epoch: [397][  150/  155]    Loss 2.999383    mAP 0.524763    
2023-04-18 02:41:04,408 - Epoch: [397][  155/  155]    Loss 3.001893    mAP 0.522781    
2023-04-18 02:41:04,512 - ==> mAP: 0.52278    Loss: 3.002

2023-04-18 02:41:04,516 - ==> Best [mAP: 0.535118   vloss: 2.998958   Sparsity:0.00   Params: 2177088 on epoch: 395]
2023-04-18 02:41:04,516 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-18 02:41:04,552 - 

2023-04-18 02:41:04,552 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-18 02:41:16,083 - Epoch: [398][   50/  518]    Overall Loss 2.779500    Objective Loss 2.779500                                        LR 0.000001    Time 0.230570    
2023-04-18 02:41:26,778 - Epoch: [398][  100/  518]    Overall Loss 2.817496    Objective Loss 2.817496                                        LR 0.000001    Time 0.222215    
2023-04-18 02:41:37,511 - Epoch: [398][  150/  518]    Overall Loss 2.806735    Objective Loss 2.806735                                        LR 0.000001    Time 0.219689    
2023-04-18 02:41:48,175 - Epoch: [398][  200/  518]    Overall Loss 2.811883    Objective Loss 2.811883                                        LR 0.000001    Time 0.218079    
2023-04-18 02:41:58,879 - Epoch: [398][  250/  518]    Overall Loss 2.812979    Objective Loss 2.812979                                        LR 0.000001    Time 0.217270    
2023-04-18 02:42:09,525 - Epoch: [398][  300/  518]    Overall Loss 2.823885    Objective Loss 2.823885                                        LR 0.000001    Time 0.216542    
2023-04-18 02:42:20,285 - Epoch: [398][  350/  518]    Overall Loss 2.821275    Objective Loss 2.821275                                        LR 0.000001    Time 0.216345    
2023-04-18 02:42:31,045 - Epoch: [398][  400/  518]    Overall Loss 2.825068    Objective Loss 2.825068                                        LR 0.000001    Time 0.216197    
2023-04-18 02:42:41,687 - Epoch: [398][  450/  518]    Overall Loss 2.826926    Objective Loss 2.826926                                        LR 0.000001    Time 0.215822    
2023-04-18 02:42:52,460 - Epoch: [398][  500/  518]    Overall Loss 2.826933    Objective Loss 2.826933                                        LR 0.000001    Time 0.215782    
2023-04-18 02:42:56,167 - Epoch: [398][  518/  518]    Overall Loss 2.827813    Objective Loss 2.827813                                        LR 0.000001    Time 0.215439    
2023-04-18 02:42:56,248 - --- validate (epoch=398)-----------
2023-04-18 02:42:56,248 - 4952 samples (32 per mini-batch)
2023-04-18 02:43:39,637 - Epoch: [398][   50/  155]    Loss 3.022628    mAP 0.517477    
2023-04-18 02:44:21,680 - Epoch: [398][  100/  155]    Loss 3.002972    mAP 0.526642    
2023-04-18 02:45:04,250 - Epoch: [398][  150/  155]    Loss 3.003498    mAP 0.527246    
2023-04-18 02:45:07,862 - Epoch: [398][  155/  155]    Loss 3.000252    mAP 0.528401    
2023-04-18 02:45:07,935 - ==> mAP: 0.52840    Loss: 3.000

2023-04-18 02:45:07,939 - ==> Best [mAP: 0.535118   vloss: 2.998958   Sparsity:0.00   Params: 2177088 on epoch: 395]
2023-04-18 02:45:07,939 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-18 02:45:07,973 - 

2023-04-18 02:45:07,973 - Training epoch: 16551 samples (32 per mini-batch)
2023-04-18 02:45:19,429 - Epoch: [399][   50/  518]    Overall Loss 2.869278    Objective Loss 2.869278                                        LR 0.000001    Time 0.229063    
2023-04-18 02:45:30,083 - Epoch: [399][  100/  518]    Overall Loss 2.862607    Objective Loss 2.862607                                        LR 0.000001    Time 0.221058    
2023-04-18 02:45:40,756 - Epoch: [399][  150/  518]    Overall Loss 2.833317    Objective Loss 2.833317                                        LR 0.000001    Time 0.218515    
2023-04-18 02:45:51,399 - Epoch: [399][  200/  518]    Overall Loss 2.829925    Objective Loss 2.829925                                        LR 0.000001    Time 0.217095    
2023-04-18 02:46:02,116 - Epoch: [399][  250/  518]    Overall Loss 2.831091    Objective Loss 2.831091                                        LR 0.000001    Time 0.216536    
2023-04-18 02:46:12,785 - Epoch: [399][  300/  518]    Overall Loss 2.829507    Objective Loss 2.829507                                        LR 0.000001    Time 0.216004    
2023-04-18 02:46:23,455 - Epoch: [399][  350/  518]    Overall Loss 2.833230    Objective Loss 2.833230                                        LR 0.000001    Time 0.215630    
2023-04-18 02:46:34,141 - Epoch: [399][  400/  518]    Overall Loss 2.831887    Objective Loss 2.831887                                        LR 0.000001    Time 0.215386    
2023-04-18 02:46:44,864 - Epoch: [399][  450/  518]    Overall Loss 2.836719    Objective Loss 2.836719                                        LR 0.000001    Time 0.215282    
2023-04-18 02:46:55,573 - Epoch: [399][  500/  518]    Overall Loss 2.837861    Objective Loss 2.837861                                        LR 0.000001    Time 0.215167    
2023-04-18 02:46:59,243 - Epoch: [399][  518/  518]    Overall Loss 2.833854    Objective Loss 2.833854                                        LR 0.000001    Time 0.214775    
2023-04-18 02:46:59,323 - --- validate (epoch=399)-----------
2023-04-18 02:46:59,323 - 4952 samples (32 per mini-batch)
2023-04-18 02:47:42,419 - Epoch: [399][   50/  155]    Loss 2.996597    mAP 0.530421    
2023-04-18 02:48:26,159 - Epoch: [399][  100/  155]    Loss 2.987955    mAP 0.530118    
2023-04-18 02:49:08,719 - Epoch: [399][  150/  155]    Loss 3.005549    mAP 0.535845    
2023-04-18 02:49:12,757 - Epoch: [399][  155/  155]    Loss 3.005650    mAP 0.533132    
2023-04-18 02:49:12,832 - ==> mAP: 0.53313    Loss: 3.006

2023-04-18 02:49:12,836 - ==> Best [mAP: 0.535118   vloss: 2.998958   Sparsity:0.00   Params: 2177088 on epoch: 395]
2023-04-18 02:49:12,836 - Saving checkpoint to: logs/2023.04.16-224243/qat_checkpoint.pth.tar
2023-04-18 02:49:12,871 - --- test ---------------------
2023-04-18 02:49:12,872 - 4952 samples (32 per mini-batch)
2023-04-18 02:49:55,374 - Test: [   50/  155]    Loss 2.984912    mAP 0.530977    
2023-04-18 02:50:39,267 - Test: [  100/  155]    Loss 3.001256    mAP 0.520208    
2023-04-18 02:51:22,348 - Test: [  150/  155]    Loss 3.009883    mAP 0.518930    
2023-04-18 02:51:26,186 - Test: [  155/  155]    Loss 3.006834    mAP 0.518636    
2023-04-18 02:51:26,266 - ==> mAP: 0.51864    Loss: 3.007

2023-04-18 02:51:26,268 - 
2023-04-18 02:51:26,269 - Log file for this run: /home/seldauyanik/Workspace/ai8x-training/logs/2023.04.16-224243/2023.04.16-224243.log
